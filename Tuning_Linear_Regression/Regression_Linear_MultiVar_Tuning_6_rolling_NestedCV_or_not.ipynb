{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Tuning\n",
    "    Find the best approach for training: Rolling Nested CV or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\maria\\anaconda3\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from pandas) (1.18.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from python-dateutil>=2.6.1->pandas) (1.14.0)\n",
      "Requirement already satisfied: sklearn in c:\\users\\maria\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\maria\\anaconda3\\lib\\site-packages (from sklearn) (0.22.1)\n",
      "Requirement already satisfied: scipy>=0.17.0 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.4.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (0.14.1)\n",
      "Requirement already satisfied: numpy>=1.11.0 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.18.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install sklearn\n",
    "\n",
    "import pandas as pd;\n",
    "import numpy as np;\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler;\n",
    "from sklearn import metrics;\n",
    "from sklearn.model_selection import TimeSeriesSplit;\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# empty list to append metric values\n",
    "mae_gen = []\n",
    "mse_gen  =[]\n",
    "rmse_gen = []\n",
    "mae_nor = []\n",
    "mae_spi = []\n",
    "mse_nor = []\n",
    "mse_spi = []\n",
    "rmse_nor = []\n",
    "rmse_spi = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data set processing (fixed test set (2 months)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:6245: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "# data\n",
    "data = pd.read_csv('Data_set_1_smaller.csv', index_col = 0)\n",
    "data = data.loc[data.index > 2018110000, :]\n",
    "    \n",
    "# reset index\n",
    "data.reset_index(inplace = True)\n",
    "data.drop('index', axis = 1, inplace = True)\n",
    "    \n",
    "# Divide features and labels\n",
    "X = data.iloc[:, 0:15]\n",
    "y = data.loc[:, 'Offers']\n",
    "\n",
    "X.fillna(X.mean(), inplace = True)\n",
    "y.fillna(y.mean(), inplace = True)\n",
    "    \n",
    "X = X.astype('float64')\n",
    "X = X.round(20)\n",
    "    \n",
    "# divide data into train and test with 15% test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "             X, y, test_size = 0.15, shuffle = False)\n",
    "    \n",
    "# feature scaling\n",
    "sc_X = MinMaxScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)\n",
    "    \n",
    "# create time series split for CV\n",
    "splits = 4\n",
    "tscv = TimeSeriesSplit(n_splits = splits)\n",
    "    \n",
    "# create linear regressor \n",
    "regressor = LinearRegression()\n",
    "    \n",
    "for train_index, test_index in tscv.split(X_train):\n",
    "    X_train_split, X_test_split = X_train[train_index], X_train[test_index]\n",
    "    y_train_split, y_test_split = y_train[train_index], y_train[test_index]\n",
    "    regressor.fit(X_train_split, y_train_split)\n",
    "    \n",
    "# predict for X_test  \n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "\n",
    "rmse_error = mse(y_test, y_pred, squared = False)\n",
    "mse_error = mse(y_test, y_pred) # 1479.61335\n",
    "mae_error = mae(y_test, y_pred) # 23.1525\n",
    "    \n",
    "rmse_gen.append(rmse_error)\n",
    "mse_gen.append(mse_error)\n",
    "mae_gen.append(mae_error)\n",
    "    \n",
    "# =============================================================================\n",
    "# Metrics evaluation on spike regions\n",
    "# =============================================================================\n",
    "    \n",
    "y_spike_occ = pd.read_csv('Spike_binary_1std.csv', usecols = [6])\n",
    "    \n",
    "# create array same size as y_test\n",
    "y_spike_occ = y_spike_occ.iloc[- len(y_test):]\n",
    "y_spike_occ = pd.Series(y_spike_occ.iloc[:,0]).values\n",
    "    \n",
    "# smal adjustment\n",
    "y_test.replace(0, 0.0001,inplace = True)\n",
    "\n",
    "# select y_pred and y_test only for regions with spikes\n",
    "y_test_spike = (y_test.T * y_spike_occ).T\n",
    "y_pred_spike = (y_pred.T * y_spike_occ).T\n",
    "y_test_spike = y_test_spike[y_test_spike != 0]\n",
    "y_pred_spike = y_pred_spike[y_pred_spike != 0]\n",
    "    \n",
    "# calculate metric\n",
    "rmse_spike = mse(y_test_spike, y_pred_spike, squared = False)\n",
    "mse_spike = mse(y_test_spike, y_pred_spike)\n",
    "mae_spike = mae(y_test_spike, y_pred_spike)\n",
    "    \n",
    "rmse_spi.append(rmse_spike)\n",
    "mse_spi.append(mse_spike)\n",
    "mae_spi.append(mae_spike)\n",
    "    \n",
    "# =============================================================================\n",
    "# Metric evaluation on normal regions\n",
    "# =============================================================================\n",
    "    \n",
    "# inverse y_spike_occ so the only normal occurences are chosen\n",
    "y_normal_occ = (y_spike_occ - 1) * (-1)\n",
    "    \n",
    "# sanity check\n",
    "y_normal_occ.sum() + y_spike_occ.sum() # gives the correct total \n",
    "    \n",
    "# select y_pred and y_test only for normal regions\n",
    "y_test_normal = (y_test.T * y_normal_occ).T\n",
    "y_pred_normal = (y_pred.T * y_normal_occ).T\n",
    "y_test_normal = y_test_normal[y_test_normal != 0.00]\n",
    "y_pred_normal = y_pred_normal[y_pred_normal != 0.00]\n",
    "    \n",
    "# calculate metric\n",
    "rmse_normal = mse(y_test_normal, y_pred_normal, squared = False)\n",
    "mse_normal = mse(y_test_normal, y_pred_normal)\n",
    "mae_normal = mae(y_test_normal, y_pred_normal)\n",
    "    \n",
    "rmse_nor.append(rmse_normal)\n",
    "mse_nor.append(mse_normal)\n",
    "mae_nor.append(mae_normal)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing (moving Nested CV):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:6245: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "# data\n",
    "data = pd.read_csv('Data_set_1_smaller.csv', index_col = 0)\n",
    "data = data.loc[data.index > 2017010000, :]\n",
    "    \n",
    "# reset index\n",
    "data.reset_index(inplace = True)\n",
    "data.drop('index', axis = 1, inplace = True)\n",
    "    \n",
    "# Divide features and labels\n",
    "X = data.iloc[:, 0:15]\n",
    "y = data.loc[:, 'Offers']\n",
    "\n",
    "X.fillna(X.mean(), inplace = True)\n",
    "y.fillna(y.mean(), inplace = True)\n",
    "    \n",
    "X = X.astype('float64')\n",
    "X = X.round(20)\n",
    "    \n",
    "# divide data into train and test with 15% test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "             X, y, test_size = 0.15, shuffle = False)\n",
    "    \n",
    "# feature scaling\n",
    "sc_X = MinMaxScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)\n",
    "    \n",
    "# create time series split for CV\n",
    "splits = 4\n",
    "# 2 * 48 * 0.85 * 30.5 = 2489\n",
    "tscv = TimeSeriesSplit(n_splits = splits, max_train_size = 2489)\n",
    "    \n",
    "# create linear regressor \n",
    "regressor = LinearRegression()\n",
    "    \n",
    "for train_index, test_index in tscv.split(X_train):\n",
    "    X_train_split, X_test_split = X_train[train_index], X_train[test_index]\n",
    "    y_train_split, y_test_split = y_train[train_index], y_train[test_index]\n",
    "    regressor.fit(X_train_split, y_train_split)\n",
    "    \n",
    "# predict for X_test  \n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "\n",
    "rmse_error = mse(y_test, y_pred, squared = False)\n",
    "mse_error = mse(y_test, y_pred) # 1479.61335\n",
    "mae_error = mae(y_test, y_pred) # 23.1525\n",
    "    \n",
    "rmse_gen.append(rmse_error)\n",
    "mse_gen.append(mse_error)\n",
    "mae_gen.append(mae_error)\n",
    "    \n",
    "# =============================================================================\n",
    "# Metrics evaluation on spike regions\n",
    "# =============================================================================\n",
    "    \n",
    "y_spike_occ = pd.read_csv('Spike_binary_1std.csv', usecols = [6])\n",
    "    \n",
    "# create array same size as y_test\n",
    "y_spike_occ = y_spike_occ.iloc[- len(y_test):]\n",
    "y_spike_occ = pd.Series(y_spike_occ.iloc[:,0]).values\n",
    "    \n",
    "# smal adjustment\n",
    "y_test.replace(0, 0.0001,inplace = True)\n",
    "\n",
    "# select y_pred and y_test only for regions with spikes\n",
    "y_test_spike = (y_test.T * y_spike_occ).T\n",
    "y_pred_spike = (y_pred.T * y_spike_occ).T\n",
    "y_test_spike = y_test_spike[y_test_spike != 0]\n",
    "y_pred_spike = y_pred_spike[y_pred_spike != 0]\n",
    "    \n",
    "# calculate metric\n",
    "rmse_spike = mse(y_test_spike, y_pred_spike, squared = False)\n",
    "mse_spike = mse(y_test_spike, y_pred_spike)\n",
    "mae_spike = mae(y_test_spike, y_pred_spike)\n",
    "    \n",
    "rmse_spi.append(rmse_spike)\n",
    "mse_spi.append(mse_spike)\n",
    "mae_spi.append(mae_spike)\n",
    "    \n",
    "# =============================================================================\n",
    "# Metric evaluation on normal regions\n",
    "# =============================================================================\n",
    "    \n",
    "# inverse y_spike_occ so the only normal occurences are chosen\n",
    "y_normal_occ = (y_spike_occ - 1) * (-1)\n",
    "    \n",
    "# sanity check\n",
    "y_normal_occ.sum() + y_spike_occ.sum() # gives the correct total \n",
    "    \n",
    "# select y_pred and y_test only for normal regions\n",
    "y_test_normal = (y_test.T * y_normal_occ).T\n",
    "y_pred_normal = (y_pred.T * y_normal_occ).T\n",
    "y_test_normal = y_test_normal[y_test_normal != 0.00]\n",
    "y_pred_normal = y_pred_normal[y_pred_normal != 0.00]\n",
    "    \n",
    "# calculate metric\n",
    "rmse_normal = mse(y_test_normal, y_pred_normal, squared = False)\n",
    "mse_normal = mse(y_test_normal, y_pred_normal)\n",
    "mae_normal = mae(y_test_normal, y_pred_normal)\n",
    "    \n",
    "rmse_nor.append(rmse_normal)\n",
    "mse_nor.append(mse_normal)\n",
    "mae_nor.append(mae_normal)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse_general</th>\n",
       "      <th>mae_general</th>\n",
       "      <th>rmse_spike</th>\n",
       "      <th>mae_spike</th>\n",
       "      <th>rmse_normal</th>\n",
       "      <th>mae_normal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30.829045</td>\n",
       "      <td>22.178709</td>\n",
       "      <td>63.543469</td>\n",
       "      <td>51.004364</td>\n",
       "      <td>20.844857</td>\n",
       "      <td>17.361690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>426.678705</td>\n",
       "      <td>39.057183</td>\n",
       "      <td>544.102755</td>\n",
       "      <td>94.714823</td>\n",
       "      <td>397.613160</td>\n",
       "      <td>27.359341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rmse_general  mae_general  rmse_spike  mae_spike  rmse_normal  mae_normal\n",
       "0     30.829045    22.178709   63.543469  51.004364    20.844857   17.361690\n",
       "1    426.678705    39.057183  544.102755  94.714823   397.613160   27.359341"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({                       \n",
    "                        'rmse_general': rmse_gen, \n",
    "                 \n",
    "                        'mae_general': mae_gen,\n",
    "                        \n",
    "                        'rmse_spike': rmse_spi,\n",
    "                 \n",
    "                        'mae_spike': mae_spi,\n",
    "                        \n",
    "                        'rmse_normal': rmse_nor,\n",
    "                    \n",
    "                        'mae_normal': mae_nor})\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_50c05278_caa2_11ea_914d_7cb27da2bf47row0_col0 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_50c05278_caa2_11ea_914d_7cb27da2bf47row0_col1 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_50c05278_caa2_11ea_914d_7cb27da2bf47row0_col2 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_50c05278_caa2_11ea_914d_7cb27da2bf47row0_col3 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_50c05278_caa2_11ea_914d_7cb27da2bf47row0_col4 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_50c05278_caa2_11ea_914d_7cb27da2bf47row0_col5 {\n",
       "            background-color:  yellow;\n",
       "        }</style><table id=\"T_50c05278_caa2_11ea_914d_7cb27da2bf47\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >rmse_general</th>        <th class=\"col_heading level0 col1\" >mae_general</th>        <th class=\"col_heading level0 col2\" >rmse_spike</th>        <th class=\"col_heading level0 col3\" >mae_spike</th>        <th class=\"col_heading level0 col4\" >rmse_normal</th>        <th class=\"col_heading level0 col5\" >mae_normal</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_50c05278_caa2_11ea_914d_7cb27da2bf47level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_50c05278_caa2_11ea_914d_7cb27da2bf47row0_col0\" class=\"data row0 col0\" >30.829045</td>\n",
       "                        <td id=\"T_50c05278_caa2_11ea_914d_7cb27da2bf47row0_col1\" class=\"data row0 col1\" >22.178709</td>\n",
       "                        <td id=\"T_50c05278_caa2_11ea_914d_7cb27da2bf47row0_col2\" class=\"data row0 col2\" >63.543469</td>\n",
       "                        <td id=\"T_50c05278_caa2_11ea_914d_7cb27da2bf47row0_col3\" class=\"data row0 col3\" >51.004364</td>\n",
       "                        <td id=\"T_50c05278_caa2_11ea_914d_7cb27da2bf47row0_col4\" class=\"data row0 col4\" >20.844857</td>\n",
       "                        <td id=\"T_50c05278_caa2_11ea_914d_7cb27da2bf47row0_col5\" class=\"data row0 col5\" >17.361690</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_50c05278_caa2_11ea_914d_7cb27da2bf47level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_50c05278_caa2_11ea_914d_7cb27da2bf47row1_col0\" class=\"data row1 col0\" >426.678705</td>\n",
       "                        <td id=\"T_50c05278_caa2_11ea_914d_7cb27da2bf47row1_col1\" class=\"data row1 col1\" >39.057183</td>\n",
       "                        <td id=\"T_50c05278_caa2_11ea_914d_7cb27da2bf47row1_col2\" class=\"data row1 col2\" >544.102755</td>\n",
       "                        <td id=\"T_50c05278_caa2_11ea_914d_7cb27da2bf47row1_col3\" class=\"data row1 col3\" >94.714823</td>\n",
       "                        <td id=\"T_50c05278_caa2_11ea_914d_7cb27da2bf47row1_col4\" class=\"data row1 col4\" >397.613160</td>\n",
       "                        <td id=\"T_50c05278_caa2_11ea_914d_7cb27da2bf47row1_col5\" class=\"data row1 col5\" >27.359341</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1e618b4afc8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def highlight_min(s):\n",
    "    '''\n",
    "    highlight the maximum in a Series yellow.\n",
    "    '''\n",
    "    is_max = s == s.min()\n",
    "    return ['background-color: yellow' if v else '' for v in is_max]\n",
    "\n",
    "results.style.apply(highlight_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
