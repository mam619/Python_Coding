{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Parameter Tunning with MinMax\n",
    "    \n",
    "    GridSearchCV for: hidden layers with previous parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages (1.0.5)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages (from pandas) (2020.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages (from pandas) (1.18.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas) (1.14.0)\n",
      "Requirement already satisfied: sklearn in /home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages (from sklearn) (0.23.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages (from scikit-learn->sklearn) (0.16.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.4.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.18.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install sklearn\n",
    "\n",
    "import pandas as pd;\n",
    "import numpy as np;\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split, cross_validate, cross_val_predict;\n",
    "from sklearn.preprocessing import MinMaxScaler;\n",
    "from sklearn import metrics;\n",
    "from sklearn.model_selection import TimeSeriesSplit;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data; set X and y; fill nan values and split in test and training  data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/pandas/core/generic.py:6245: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "# import data\n",
    "data = pd.read_csv('Data_set_1_smaller.csv', index_col = 0)\n",
    "\n",
    "# filter max values for offer if required\n",
    "print(data.Offers.max()) #max is 2500... no need to filter max values\n",
    "\n",
    "# 2017 & 2018 data\n",
    "data = data.loc[data.index > 2018060000, :]\n",
    "\n",
    "# reset index\n",
    "data.reset_index(inplace = True)\n",
    "data.drop('index', axis = 1, inplace = True)\n",
    "\n",
    "# Divide features and labels\n",
    "X = data.iloc[:, 0:15]\n",
    "y = data.loc[:, 'Offers']\n",
    "\n",
    "# Fill nan values (BEFORE OR AFTER TEST, TRAIN SPLIT!!!)\n",
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "X.fillna(X.mean(), inplace = True)\n",
    "y.fillna(y.mean(), inplace = True)\n",
    "\n",
    "X = X.astype('float64')\n",
    "X = X.round(20)\n",
    "\n",
    "# divide data into train and test with 20% test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "         X, y, test_size=0.1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply feature scaling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_X = MinMaxScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the Keras libraries and packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential # to initialise the NN\n",
    "from keras.layers import Dense # to create layers\n",
    "from keras.layers import Dropout\n",
    "import keras.optimizers\n",
    "from keras import initializers\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create regressor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# possible debug\n",
    "X_train = np.nan_to_num(X_train)\n",
    "X_test = np.nan_to_num(X_test)\n",
    "\n",
    "def regressor_tunning(n_hidden, n_neurons = 30, optimizer = 'RMSprop', kernel_initializer=\"he_normal\",\n",
    "    bias_initializer= initializers.Ones()):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(output_dim = n_neurons, \n",
    "                    input_dim = 15))\n",
    "    model.add(keras.layers.LeakyReLU(alpha = 0.2))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(Dense(n_neurons))\n",
    "        model.add(keras.layers.LeakyReLU(alpha = 0.2))\n",
    "    model.add(Dense(output_dim = 1, \n",
    "                    activation = 'linear'))\n",
    "    model.compile(loss = 'mse', optimizer = optimizer, metrics = ['mse', 'mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Randomized tunning for the whole ANN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=30)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9246/9246 [==============================] - 2s 164us/step - loss: 4777.0344 - mse: 4777.0312 - mae: 47.6443\n",
      "Epoch 2/100\n",
      "9246/9246 [==============================] - 1s 96us/step - loss: 1838.7513 - mse: 1838.7515 - mae: 25.5932\n",
      "Epoch 3/100\n",
      "9246/9246 [==============================] - 1s 100us/step - loss: 1821.0258 - mse: 1821.0264 - mae: 25.4586\n",
      "Epoch 4/100\n",
      "9246/9246 [==============================] - 1s 93us/step - loss: 1818.1903 - mse: 1818.1923 - mae: 25.3388\n",
      "Epoch 5/100\n",
      "9246/9246 [==============================] - 1s 95us/step - loss: 1809.1127 - mse: 1809.1124 - mae: 25.3181\n",
      "Epoch 6/100\n",
      "9246/9246 [==============================] - 1s 94us/step - loss: 1801.5916 - mse: 1801.5907 - mae: 25.2337\n",
      "Epoch 7/100\n",
      "9246/9246 [==============================] - 1s 97us/step - loss: 1798.8296 - mse: 1798.8297 - mae: 25.1654\n",
      "Epoch 8/100\n",
      "9246/9246 [==============================] - 1s 96us/step - loss: 1796.8371 - mse: 1796.8373 - mae: 25.1555\n",
      "Epoch 9/100\n",
      "9246/9246 [==============================] - 1s 90us/step - loss: 1791.6617 - mse: 1791.6627 - mae: 25.0844\n",
      "Epoch 10/100\n",
      "9246/9246 [==============================] - 1s 91us/step - loss: 1791.1207 - mse: 1791.1211 - mae: 25.0514\n",
      "Epoch 11/100\n",
      "9246/9246 [==============================] - 1s 100us/step - loss: 1787.7088 - mse: 1787.7091 - mae: 24.9326\n",
      "Epoch 12/100\n",
      "9246/9246 [==============================] - 1s 99us/step - loss: 1784.2708 - mse: 1784.2708 - mae: 24.9066\n",
      "Epoch 13/100\n",
      "9246/9246 [==============================] - 1s 101us/step - loss: 1784.6446 - mse: 1784.6442 - mae: 24.9204\n",
      "Epoch 14/100\n",
      "9246/9246 [==============================] - 1s 95us/step - loss: 1783.6241 - mse: 1783.6232 - mae: 24.9121\n",
      "Epoch 15/100\n",
      "9246/9246 [==============================] - 1s 106us/step - loss: 1779.2838 - mse: 1779.2832 - mae: 24.8956\n",
      "Epoch 16/100\n",
      "9246/9246 [==============================] - 1s 98us/step - loss: 1780.9489 - mse: 1780.9497 - mae: 24.8885\n",
      "Epoch 17/100\n",
      "9246/9246 [==============================] - 1s 96us/step - loss: 1779.9913 - mse: 1779.9915 - mae: 24.8689\n",
      "Epoch 18/100\n",
      "9246/9246 [==============================] - 1s 105us/step - loss: 1779.9446 - mse: 1779.9446 - mae: 24.8802\n",
      "Epoch 19/100\n",
      "9246/9246 [==============================] - 1s 102us/step - loss: 1777.3126 - mse: 1777.3126 - mae: 24.8343\n",
      "Epoch 20/100\n",
      "9246/9246 [==============================] - 1s 98us/step - loss: 1777.3627 - mse: 1777.3630 - mae: 24.7795\n",
      "Epoch 21/100\n",
      "9246/9246 [==============================] - 1s 106us/step - loss: 1778.3770 - mse: 1778.3767 - mae: 24.8172\n",
      "Epoch 22/100\n",
      "9246/9246 [==============================] - 1s 116us/step - loss: 1777.0101 - mse: 1777.0101 - mae: 24.7938\n",
      "Epoch 23/100\n",
      "9246/9246 [==============================] - 1s 100us/step - loss: 1773.7426 - mse: 1773.7428 - mae: 24.7765\n",
      "Epoch 24/100\n",
      "9246/9246 [==============================] - 1s 108us/step - loss: 1775.8267 - mse: 1775.8273 - mae: 24.7776\n",
      "Epoch 25/100\n",
      "9246/9246 [==============================] - 1s 93us/step - loss: 1775.7189 - mse: 1775.7190 - mae: 24.7784\n",
      "Epoch 26/100\n",
      "9246/9246 [==============================] - 1s 93us/step - loss: 1774.4784 - mse: 1774.4788 - mae: 24.7891\n",
      "Epoch 27/100\n",
      "9246/9246 [==============================] - 1s 96us/step - loss: 1776.6142 - mse: 1776.6140 - mae: 24.7249\n",
      "Epoch 28/100\n",
      "9246/9246 [==============================] - 1s 91us/step - loss: 1772.7324 - mse: 1772.7322 - mae: 24.7354\n",
      "Epoch 29/100\n",
      "9246/9246 [==============================] - 1s 95us/step - loss: 1774.5428 - mse: 1774.5422 - mae: 24.7423\n",
      "Epoch 30/100\n",
      "9246/9246 [==============================] - 1s 94us/step - loss: 1772.9076 - mse: 1772.9076 - mae: 24.7021\n",
      "Epoch 31/100\n",
      "9246/9246 [==============================] - 1s 95us/step - loss: 1774.5119 - mse: 1774.5114 - mae: 24.7637\n",
      "Epoch 32/100\n",
      "9246/9246 [==============================] - 1s 95us/step - loss: 1773.8747 - mse: 1773.8743 - mae: 24.7400\n",
      "Epoch 33/100\n",
      "9246/9246 [==============================] - 1s 100us/step - loss: 1773.6275 - mse: 1773.6274 - mae: 24.7075\n",
      "Epoch 34/100\n",
      "9246/9246 [==============================] - 1s 96us/step - loss: 1772.8741 - mse: 1772.8746 - mae: 24.7191\n",
      "Epoch 35/100\n",
      "9246/9246 [==============================] - 1s 95us/step - loss: 1773.6179 - mse: 1773.6174 - mae: 24.7420\n",
      "Epoch 36/100\n",
      "9246/9246 [==============================] - 1s 93us/step - loss: 1773.1863 - mse: 1773.1857 - mae: 24.6983\n",
      "Epoch 37/100\n",
      "9246/9246 [==============================] - 1s 91us/step - loss: 1775.1394 - mse: 1775.1392 - mae: 24.6502\n",
      "Epoch 38/100\n",
      "9246/9246 [==============================] - 1s 106us/step - loss: 1767.8240 - mse: 1767.8237 - mae: 24.6366\n",
      "Epoch 39/100\n",
      "9246/9246 [==============================] - 1s 102us/step - loss: 1772.1553 - mse: 1772.1555 - mae: 24.7111\n",
      "Epoch 40/100\n",
      "9246/9246 [==============================] - 1s 98us/step - loss: 1771.9660 - mse: 1771.9662 - mae: 24.6966\n",
      "Epoch 41/100\n",
      "9246/9246 [==============================] - 1s 95us/step - loss: 1771.8042 - mse: 1771.8044 - mae: 24.6970\n",
      "Epoch 42/100\n",
      "9246/9246 [==============================] - 1s 97us/step - loss: 1770.6459 - mse: 1770.6455 - mae: 24.6879\n",
      "Epoch 43/100\n",
      "9246/9246 [==============================] - 1s 97us/step - loss: 1769.6502 - mse: 1769.6504 - mae: 24.7233\n",
      "Epoch 44/100\n",
      "9246/9246 [==============================] - 1s 105us/step - loss: 1770.2667 - mse: 1770.2666 - mae: 24.7078\n",
      "Epoch 45/100\n",
      "9246/9246 [==============================] - 1s 94us/step - loss: 1770.1530 - mse: 1770.1528 - mae: 24.6215\n",
      "Epoch 46/100\n",
      "9246/9246 [==============================] - 1s 96us/step - loss: 1770.3683 - mse: 1770.3678 - mae: 24.6725\n",
      "Epoch 47/100\n",
      "9246/9246 [==============================] - 1s 103us/step - loss: 1770.0938 - mse: 1770.0931 - mae: 24.5888\n",
      "Epoch 48/100\n",
      "9246/9246 [==============================] - 1s 91us/step - loss: 1769.4146 - mse: 1769.4154 - mae: 24.7048\n",
      "Epoch 49/100\n",
      "9246/9246 [==============================] - 1s 95us/step - loss: 1769.0802 - mse: 1769.0802 - mae: 24.6465\n",
      "Epoch 50/100\n",
      "9246/9246 [==============================] - 1s 94us/step - loss: 1768.4493 - mse: 1768.4498 - mae: 24.6853\n",
      "Epoch 51/100\n",
      "9246/9246 [==============================] - 1s 93us/step - loss: 1770.2315 - mse: 1770.2316 - mae: 24.6528\n",
      "Epoch 52/100\n",
      "9246/9246 [==============================] - 1s 94us/step - loss: 1769.2525 - mse: 1769.2529 - mae: 24.6226\n",
      "Epoch 53/100\n",
      "9246/9246 [==============================] - 1s 94us/step - loss: 1767.3014 - mse: 1767.3013 - mae: 24.6410\n",
      "Epoch 54/100\n",
      "9246/9246 [==============================] - 1s 99us/step - loss: 1766.7696 - mse: 1766.7697 - mae: 24.6476\n",
      "Epoch 55/100\n",
      "9246/9246 [==============================] - 1s 92us/step - loss: 1766.5846 - mse: 1766.5845 - mae: 24.5960\n",
      "Epoch 56/100\n",
      "9246/9246 [==============================] - 1s 111us/step - loss: 1767.6282 - mse: 1767.6284 - mae: 24.6393\n",
      "Epoch 57/100\n",
      "9246/9246 [==============================] - 1s 130us/step - loss: 1767.7192 - mse: 1767.7196 - mae: 24.6372\n",
      "Epoch 58/100\n",
      "9246/9246 [==============================] - 1s 107us/step - loss: 1766.1815 - mse: 1766.1816 - mae: 24.6594\n",
      "Epoch 59/100\n",
      "9246/9246 [==============================] - 1s 90us/step - loss: 1767.1617 - mse: 1767.1619 - mae: 24.6555\n",
      "Epoch 60/100\n",
      "9246/9246 [==============================] - 1s 96us/step - loss: 1768.1695 - mse: 1768.1685 - mae: 24.5837\n",
      "Epoch 61/100\n",
      "9246/9246 [==============================] - 1s 93us/step - loss: 1766.3086 - mse: 1766.3074 - mae: 24.6076\n",
      "Epoch 62/100\n",
      "9246/9246 [==============================] - 1s 93us/step - loss: 1767.7948 - mse: 1767.7952 - mae: 24.5664\n",
      "Epoch 63/100\n",
      "9246/9246 [==============================] - 1s 97us/step - loss: 1765.6069 - mse: 1765.6067 - mae: 24.5888\n",
      "Epoch 64/100\n",
      "9246/9246 [==============================] - 1s 93us/step - loss: 1765.0725 - mse: 1765.0730 - mae: 24.7087\n",
      "Epoch 65/100\n",
      "9246/9246 [==============================] - 1s 92us/step - loss: 1763.1038 - mse: 1763.1033 - mae: 24.6095\n",
      "Epoch 66/100\n",
      "9246/9246 [==============================] - 1s 104us/step - loss: 1760.8756 - mse: 1760.8762 - mae: 24.5847\n",
      "Epoch 67/100\n",
      "9246/9246 [==============================] - 1s 107us/step - loss: 1760.8807 - mse: 1760.8802 - mae: 24.5560\n",
      "Epoch 68/100\n",
      "9246/9246 [==============================] - 1s 103us/step - loss: 1763.6151 - mse: 1763.6154 - mae: 24.5860\n",
      "Epoch 69/100\n",
      "9246/9246 [==============================] - 1s 99us/step - loss: 1763.1479 - mse: 1763.1484 - mae: 24.5697\n",
      "Epoch 70/100\n",
      "9246/9246 [==============================] - 1s 93us/step - loss: 1759.9877 - mse: 1759.9890 - mae: 24.5405\n",
      "Epoch 71/100\n",
      "9246/9246 [==============================] - 1s 96us/step - loss: 1763.4222 - mse: 1763.4220 - mae: 24.5819\n",
      "Epoch 72/100\n",
      "9246/9246 [==============================] - 1s 95us/step - loss: 1762.1952 - mse: 1762.1953 - mae: 24.5739\n",
      "Epoch 73/100\n",
      "9246/9246 [==============================] - 1s 93us/step - loss: 1764.0215 - mse: 1764.0223 - mae: 24.5947\n",
      "Epoch 74/100\n",
      "9246/9246 [==============================] - 1s 105us/step - loss: 1762.9754 - mse: 1762.9756 - mae: 24.5326\n",
      "Epoch 75/100\n",
      "9246/9246 [==============================] - 1s 108us/step - loss: 1760.9530 - mse: 1760.9531 - mae: 24.5301\n",
      "Epoch 76/100\n",
      "9246/9246 [==============================] - 1s 103us/step - loss: 1761.5366 - mse: 1761.5377 - mae: 24.6506\n",
      "Epoch 77/100\n",
      "9246/9246 [==============================] - 1s 118us/step - loss: 1759.9239 - mse: 1759.9240 - mae: 24.5246\n",
      "Epoch 78/100\n",
      "9246/9246 [==============================] - 1s 119us/step - loss: 1759.1785 - mse: 1759.1781 - mae: 24.5546\n",
      "Epoch 79/100\n",
      "9246/9246 [==============================] - 1s 110us/step - loss: 1759.3572 - mse: 1759.3574 - mae: 24.5632\n",
      "Epoch 80/100\n",
      "9246/9246 [==============================] - 1s 106us/step - loss: 1757.3900 - mse: 1757.3903 - mae: 24.5692\n",
      "Epoch 81/100\n",
      "9246/9246 [==============================] - 1s 107us/step - loss: 1759.2420 - mse: 1759.2424 - mae: 24.5258\n",
      "Epoch 82/100\n",
      "9246/9246 [==============================] - 1s 103us/step - loss: 1760.6249 - mse: 1760.6252 - mae: 24.5819\n",
      "Epoch 83/100\n",
      "9246/9246 [==============================] - 1s 104us/step - loss: 1758.5752 - mse: 1758.5753 - mae: 24.5229\n",
      "Epoch 84/100\n",
      "9246/9246 [==============================] - 1s 106us/step - loss: 1756.6867 - mse: 1756.6863 - mae: 24.5543\n",
      "Epoch 85/100\n",
      "9246/9246 [==============================] - 1s 109us/step - loss: 1756.1659 - mse: 1756.1654 - mae: 24.5384\n",
      "Epoch 86/100\n",
      "9246/9246 [==============================] - 1s 106us/step - loss: 1755.8254 - mse: 1755.8252 - mae: 24.5200\n",
      "Epoch 87/100\n",
      "9246/9246 [==============================] - 1s 105us/step - loss: 1756.6628 - mse: 1756.6631 - mae: 24.5151\n",
      "Epoch 88/100\n",
      "9246/9246 [==============================] - 1s 101us/step - loss: 1755.2639 - mse: 1755.2633 - mae: 24.4688\n",
      "Epoch 89/100\n",
      "9246/9246 [==============================] - 1s 103us/step - loss: 1753.2200 - mse: 1753.2202 - mae: 24.4603\n",
      "Epoch 90/100\n",
      "9246/9246 [==============================] - 1s 118us/step - loss: 1751.8775 - mse: 1751.8781 - mae: 24.5624\n",
      "Epoch 91/100\n",
      "9246/9246 [==============================] - 1s 105us/step - loss: 1754.4995 - mse: 1754.4999 - mae: 24.4375\n",
      "Epoch 92/100\n",
      "9246/9246 [==============================] - 1s 103us/step - loss: 1751.3316 - mse: 1751.3315 - mae: 24.4604\n",
      "Epoch 93/100\n",
      "9246/9246 [==============================] - 1s 103us/step - loss: 1750.1857 - mse: 1750.1852 - mae: 24.4987\n",
      "Epoch 94/100\n",
      "9246/9246 [==============================] - 1s 103us/step - loss: 1750.1252 - mse: 1750.1256 - mae: 24.4565\n",
      "Epoch 95/100\n",
      "9246/9246 [==============================] - 1s 104us/step - loss: 1752.1098 - mse: 1752.1102 - mae: 24.5036\n",
      "Epoch 96/100\n",
      "9246/9246 [==============================] - 1s 99us/step - loss: 1748.2105 - mse: 1748.2100 - mae: 24.4238\n",
      "Epoch 97/100\n",
      "9246/9246 [==============================] - 1s 104us/step - loss: 1748.4661 - mse: 1748.4664 - mae: 24.4912\n",
      "Epoch 98/100\n",
      "9246/9246 [==============================] - 1s 105us/step - loss: 1748.9721 - mse: 1748.9722 - mae: 24.4043\n",
      "Epoch 99/100\n",
      "9246/9246 [==============================] - 1s 104us/step - loss: 1747.0962 - mse: 1747.0961 - mae: 24.4092\n",
      "Epoch 100/100\n",
      "9246/9246 [==============================] - 1s 100us/step - loss: 1748.2558 - mse: 1748.2557 - mae: 24.4107\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=TimeSeriesSplit(max_train_size=None, n_splits=6),\n",
       "             estimator=<keras.wrappers.scikit_learn.KerasRegressor object at 0x7fba6b842950>,\n",
       "             n_jobs=-1, param_grid={'n_hidden': [1, 2, 3, 4, 5, 6]},\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor = KerasRegressor(build_fn = regressor_tunning)\n",
    "\n",
    "# Dictionary to include the parameters\n",
    "parameters = {'n_hidden': [1, 2, 3, 4, 5, 6]\n",
    "               }\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits = 6)\n",
    "\n",
    "# add some early stopping\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='mse', patience = 15)\n",
    "\n",
    "rnd_search_cv = GridSearchCV(estimator = regressor,\n",
    "                                   param_grid = parameters,\n",
    "                                   scoring = 'neg_mean_squared_error',\n",
    "                                   n_jobs = -1,\n",
    "                                   cv = tscv)\n",
    "\n",
    "# checkpoints:\n",
    "# early_stopping_cb = keras.callbacks.EarlyStopping(patience = 10, restore_best_weights = True)\n",
    "# checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\")\n",
    "\n",
    "rnd_search_cv.fit(X_train, y_train, batch_size = 20, epochs = 100, callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# with batch of 32 and 100 epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the best parameters are:{'n_hidden': 2}\n",
      "the best score is:-1954.5657673868488\n"
     ]
    }
   ],
   "source": [
    "best_params_1 = rnd_search_cv.best_params_\n",
    "best_score_1 = rnd_search_cv.best_score_\n",
    "\n",
    "print(\"the best parameters are:{}\".format(best_params_1))\n",
    "print(\"the best score is:{}\".format(best_score_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([37.21530068, 35.11886628, 50.00599865, 57.52494407, 62.28967369,\n",
      "       55.27675267]), 'std_fit_time': array([16.47540748, 12.8374057 , 27.55469417, 30.69671894, 27.02199113,\n",
      "       18.2099514 ]), 'mean_score_time': array([0.09623369, 0.10681558, 0.12273228, 0.14138965, 0.15728744,\n",
      "       0.14577214]), 'std_score_time': array([0.0050506 , 0.00678777, 0.00617301, 0.00900352, 0.01967463,\n",
      "       0.02759429]), 'param_n_hidden': masked_array(data=[1, 2, 3, 4, 5, 6],\n",
      "             mask=[False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'n_hidden': 1}, {'n_hidden': 2}, {'n_hidden': 3}, {'n_hidden': 4}, {'n_hidden': 5}, {'n_hidden': 6}], 'split0_test_score': array([-1122.49696713, -1119.84323883, -1149.43128488, -1143.12986462,\n",
      "       -1156.02197316, -1110.42217023]), 'split1_test_score': array([-1775.84807139, -1782.27676771, -1771.8059906 , -1844.70528206,\n",
      "       -1760.96782862, -2164.94725847]), 'split2_test_score': array([-2783.15965204, -2796.16525747, -2887.29586297, -2869.20594367,\n",
      "       -2948.8275655 , -3116.05642889]), 'split3_test_score': array([-1480.56933156, -1407.50466352, -1417.6421548 , -1488.77202657,\n",
      "       -1417.69735925, -1402.04402211]), 'split4_test_score': array([-2706.96692059, -2729.50057325, -2844.54819263, -3494.22703472,\n",
      "       -3153.084629  , -3735.00799094]), 'split5_test_score': array([-1882.06699634, -1892.10410353, -1843.33882711, -2169.29341191,\n",
      "       -2029.67342232, -2030.34727949]), 'mean_test_score': array([-1958.51798984, -1954.56576739, -1985.67705217, -2168.22226059,\n",
      "       -2077.71212964, -2259.80419169]), 'std_test_score': array([606.46362859, 624.29108661, 663.14248659, 802.78662675,\n",
      "       741.96080605, 915.41192869]), 'rank_test_score': array([2, 1, 3, 5, 4, 6], dtype=int32)}\n"
     ]
    }
   ],
   "source": [
    "results_cv = rnd_search_cv.cv_results_\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# with batch of 20 and 100 epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the best parameters are:{'n_hidden': 2}\n",
      "the best score is:-1954.5657673868488\n"
     ]
    }
   ],
   "source": [
    "best_params_1 = rnd_search_cv.best_params_\n",
    "best_score_1 = rnd_search_cv.best_score_\n",
    "\n",
    "print(\"the best parameters are:{}\".format(best_params_1))\n",
    "print(\"the best score is:{}\".format(best_score_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
