{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression LSTM with best parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\maria\\anaconda3\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from pandas) (1.18.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from python-dateutil>=2.6.1->pandas) (1.14.0)\n",
      "Requirement already satisfied: sklearn in c:\\users\\maria\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\maria\\anaconda3\\lib\\site-packages (from sklearn) (0.22.1)\n",
      "Requirement already satisfied: numpy>=1.11.0 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.18.1)\n",
      "Requirement already satisfied: scipy>=0.17.0 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.4.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (0.14.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\maria\\anaconda3\\lib\\site-packages (3.1.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.11 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from matplotlib) (1.18.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from matplotlib) (2.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\maria\\anaconda3\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib) (45.2.0.post20200210)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from python-dateutil>=2.1->matplotlib) (1.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install sklearn\n",
    "!pip install matplotlib\n",
    "\n",
    "import pandas as pd;\n",
    "import numpy as np;\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "date =  [2018010000, \n",
    "         2018030000, \n",
    "         2018050000,\n",
    "         2018070000,\n",
    "         2018090000,\n",
    "         2018110000]\n",
    "\n",
    "# parameters\n",
    "steps = 48\n",
    "n_hidden = 2\n",
    "units = 100\n",
    "batch_size = 48\n",
    "epochs = 100\n",
    "features_num = 14\n",
    "\n",
    "# lists to append results\n",
    "mae_gen = []\n",
    "mae_nor = []\n",
    "mae_spi = []\n",
    "rmse_gen = []\n",
    "rmse_nor = []\n",
    "rmse_spi = []\n",
    "y_pred_list = []\n",
    "time_count = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import keras libraries, packages and data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LeakyReLU\n",
    "from keras import initializers\n",
    "from keras import optimizers\n",
    "\n",
    "# import data\n",
    "data_full = pd.read_csv('Data_set_1_smaller_(1).csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create loop for different dates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n",
      "C:\\Users\\maria\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:6245: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "279/279 [==============================] - 29s 105ms/step - loss: 0.0649 - mse: 0.0649 - mae: 0.1577\n",
      "Epoch 2/100\n",
      "279/279 [==============================] - 28s 102ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0279\n",
      "Epoch 3/100\n",
      "279/279 [==============================] - 29s 105ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0212\n",
      "Epoch 4/100\n",
      "279/279 [==============================] - 28s 99ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0201\n",
      "Epoch 5/100\n",
      "279/279 [==============================] - 28s 101ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0196\n",
      "Epoch 6/100\n",
      "279/279 [==============================] - 28s 101ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0192\n",
      "Epoch 7/100\n",
      "279/279 [==============================] - 28s 100ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0189\n",
      "Epoch 8/100\n",
      "279/279 [==============================] - 28s 99ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0187\n",
      "Epoch 9/100\n",
      "279/279 [==============================] - 27s 95ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0186\n",
      "Epoch 10/100\n",
      "279/279 [==============================] - 26s 92ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0184 1s - loss: 0.0012 - mse:\n",
      "Epoch 11/100\n",
      "279/279 [==============================] - 28s 101ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0182\n",
      "Epoch 12/100\n",
      "279/279 [==============================] - 28s 99ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0180\n",
      "Epoch 13/100\n",
      "279/279 [==============================] - 29s 103ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0178\n",
      "Epoch 14/100\n",
      "279/279 [==============================] - 27s 98ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0177\n",
      "Epoch 15/100\n",
      "279/279 [==============================] - 28s 101ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0176\n",
      "Epoch 16/100\n",
      "279/279 [==============================] - 28s 100ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0172\n",
      "Epoch 17/100\n",
      "279/279 [==============================] - 26s 94ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0171\n",
      "Epoch 18/100\n",
      "279/279 [==============================] - 26s 93ms/step - loss: 9.7649e-04 - mse: 9.7649e-04 - mae: 0.0170 3s - loss: 9.771\n",
      "Epoch 19/100\n",
      "279/279 [==============================] - 26s 94ms/step - loss: 9.5754e-04 - mse: 9.5754e-04 - mae: 0.0169\n",
      "Epoch 20/100\n",
      "279/279 [==============================] - 26s 94ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0169\n",
      "Epoch 21/100\n",
      "279/279 [==============================] - 26s 93ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0171\n",
      "Epoch 22/100\n",
      "279/279 [==============================] - 26s 93ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0169\n",
      "Epoch 23/100\n",
      "279/279 [==============================] - 26s 92ms/step - loss: 9.6103e-04 - mse: 9.6103e-04 - mae: 0.0167\n",
      "Epoch 24/100\n",
      "279/279 [==============================] - 26s 94ms/step - loss: 9.7656e-04 - mse: 9.7656e-04 - mae: 0.0165\n",
      "Epoch 25/100\n",
      "279/279 [==============================] - 26s 93ms/step - loss: 8.6997e-04 - mse: 8.6997e-04 - mae: 0.0164 1s - loss: 8.9672e-04 - mse: 8.96\n",
      "Epoch 26/100\n",
      "279/279 [==============================] - 26s 94ms/step - loss: 9.6711e-04 - mse: 9.6711e-04 - mae: 0.0169\n",
      "Epoch 27/100\n",
      "279/279 [==============================] - 27s 96ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0168\n",
      "Epoch 28/100\n",
      "279/279 [==============================] - 26s 92ms/step - loss: 9.0843e-04 - mse: 9.0843e-04 - mae: 0.0166\n",
      "Epoch 29/100\n",
      "279/279 [==============================] - 28s 101ms/step - loss: 8.9433e-04 - mse: 8.9433e-04 - mae: 0.0165\n",
      "Epoch 30/100\n",
      "279/279 [==============================] - 28s 100ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0167\n",
      "Epoch 31/100\n",
      "279/279 [==============================] - 26s 93ms/step - loss: 9.9484e-04 - mse: 9.9484e-04 - mae: 0.0166ss: 0.0010 - mse: 0.0010 - ETA: 2s - loss: 9.7323e-04 - mse\n",
      "Epoch 32/100\n",
      "279/279 [==============================] - 26s 94ms/step - loss: 9.1071e-04 - mse: 9.1071e-04 - mae: 0.0165\n",
      "Epoch 33/100\n",
      "279/279 [==============================] - 25s 91ms/step - loss: 9.6974e-04 - mse: 9.6974e-04 - mae: 0.0164\n",
      "Epoch 34/100\n",
      "279/279 [==============================] - 26s 93ms/step - loss: 8.8723e-04 - mse: 8.8723e-04 - mae: 0.0165\n",
      "Epoch 35/100\n",
      "279/279 [==============================] - 26s 92ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0164\n",
      "Epoch 36/100\n",
      "279/279 [==============================] - 25s 88ms/step - loss: 8.9917e-04 - mse: 8.9917e-04 - mae: 0.0162\n",
      "Epoch 37/100\n",
      "279/279 [==============================] - 25s 89ms/step - loss: 8.7169e-04 - mse: 8.7169e-04 - mae: 0.0162\n",
      "Epoch 38/100\n",
      "279/279 [==============================] - 26s 92ms/step - loss: 9.3398e-04 - mse: 9.3398e-04 - mae: 0.0161\n",
      "Epoch 39/100\n",
      "279/279 [==============================] - 25s 89ms/step - loss: 9.2629e-04 - mse: 9.2629e-04 - mae: 0.0161\n",
      "Epoch 40/100\n",
      "279/279 [==============================] - 25s 90ms/step - loss: 9.6531e-04 - mse: 9.6531e-04 - mae: 0.0163\n",
      "Epoch 41/100\n",
      "279/279 [==============================] - 25s 89ms/step - loss: 9.3493e-04 - mse: 9.3493e-04 - mae: 0.0161\n",
      "Epoch 42/100\n",
      "279/279 [==============================] - 25s 91ms/step - loss: 9.1180e-04 - mse: 9.1180e-04 - mae: 0.0160\n",
      "Epoch 43/100\n",
      "279/279 [==============================] - ETA: 0s - loss: 8.9890e-04 - mse: 8.9890e-04 - mae: 0.016 - 27s 96ms/step - loss: 8.9890e-04 - mse: 8.9890e-04 - mae: 0.0163\n",
      "Epoch 44/100\n",
      "279/279 [==============================] - 26s 93ms/step - loss: 8.8612e-04 - mse: 8.8612e-04 - mae: 0.0162\n",
      "Epoch 45/100\n",
      "279/279 [==============================] - 25s 89ms/step - loss: 8.7872e-04 - mse: 8.7872e-04 - mae: 0.0160 2s - loss: 8.5237e-04 - mse\n",
      "Epoch 46/100\n",
      "279/279 [==============================] - 26s 94ms/step - loss: 8.6433e-04 - mse: 8.6433e-04 - mae: 0.0161\n",
      "Epoch 47/100\n",
      "279/279 [==============================] - 26s 92ms/step - loss: 9.6919e-04 - mse: 9.6919e-04 - mae: 0.0163\n",
      "Epoch 48/100\n",
      "279/279 [==============================] - 24s 88ms/step - loss: 9.2918e-04 - mse: 9.2918e-04 - mae: 0.0162 0s - loss: 9.4239e-04 - mse: 9.4239e-04 - mae:\n",
      "Epoch 49/100\n",
      "279/279 [==============================] - 25s 89ms/step - loss: 8.4965e-04 - mse: 8.4965e-04 - mae: 0.0158 2s - loss: 8.2824e-\n",
      "Epoch 50/100\n",
      "279/279 [==============================] - 26s 93ms/step - loss: 8.8684e-04 - mse: 8.8684e-04 - mae: 0.0160\n",
      "Epoch 51/100\n",
      "279/279 [==============================] - 26s 92ms/step - loss: 9.0583e-04 - mse: 9.0583e-04 - mae: 0.0160\n",
      "Epoch 52/100\n",
      "279/279 [==============================] - 26s 95ms/step - loss: 7.8108e-04 - mse: 7.8108e-04 - mae: 0.0159 2s - loss: 7.4633e-04 - m\n",
      "Epoch 53/100\n",
      "279/279 [==============================] - 27s 97ms/step - loss: 8.7067e-04 - mse: 8.7067e-04 - mae: 0.0161\n",
      "Epoch 54/100\n",
      "279/279 [==============================] - 25s 90ms/step - loss: 8.7467e-04 - mse: 8.7467e-04 - mae: 0.0159 - loss: 0.0011 - mse: 0.0011 - mae - ETA: 4s \n",
      "Epoch 55/100\n",
      "279/279 [==============================] - 25s 90ms/step - loss: 8.8193e-04 - mse: 8.8193e-04 - mae: 0.0160\n",
      "Epoch 56/100\n",
      "279/279 [==============================] - 25s 91ms/step - loss: 8.5027e-04 - mse: 8.5027e-04 - mae: 0.0159 3s - loss: 8.3301e-\n",
      "Epoch 57/100\n",
      "279/279 [==============================] - 25s 89ms/step - loss: 9.0016e-04 - mse: 9.0016e-04 - mae: 0.0159\n",
      "Epoch 58/100\n",
      "279/279 [==============================] - 26s 92ms/step - loss: 7.9972e-04 - mse: 7.9972e-04 - mae: 0.0157\n",
      "Epoch 59/100\n",
      "279/279 [==============================] - 25s 90ms/step - loss: 8.7580e-04 - mse: 8.7580e-04 - mae: 0.0159\n",
      "Epoch 60/100\n",
      "279/279 [==============================] - 25s 90ms/step - loss: 8.3900e-04 - mse: 8.3900e-04 - mae: 0.0161\n",
      "Epoch 61/100\n",
      "279/279 [==============================] - 26s 92ms/step - loss: 8.2663e-04 - mse: 8.2663e-04 - mae: 0.0157\n",
      "Epoch 62/100\n",
      "279/279 [==============================] - 26s 93ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0164\n",
      "Epoch 63/100\n",
      "279/279 [==============================] - 26s 93ms/step - loss: 8.3367e-04 - mse: 8.3366e-04 - mae: 0.0156\n",
      "Epoch 64/100\n",
      "279/279 [==============================] - 26s 91ms/step - loss: 7.4308e-04 - mse: 7.4308e-04 - mae: 0.0156\n",
      "Epoch 65/100\n",
      "279/279 [==============================] - 26s 94ms/step - loss: 8.6994e-04 - mse: 8.6994e-04 - mae: 0.0157\n",
      "Epoch 66/100\n",
      "279/279 [==============================] - 27s 97ms/step - loss: 7.1151e-04 - mse: 7.1151e-04 - mae: 0.0157\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279/279 [==============================] - 25s 91ms/step - loss: 7.8849e-04 - mse: 7.8849e-04 - mae: 0.0156\n",
      "Epoch 68/100\n",
      "279/279 [==============================] - 25s 91ms/step - loss: 8.5174e-04 - mse: 8.5174e-04 - mae: 0.0156\n",
      "Epoch 69/100\n",
      "279/279 [==============================] - 25s 90ms/step - loss: 6.7093e-04 - mse: 6.7093e-04 - mae: 0.0154\n",
      "Epoch 70/100\n",
      "279/279 [==============================] - 25s 89ms/step - loss: 7.5679e-04 - mse: 7.5679e-04 - mae: 0.0156\n",
      "Epoch 71/100\n",
      "279/279 [==============================] - 25s 91ms/step - loss: 9.2386e-04 - mse: 9.2386e-04 - mae: 0.0161\n",
      "Epoch 72/100\n",
      "279/279 [==============================] - 25s 89ms/step - loss: 7.5676e-04 - mse: 7.5676e-04 - mae: 0.0154 1s - loss: 7.8318e-04 - mse: 7.83\n",
      "Epoch 73/100\n",
      "279/279 [==============================] - 25s 91ms/step - loss: 7.6773e-04 - mse: 7.6773e-04 - mae: 0.0156\n",
      "Epoch 74/100\n",
      "279/279 [==============================] - 25s 91ms/step - loss: 7.2673e-04 - mse: 7.2673e-04 - mae: 0.0153\n",
      "Epoch 75/100\n",
      "279/279 [==============================] - 25s 91ms/step - loss: 7.8754e-04 - mse: 7.8754e-04 - mae: 0.0155\n",
      "Epoch 76/100\n",
      "279/279 [==============================] - 27s 95ms/step - loss: 6.7024e-04 - mse: 6.7024e-04 - mae: 0.0153\n",
      "Epoch 77/100\n",
      "279/279 [==============================] - 26s 93ms/step - loss: 6.8891e-04 - mse: 6.8891e-04 - mae: 0.0153\n",
      "Epoch 78/100\n",
      "279/279 [==============================] - 25s 90ms/step - loss: 8.4765e-04 - mse: 8.4765e-04 - mae: 0.0158\n",
      "Epoch 79/100\n",
      "279/279 [==============================] - 25s 90ms/step - loss: 6.9294e-04 - mse: 6.9294e-04 - mae: 0.0153\n",
      "Epoch 80/100\n",
      "279/279 [==============================] - 25s 89ms/step - loss: 7.7828e-04 - mse: 7.7828e-04 - mae: 0.0156\n",
      "Epoch 81/100\n",
      "279/279 [==============================] - 26s 92ms/step - loss: 6.4491e-04 - mse: 6.4491e-04 - mae: 0.0151\n",
      "Epoch 82/100\n",
      "279/279 [==============================] - 26s 92ms/step - loss: 6.6092e-04 - mse: 6.6092e-04 - mae: 0.0152\n",
      "Epoch 83/100\n",
      "279/279 [==============================] - 25s 90ms/step - loss: 6.4585e-04 - mse: 6.4585e-04 - mae: 0.0150\n",
      "Epoch 84/100\n",
      "279/279 [==============================] - 26s 92ms/step - loss: 6.5050e-04 - mse: 6.5050e-04 - mae: 0.0150\n",
      "Epoch 85/100\n",
      "279/279 [==============================] - 25s 91ms/step - loss: 7.0374e-04 - mse: 7.0374e-04 - mae: 0.0153\n",
      "Epoch 86/100\n",
      "279/279 [==============================] - 25s 91ms/step - loss: 6.5447e-04 - mse: 6.5447e-04 - mae: 0.0150\n",
      "Epoch 87/100\n",
      "279/279 [==============================] - 25s 90ms/step - loss: 6.2396e-04 - mse: 6.2396e-04 - mae: 0.0148\n",
      "Epoch 88/100\n",
      "279/279 [==============================] - 25s 90ms/step - loss: 7.5604e-04 - mse: 7.5604e-04 - mae: 0.0151\n",
      "Epoch 89/100\n",
      "279/279 [==============================] - 26s 92ms/step - loss: 6.6910e-04 - mse: 6.6910e-04 - mae: 0.0150 3s - loss: \n",
      "Epoch 90/100\n",
      "279/279 [==============================] - 25s 89ms/step - loss: 6.6879e-04 - mse: 6.6879e-04 - mae: 0.0150\n",
      "Epoch 91/100\n",
      "279/279 [==============================] - 25s 91ms/step - loss: 7.7290e-04 - mse: 7.7290e-04 - mae: 0.0153\n",
      "Epoch 92/100\n",
      "279/279 [==============================] - 25s 91ms/step - loss: 7.3058e-04 - mse: 7.3058e-04 - mae: 0.0152\n",
      "Epoch 93/100\n",
      "279/279 [==============================] - 25s 89ms/step - loss: 6.6906e-04 - mse: 6.6906e-04 - mae: 0.0150\n",
      "Epoch 94/100\n",
      "279/279 [==============================] - 25s 91ms/step - loss: 7.1187e-04 - mse: 7.1187e-04 - mae: 0.0151\n",
      "Epoch 95/100\n",
      "279/279 [==============================] - 25s 90ms/step - loss: 8.0146e-04 - mse: 8.0146e-04 - mae: 0.0155\n",
      "Epoch 96/100\n",
      "279/279 [==============================] - 25s 90ms/step - loss: 6.0804e-04 - mse: 6.0804e-04 - mae: 0.0146\n",
      "Epoch 97/100\n",
      "279/279 [==============================] - 27s 95ms/step - loss: 6.9300e-04 - mse: 6.9300e-04 - mae: 0.0152\n",
      "Epoch 98/100\n",
      "279/279 [==============================] - 26s 93ms/step - loss: 7.9195e-04 - mse: 7.9195e-04 - mae: 0.0153\n",
      "Epoch 99/100\n",
      "279/279 [==============================] - 27s 98ms/step - loss: 7.0131e-04 - mse: 7.0131e-04 - mae: 0.0152\n",
      "Epoch 100/100\n",
      "279/279 [==============================] - 28s 100ms/step - loss: 7.5301e-04 - mse: 7.5301e-04 - mae: 0.0153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n",
      "C:\\Users\\maria\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:6245: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "234/234 [==============================] - 21s 88ms/step - loss: 0.0802 - mse: 0.0802 - mae: 0.1953\n",
      "Epoch 2/100\n",
      "234/234 [==============================] - 21s 89ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0363\n",
      "Epoch 3/100\n",
      "234/234 [==============================] - 20s 87ms/step - loss: 9.4911e-04 - mse: 9.4911e-04 - mae: 0.0203 3s - loss:\n",
      "Epoch 4/100\n",
      "234/234 [==============================] - 20s 87ms/step - loss: 8.2767e-04 - mse: 8.2767e-04 - mae: 0.0184 6s - loss: 7.3837e-04 - mse: 7.3837e-04 - mae: 0.0 - ETA: 5s -  - ETA: 1s - loss: 8.4683e-04 - mse: 8.4\n",
      "Epoch 5/100\n",
      "234/234 [==============================] - 22s 92ms/step - loss: 7.8100e-04 - mse: 7.8100e-04 - mae: 0.0176\n",
      "Epoch 6/100\n",
      "234/234 [==============================] - 20s 84ms/step - loss: 7.5082e-04 - mse: 7.5082e-04 - mae: 0.0171\n",
      "Epoch 7/100\n",
      "234/234 [==============================] - 21s 89ms/step - loss: 7.2099e-04 - mse: 7.2099e-04 - mae: 0.0166\n",
      "Epoch 8/100\n",
      "234/234 [==============================] - 20s 87ms/step - loss: 6.9899e-04 - mse: 6.9899e-04 - mae: 0.0163\n",
      "Epoch 9/100\n",
      "234/234 [==============================] - 21s 89ms/step - loss: 6.7782e-04 - mse: 6.7782e-04 - mae: 0.0159\n",
      "Epoch 10/100\n",
      "234/234 [==============================] - 21s 89ms/step - loss: 6.6835e-04 - mse: 6.6835e-04 - mae: 0.0157\n",
      "Epoch 11/100\n",
      "234/234 [==============================] - 21s 89ms/step - loss: 6.5880e-04 - mse: 6.5880e-04 - mae: 0.0156\n",
      "Epoch 12/100\n",
      "234/234 [==============================] - 21s 91ms/step - loss: 6.5081e-04 - mse: 6.5081e-04 - mae: 0.0155 13s - loss: 7.7661e-04 - mse: 7.7661 - ETA: 12s - loss: 7.2216e-04 - mse: 7.22  - ETA: 2s - loss: 6.7739e-04 - mse\n",
      "Epoch 13/100\n",
      "234/234 [==============================] - 21s 88ms/step - loss: 6.4696e-04 - mse: 6.4696e-04 - mae: 0.0153 2s - loss: 6.6864e-04 - mse: 6\n",
      "Epoch 14/100\n",
      "234/234 [==============================] - 21s 88ms/step - loss: 6.3954e-04 - mse: 6.3954e-04 - mae: 0.0152\n",
      "Epoch 15/100\n",
      "234/234 [==============================] - 21s 89ms/step - loss: 6.3739e-04 - mse: 6.3739e-04 - mae: 0.0152\n",
      "Epoch 16/100\n",
      "234/234 [==============================] - 21s 88ms/step - loss: 6.3077e-04 - mse: 6.3077e-04 - mae: 0.0151\n",
      "Epoch 17/100\n",
      "234/234 [==============================] - 21s 90ms/step - loss: 6.3881e-04 - mse: 6.3881e-04 - mae: 0.0151\n",
      "Epoch 18/100\n",
      "234/234 [==============================] - 21s 89ms/step - loss: 6.3345e-04 - mse: 6.3345e-04 - mae: 0.0151 4s \n",
      "Epoch 19/100\n",
      "234/234 [==============================] - 20s 87ms/step - loss: 6.2638e-04 - mse: 6.2638e-04 - mae: 0.0150\n",
      "Epoch 20/100\n",
      "234/234 [==============================] - 21s 89ms/step - loss: 6.2134e-04 - mse: 6.2134e-04 - mae: 0.0149\n",
      "Epoch 21/100\n",
      "234/234 [==============================] - 21s 89ms/step - loss: 6.2134e-04 - mse: 6.2134e-04 - mae: 0.0148 2s - loss: 6.4728e-0\n",
      "Epoch 22/100\n",
      "234/234 [==============================] - 20s 86ms/step - loss: 6.2672e-04 - mse: 6.2672e-04 - mae: 0.0149 2s - loss: 6.5336e-04 - mse: 6.5336e-0 - ETA: 1s - loss: 6.4091e-04 - mse: 6.409\n",
      "Epoch 23/100\n",
      "234/234 [==============================] - 21s 89ms/step - loss: 6.2064e-04 - mse: 6.2064e-04 - mae: 0.0148\n",
      "Epoch 24/100\n",
      "234/234 [==============================] - 21s 90ms/step - loss: 6.2110e-04 - mse: 6.2110e-04 - mae: 0.0148 1s - loss: 6.3726e-04 - mse: 6.37\n",
      "Epoch 25/100\n",
      "234/234 [==============================] - 21s 88ms/step - loss: 6.1700e-04 - mse: 6.1700e-04 - mae: 0.0148\n",
      "Epoch 26/100\n",
      "234/234 [==============================] - 21s 91ms/step - loss: 6.1234e-04 - mse: 6.1234e-04 - mae: 0.0147\n",
      "Epoch 27/100\n",
      "234/234 [==============================] - 24s 100ms/step - loss: 6.0962e-04 - mse: 6.0962e-04 - mae: 0.01471s - loss: 6.1879e-04 - mse: 6.1879e-04 \n",
      "Epoch 28/100\n",
      "234/234 [==============================] - 23s 99ms/step - loss: 6.0997e-04 - mse: 6.0997e-04 - mae: 0.0147\n",
      "Epoch 29/100\n",
      "234/234 [==============================] - 22s 95ms/step - loss: 6.1376e-04 - mse: 6.1376e-04 - mae: 0.0147\n",
      "Epoch 30/100\n",
      "234/234 [==============================] - 21s 90ms/step - loss: 6.1523e-04 - mse: 6.1523e-04 - mae: 0.0147\n",
      "Epoch 31/100\n",
      "234/234 [==============================] - 21s 88ms/step - loss: 6.0579e-04 - mse: 6.0579e-04 - mae: 0.0145 4s\n",
      "Epoch 32/100\n",
      "234/234 [==============================] - 21s 90ms/step - loss: 6.0385e-04 - mse: 6.0385e-04 - mae: 0.0146\n",
      "Epoch 33/100\n",
      "234/234 [==============================] - 21s 91ms/step - loss: 6.0419e-04 - mse: 6.0419e-04 - mae: 0.0145 10s \n",
      "Epoch 34/100\n",
      "234/234 [==============================] - 21s 88ms/step - loss: 5.9873e-04 - mse: 5.9873e-04 - mae: 0.0145\n",
      "Epoch 35/100\n",
      "234/234 [==============================] - 21s 89ms/step - loss: 6.0621e-04 - mse: 6.0621e-04 - mae: 0.0145\n",
      "Epoch 36/100\n",
      "234/234 [==============================] - 21s 90ms/step - loss: 6.0526e-04 - mse: 6.0526e-04 - mae: 0.0146\n",
      "Epoch 37/100\n",
      "234/234 [==============================] - 21s 88ms/step - loss: 6.0474e-04 - mse: 6.0474e-04 - mae: 0.0145\n",
      "Epoch 38/100\n",
      "234/234 [==============================] - 21s 90ms/step - loss: 6.0518e-04 - mse: 6.0518e-04 - mae: 0.0145\n",
      "Epoch 39/100\n",
      "234/234 [==============================] - 22s 92ms/step - loss: 6.0367e-04 - mse: 6.0367e-04 - mae: 0.0145\n",
      "Epoch 40/100\n",
      "234/234 [==============================] - ETA: 0s - loss: 6.0096e-04 - mse: 6.0096e-04 - mae: 0.014 - 21s 90ms/step - loss: 6.0070e-04 - mse: 6.0070e-04 - mae: 0.0145\n",
      "Epoch 41/100\n",
      "234/234 [==============================] - 21s 90ms/step - loss: 5.9313e-04 - mse: 5.9313e-04 - mae: 0.0144 2s - loss: 6.1689e-04 - mse: 6\n",
      "Epoch 42/100\n",
      "234/234 [==============================] - 22s 93ms/step - loss: 5.9632e-04 - mse: 5.9632e-04 - mae: 0.0145\n",
      "Epoch 43/100\n",
      "234/234 [==============================] - 20s 87ms/step - loss: 5.9291e-04 - mse: 5.9291e-04 - mae: 0.0144\n",
      "Epoch 44/100\n",
      "234/234 [==============================] - 21s 90ms/step - loss: 5.9125e-04 - mse: 5.9125e-04 - mae: 0.0144\n",
      "Epoch 45/100\n",
      "234/234 [==============================] - 21s 90ms/step - loss: 5.8816e-04 - mse: 5.8816e-04 - mae: 0.0144\n",
      "Epoch 46/100\n",
      "234/234 [==============================] - 21s 90ms/step - loss: 5.9239e-04 - mse: 5.9239e-04 - mae: 0.0144\n",
      "Epoch 47/100\n",
      "234/234 [==============================] - 21s 90ms/step - loss: 5.9102e-04 - mse: 5.9102e-04 - mae: 0.0144\n",
      "Epoch 48/100\n",
      "234/234 [==============================] - 21s 91ms/step - loss: 5.8526e-04 - mse: 5.8526e-04 - mae: 0.0144 0s - loss: 5.9074e-04 - mse: 5.9074e-04 - mae: 0.\n",
      "Epoch 49/100\n",
      "234/234 [==============================] - 21s 88ms/step - loss: 5.8601e-04 - mse: 5.8601e-04 - mae: 0.0143\n",
      "Epoch 50/100\n",
      "234/234 [==============================] - 21s 91ms/step - loss: 5.8267e-04 - mse: 5.8267e-04 - mae: 0.0143 10s - loss: 5.67 - ETA: 2s - loss: 6.0646e-04 \n",
      "Epoch 51/100\n",
      "234/234 [==============================] - 21s 90ms/step - loss: 5.8102e-04 - mse: 5.8102e-04 - mae: 0.0142\n",
      "Epoch 52/100\n",
      "234/234 [==============================] - 21s 90ms/step - loss: 5.8657e-04 - mse: 5.8657e-04 - mae: 0.0143\n",
      "Epoch 53/100\n",
      "234/234 [==============================] - 21s 91ms/step - loss: 5.8177e-04 - mse: 5.8177e-04 - mae: 0.0142\n",
      "Epoch 54/100\n",
      "234/234 [==============================] - 21s 92ms/step - loss: 5.7831e-04 - mse: 5.7831e-04 - mae: 0.0143\n",
      "Epoch 55/100\n",
      "234/234 [==============================] - 22s 93ms/step - loss: 5.8309e-04 - mse: 5.8309e-04 - mae: 0.0143\n",
      "Epoch 56/100\n",
      "234/234 [==============================] - 22s 96ms/step - loss: 5.8126e-04 - mse: 5.8126e-04 - mae: 0.0143\n",
      "Epoch 57/100\n",
      "234/234 [==============================] - 21s 90ms/step - loss: 5.8997e-04 - mse: 5.8997e-04 - mae: 0.0143\n",
      "Epoch 58/100\n",
      "234/234 [==============================] - 21s 90ms/step - loss: 5.8675e-04 - mse: 5.8675e-04 - mae: 0.0143\n",
      "Epoch 59/100\n",
      "234/234 [==============================] - 21s 90ms/step - loss: 5.8260e-04 - mse: 5.8260e-04 - mae: 0.0143 1s - loss: 5.9685e-04 - mse: 5.9685e\n",
      "Epoch 60/100\n",
      "234/234 [==============================] - 22s 93ms/step - loss: 5.7892e-04 - mse: 5.7892e-04 - mae: 0.0141\n",
      "Epoch 61/100\n",
      "234/234 [==============================] - 22s 96ms/step - loss: 5.7939e-04 - mse: 5.7939e-04 - mae: 0.0142\n",
      "Epoch 62/100\n",
      "234/234 [==============================] - 22s 95ms/step - loss: 5.7281e-04 - mse: 5.7281e-04 - mae: 0.0141\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234/234 [==============================] - 22s 95ms/step - loss: 5.7325e-04 - mse: 5.7325e-04 - mae: 0.0141\n",
      "Epoch 64/100\n",
      "234/234 [==============================] - 21s 88ms/step - loss: 5.7504e-04 - mse: 5.7504e-04 - mae: 0.0141\n",
      "Epoch 65/100\n",
      "234/234 [==============================] - 21s 89ms/step - loss: 5.6627e-04 - mse: 5.6627e-04 - mae: 0.0140\n",
      "Epoch 66/100\n",
      "234/234 [==============================] - 22s 94ms/step - loss: 5.6583e-04 - mse: 5.6583e-04 - mae: 0.0141\n",
      "Epoch 67/100\n",
      "234/234 [==============================] - 21s 90ms/step - loss: 5.5715e-04 - mse: 5.5715e-04 - mae: 0.0140\n",
      "Epoch 68/100\n",
      "234/234 [==============================] - 22s 92ms/step - loss: 5.6397e-04 - mse: 5.6397e-04 - mae: 0.0141\n",
      "Epoch 69/100\n",
      "234/234 [==============================] - 22s 96ms/step - loss: 5.4937e-04 - mse: 5.4937e-04 - mae: 0.0139\n",
      "Epoch 70/100\n",
      "234/234 [==============================] - 21s 88ms/step - loss: 5.4292e-04 - mse: 5.4292e-04 - mae: 0.0140\n",
      "Epoch 71/100\n",
      "234/234 [==============================] - 21s 91ms/step - loss: 5.3236e-04 - mse: 5.3236e-04 - mae: 0.0138\n",
      "Epoch 72/100\n",
      "234/234 [==============================] - 21s 91ms/step - loss: 5.3329e-04 - mse: 5.3329e-04 - mae: 0.0138 5 - ETA: 0s - loss: 5.4172e-04 - mse: 5.4172e-04 - mae\n",
      "Epoch 73/100\n",
      "234/234 [==============================] - 21s 89ms/step - loss: 5.4051e-04 - mse: 5.4051e-04 - mae: 0.0139\n",
      "Epoch 74/100\n",
      "234/234 [==============================] - 21s 89ms/step - loss: 5.2952e-04 - mse: 5.2952e-04 - mae: 0.0138\n",
      "Epoch 75/100\n",
      "234/234 [==============================] - 21s 91ms/step - loss: 5.2798e-04 - mse: 5.2798e-04 - mae: 0.0138\n",
      "Epoch 76/100\n",
      "234/234 [==============================] - 21s 89ms/step - loss: 5.2423e-04 - mse: 5.2423e-04 - mae: 0.0138\n",
      "Epoch 77/100\n",
      "234/234 [==============================] - 21s 90ms/step - loss: 5.1864e-04 - mse: 5.1864e-04 - mae: 0.0137\n",
      "Epoch 78/100\n",
      "234/234 [==============================] - 22s 92ms/step - loss: 5.1972e-04 - mse: 5.1972e-04 - mae: 0.0138\n",
      "Epoch 79/100\n",
      "234/234 [==============================] - 21s 89ms/step - loss: 5.1141e-04 - mse: 5.1141e-04 - mae: 0.0138\n",
      "Epoch 80/100\n",
      "234/234 [==============================] - 22s 92ms/step - loss: 5.0156e-04 - mse: 5.0156e-04 - mae: 0.0136\n",
      "Epoch 81/100\n",
      "234/234 [==============================] - 22s 92ms/step - loss: 5.0359e-04 - mse: 5.0359e-04 - mae: 0.0136\n",
      "Epoch 82/100\n",
      "234/234 [==============================] - 22s 93ms/step - loss: 5.1594e-04 - mse: 5.1594e-04 - mae: 0.0136\n",
      "Epoch 83/100\n",
      "234/234 [==============================] - 24s 101ms/step - loss: 5.0088e-04 - mse: 5.0088e-04 - mae: 0.0136\n",
      "Epoch 84/100\n",
      "234/234 [==============================] - 23s 98ms/step - loss: 5.1691e-04 - mse: 5.1691e-04 - mae: 0.0136\n",
      "Epoch 85/100\n",
      "234/234 [==============================] - 20s 87ms/step - loss: 5.1321e-04 - mse: 5.1321e-04 - mae: 0.0136\n",
      "Epoch 86/100\n",
      "234/234 [==============================] - 22s 93ms/step - loss: 5.1022e-04 - mse: 5.1022e-04 - mae: 0.0136 4s \n",
      "Epoch 87/100\n",
      "234/234 [==============================] - 21s 91ms/step - loss: 5.0052e-04 - mse: 5.0052e-04 - mae: 0.0136 1s - loss: 5.0981e-04 - mse: 5.0981e-0\n",
      "Epoch 88/100\n",
      "234/234 [==============================] - 21s 89ms/step - loss: 5.0563e-04 - mse: 5.0563e-04 - mae: 0.0136\n",
      "Epoch 89/100\n",
      "234/234 [==============================] - 22s 92ms/step - loss: 4.9938e-04 - mse: 4.9938e-04 - mae: 0.0135 8s - loss: 4.0787e- - ETA: \n",
      "Epoch 90/100\n",
      "234/234 [==============================] - 21s 91ms/step - loss: 4.9369e-04 - mse: 4.9369e-04 - mae: 0.0135\n",
      "Epoch 91/100\n",
      "234/234 [==============================] - 21s 88ms/step - loss: 5.0229e-04 - mse: 5.0229e-04 - mae: 0.0136 9s - lo\n",
      "Epoch 92/100\n",
      "234/234 [==============================] - 21s 92ms/step - loss: 5.0224e-04 - mse: 5.0224e-04 - mae: 0.0135 4s - lo\n",
      "Epoch 93/100\n",
      "234/234 [==============================] - 21s 91ms/step - loss: 4.9860e-04 - mse: 4.9860e-04 - mae: 0.0135\n",
      "Epoch 94/100\n",
      "234/234 [==============================] - 21s 90ms/step - loss: 4.8657e-04 - mse: 4.8657e-04 - mae: 0.0134\n",
      "Epoch 95/100\n",
      "234/234 [==============================] - 22s 94ms/step - loss: 4.8990e-04 - mse: 4.8990e-04 - mae: 0.0134\n",
      "Epoch 96/100\n",
      "234/234 [==============================] - 24s 101ms/step - loss: 5.1288e-04 - mse: 5.1288e-04 - mae: 0.0135\n",
      "Epoch 97/100\n",
      "234/234 [==============================] - 24s 101ms/step - loss: 4.9217e-04 - mse: 4.9217e-04 - mae: 0.0134\n",
      "Epoch 98/100\n",
      "234/234 [==============================] - 22s 95ms/step - loss: 4.7627e-04 - mse: 4.7627e-04 - mae: 0.0133\n",
      "Epoch 99/100\n",
      "234/234 [==============================] - 22s 94ms/step - loss: 4.8159e-04 - mse: 4.8159e-04 - mae: 0.0133 3s - loss: 4\n",
      "Epoch 100/100\n",
      "234/234 [==============================] - 22s 96ms/step - loss: 4.7654e-04 - mse: 4.7654e-04 - mae: 0.0133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n",
      "C:\\Users\\maria\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:6245: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "187/187 [==============================] - 17s 89ms/step - loss: 0.0844 - mse: 0.0844 - mae: 0.2096\n",
      "Epoch 2/100\n",
      "187/187 [==============================] - 17s 89ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0490 2s - loss: 0.0047 - m\n",
      "Epoch 3/100\n",
      "187/187 [==============================] - 17s 90ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0222\n",
      "Epoch 4/100\n",
      "187/187 [==============================] - 20s 105ms/step - loss: 7.4373e-04 - mse: 7.4373e-04 - mae: 0.0179\n",
      "Epoch 5/100\n",
      "187/187 [==============================] - 20s 108ms/step - loss: 6.7945e-04 - mse: 6.7945e-04 - mae: 0.0167\n",
      "Epoch 6/100\n",
      "187/187 [==============================] - 25s 136ms/step - loss: 6.4053e-04 - mse: 6.4053e-04 - mae: 0.0159\n",
      "Epoch 7/100\n",
      "187/187 [==============================] - 19s 103ms/step - loss: 6.1727e-04 - mse: 6.1727e-04 - mae: 0.0156\n",
      "Epoch 8/100\n",
      "187/187 [==============================] - 20s 106ms/step - loss: 5.9089e-04 - mse: 5.9089e-04 - mae: 0.0153\n",
      "Epoch 9/100\n",
      "187/187 [==============================] - 30s 159ms/step - loss: 5.7156e-04 - mse: 5.7156e-04 - mae: 0.0149\n",
      "Epoch 10/100\n",
      "187/187 [==============================] - 25s 135ms/step - loss: 5.6303e-04 - mse: 5.6303e-04 - mae: 0.0147\n",
      "Epoch 11/100\n",
      "187/187 [==============================] - 25s 134ms/step - loss: 5.4928e-04 - mse: 5.4928e-04 - mae: 0.0145\n",
      "Epoch 12/100\n",
      "187/187 [==============================] - 22s 119ms/step - loss: 5.5024e-04 - mse: 5.5024e-04 - mae: 0.0145\n",
      "Epoch 13/100\n",
      "187/187 [==============================] - 20s 108ms/step - loss: 5.4570e-04 - mse: 5.4570e-04 - mae: 0.0143\n",
      "Epoch 14/100\n",
      "187/187 [==============================] - 20s 109ms/step - loss: 5.3499e-04 - mse: 5.3499e-04 - mae: 0.0142\n",
      "Epoch 15/100\n",
      "187/187 [==============================] - 19s 104ms/step - loss: 5.3669e-04 - mse: 5.3669e-04 - mae: 0.0142\n",
      "Epoch 16/100\n",
      "187/187 [==============================] - 21s 111ms/step - loss: 5.3486e-04 - mse: 5.3486e-04 - mae: 0.0142\n",
      "Epoch 17/100\n",
      "187/187 [==============================] - 25s 132ms/step - loss: 5.3020e-04 - mse: 5.3020e-04 - mae: 0.0140\n",
      "Epoch 18/100\n",
      "187/187 [==============================] - 21s 114ms/step - loss: 5.3133e-04 - mse: 5.3133e-04 - mae: 0.0141\n",
      "Epoch 19/100\n",
      "187/187 [==============================] - 20s 106ms/step - loss: 5.2634e-04 - mse: 5.2634e-04 - mae: 0.0140\n",
      "Epoch 20/100\n",
      "187/187 [==============================] - 20s 109ms/step - loss: 5.2955e-04 - mse: 5.2955e-04 - mae: 0.0140\n",
      "Epoch 21/100\n",
      "187/187 [==============================] - 21s 112ms/step - loss: 5.2493e-04 - mse: 5.2493e-04 - mae: 0.0139\n",
      "Epoch 22/100\n",
      "187/187 [==============================] - 21s 110ms/step - loss: 5.2451e-04 - mse: 5.2451e-04 - mae: 0.0138\n",
      "Epoch 23/100\n",
      "187/187 [==============================] - 19s 104ms/step - loss: 5.1856e-04 - mse: 5.1856e-04 - mae: 0.01382s - loss: 5.2925e-04 -\n",
      "Epoch 24/100\n",
      "187/187 [==============================] - 19s 103ms/step - loss: 5.1621e-04 - mse: 5.1621e-04 - mae: 0.0137\n",
      "Epoch 25/100\n",
      "187/187 [==============================] - 20s 107ms/step - loss: 5.1709e-04 - mse: 5.1709e-04 - mae: 0.0137\n",
      "Epoch 26/100\n",
      "187/187 [==============================] - 19s 100ms/step - loss: 5.1635e-04 - mse: 5.1635e-04 - mae: 0.0137\n",
      "Epoch 27/100\n",
      "187/187 [==============================] - 20s 108ms/step - loss: 5.1646e-04 - mse: 5.1646e-04 - mae: 0.0138\n",
      "Epoch 28/100\n",
      "187/187 [==============================] - 21s 111ms/step - loss: 5.1528e-04 - mse: 5.1528e-04 - mae: 0.0137\n",
      "Epoch 29/100\n",
      "187/187 [==============================] - 21s 112ms/step - loss: 5.0924e-04 - mse: 5.0924e-04 - mae: 0.0136\n",
      "Epoch 30/100\n",
      "187/187 [==============================] - 21s 113ms/step - loss: 5.1043e-04 - mse: 5.1043e-04 - mae: 0.0136\n",
      "Epoch 31/100\n",
      "187/187 [==============================] - 19s 102ms/step - loss: 5.1140e-04 - mse: 5.1140e-04 - mae: 0.0136\n",
      "Epoch 32/100\n",
      "187/187 [==============================] - 21s 110ms/step - loss: 5.1152e-04 - mse: 5.1152e-04 - mae: 0.0136\n",
      "Epoch 33/100\n",
      "187/187 [==============================] - 15s 81ms/step - loss: 5.0829e-04 - mse: 5.0829e-04 - mae: 0.0135\n",
      "Epoch 34/100\n",
      "187/187 [==============================] - 21s 111ms/step - loss: 5.0144e-04 - mse: 5.0144e-04 - mae: 0.0134\n",
      "Epoch 35/100\n",
      "187/187 [==============================] - 20s 107ms/step - loss: 5.0029e-04 - mse: 5.0029e-04 - mae: 0.0135\n",
      "Epoch 36/100\n",
      "187/187 [==============================] - 21s 113ms/step - loss: 4.9952e-04 - mse: 4.9952e-04 - mae: 0.0134\n",
      "Epoch 37/100\n",
      "187/187 [==============================] - 20s 109ms/step - loss: 5.0081e-04 - mse: 5.0081e-04 - mae: 0.0134\n",
      "Epoch 38/100\n",
      "187/187 [==============================] - 20s 106ms/step - loss: 4.9841e-04 - mse: 4.9841e-04 - mae: 0.0134\n",
      "Epoch 39/100\n",
      "187/187 [==============================] - 16s 84ms/step - loss: 5.0148e-04 - mse: 5.0148e-04 - mae: 0.0135\n",
      "Epoch 40/100\n",
      "187/187 [==============================] - 18s 96ms/step - loss: 4.9710e-04 - mse: 4.9710e-04 - mae: 0.0133\n",
      "Epoch 41/100\n",
      "187/187 [==============================] - 19s 99ms/step - loss: 4.9673e-04 - mse: 4.9673e-04 - mae: 0.0133\n",
      "Epoch 42/100\n",
      "187/187 [==============================] - 17s 91ms/step - loss: 5.0066e-04 - mse: 5.0066e-04 - mae: 0.0134\n",
      "Epoch 43/100\n",
      "187/187 [==============================] - 20s 109ms/step - loss: 4.9357e-04 - mse: 4.9357e-04 - mae: 0.01334s - loss: 5.19\n",
      "Epoch 44/100\n",
      "187/187 [==============================] - 19s 100ms/step - loss: 4.9357e-04 - mse: 4.9357e-04 - mae: 0.0132\n",
      "Epoch 45/100\n",
      "187/187 [==============================] - 20s 109ms/step - loss: 4.9298e-04 - mse: 4.9298e-04 - mae: 0.0132\n",
      "Epoch 46/100\n",
      "187/187 [==============================] - 20s 105ms/step - loss: 4.9131e-04 - mse: 4.9131e-04 - mae: 0.0132\n",
      "Epoch 47/100\n",
      "187/187 [==============================] - 22s 116ms/step - loss: 4.9437e-04 - mse: 4.9437e-04 - mae: 0.0132\n",
      "Epoch 48/100\n",
      "187/187 [==============================] - 21s 110ms/step - loss: 4.9289e-04 - mse: 4.9289e-04 - mae: 0.0132\n",
      "Epoch 49/100\n",
      "187/187 [==============================] - 20s 108ms/step - loss: 4.9209e-04 - mse: 4.9209e-04 - mae: 0.0132\n",
      "Epoch 50/100\n",
      "187/187 [==============================] - 22s 115ms/step - loss: 4.9093e-04 - mse: 4.9093e-04 - mae: 0.0132\n",
      "Epoch 51/100\n",
      "187/187 [==============================] - 21s 110ms/step - loss: 4.8824e-04 - mse: 4.8824e-04 - mae: 0.01321s - loss: 4.9149e-04 - mse: 4.9149e-04\n",
      "Epoch 52/100\n",
      "187/187 [==============================] - 21s 114ms/step - loss: 4.8929e-04 - mse: 4.8929e-04 - mae: 0.0132\n",
      "Epoch 53/100\n",
      "187/187 [==============================] - 21s 111ms/step - loss: 4.8702e-04 - mse: 4.8702e-04 - mae: 0.0132\n",
      "Epoch 54/100\n",
      "187/187 [==============================] - 25s 135ms/step - loss: 4.8507e-04 - mse: 4.8507e-04 - mae: 0.0131\n",
      "Epoch 55/100\n",
      "187/187 [==============================] - 46s 246ms/step - loss: 4.7912e-04 - mse: 4.7912e-04 - mae: 0.0130\n",
      "Epoch 56/100\n",
      "187/187 [==============================] - 23s 122ms/step - loss: 4.8126e-04 - mse: 4.8126e-04 - mae: 0.0131\n",
      "Epoch 57/100\n",
      "187/187 [==============================] - 21s 113ms/step - loss: 4.7930e-04 - mse: 4.7930e-04 - mae: 0.0130\n",
      "Epoch 58/100\n",
      "187/187 [==============================] - 23s 121ms/step - loss: 4.8284e-04 - mse: 4.8284e-04 - mae: 0.0130\n",
      "Epoch 59/100\n",
      "187/187 [==============================] - 21s 113ms/step - loss: 4.8002e-04 - mse: 4.8002e-04 - mae: 0.0130\n",
      "Epoch 60/100\n",
      "187/187 [==============================] - 22s 118ms/step - loss: 4.7760e-04 - mse: 4.7760e-04 - mae: 0.0130\n",
      "Epoch 61/100\n",
      "187/187 [==============================] - 21s 112ms/step - loss: 4.8049e-04 - mse: 4.8049e-04 - mae: 0.0130\n",
      "Epoch 62/100\n",
      "187/187 [==============================] - 22s 116ms/step - loss: 4.8005e-04 - mse: 4.8005e-04 - mae: 0.0131\n",
      "Epoch 63/100\n",
      "187/187 [==============================] - 21s 115ms/step - loss: 4.8039e-04 - mse: 4.8039e-04 - mae: 0.01315s - l\n",
      "Epoch 64/100\n",
      "187/187 [==============================] - 22s 119ms/step - loss: 4.7406e-04 - mse: 4.7406e-04 - mae: 0.0129\n",
      "Epoch 65/100\n",
      "187/187 [==============================] - 22s 115ms/step - loss: 4.7444e-04 - mse: 4.7444e-04 - mae: 0.0129\n",
      "Epoch 66/100\n",
      "187/187 [==============================] - 21s 114ms/step - loss: 4.6798e-04 - mse: 4.6798e-04 - mae: 0.0128\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187/187 [==============================] - 22s 116ms/step - loss: 4.6886e-04 - mse: 4.6886e-04 - mae: 0.0129\n",
      "Epoch 68/100\n",
      "187/187 [==============================] - 21s 113ms/step - loss: 4.7043e-04 - mse: 4.7043e-04 - mae: 0.0129\n",
      "Epoch 69/100\n",
      "187/187 [==============================] - 23s 122ms/step - loss: 4.6751e-04 - mse: 4.6751e-04 - mae: 0.0129\n",
      "Epoch 70/100\n",
      "187/187 [==============================] - 21s 114ms/step - loss: 4.6719e-04 - mse: 4.6719e-04 - mae: 0.0128\n",
      "Epoch 71/100\n",
      "187/187 [==============================] - 22s 116ms/step - loss: 4.6397e-04 - mse: 4.6397e-04 - mae: 0.0128\n",
      "Epoch 72/100\n",
      "187/187 [==============================] - 22s 115ms/step - loss: 4.6662e-04 - mse: 4.6662e-04 - mae: 0.0128\n",
      "Epoch 73/100\n",
      "187/187 [==============================] - 22s 119ms/step - loss: 4.6407e-04 - mse: 4.6407e-04 - mae: 0.0128\n",
      "Epoch 74/100\n",
      "187/187 [==============================] - 21s 112ms/step - loss: 4.6139e-04 - mse: 4.6139e-04 - mae: 0.0126\n",
      "Epoch 75/100\n",
      "187/187 [==============================] - 20s 109ms/step - loss: 4.5428e-04 - mse: 4.5428e-04 - mae: 0.0126\n",
      "Epoch 76/100\n",
      "187/187 [==============================] - 21s 111ms/step - loss: 4.5935e-04 - mse: 4.5935e-04 - mae: 0.0127\n",
      "Epoch 77/100\n",
      "187/187 [==============================] - 21s 112ms/step - loss: 4.6508e-04 - mse: 4.6508e-04 - mae: 0.0127\n",
      "Epoch 78/100\n",
      "187/187 [==============================] - 21s 112ms/step - loss: 4.5913e-04 - mse: 4.5913e-04 - mae: 0.0127\n",
      "Epoch 79/100\n",
      "187/187 [==============================] - 21s 112ms/step - loss: 4.5261e-04 - mse: 4.5261e-04 - mae: 0.0126\n",
      "Epoch 80/100\n",
      "187/187 [==============================] - 21s 114ms/step - loss: 4.6077e-04 - mse: 4.6077e-04 - mae: 0.0127\n",
      "Epoch 81/100\n",
      "187/187 [==============================] - 21s 110ms/step - loss: 4.5622e-04 - mse: 4.5622e-04 - mae: 0.0126\n",
      "Epoch 82/100\n",
      "187/187 [==============================] - 21s 115ms/step - loss: 4.5721e-04 - mse: 4.5721e-04 - mae: 0.0126\n",
      "Epoch 83/100\n",
      "187/187 [==============================] - 20s 108ms/step - loss: 4.4477e-04 - mse: 4.4477e-04 - mae: 0.01252s - loss: 4.5995e-04 - mse: 4.599\n",
      "Epoch 84/100\n",
      "187/187 [==============================] - 21s 115ms/step - loss: 4.5786e-04 - mse: 4.5786e-04 - mae: 0.0126\n",
      "Epoch 85/100\n",
      "187/187 [==============================] - 21s 113ms/step - loss: 4.5280e-04 - mse: 4.5280e-04 - mae: 0.0126\n",
      "Epoch 86/100\n",
      "187/187 [==============================] - 21s 111ms/step - loss: 4.5046e-04 - mse: 4.5046e-04 - mae: 0.0126\n",
      "Epoch 87/100\n",
      "187/187 [==============================] - 22s 117ms/step - loss: 4.5488e-04 - mse: 4.5488e-04 - mae: 0.0125\n",
      "Epoch 88/100\n",
      "187/187 [==============================] - 20s 106ms/step - loss: 4.4267e-04 - mse: 4.4267e-04 - mae: 0.0124\n",
      "Epoch 89/100\n",
      "187/187 [==============================] - 21s 112ms/step - loss: 4.4410e-04 - mse: 4.4410e-04 - mae: 0.0125\n",
      "Epoch 90/100\n",
      "187/187 [==============================] - 20s 108ms/step - loss: 4.4751e-04 - mse: 4.4751e-04 - mae: 0.01241s - loss: 4.5458e-04 - mse: 4.5458e-04 \n",
      "Epoch 91/100\n",
      "187/187 [==============================] - 22s 116ms/step - loss: 4.4483e-04 - mse: 4.4483e-04 - mae: 0.0125\n",
      "Epoch 92/100\n",
      "187/187 [==============================] - 20s 108ms/step - loss: 4.4116e-04 - mse: 4.4116e-04 - mae: 0.0124\n",
      "Epoch 93/100\n",
      "187/187 [==============================] - 17s 91ms/step - loss: 4.4168e-04 - mse: 4.4168e-04 - mae: 0.0124 4s - l\n",
      "Epoch 94/100\n",
      "187/187 [==============================] - 20s 107ms/step - loss: 4.3651e-04 - mse: 4.3651e-04 - mae: 0.0124\n",
      "Epoch 95/100\n",
      "187/187 [==============================] - 22s 116ms/step - loss: 4.4014e-04 - mse: 4.4014e-04 - mae: 0.0124\n",
      "Epoch 96/100\n",
      "187/187 [==============================] - 20s 109ms/step - loss: 4.3319e-04 - mse: 4.3319e-04 - mae: 0.0124\n",
      "Epoch 97/100\n",
      "187/187 [==============================] - 20s 109ms/step - loss: 4.2958e-04 - mse: 4.2958e-04 - mae: 0.0122\n",
      "Epoch 98/100\n",
      "187/187 [==============================] - 19s 103ms/step - loss: 4.3715e-04 - mse: 4.3715e-04 - mae: 0.01235\n",
      "Epoch 99/100\n",
      "187/187 [==============================] - 21s 111ms/step - loss: 4.4030e-04 - mse: 4.4030e-04 - mae: 0.0124\n",
      "Epoch 100/100\n",
      "187/187 [==============================] - 27s 143ms/step - loss: 4.3124e-04 - mse: 4.3124e-04 - mae: 0.01224s - loss: 4.5999e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n",
      "C:\\Users\\maria\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:6245: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "140/140 [==============================] - 12s 89ms/step - loss: 0.1163 - mse: 0.1163 - mae: 0.2443 2s - loss: 0.1415 - mse - ETA: 1s - loss: 0.1237 - mse: 0.1237 \n",
      "Epoch 2/100\n",
      "140/140 [==============================] - 12s 85ms/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0780\n",
      "Epoch 3/100\n",
      "140/140 [==============================] - 13s 90ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0358\n",
      "Epoch 4/100\n",
      "140/140 [==============================] - 12s 88ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0230\n",
      "Epoch 5/100\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.0010 - mse: 0.0010 - mae: 0.019 - 9s 65ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0193\n",
      "Epoch 6/100\n",
      "140/140 [==============================] - 11s 82ms/step - loss: 9.3029e-04 - mse: 9.3029e-04 - mae: 0.0182\n",
      "Epoch 7/100\n",
      "140/140 [==============================] - 13s 93ms/step - loss: 8.9460e-04 - mse: 8.9460e-04 - mae: 0.0174\n",
      "Epoch 8/100\n",
      "140/140 [==============================] - 13s 95ms/step - loss: 8.6950e-04 - mse: 8.6950e-04 - mae: 0.0169\n",
      "Epoch 9/100\n",
      "140/140 [==============================] - 13s 94ms/step - loss: 8.3997e-04 - mse: 8.3997e-04 - mae: 0.0165\n",
      "Epoch 10/100\n",
      "140/140 [==============================] - 13s 90ms/step - loss: 8.1118e-04 - mse: 8.1118e-04 - mae: 0.0160\n",
      "Epoch 11/100\n",
      "140/140 [==============================] - 13s 93ms/step - loss: 7.8792e-04 - mse: 7.8792e-04 - mae: 0.0156\n",
      "Epoch 12/100\n",
      "140/140 [==============================] - 13s 90ms/step - loss: 7.7613e-04 - mse: 7.7613e-04 - mae: 0.0154\n",
      "Epoch 13/100\n",
      "140/140 [==============================] - 13s 93ms/step - loss: 7.6214e-04 - mse: 7.6214e-04 - mae: 0.0151\n",
      "Epoch 14/100\n",
      "140/140 [==============================] - 13s 91ms/step - loss: 7.5811e-04 - mse: 7.5811e-04 - mae: 0.0150\n",
      "Epoch 15/100\n",
      "140/140 [==============================] - 13s 91ms/step - loss: 7.5381e-04 - mse: 7.5381e-04 - mae: 0.0149\n",
      "Epoch 16/100\n",
      "140/140 [==============================] - 13s 91ms/step - loss: 7.4627e-04 - mse: 7.4627e-04 - mae: 0.0147\n",
      "Epoch 17/100\n",
      "140/140 [==============================] - 13s 91ms/step - loss: 7.3565e-04 - mse: 7.3565e-04 - mae: 0.0147\n",
      "Epoch 18/100\n",
      "140/140 [==============================] - 13s 94ms/step - loss: 7.3646e-04 - mse: 7.3646e-04 - mae: 0.0146\n",
      "Epoch 19/100\n",
      "140/140 [==============================] - 13s 92ms/step - loss: 7.3168e-04 - mse: 7.3168e-04 - mae: 0.0146 0s - loss: 7.4291e-04 - mse: 7.4291e-04 - mae:\n",
      "Epoch 20/100\n",
      "140/140 [==============================] - 13s 93ms/step - loss: 7.2489e-04 - mse: 7.2489e-04 - mae: 0.0144 2s - loss: 6.4488e-04 -\n",
      "Epoch 21/100\n",
      "140/140 [==============================] - 13s 92ms/step - loss: 7.2981e-04 - mse: 7.2981e-04 - mae: 0.0144\n",
      "Epoch 22/100\n",
      "140/140 [==============================] - 13s 92ms/step - loss: 7.2366e-04 - mse: 7.2366e-04 - mae: 0.0143\n",
      "Epoch 23/100\n",
      "140/140 [==============================] - 13s 94ms/step - loss: 7.2631e-04 - mse: 7.2631e-04 - mae: 0.0143\n",
      "Epoch 24/100\n",
      "140/140 [==============================] - 13s 92ms/step - loss: 7.2069e-04 - mse: 7.2069e-04 - mae: 0.0143\n",
      "Epoch 25/100\n",
      "140/140 [==============================] - 13s 92ms/step - loss: 7.2268e-04 - mse: 7.2268e-04 - mae: 0.0143\n",
      "Epoch 26/100\n",
      "140/140 [==============================] - 13s 93ms/step - loss: 7.0880e-04 - mse: 7.0880e-04 - mae: 0.0141 4s \n",
      "Epoch 27/100\n",
      "140/140 [==============================] - 13s 92ms/step - loss: 7.0981e-04 - mse: 7.0981e-04 - mae: 0.0140\n",
      "Epoch 28/100\n",
      "140/140 [==============================] - 13s 91ms/step - loss: 7.1396e-04 - mse: 7.1396e-04 - mae: 0.0141\n",
      "Epoch 29/100\n",
      "140/140 [==============================] - 12s 89ms/step - loss: 6.9900e-04 - mse: 6.9900e-04 - mae: 0.0139\n",
      "Epoch 30/100\n",
      "140/140 [==============================] - 13s 94ms/step - loss: 7.0418e-04 - mse: 7.0418e-04 - mae: 0.0140\n",
      "Epoch 31/100\n",
      "140/140 [==============================] - 13s 92ms/step - loss: 7.0959e-04 - mse: 7.0959e-04 - mae: 0.0140\n",
      "Epoch 32/100\n",
      "140/140 [==============================] - 13s 92ms/step - loss: 7.0003e-04 - mse: 7.0003e-04 - mae: 0.0139\n",
      "Epoch 33/100\n",
      "140/140 [==============================] - 13s 90ms/step - loss: 6.9737e-04 - mse: 6.9737e-04 - mae: 0.0139\n",
      "Epoch 34/100\n",
      "140/140 [==============================] - 13s 92ms/step - loss: 6.9657e-04 - mse: 6.9657e-04 - mae: 0.0138\n",
      "Epoch 35/100\n",
      "140/140 [==============================] - 13s 90ms/step - loss: 6.9231e-04 - mse: 6.9231e-04 - mae: 0.0137\n",
      "Epoch 36/100\n",
      "140/140 [==============================] - 13s 92ms/step - loss: 6.9455e-04 - mse: 6.9455e-04 - mae: 0.0139\n",
      "Epoch 37/100\n",
      "140/140 [==============================] - 13s 92ms/step - loss: 6.9221e-04 - mse: 6.9221e-04 - mae: 0.0137\n",
      "Epoch 38/100\n",
      "140/140 [==============================] - 13s 92ms/step - loss: 6.8664e-04 - mse: 6.8664e-04 - mae: 0.0136\n",
      "Epoch 39/100\n",
      "140/140 [==============================] - 13s 91ms/step - loss: 6.8624e-04 - mse: 6.8624e-04 - mae: 0.0136\n",
      "Epoch 40/100\n",
      "140/140 [==============================] - 13s 91ms/step - loss: 6.8947e-04 - mse: 6.8947e-04 - mae: 0.0136\n",
      "Epoch 41/100\n",
      "140/140 [==============================] - 13s 90ms/step - loss: 6.9005e-04 - mse: 6.9005e-04 - mae: 0.0137\n",
      "Epoch 42/100\n",
      "140/140 [==============================] - 13s 93ms/step - loss: 6.8654e-04 - mse: 6.8654e-04 - mae: 0.0136\n",
      "Epoch 43/100\n",
      "140/140 [==============================] - 13s 91ms/step - loss: 6.8649e-04 - mse: 6.8649e-04 - mae: 0.0136\n",
      "Epoch 44/100\n",
      "140/140 [==============================] - 13s 93ms/step - loss: 6.7869e-04 - mse: 6.7869e-04 - mae: 0.0136 3s - loss: 6.233\n",
      "Epoch 45/100\n",
      "140/140 [==============================] - 13s 89ms/step - loss: 6.8711e-04 - mse: 6.8711e-04 - mae: 0.0135\n",
      "Epoch 46/100\n",
      "140/140 [==============================] - 13s 92ms/step - loss: 6.8031e-04 - mse: 6.8031e-04 - mae: 0.0135\n",
      "Epoch 47/100\n",
      "140/140 [==============================] - 13s 92ms/step - loss: 6.8239e-04 - mse: 6.8239e-04 - mae: 0.0135 0s - loss: 6.9511e-04 - mse: 6.9511e-04 - mae: \n",
      "Epoch 48/100\n",
      "140/140 [==============================] - 13s 92ms/step - loss: 6.8124e-04 - mse: 6.8124e-04 - mae: 0.0134\n",
      "Epoch 49/100\n",
      "140/140 [==============================] - 13s 90ms/step - loss: 6.7160e-04 - mse: 6.7160e-04 - mae: 0.0133\n",
      "Epoch 50/100\n",
      "140/140 [==============================] - 13s 92ms/step - loss: 6.7746e-04 - mse: 6.7746e-04 - mae: 0.0134\n",
      "Epoch 51/100\n",
      "140/140 [==============================] - 13s 91ms/step - loss: 6.6880e-04 - mse: 6.6880e-04 - mae: 0.0133\n",
      "Epoch 52/100\n",
      "140/140 [==============================] - 13s 91ms/step - loss: 6.7191e-04 - mse: 6.7191e-04 - mae: 0.0134\n",
      "Epoch 53/100\n",
      "140/140 [==============================] - 11s 80ms/step - loss: 6.6730e-04 - mse: 6.6730e-04 - mae: 0.0134\n",
      "Epoch 54/100\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 6.7521e-04 - mse: 6.7521e-04 - mae: 0.0134\n",
      "Epoch 55/100\n",
      "140/140 [==============================] - 9s 68ms/step - loss: 6.6714e-04 - mse: 6.6714e-04 - mae: 0.0132\n",
      "Epoch 56/100\n",
      "140/140 [==============================] - 13s 91ms/step - loss: 6.6305e-04 - mse: 6.6305e-04 - mae: 0.0133\n",
      "Epoch 57/100\n",
      "140/140 [==============================] - 13s 90ms/step - loss: 6.6599e-04 - mse: 6.6599e-04 - mae: 0.0133\n",
      "Epoch 58/100\n",
      "140/140 [==============================] - 13s 93ms/step - loss: 6.6294e-04 - mse: 6.6294e-04 - mae: 0.0133\n",
      "Epoch 59/100\n",
      "140/140 [==============================] - 13s 92ms/step - loss: 6.6128e-04 - mse: 6.6128e-04 - mae: 0.0131\n",
      "Epoch 60/100\n",
      "140/140 [==============================] - 13s 91ms/step - loss: 6.6116e-04 - mse: 6.6116e-04 - mae: 0.0132\n",
      "Epoch 61/100\n",
      "140/140 [==============================] - 13s 90ms/step - loss: 6.5909e-04 - mse: 6.5909e-04 - mae: 0.0132\n",
      "Epoch 62/100\n",
      "140/140 [==============================] - 13s 91ms/step - loss: 6.5491e-04 - mse: 6.5491e-04 - mae: 0.0131\n",
      "Epoch 63/100\n",
      "140/140 [==============================] - 13s 91ms/step - loss: 6.6052e-04 - mse: 6.6052e-04 - mae: 0.0130\n",
      "Epoch 64/100\n",
      "140/140 [==============================] - 13s 91ms/step - loss: 6.5613e-04 - mse: 6.5613e-04 - mae: 0.0130\n",
      "Epoch 65/100\n",
      "140/140 [==============================] - 13s 92ms/step - loss: 6.5104e-04 - mse: 6.5104e-04 - mae: 0.0130\n",
      "Epoch 66/100\n",
      "140/140 [==============================] - 13s 91ms/step - loss: 6.5332e-04 - mse: 6.5332e-04 - mae: 0.0131\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 11s 76ms/step - loss: 6.5248e-04 - mse: 6.5248e-04 - mae: 0.0130\n",
      "Epoch 68/100\n",
      "140/140 [==============================] - 9s 67ms/step - loss: 6.4823e-04 - mse: 6.4823e-04 - mae: 0.0129\n",
      "Epoch 69/100\n",
      "140/140 [==============================] - 10s 69ms/step - loss: 6.4271e-04 - mse: 6.4271e-04 - mae: 0.0129\n",
      "Epoch 70/100\n",
      "140/140 [==============================] - 13s 90ms/step - loss: 6.4386e-04 - mse: 6.4386e-04 - mae: 0.0128\n",
      "Epoch 71/100\n",
      "140/140 [==============================] - 13s 91ms/step - loss: 6.4670e-04 - mse: 6.4670e-04 - mae: 0.0128\n",
      "Epoch 72/100\n",
      "140/140 [==============================] - 13s 92ms/step - loss: 6.4923e-04 - mse: 6.4923e-04 - mae: 0.0130\n",
      "Epoch 73/100\n",
      "140/140 [==============================] - 13s 91ms/step - loss: 6.3639e-04 - mse: 6.3639e-04 - mae: 0.0128\n",
      "Epoch 74/100\n",
      "140/140 [==============================] - 13s 92ms/step - loss: 6.3400e-04 - mse: 6.3400e-04 - mae: 0.0128\n",
      "Epoch 75/100\n",
      "140/140 [==============================] - 13s 91ms/step - loss: 6.4966e-04 - mse: 6.4966e-04 - mae: 0.0130\n",
      "Epoch 76/100\n",
      "140/140 [==============================] - 13s 92ms/step - loss: 6.4075e-04 - mse: 6.4075e-04 - mae: 0.0130\n",
      "Epoch 77/100\n",
      "140/140 [==============================] - 13s 90ms/step - loss: 6.4385e-04 - mse: 6.4385e-04 - mae: 0.0129\n",
      "Epoch 78/100\n",
      "140/140 [==============================] - 13s 91ms/step - loss: 6.3481e-04 - mse: 6.3481e-04 - mae: 0.0128\n",
      "Epoch 79/100\n",
      "140/140 [==============================] - 13s 93ms/step - loss: 6.3453e-04 - mse: 6.3453e-04 - mae: 0.0128\n",
      "Epoch 80/100\n",
      "140/140 [==============================] - 13s 92ms/step - loss: 6.2614e-04 - mse: 6.2614e-04 - mae: 0.0127\n",
      "Epoch 81/100\n",
      "140/140 [==============================] - 11s 79ms/step - loss: 6.3439e-04 - mse: 6.3439e-04 - mae: 0.0128\n",
      "Epoch 82/100\n",
      "140/140 [==============================] - 13s 91ms/step - loss: 6.2315e-04 - mse: 6.2315e-04 - mae: 0.0126\n",
      "Epoch 83/100\n",
      "140/140 [==============================] - 13s 92ms/step - loss: 6.1390e-04 - mse: 6.1390e-04 - mae: 0.0124\n",
      "Epoch 84/100\n",
      "140/140 [==============================] - 12s 85ms/step - loss: 6.2323e-04 - mse: 6.2323e-04 - mae: 0.0126\n",
      "Epoch 85/100\n",
      "140/140 [==============================] - 11s 82ms/step - loss: 6.2958e-04 - mse: 6.2958e-04 - mae: 0.0127\n",
      "Epoch 86/100\n",
      "140/140 [==============================] - 12s 84ms/step - loss: 6.2309e-04 - mse: 6.2309e-04 - mae: 0.0127\n",
      "Epoch 87/100\n",
      "140/140 [==============================] - 12s 89ms/step - loss: 6.2409e-04 - mse: 6.2409e-04 - mae: 0.0126\n",
      "Epoch 88/100\n",
      "140/140 [==============================] - 13s 91ms/step - loss: 6.1835e-04 - mse: 6.1835e-04 - mae: 0.0125\n",
      "Epoch 89/100\n",
      "140/140 [==============================] - 13s 92ms/step - loss: 6.1842e-04 - mse: 6.1842e-04 - mae: 0.0125\n",
      "Epoch 90/100\n",
      "140/140 [==============================] - 13s 91ms/step - loss: 6.1693e-04 - mse: 6.1693e-04 - mae: 0.0127\n",
      "Epoch 91/100\n",
      "140/140 [==============================] - 13s 91ms/step - loss: 6.0866e-04 - mse: 6.0866e-04 - mae: 0.0124\n",
      "Epoch 92/100\n",
      "140/140 [==============================] - 13s 92ms/step - loss: 6.1420e-04 - mse: 6.1420e-04 - mae: 0.0125\n",
      "Epoch 93/100\n",
      "140/140 [==============================] - 13s 91ms/step - loss: 6.1223e-04 - mse: 6.1223e-04 - mae: 0.0124\n",
      "Epoch 94/100\n",
      "140/140 [==============================] - 13s 91ms/step - loss: 6.1404e-04 - mse: 6.1404e-04 - mae: 0.0126\n",
      "Epoch 95/100\n",
      "140/140 [==============================] - 12s 85ms/step - loss: 6.1758e-04 - mse: 6.1758e-04 - mae: 0.0126\n",
      "Epoch 96/100\n",
      "140/140 [==============================] - 8s 61ms/step - loss: 6.0857e-04 - mse: 6.0857e-04 - mae: 0.0125\n",
      "Epoch 97/100\n",
      "140/140 [==============================] - 9s 61ms/step - loss: 5.9896e-04 - mse: 5.9896e-04 - mae: 0.0123\n",
      "Epoch 98/100\n",
      "140/140 [==============================] - 10s 74ms/step - loss: 5.9974e-04 - mse: 5.9974e-04 - mae: 0.0124\n",
      "Epoch 99/100\n",
      "140/140 [==============================] - 13s 94ms/step - loss: 6.0255e-04 - mse: 6.0255e-04 - mae: 0.0124\n",
      "Epoch 100/100\n",
      "140/140 [==============================] - 13s 96ms/step - loss: 5.9602e-04 - mse: 5.9602e-04 - mae: 0.0124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n",
      "C:\\Users\\maria\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:6245: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "93/93 [==============================] - 9s 97ms/step - loss: 0.1589 - mse: 0.1589 - mae: 0.3040:\n",
      "Epoch 2/100\n",
      "93/93 [==============================] - 9s 94ms/step - loss: 0.0323 - mse: 0.0323 - mae: 0.1394\n",
      "Epoch 3/100\n",
      "93/93 [==============================] - 8s 87ms/step - loss: 0.0074 - mse: 0.0074 - mae: 0.0648: 1s - loss: 0.0080 - mse: 0.00\n",
      "Epoch 4/100\n",
      "93/93 [==============================] - 9s 95ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0364\n",
      "Epoch 5/100\n",
      "93/93 [==============================] - 9s 95ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0261\n",
      "Epoch 6/100\n",
      "93/93 [==============================] - 8s 86ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0216\n",
      "Epoch 7/100\n",
      "93/93 [==============================] - 9s 93ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0203\n",
      "Epoch 8/100\n",
      "93/93 [==============================] - 9s 94ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0192\n",
      "Epoch 9/100\n",
      "93/93 [==============================] - 8s 89ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0190\n",
      "Epoch 10/100\n",
      "93/93 [==============================] - 9s 94ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0185\n",
      "Epoch 11/100\n",
      "93/93 [==============================] - 9s 94ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0184\n",
      "Epoch 12/100\n",
      "93/93 [==============================] - 8s 87ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0180\n",
      "Epoch 13/100\n",
      "93/93 [==============================] - 9s 95ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0178\n",
      "Epoch 14/100\n",
      "93/93 [==============================] - 9s 92ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0176\n",
      "Epoch 15/100\n",
      "93/93 [==============================] - 8s 84ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0170\n",
      "Epoch 16/100\n",
      "93/93 [==============================] - 9s 94ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0167\n",
      "Epoch 17/100\n",
      "93/93 [==============================] - 8s 91ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0169\n",
      "Epoch 18/100\n",
      "93/93 [==============================] - 8s 86ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0166\n",
      "Epoch 19/100\n",
      "93/93 [==============================] - 9s 95ms/step - loss: 9.8515e-04 - mse: 9.8515e-04 - mae: 0.0161\n",
      "Epoch 20/100\n",
      "93/93 [==============================] - 9s 93ms/step - loss: 9.9458e-04 - mse: 9.9458e-04 - mae: 0.0162\n",
      "Epoch 21/100\n",
      "93/93 [==============================] - 8s 88ms/step - loss: 9.8421e-04 - mse: 9.8421e-04 - mae: 0.0158\n",
      "Epoch 22/100\n",
      "93/93 [==============================] - 9s 94ms/step - loss: 9.7159e-04 - mse: 9.7159e-04 - mae: 0.0157: 1s - loss: 9.5592e-04 - mse: 9.5592e-04\n",
      "Epoch 23/100\n",
      "93/93 [==============================] - 9s 94ms/step - loss: 9.7554e-04 - mse: 9.7554e-04 - mae: 0.0157\n",
      "Epoch 24/100\n",
      "93/93 [==============================] - 8s 89ms/step - loss: 9.5988e-04 - mse: 9.5988e-04 - mae: 0.0156\n",
      "Epoch 25/100\n",
      "93/93 [==============================] - 8s 90ms/step - loss: 9.6304e-04 - mse: 9.6304e-04 - mae: 0.0154\n",
      "Epoch 26/100\n",
      "93/93 [==============================] - ETA: 0s - loss: 9.5583e-04 - mse: 9.5583e-04 - mae: 0.015 - 9s 94ms/step - loss: 9.5583e-04 - mse: 9.5583e-04 - mae: 0.0153\n",
      "Epoch 27/100\n",
      "93/93 [==============================] - 8s 91ms/step - loss: 9.4384e-04 - mse: 9.4384e-04 - mae: 0.0151\n",
      "Epoch 28/100\n",
      "93/93 [==============================] - 8s 88ms/step - loss: 9.2359e-04 - mse: 9.2359e-04 - mae: 0.0150\n",
      "Epoch 29/100\n",
      "93/93 [==============================] - 9s 95ms/step - loss: 9.1921e-04 - mse: 9.1921e-04 - mae: 0.0149\n",
      "Epoch 30/100\n",
      "93/93 [==============================] - 8s 88ms/step - loss: 9.7732e-04 - mse: 9.7732e-04 - mae: 0.0152\n",
      "Epoch 31/100\n",
      "93/93 [==============================] - 9s 96ms/step - loss: 8.9952e-04 - mse: 8.9952e-04 - mae: 0.0146: 2s - loss: 0.0010 -\n",
      "Epoch 32/100\n",
      "93/93 [==============================] - 9s 92ms/step - loss: 9.4297e-04 - mse: 9.4297e-04 - mae: 0.0153\n",
      "Epoch 33/100\n",
      "93/93 [==============================] - 9s 94ms/step - loss: 9.3912e-04 - mse: 9.3912e-04 - mae: 0.0149\n",
      "Epoch 34/100\n",
      "93/93 [==============================] - 9s 92ms/step - loss: 9.3372e-04 - mse: 9.3372e-04 - mae: 0.0147\n",
      "Epoch 35/100\n",
      "93/93 [==============================] - 9s 93ms/step - loss: 8.7766e-04 - mse: 8.7766e-04 - mae: 0.0141\n",
      "Epoch 36/100\n",
      "93/93 [==============================] - 8s 90ms/step - loss: 8.8580e-04 - mse: 8.8580e-04 - mae: 0.0143\n",
      "Epoch 37/100\n",
      "93/93 [==============================] - 8s 89ms/step - loss: 9.1266e-04 - mse: 9.1266e-04 - mae: 0.0143\n",
      "Epoch 38/100\n",
      "93/93 [==============================] - 9s 95ms/step - loss: 9.0403e-04 - mse: 9.0403e-04 - mae: 0.0143\n",
      "Epoch 39/100\n",
      "93/93 [==============================] - 9s 93ms/step - loss: 8.8472e-04 - mse: 8.8472e-04 - mae: 0.0142\n",
      "Epoch 40/100\n",
      "93/93 [==============================] - 8s 90ms/step - loss: 8.9358e-04 - mse: 8.9358e-04 - mae: 0.0142\n",
      "Epoch 41/100\n",
      "93/93 [==============================] - 9s 92ms/step - loss: 8.7989e-04 - mse: 8.7989e-04 - mae: 0.0141\n",
      "Epoch 42/100\n",
      "93/93 [==============================] - 9s 95ms/step - loss: 8.6739e-04 - mse: 8.6739e-04 - mae: 0.0139\n",
      "Epoch 43/100\n",
      "93/93 [==============================] - 8s 89ms/step - loss: 8.5673e-04 - mse: 8.5673e-04 - mae: 0.0140\n",
      "Epoch 44/100\n",
      "93/93 [==============================] - 8s 91ms/step - loss: 8.5675e-04 - mse: 8.5675e-04 - mae: 0.0138\n",
      "Epoch 45/100\n",
      "93/93 [==============================] - 8s 86ms/step - loss: 8.6400e-04 - mse: 8.6400e-04 - mae: 0.0138\n",
      "Epoch 46/100\n",
      "93/93 [==============================] - 8s 86ms/step - loss: 8.3603e-04 - mse: 8.3603e-04 - mae: 0.0138\n",
      "Epoch 47/100\n",
      "93/93 [==============================] - 8s 82ms/step - loss: 8.6721e-04 - mse: 8.6721e-04 - mae: 0.0138\n",
      "Epoch 48/100\n",
      "93/93 [==============================] - 8s 91ms/step - loss: 8.2211e-04 - mse: 8.2211e-04 - mae: 0.0135\n",
      "Epoch 49/100\n",
      "93/93 [==============================] - 8s 81ms/step - loss: 8.2768e-04 - mse: 8.2768e-04 - mae: 0.0136\n",
      "Epoch 50/100\n",
      "93/93 [==============================] - 8s 84ms/step - loss: 8.8335e-04 - mse: 8.8335e-04 - mae: 0.0138\n",
      "Epoch 51/100\n",
      "93/93 [==============================] - 8s 88ms/step - loss: 8.2690e-04 - mse: 8.2690e-04 - mae: 0.0134: 0s - loss: 8.8479e-04 - mse: 8.8479e-04 - ma\n",
      "Epoch 52/100\n",
      "93/93 [==============================] - 9s 91ms/step - loss: 8.3021e-04 - mse: 8.3021e-04 - mae: 0.0132\n",
      "Epoch 53/100\n",
      "93/93 [==============================] - 8s 84ms/step - loss: 9.0626e-04 - mse: 9.0626e-04 - mae: 0.0136\n",
      "Epoch 54/100\n",
      "93/93 [==============================] - 9s 93ms/step - loss: 8.4672e-04 - mse: 8.4672e-04 - mae: 0.0136\n",
      "Epoch 55/100\n",
      "93/93 [==============================] - 9s 98ms/step - loss: 7.9594e-04 - mse: 7.9594e-04 - mae: 0.0131\n",
      "Epoch 56/100\n",
      "93/93 [==============================] - 8s 85ms/step - loss: 8.5053e-04 - mse: 8.5053e-04 - mae: 0.0136\n",
      "Epoch 57/100\n",
      "93/93 [==============================] - 9s 92ms/step - loss: 8.2915e-04 - mse: 8.2915e-04 - mae: 0.0132\n",
      "Epoch 58/100\n",
      "93/93 [==============================] - 9s 92ms/step - loss: 8.3725e-04 - mse: 8.3725e-04 - mae: 0.0134\n",
      "Epoch 59/100\n",
      "93/93 [==============================] - 8s 88ms/step - loss: 8.0105e-04 - mse: 8.0105e-04 - mae: 0.0129\n",
      "Epoch 60/100\n",
      "93/93 [==============================] - 8s 86ms/step - loss: 8.3074e-04 - mse: 8.3074e-04 - mae: 0.0132\n",
      "Epoch 61/100\n",
      "93/93 [==============================] - 9s 92ms/step - loss: 8.0497e-04 - mse: 8.0497e-04 - mae: 0.0129\n",
      "Epoch 62/100\n",
      "93/93 [==============================] - 8s 85ms/step - loss: 8.7134e-04 - mse: 8.7134e-04 - mae: 0.0133\n",
      "Epoch 63/100\n",
      "93/93 [==============================] - 9s 94ms/step - loss: 7.7431e-04 - mse: 7.7431e-04 - mae: 0.0127\n",
      "Epoch 64/100\n",
      "93/93 [==============================] - 9s 93ms/step - loss: 8.4823e-04 - mse: 8.4823e-04 - mae: 0.0132\n",
      "Epoch 65/100\n",
      "93/93 [==============================] - 8s 84ms/step - loss: 8.0887e-04 - mse: 8.0887e-04 - mae: 0.0132\n",
      "Epoch 66/100\n",
      "93/93 [==============================] - 9s 95ms/step - loss: 8.1521e-04 - mse: 8.1521e-04 - mae: 0.0130\n",
      "Epoch 67/100\n",
      "93/93 [==============================] - 8s 89ms/step - loss: 7.7671e-04 - mse: 7.7671e-04 - mae: 0.0127: 0s - loss: 8.2461e-04 - mse: 8.2461e-04 - mae\n",
      "Epoch 68/100\n",
      "93/93 [==============================] - 8s 86ms/step - loss: 7.7014e-04 - mse: 7.7014e-04 - mae: 0.0127\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 8s 90ms/step - loss: 8.6341e-04 - mse: 8.6341e-04 - mae: 0.0131\n",
      "Epoch 70/100\n",
      "93/93 [==============================] - 9s 92ms/step - loss: 8.3535e-04 - mse: 8.3535e-04 - mae: 0.0130\n",
      "Epoch 71/100\n",
      "93/93 [==============================] - 9s 91ms/step - loss: 7.6621e-04 - mse: 7.6621e-04 - mae: 0.0125\n",
      "Epoch 72/100\n",
      "93/93 [==============================] - 8s 85ms/step - loss: 7.7514e-04 - mse: 7.7514e-04 - mae: 0.0128\n",
      "Epoch 73/100\n",
      "93/93 [==============================] - 8s 91ms/step - loss: 8.2302e-04 - mse: 8.2302e-04 - mae: 0.0130\n",
      "Epoch 74/100\n",
      "93/93 [==============================] - 9s 94ms/step - loss: 7.7163e-04 - mse: 7.7163e-04 - mae: 0.0126\n",
      "Epoch 75/100\n",
      "93/93 [==============================] - 8s 83ms/step - loss: 8.4073e-04 - mse: 8.4073e-04 - mae: 0.0129\n",
      "Epoch 76/100\n",
      "93/93 [==============================] - 9s 92ms/step - loss: 7.9245e-04 - mse: 7.9245e-04 - mae: 0.0130\n",
      "Epoch 77/100\n",
      "93/93 [==============================] - 8s 88ms/step - loss: 7.8340e-04 - mse: 7.8340e-04 - mae: 0.0126\n",
      "Epoch 78/100\n",
      "93/93 [==============================] - 8s 88ms/step - loss: 8.3756e-04 - mse: 8.3756e-04 - mae: 0.0131\n",
      "Epoch 79/100\n",
      "93/93 [==============================] - 9s 92ms/step - loss: 7.7274e-04 - mse: 7.7274e-04 - mae: 0.0126\n",
      "Epoch 80/100\n",
      "93/93 [==============================] - 7s 73ms/step - loss: 7.4435e-04 - mse: 7.4435e-04 - mae: 0.0124\n",
      "Epoch 81/100\n",
      "93/93 [==============================] - 8s 88ms/step - loss: 8.1503e-04 - mse: 8.1503e-04 - mae: 0.0130\n",
      "Epoch 82/100\n",
      "93/93 [==============================] - 7s 80ms/step - loss: 7.3887e-04 - mse: 7.3887e-04 - mae: 0.0123\n",
      "Epoch 83/100\n",
      "93/93 [==============================] - 8s 86ms/step - loss: 8.3969e-04 - mse: 8.3969e-04 - mae: 0.0132\n",
      "Epoch 84/100\n",
      "93/93 [==============================] - 8s 86ms/step - loss: 7.7159e-04 - mse: 7.7159e-04 - mae: 0.0125\n",
      "Epoch 85/100\n",
      "93/93 [==============================] - 6s 62ms/step - loss: 7.7242e-04 - mse: 7.7242e-04 - mae: 0.0127\n",
      "Epoch 86/100\n",
      "93/93 [==============================] - 6s 62ms/step - loss: 8.3631e-04 - mse: 8.3631e-04 - mae: 0.0130\n",
      "Epoch 87/100\n",
      "93/93 [==============================] - 6s 68ms/step - loss: 7.3343e-04 - mse: 7.3343e-04 - mae: 0.0122\n",
      "Epoch 88/100\n",
      "93/93 [==============================] - 9s 94ms/step - loss: 8.0951e-04 - mse: 8.0951e-04 - mae: 0.0129\n",
      "Epoch 89/100\n",
      "93/93 [==============================] - 8s 90ms/step - loss: 7.9119e-04 - mse: 7.9119e-04 - mae: 0.0128\n",
      "Epoch 90/100\n",
      "93/93 [==============================] - 8s 88ms/step - loss: 7.9008e-04 - mse: 7.9008e-04 - mae: 0.0126\n",
      "Epoch 91/100\n",
      "93/93 [==============================] - 6s 67ms/step - loss: 7.2148e-04 - mse: 7.2148e-04 - mae: 0.0120\n",
      "Epoch 92/100\n",
      "93/93 [==============================] - 8s 85ms/step - loss: 7.2713e-04 - mse: 7.2713e-04 - mae: 0.0120\n",
      "Epoch 93/100\n",
      "84/93 [==========================>...] - ETA: 0s - loss: 8.3997e-04 - mse: 8.3997e-04 - mae: 0.0129"
     ]
    }
   ],
   "source": [
    "# function to split data into correct shape for RNN\n",
    "def split_data(X, y, steps):\n",
    "    X_, y_ = list(), list()\n",
    "    for i in range(steps, len(y)):\n",
    "        X_.append(X[i - steps : i, :])\n",
    "        y_.append(y[i]) \n",
    "    return np.array(X_), np.array(y_)\n",
    "\n",
    "def regressor_tunning(kernel_initializer = 'he_uniform',\n",
    "                      bias_initializer = initializers.Ones()):\n",
    "    model = Sequential()\n",
    "    if n_hidden == 0:\n",
    "        model.add(LSTM(units = units,                    \n",
    "                       input_shape = (steps, features_num), \n",
    "                       kernel_initializer = kernel_initializer,\n",
    "                       bias_initializer = bias_initializer))\n",
    "        model.add(LeakyReLU(alpha = 0.2))\n",
    "        model.add(Dropout(0.2))\n",
    "    else:\n",
    "        model.add(LSTM(units = units,                    \n",
    "                       input_shape = (steps, features_num), \n",
    "                       return_sequences = True,\n",
    "                       kernel_initializer = kernel_initializer,\n",
    "                       bias_initializer = bias_initializer))\n",
    "        model.add(LeakyReLU(alpha = 0.2))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(LSTM(units = units, \n",
    "                       input_shape = (steps, features_num), \n",
    "                       kernel_initializer = kernel_initializer,\n",
    "                       bias_initializer = bias_initializer))\n",
    "        model.add(LeakyReLU(alpha = 0.2))\n",
    "        model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    optimizer = optimizers.RMSprop()\n",
    "    model.compile(loss = 'mse', metrics = ['mse', 'mae'], optimizer = optimizer)\n",
    "    return model\n",
    "  \n",
    "# LOOP STARTS\n",
    "for i in date:\n",
    "    start_time = time.time()\n",
    "    # data\n",
    "    data = data_full.loc[data_full.index > i, :]\n",
    "\n",
    "    # reset index\n",
    "    data.reset_index(inplace = True)\n",
    "    data.drop('index', axis = 1, inplace = True)\n",
    "\n",
    "    # fill nan values in the whole data set\n",
    "    data.fillna(data.mean(), inplace = True)\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    # divide data into train and test \n",
    "    data_train, data_test = train_test_split(\n",
    "             data, test_size = 0.15, shuffle=False)  \n",
    "    \n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "    # data scaling  (including offer (y))\n",
    "    sc_X = MinMaxScaler()\n",
    "    data_train = sc_X.fit_transform(data_train)\n",
    "    data_test = sc_X.transform(data_test)\n",
    "    \n",
    "    # divide features and labels\n",
    "    X_train = data_train[:, 0:14] \n",
    "    y_train = data_train[:, -1]\n",
    "    X_test = data_test[:, 0:14] \n",
    "    y_test = data_test[:, -1] \n",
    "\n",
    "    # divide data into train and test \n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "             X_train, y_train, test_size = 0.10, shuffle=False)\n",
    "\n",
    "    # put data into correct shape\n",
    "    X_train, y_train = split_data(X_train, y_train, steps)\n",
    "    X_test, y_test = split_data(X_test, y_test, steps)\n",
    "    X_val, y_val = split_data(X_val, y_val, steps)\n",
    "\n",
    "    model = regressor_tunning()\n",
    "    \n",
    "    # fitting the LSTM to the training set\n",
    "    history = model.fit(X_train,\n",
    "                        y_train, \n",
    "                        batch_size = batch_size, \n",
    "                        epochs = epochs,\n",
    "                        shuffle = False)\n",
    "                        #validation_data = (X_val, y_val))\n",
    "    \n",
    "    model.reset_states()\n",
    "    \n",
    "    # make new predicitons with test set\n",
    "    y_pred = model.predict(X_test, batch_size = batch_size)\n",
    "    \n",
    "    # prices col = 15 (inverso should not be used as scalling was made with the whole data set)\n",
    "    y_pred = (y_pred * sc_X.data_range_[14]) + (sc_X.data_min_[14])\n",
    "    y_test = (y_test * sc_X.data_range_[14]) + (sc_X.data_min_[14])\n",
    "\n",
    "    # smal adjustment\n",
    "    y_test = pd.Series(y_test)\n",
    "    y_test.replace(0, 0.0001,inplace = True)\n",
    "    \n",
    "    y_pred_list.append(y_pred)\n",
    "    \n",
    "    from sklearn.metrics import mean_squared_error as mse\n",
    "    from sklearn.metrics import mean_absolute_error as mae\n",
    "\n",
    "    rmse_error = mse(y_test, y_pred, squared = False)\n",
    "    mae_error = mae(y_test, y_pred)\n",
    "    \n",
    "    rmse_gen.append(rmse_error)\n",
    "    mae_gen.append(mae_error)\n",
    "    \n",
    "    # =============================================================================\n",
    "    # Metrics evaluation on spike regions\n",
    "    # =============================================================================\n",
    "    \n",
    "    # Need to process data with spike occurences the same way as features\n",
    "    data = pd.read_csv('Spike_binary_1std.csv', index_col = 0)\n",
    "\n",
    "    # set predictive window according with tuning best results\n",
    "    data = data.loc[data.index > i, :]\n",
    "\n",
    "    # make sure shaded area will correspond to values outputed by LSTM\n",
    "    data.reset_index(drop = True, inplace = True)\n",
    "\n",
    "    # fill_nan is already made - so lets split data into test and train\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    # divide data into train and test \n",
    "    shade_train, shade_test = train_test_split(\n",
    "             data, test_size = 0.15, shuffle = False)\n",
    "\n",
    "    # reset index of testing data\n",
    "    shade_test.reset_index(drop = True, inplace = True)\n",
    "\n",
    "    # function to split data into correct shape for RNN\n",
    "    def split_data_shade(shade_test, steps):\n",
    "        y_spike_occ = list()\n",
    "        upper_lim = list()\n",
    "        lower_lim = list()\n",
    "        for i in range(steps, len(shade_test.index)):\n",
    "            y_spike_occ.append(shade_test['spike_occurance'][i])\n",
    "            upper_lim.append(shade_test['spike_upperlim'][i])\n",
    "            lower_lim.append(shade_test['spike_lowerlim'][i])\n",
    "        return np.array(y_spike_occ), np.array(upper_lim), np.array(lower_lim)\n",
    "    \n",
    "    # shape y_spike_occ for the right size to compare results in normal and spike regions\n",
    "    y_spike_occ, spike_upperlim, spike_lowerlim = split_data_shade(shade_test, steps)\n",
    "\n",
    "    # continue\n",
    "    \n",
    "    # select y_pred and y_test only for regions with spikes\n",
    "    y_test_spike = (y_test.T * y_spike_occ).T\n",
    "    y_pred_spike = (y_pred.T * y_spike_occ).T\n",
    "    y_test_spike = y_test_spike[y_test_spike != 0]\n",
    "    y_pred_spike = y_pred_spike[y_pred_spike != 0]\n",
    "    \n",
    "    # calculate metric\n",
    "    rmse_spike = mse(y_test_spike, y_pred_spike, squared = False)\n",
    "    mae_spike = mae(y_test_spike, y_pred_spike)\n",
    "    \n",
    "    rmse_spi.append(rmse_spike)\n",
    "    mae_spi.append(mae_spike)\n",
    "    \n",
    "    # =============================================================================\n",
    "    # Metric evaluation on normal regions\n",
    "    # =============================================================================\n",
    "    \n",
    "    # inverse y_spike_occ so the only normal occurences are chosen\n",
    "    y_normal_occ = (y_spike_occ - 1) * (-1)\n",
    "    \n",
    "    # sanity check\n",
    "    y_normal_occ.sum() + y_spike_occ.sum() # gives the correct total \n",
    "    \n",
    "    # select y_pred and y_test only for normal regions\n",
    "    y_test_normal = (y_test.T * y_normal_occ).T\n",
    "    y_pred_normal = (y_pred.T * y_normal_occ).T\n",
    "    y_test_normal = y_test_normal[y_test_normal != 0.00]\n",
    "    y_pred_normal = y_pred_normal[y_pred_normal != 0.00]\n",
    "    \n",
    "    # calculate metric\n",
    "    rmse_normal = mse(y_test_normal, y_pred_normal, squared = False)\n",
    "    mae_normal = mae(y_test_normal, y_pred_normal)\n",
    "    \n",
    "    rmse_nor.append(rmse_normal)\n",
    "    mae_nor.append(mae_normal)\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    time_count.append(elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({                        \n",
    "                        'rmse_general': rmse_gen, \n",
    "                 \n",
    "                        'mae_general': mae_gen,\n",
    "                        \n",
    "                        'rmse_spike': rmse_spi,\n",
    "                 \n",
    "                        'mae_spike': mae_spi,\n",
    "                        \n",
    "                        'rmse_normal': rmse_nor,\n",
    "                    \n",
    "                        'mae_normal': mae_nor,\n",
    "    \n",
    "                        'time': time_count})\n",
    "\n",
    "\n",
    "results.to_csv('Results_LSTM_Prediction_window.csv')\n",
    "y_pred_list.to_csv('Predictions_LSTM_Prediciton_window.csv')\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_min(s):\n",
    "    '''\n",
    "    highlight the maximum in a Series yellow.\n",
    "    '''\n",
    "    is_max = s == s.min()\n",
    "    return ['background-color: yellow' if v else '' for v in is_max]\n",
    "\n",
    "results.style.apply(highlight_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "fontsize = 13\n",
    "\n",
    "date_labels =   ['12', \n",
    "                 '10', \n",
    "                 '8',\n",
    "                 '6', \n",
    "                 '4', \n",
    "                 '2']\n",
    "\n",
    "plt.figure(figsize=(10,3.5))\n",
    "plt.minorticks_on()\n",
    "plt.grid(which='major', linestyle='-', linewidth='0.5')\n",
    "plt.grid(which='minor', linestyle=':', linewidth='0.5')\n",
    "plt.title('ANN: Averaged RMSE for different prediction windows', fontsize = fontsize + 2)\n",
    "plt.plot([0,1,2,3,4,5], rmse_gen, label = 'On the whole test set')\n",
    "plt.plot([0,1,2,3,4,5], rmse_spi, label = 'Spike regions')\n",
    "plt.plot([0,1,2,3,4,5], rmse_nor, label = 'Non-spike regions')\n",
    "plt.legend(loc = 'upper right', fontsize = fontsize - 1)\n",
    "plt.ylabel('RMSE (£/MWh)', fontsize = fontsize)\n",
    "plt.xlabel('Predictive window (in months)', fontsize = fontsize)\n",
    "plt.xticks([0,1,2,3,4,5], list(np.arange(2, 14, 2))[::-1], fontsize = fontsize)\n",
    "plt.yticks(fontsize = fontsize)\n",
    "plt.xlim(0, 5)\n",
    "plt.tight_layout()\n",
    "plt.savefig('RMSE_predictive_window.png')\n",
    "\n",
    "plt.figure(figsize=(10,3.5))\n",
    "plt.minorticks_on()\n",
    "plt.grid(which='major', linestyle='-', linewidth='0.5')\n",
    "plt.grid(which='minor', linestyle=':', linewidth='0.5')\n",
    "plt.title('Random Forest: Averaged MAE for different prediction windows', fontsize = fontsize + 2)\n",
    "plt.plot([0,1,2,3,4,5], rmse_gen, label = 'On the whole test set')\n",
    "plt.plot([0,1,2,3,4,5], rmse_spi, label = 'Spike regions')\n",
    "plt.plot([0,1,2,3,4,5], rmse_nor, label = 'Non-spike regions')\n",
    "plt.legend(loc = 'upper right', fontsize = fontsize - 1)\n",
    "plt.ylabel('MAE (£/MWh)', fontsize = fontsize)\n",
    "plt.xlabel('Predictive window (in months)', fontsize = fontsize)\n",
    "plt.xticks([0,1,2,3,4,5], list(np.arange(2, 14, 2))[::-1], fontsize = fontsize)\n",
    "plt.yticks(fontsize = fontsize)\n",
    "plt.xlim(0, 5)\n",
    "plt.tight_layout()\n",
    "plt.savefig('MAE_predictive_window.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "plt.plot(y_pred)\n",
    "plt.plot(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
