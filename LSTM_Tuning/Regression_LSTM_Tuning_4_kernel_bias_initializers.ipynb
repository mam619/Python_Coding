{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Parameter Tuning\n",
    "    \n",
    "    Look for the best kernel initializer and bias initializer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\maria\\anaconda3\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from pandas) (1.18.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from python-dateutil>=2.6.1->pandas) (1.14.0)\n",
      "Requirement already satisfied: sklearn in c:\\users\\maria\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\maria\\anaconda3\\lib\\site-packages (from sklearn) (0.22.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (0.14.1)\n",
      "Requirement already satisfied: numpy>=1.11.0 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.18.1)\n",
      "Requirement already satisfied: scipy>=0.17.0 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.4.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\maria\\anaconda3\\lib\\site-packages (3.1.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: numpy>=1.11 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from matplotlib) (1.18.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from matplotlib) (2.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: six in c:\\users\\maria\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib) (1.14.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\maria\\anaconda3\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib) (45.2.0.post20200210)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install sklearn\n",
    "!pip install matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd;\n",
    "import numpy as np;\n",
    "import sklearn\n",
    "\n",
    "# parameters\n",
    "steps = 48\n",
    "n_hidden = 2\n",
    "units = 100\n",
    "batch_size = 48\n",
    "features_num = 14\n",
    "\n",
    "# months to evaluate model on\n",
    "date = 2018090000\n",
    "\n",
    "# lists to append results\n",
    "mae_gen = []\n",
    "mae_nor = []\n",
    "mae_spi = []\n",
    "rmse_gen = []\n",
    "rmse_nor = []\n",
    "rmse_spi = []\n",
    "y_pred_list = []\n",
    "time_count = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data; set X and y; fill nan values and split in test and training  data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "data = pd.read_csv('Data_set_1_smaller_(1).csv', index_col = 0)\n",
    "\n",
    "# data\n",
    "data = data.loc[data.index > date, :]\n",
    "\n",
    "# reset index\n",
    "data.reset_index(inplace = True)\n",
    "data.drop('index', axis = 1, inplace = True)\n",
    "\n",
    "# fill nan values\n",
    "data.fillna(data.mean(), inplace = True)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# divide data into train and test \n",
    "data_train, data_test = train_test_split(\n",
    "         data, test_size = 0.15, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply feature scaling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# data scaling  (including offer (y))\n",
    "sc_X = MinMaxScaler()\n",
    "data_train = sc_X.fit_transform(data_train)\n",
    "data_test = sc_X.transform(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the Keras libraries and packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LeakyReLU\n",
    "from keras import initializers\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Need to process data with spike occurences the same way as features and offers:\n",
    "(Required to evaluate predictions in both normal regions and spike regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data for shaded area\n",
    "data = pd.read_csv('Spike_binary_1std.csv', index_col = 0)\n",
    "\n",
    "# set predictive window according with tuning best results\n",
    "data = data.loc[data.index > date, :]\n",
    "\n",
    "# make sure shaded area will correspond to values outputed by LSTM\n",
    "data.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# fill_nan is already made - so lets split data into test and train\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# divide data into train and test \n",
    "shade_train, shade_test = train_test_split(\n",
    "         data, test_size = 0.15, shuffle = False)\n",
    "\n",
    "# reset index of testing data\n",
    "shade_test.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# function to split data into correct shape for RNN\n",
    "def split_data(shade_test, steps):\n",
    "    y_spike_occ = list()\n",
    "    upper_lim = list()\n",
    "    lower_lim = list()\n",
    "    for i in range(steps, len(shade_test.index)):\n",
    "        y_spike_occ.append(shade_test['spike_occurance'][i])\n",
    "        upper_lim.append(shade_test['spike_upperlim'][i])\n",
    "        lower_lim.append(shade_test['spike_lowerlim'][i])\n",
    "    return np.array(y_spike_occ), np.array(upper_lim), np.array(lower_lim)\n",
    "\n",
    "# function to cut data set so it can be divisible by the batch_size\n",
    "def cut_data(data, batch_size):\n",
    "     # see if it is divisivel\n",
    "    condition = data.shape[0] % batch_size\n",
    "    if condition == 0:\n",
    "        return data\n",
    "    else:\n",
    "        return data[: -condition]\n",
    "\n",
    "# shape y_spike_occ for the right size to compare results in normal and spike regions\n",
    "y_spike_occ, spike_upperlim, spike_lowerlim = split_data(shade_test, steps)\n",
    "y_spike_occ = cut_data(y_spike_occ, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create regressor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0310 - val_loss: 5.6415e-04 - val_mse: 5.6415e-04 - val_mae: 0.0126\n",
      "Epoch 2/100\n",
      "87/87 [==============================] - 10s 118ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0224 - val_loss: 5.0598e-04 - val_mse: 5.0598e-04 - val_mae: 0.0116\n",
      "Epoch 3/100\n",
      "87/87 [==============================] - 10s 110ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0203 - val_loss: 4.0239e-04 - val_mse: 4.0239e-04 - val_mae: 0.0120\n",
      "Epoch 4/100\n",
      "87/87 [==============================] - 8s 93ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0191 - val_loss: 3.9946e-04 - val_mse: 3.9946e-04 - val_mae: 0.0122\n",
      "Epoch 5/100\n",
      "87/87 [==============================] - 8s 90ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0184 - val_loss: 4.0671e-04 - val_mse: 4.0671e-04 - val_mae: 0.0125\n",
      "Epoch 6/100\n",
      "87/87 [==============================] - 8s 91ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0181 - val_loss: 4.0339e-04 - val_mse: 4.0339e-04 - val_mae: 0.0125 - ETA: 0s - loss: 0.0011 - mse: 0.0011 - mae: 0.018\n",
      "Epoch 7/100\n",
      "87/87 [==============================] - 8s 90ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0174 - val_loss: 3.9098e-04 - val_mse: 3.9098e-04 - val_mae: 0.0127\n",
      "Epoch 8/100\n",
      "87/87 [==============================] - 8s 93ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0172 - val_loss: 3.6822e-04 - val_mse: 3.6822e-04 - val_mae: 0.0120\n",
      "Epoch 9/100\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0170 - val_loss: 3.6382e-04 - val_mse: 3.6382e-04 - val_mae: 0.0118\n",
      "Epoch 10/100\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0165 - val_loss: 3.4973e-04 - val_mse: 3.4973e-04 - val_mae: 0.0118\n",
      "Epoch 11/100\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0163 - val_loss: 3.4737e-04 - val_mse: 3.4737e-04 - val_mae: 0.0117\n",
      "Epoch 12/100\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0161 - val_loss: 3.5169e-04 - val_mse: 3.5169e-04 - val_mae: 0.0122\n",
      "Epoch 13/100\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0161 - val_loss: 3.4548e-04 - val_mse: 3.4548e-04 - val_mae: 0.0120\n",
      "Epoch 14/100\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 9.9550e-04 - mse: 9.9550e-04 - mae: 0.0159 - val_loss: 3.4796e-04 - val_mse: 3.4796e-04 - val_mae: 0.0121\n",
      "Epoch 15/100\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 9.8756e-04 - mse: 9.8756e-04 - mae: 0.0158 - val_loss: 3.3728e-04 - val_mse: 3.3728e-04 - val_mae: 0.0115\n",
      "Epoch 16/100\n",
      "87/87 [==============================] - 9s 106ms/step - loss: 9.8495e-04 - mse: 9.8495e-04 - mae: 0.0157 - val_loss: 3.4193e-04 - val_mse: 3.4193e-04 - val_mae: 0.0121\n",
      "Epoch 17/100\n",
      "87/87 [==============================] - 9s 106ms/step - loss: 9.8004e-04 - mse: 9.8004e-04 - mae: 0.0157 - val_loss: 3.3412e-04 - val_mse: 3.3412e-04 - val_mae: 0.0117\n",
      "Epoch 18/100\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 9.6443e-04 - mse: 9.6443e-04 - mae: 0.0154 - val_loss: 3.3606e-04 - val_mse: 3.3606e-04 - val_mae: 0.0117\n",
      "Epoch 19/100\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 9.6987e-04 - mse: 9.6987e-04 - mae: 0.0155 - val_loss: 3.5575e-04 - val_mse: 3.5575e-04 - val_mae: 0.0129\n",
      "Epoch 20/100\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 9.6349e-04 - mse: 9.6349e-04 - mae: 0.0152 - val_loss: 3.2870e-04 - val_mse: 3.2870e-04 - val_mae: 0.0113\n",
      "Epoch 21/100\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 9.5802e-04 - mse: 9.5802e-04 - mae: 0.0153 - val_loss: 3.2329e-04 - val_mse: 3.2329e-04 - val_mae: 0.0114\n",
      "Epoch 22/100\n",
      "87/87 [==============================] - 9s 98ms/step - loss: 9.3238e-04 - mse: 9.3238e-04 - mae: 0.0150 - val_loss: 3.3558e-04 - val_mse: 3.3558e-04 - val_mae: 0.0118\n",
      "Epoch 23/100\n",
      "87/87 [==============================] - 8s 97ms/step - loss: 9.1902e-04 - mse: 9.1902e-04 - mae: 0.0149 - val_loss: 3.1049e-04 - val_mse: 3.1049e-04 - val_mae: 0.0114s: 7.2344e-04 - mse: 7.2344e-04 - mae: - ETA: 1s - loss: 9.3427e-04 - mse: 9.3427e-0\n",
      "Epoch 24/100\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 9.2175e-04 - mse: 9.2175e-04 - mae: 0.0148 - val_loss: 2.9219e-04 - val_mse: 2.9219e-04 - val_mae: 0.0109\n",
      "Epoch 25/100\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 9.1453e-04 - mse: 9.1453e-04 - mae: 0.0146 - val_loss: 2.7421e-04 - val_mse: 2.7421e-04 - val_mae: 0.0103\n",
      "Epoch 26/100\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 9.0291e-04 - mse: 9.0291e-04 - mae: 0.0143 - val_loss: 2.7946e-04 - val_mse: 2.7946e-04 - val_mae: 0.0107\n",
      "Epoch 27/100\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 8.5465e-04 - mse: 8.5465e-04 - mae: 0.0137 - val_loss: 2.9372e-04 - val_mse: 2.9372e-04 - val_mae: 0.0116\n",
      "Epoch 28/100\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 8.4976e-04 - mse: 8.4976e-04 - mae: 0.0136 - val_loss: 2.9556e-04 - val_mse: 2.9556e-04 - val_mae: 0.0108\n",
      "Epoch 29/100\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 8.5270e-04 - mse: 8.5270e-04 - mae: 0.0137 - val_loss: 2.7272e-04 - val_mse: 2.7272e-04 - val_mae: 0.0101\n",
      "Epoch 30/100\n",
      "87/87 [==============================] - 8s 97ms/step - loss: 8.8313e-04 - mse: 8.8313e-04 - mae: 0.0139 - val_loss: 2.7865e-04 - val_mse: 2.7865e-04 - val_mae: 0.0103\n",
      "Epoch 31/100\n",
      "87/87 [==============================] - 8s 97ms/step - loss: 8.8581e-04 - mse: 8.8581e-04 - mae: 0.0139 - val_loss: 2.7985e-04 - val_mse: 2.7985e-04 - val_mae: 0.0102mse: 6.9399e-04 - mae:  - ETA: 1s - loss: 6.6607e-04 - mse: 6\n",
      "Epoch 32/100\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 8.6783e-04 - mse: 8.6783e-04 - mae: 0.0136 - val_loss: 2.9290e-04 - val_mse: 2.9290e-04 - val_mae: 0.0106\n",
      "Epoch 33/100\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 8.3578e-04 - mse: 8.3578e-04 - mae: 0.0134 - val_loss: 2.9418e-04 - val_mse: 2.9418e-04 - val_mae: 0.0107\n",
      "Epoch 34/100\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 8.6391e-04 - mse: 8.6391e-04 - mae: 0.0136 - val_loss: 2.8405e-04 - val_mse: 2.8405e-04 - val_mae: 0.0105\n",
      "Epoch 35/100\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 8.4452e-04 - mse: 8.4452e-04 - mae: 0.0134 - val_loss: 2.9552e-04 - val_mse: 2.9552e-04 - val_mae: 0.0108\n",
      "Epoch 36/100\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 8.0709e-04 - mse: 8.0709e-04 - mae: 0.0130 - val_loss: 2.9028e-04 - val_mse: 2.9028e-04 - val_mae: 0.0113\n",
      "Epoch 37/100\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 8.3117e-04 - mse: 8.3117e-04 - mae: 0.0133 - val_loss: 2.8546e-04 - val_mse: 2.8546e-04 - val_mae: 0.0100\n",
      "Epoch 38/100\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 8.2272e-04 - mse: 8.2272e-04 - mae: 0.0133 - val_loss: 2.9951e-04 - val_mse: 2.9951e-04 - val_mae: 0.0106\n",
      "Epoch 39/100\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 8.3024e-04 - mse: 8.3024e-04 - mae: 0.0134 - val_loss: 2.6245e-04 - val_mse: 2.6245e-04 - val_mae: 0.0098\n",
      "Epoch 40/100\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 7.9887e-04 - mse: 7.9887e-04 - mae: 0.0130 - val_loss: 2.9678e-04 - val_mse: 2.9678e-04 - val_mae: 0.0113\n",
      "Epoch 41/100\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 8.0598e-04 - mse: 8.0598e-04 - mae: 0.0131 - val_loss: 2.8753e-04 - val_mse: 2.8753e-04 - val_mae: 0.0103se: 6.\n",
      "Epoch 42/100\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 8.1351e-04 - mse: 8.1351e-04 - mae: 0.0131 - val_loss: 2.9230e-04 - val_mse: 2.9230e-04 - val_mae: 0.0100\n",
      "Epoch 43/100\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 8.3601e-04 - mse: 8.3601e-04 - mae: 0.0133 - val_loss: 2.6220e-04 - val_mse: 2.6220e-04 - val_mae: 0.0100\n",
      "Epoch 44/100\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 8.1107e-04 - mse: 8.1107e-04 - mae: 0.0132 - val_loss: 2.7914e-04 - val_mse: 2.7914e-04 - val_mae: 0.0101- loss: 8.5483e-04 - mse: 8.5483e-0\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 8s 95ms/step - loss: 7.8724e-04 - mse: 7.8724e-04 - mae: 0.0130 - val_loss: 3.0705e-04 - val_mse: 3.0705e-04 - val_mae: 0.0111\n",
      "Epoch 46/100\n",
      "87/87 [==============================] - 9s 98ms/step - loss: 8.0937e-04 - mse: 8.0937e-04 - mae: 0.0131 - val_loss: 2.8286e-04 - val_mse: 2.8286e-04 - val_mae: 0.0103\n",
      "Epoch 47/100\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 8.1231e-04 - mse: 8.1231e-04 - mae: 0.0132 - val_loss: 2.5436e-04 - val_mse: 2.5436e-04 - val_mae: 0.0097\n",
      "Epoch 48/100\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 8.1387e-04 - mse: 8.1387e-04 - mae: 0.0132 - val_loss: 2.8957e-04 - val_mse: 2.8957e-04 - val_mae: 0.0104\n",
      "Epoch 49/100\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 7.9188e-04 - mse: 7.9188e-04 - mae: 0.0129 - val_loss: 3.0028e-04 - val_mse: 3.0028e-04 - val_mae: 0.0107\n",
      "Epoch 50/100\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 8.0246e-04 - mse: 8.0246e-04 - mae: 0.0131 - val_loss: 2.6302e-04 - val_mse: 2.6302e-04 - val_mae: 0.0098\n",
      "Epoch 51/100\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 7.8281e-04 - mse: 7.8281e-04 - mae: 0.0129 - val_loss: 3.0977e-04 - val_mse: 3.0977e-04 - val_mae: 0.01100\n",
      "Epoch 52/100\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 7.7623e-04 - mse: 7.7623e-04 - mae: 0.0128 - val_loss: 3.7152e-04 - val_mse: 3.7152e-04 - val_mae: 0.0124\n",
      "Epoch 53/100\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 8.0521e-04 - mse: 8.0521e-04 - mae: 0.0132 - val_loss: 3.1066e-04 - val_mse: 3.1066e-04 - val_mae: 0.0110\n",
      "Epoch 54/100\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 8.3188e-04 - mse: 8.3188e-04 - mae: 0.0129 - val_loss: 2.8659e-04 - val_mse: 2.8659e-04 - val_mae: 0.0100\n",
      "Epoch 55/100\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 7.8722e-04 - mse: 7.8722e-04 - mae: 0.0127 - val_loss: 2.8436e-04 - val_mse: 2.8436e-04 - val_mae: 0.0103\n",
      "Epoch 56/100\n",
      "87/87 [==============================] - 8s 93ms/step - loss: 7.7558e-04 - mse: 7.7558e-04 - mae: 0.0128 - val_loss: 3.3646e-04 - val_mse: 3.3646e-04 - val_mae: 0.0112\n",
      "Epoch 57/100\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 8.0604e-04 - mse: 8.0604e-04 - mae: 0.0130 - val_loss: 2.8226e-04 - val_mse: 2.8226e-04 - val_mae: 0.0103\n",
      "Epoch 58/100\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 8.3594e-04 - mse: 8.3594e-04 - mae: 0.0131 - val_loss: 2.9912e-04 - val_mse: 2.9912e-04 - val_mae: 0.0104\n",
      "Epoch 59/100\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 7.9111e-04 - mse: 7.9111e-04 - mae: 0.0128 - val_loss: 2.6357e-04 - val_mse: 2.6357e-04 - val_mae: 0.0099\n",
      "Epoch 60/100\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 7.8327e-04 - mse: 7.8327e-04 - mae: 0.0128 - val_loss: 3.4216e-04 - val_mse: 3.4216e-04 - val_mae: 0.0113\n",
      "Epoch 61/100\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 8.0934e-04 - mse: 8.0934e-04 - mae: 0.0129 - val_loss: 3.1366e-04 - val_mse: 3.1366e-04 - val_mae: 0.01110691e\n",
      "Epoch 62/100\n",
      "87/87 [==============================] - 8s 93ms/step - loss: 7.8299e-04 - mse: 7.8299e-04 - mae: 0.0127 - val_loss: 3.3479e-04 - val_mse: 3.3479e-04 - val_mae: 0.0114\n",
      "Epoch 63/100\n",
      "87/87 [==============================] - 8s 97ms/step - loss: 7.8437e-04 - mse: 7.8437e-04 - mae: 0.0128 - val_loss: 3.0096e-04 - val_mse: 3.0096e-04 - val_mae: 0.0106\n",
      "Epoch 64/100\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 7.7416e-04 - mse: 7.7416e-04 - mae: 0.0127 - val_loss: 2.7964e-04 - val_mse: 2.7964e-04 - val_mae: 0.0107\n",
      "Epoch 65/100\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 7.6089e-04 - mse: 7.6089e-04 - mae: 0.0125 - val_loss: 3.5332e-04 - val_mse: 3.5332e-04 - val_mae: 0.0123\n",
      "Epoch 66/100\n",
      "87/87 [==============================] - 9s 98ms/step - loss: 8.1416e-04 - mse: 8.1416e-04 - mae: 0.0129 - val_loss: 3.3253e-04 - val_mse: 3.3253e-04 - val_mae: 0.0111\n",
      "Epoch 67/100\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 7.7327e-04 - mse: 7.7326e-04 - mae: 0.0126 - val_loss: 2.8710e-04 - val_mse: 2.8710e-04 - val_mae: 0.0110\n",
      "Epoch 68/100\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 7.5067e-04 - mse: 7.5067e-04 - mae: 0.0125 - val_loss: 3.0165e-04 - val_mse: 3.0165e-04 - val_mae: 0.0108\n",
      "Epoch 69/100\n",
      "87/87 [==============================] - 8s 93ms/step - loss: 7.4529e-04 - mse: 7.4529e-04 - mae: 0.0123 - val_loss: 3.1839e-04 - val_mse: 3.1839e-04 - val_mae: 0.0114\n",
      "Epoch 70/100\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 7.5602e-04 - mse: 7.5602e-04 - mae: 0.0126 - val_loss: 3.2682e-04 - val_mse: 3.2682e-04 - val_mae: 0.0113\n",
      "Epoch 71/100\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 7.7409e-04 - mse: 7.7409e-04 - mae: 0.0126 - val_loss: 3.1275e-04 - val_mse: 3.1275e-04 - val_mae: 0.0113\n",
      "Epoch 72/100\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 7.5613e-04 - mse: 7.5613e-04 - mae: 0.0126 - val_loss: 3.0957e-04 - val_mse: 3.0957e-04 - val_mae: 0.0109\n",
      "Epoch 73/100\n",
      "87/87 [==============================] - 8s 93ms/step - loss: 7.5504e-04 - mse: 7.5504e-04 - mae: 0.0126 - val_loss: 4.1339e-04 - val_mse: 4.1339e-04 - val_mae: 0.0129\n",
      "Epoch 74/100\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 8.0596e-04 - mse: 8.0596e-04 - mae: 0.0126 - val_loss: 3.7188e-04 - val_mse: 3.7188e-04 - val_mae: 0.0124\n",
      "Epoch 75/100\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 7.7334e-04 - mse: 7.7334e-04 - mae: 0.0124 - val_loss: 3.2022e-04 - val_mse: 3.2022e-04 - val_mae: 0.0112\n",
      "Epoch 76/100\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 7.9965e-04 - mse: 7.9965e-04 - mae: 0.0126 - val_loss: 3.6763e-04 - val_mse: 3.6763e-04 - val_mae: 0.0125\n",
      "Epoch 77/100\n",
      "87/87 [==============================] - 8s 93ms/step - loss: 7.5294e-04 - mse: 7.5294e-04 - mae: 0.0123 - val_loss: 3.1479e-04 - val_mse: 3.1479e-04 - val_mae: 0.0113e-04 - mse\n",
      "Epoch 78/100\n",
      "87/87 [==============================] - 8s 92ms/step - loss: 8.2587e-04 - mse: 8.2587e-04 - mae: 0.0129 - val_loss: 3.3369e-04 - val_mse: 3.3369e-04 - val_mae: 0.0117\n",
      "Epoch 79/100\n",
      "87/87 [==============================] - 8s 93ms/step - loss: 7.6109e-04 - mse: 7.6109e-04 - mae: 0.0124 - val_loss: 4.2173e-04 - val_mse: 4.2173e-04 - val_mae: 0.0130\n",
      "Epoch 80/100\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 7.5521e-04 - mse: 7.5521e-04 - mae: 0.0125 - val_loss: 3.2061e-04 - val_mse: 3.2061e-04 - val_mae: 0.0114\n",
      "Epoch 81/100\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 7.5657e-04 - mse: 7.5657e-04 - mae: 0.0122 - val_loss: 3.3550e-04 - val_mse: 3.3550e-04 - val_mae: 0.0118\n",
      "Epoch 82/100\n",
      "87/87 [==============================] - 8s 92ms/step - loss: 7.2032e-04 - mse: 7.2032e-04 - mae: 0.0122 - val_loss: 4.1395e-04 - val_mse: 4.1395e-04 - val_mae: 0.0125\n",
      "Epoch 83/100\n",
      "87/87 [==============================] - 8s 93ms/step - loss: 7.7209e-04 - mse: 7.7209e-04 - mae: 0.0124 - val_loss: 3.7254e-04 - val_mse: 3.7254e-04 - val_mae: 0.0123\n",
      "Epoch 84/100\n",
      "87/87 [==============================] - 8s 91ms/step - loss: 7.3273e-04 - mse: 7.3273e-04 - mae: 0.0122 - val_loss: 3.4605e-04 - val_mse: 3.4605e-04 - val_mae: 0.0114\n",
      "Epoch 85/100\n",
      "87/87 [==============================] - 8s 92ms/step - loss: 7.2309e-04 - mse: 7.2309e-04 - mae: 0.0123 - val_loss: 3.6872e-04 - val_mse: 3.6872e-04 - val_mae: 0.0120\n",
      "Epoch 86/100\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 7.6283e-04 - mse: 7.6283e-04 - mae: 0.0125 - val_loss: 3.5943e-04 - val_mse: 3.5943e-04 - val_mae: 0.0119\n",
      "Epoch 87/100\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 7.2707e-04 - mse: 7.2707e-04 - mae: 0.0121 - val_loss: 3.6778e-04 - val_mse: 3.6778e-04 - val_mae: 0.0115\n",
      "Epoch 88/100\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 7.2395e-04 - mse: 7.2395e-04 - mae: 0.0122 - val_loss: 3.9495e-04 - val_mse: 3.9495e-04 - val_mae: 0.0126\n",
      "Epoch 89/100\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 7.1220e-04 - mse: 7.1220e-04 - mae: 0.0123 - val_loss: 3.3088e-04 - val_mse: 3.3088e-04 - val_mae: 0.0118\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 8s 92ms/step - loss: 6.9970e-04 - mse: 6.9970e-04 - mae: 0.0121 - val_loss: 3.6862e-04 - val_mse: 3.6862e-04 - val_mae: 0.0121\n",
      "Epoch 91/100\n",
      "87/87 [==============================] - 8s 92ms/step - loss: 6.9271e-04 - mse: 6.9271e-04 - mae: 0.0120 - val_loss: 3.7993e-04 - val_mse: 3.7993e-04 - val_mae: 0.0118\n",
      "Epoch 92/100\n",
      "87/87 [==============================] - 8s 92ms/step - loss: 7.1011e-04 - mse: 7.1011e-04 - mae: 0.0121 - val_loss: 4.3992e-04 - val_mse: 4.3992e-04 - val_mae: 0.0138\n",
      "Epoch 93/100\n",
      "87/87 [==============================] - 8s 91ms/step - loss: 6.9597e-04 - mse: 6.9597e-04 - mae: 0.0123 - val_loss: 4.1083e-04 - val_mse: 4.1083e-04 - val_mae: 0.0118\n",
      "Epoch 94/100\n",
      "87/87 [==============================] - 8s 92ms/step - loss: 6.8899e-04 - mse: 6.8899e-04 - mae: 0.0121 - val_loss: 5.3930e-04 - val_mse: 5.3930e-04 - val_mae: 0.0141\n",
      "Epoch 95/100\n",
      "87/87 [==============================] - 8s 92ms/step - loss: 6.8044e-04 - mse: 6.8044e-04 - mae: 0.0122 - val_loss: 3.9381e-04 - val_mse: 3.9381e-04 - val_mae: 0.0114\n",
      "Epoch 96/100\n",
      "87/87 [==============================] - 8s 93ms/step - loss: 6.1888e-04 - mse: 6.1888e-04 - mae: 0.0121 - val_loss: 4.8031e-04 - val_mse: 4.8031e-04 - val_mae: 0.0114\n",
      "Epoch 97/100\n",
      "87/87 [==============================] - 8s 97ms/step - loss: 6.1459e-04 - mse: 6.1459e-04 - mae: 0.0119 - val_loss: 3.8273e-04 - val_mse: 3.8273e-04 - val_mae: 0.0126\n",
      "Epoch 98/100\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 7.5713e-04 - mse: 7.5713e-04 - mae: 0.0119 - val_loss: 3.3352e-04 - val_mse: 3.3352e-04 - val_mae: 0.0113\n",
      "Epoch 99/100\n",
      "87/87 [==============================] - 8s 91ms/step - loss: 6.7283e-04 - mse: 6.7283e-04 - mae: 0.0121 - val_loss: 4.9631e-04 - val_mse: 4.9631e-04 - val_mae: 0.0143\n",
      "Epoch 100/100\n",
      "87/87 [==============================] - 8s 92ms/step - loss: 6.5929e-04 - mse: 6.5929e-04 - mae: 0.0117 - val_loss: 3.7951e-04 - val_mse: 3.7951e-04 - val_mae: 0.0124\n",
      "Epoch 1/100\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0382 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0249\n",
      "Epoch 2/100\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0242 - val_loss: 6.9970e-04 - val_mse: 6.9970e-04 - val_mae: 0.0162\n",
      "Epoch 3/100\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0216 - val_loss: 5.6667e-04 - val_mse: 5.6667e-04 - val_mae: 0.0129\n",
      "Epoch 4/100\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0201 - val_loss: 4.2819e-04 - val_mse: 4.2819e-04 - val_mae: 0.0114\n",
      "Epoch 5/100\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0190 - val_loss: 4.1121e-04 - val_mse: 4.1121e-04 - val_mae: 0.0117\n",
      "Epoch 6/100\n",
      "87/87 [==============================] - 8s 97ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0186 - val_loss: 3.8925e-04 - val_mse: 3.8925e-04 - val_mae: 0.0118\n",
      "Epoch 7/100\n",
      "87/87 [==============================] - 8s 98ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0180 - val_loss: 3.8244e-04 - val_mse: 3.8244e-04 - val_mae: 0.0117\n",
      "Epoch 8/100\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0178 - val_loss: 3.7003e-04 - val_mse: 3.7003e-04 - val_mae: 0.0121\n",
      "Epoch 9/100\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0174 - val_loss: 3.8113e-04 - val_mse: 3.8113e-04 - val_mae: 0.0122\n",
      "Epoch 10/100\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0171 - val_loss: 3.8027e-04 - val_mse: 3.8027e-04 - val_mae: 0.0124\n",
      "Epoch 11/100\n",
      "87/87 [==============================] - 9s 98ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0171 - val_loss: 3.6289e-04 - val_mse: 3.6289e-04 - val_mae: 0.0122\n",
      "Epoch 12/100\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0168 - val_loss: 3.5957e-04 - val_mse: 3.5957e-04 - val_mae: 0.0119\n",
      "Epoch 13/100\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0165 - val_loss: 3.7027e-04 - val_mse: 3.7027e-04 - val_mae: 0.0126\n",
      "Epoch 14/100\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0163 - val_loss: 3.4066e-04 - val_mse: 3.4066e-04 - val_mae: 0.0118\n",
      "Epoch 15/100\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0160 - val_loss: 3.4221e-04 - val_mse: 3.4221e-04 - val_mae: 0.0121\n",
      "Epoch 16/100\n",
      "87/87 [==============================] - 8s 97ms/step - loss: 9.9491e-04 - mse: 9.9491e-04 - mae: 0.0159 - val_loss: 3.3115e-04 - val_mse: 3.3115e-04 - val_mae: 0.0117\n",
      "Epoch 17/100\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 9.9210e-04 - mse: 9.9210e-04 - mae: 0.0158 - val_loss: 3.3604e-04 - val_mse: 3.3604e-04 - val_mae: 0.0117\n",
      "Epoch 18/100\n",
      "87/87 [==============================] - 8s 97ms/step - loss: 9.7966e-04 - mse: 9.7966e-04 - mae: 0.0156 - val_loss: 3.2966e-04 - val_mse: 3.2966e-04 - val_mae: 0.0115\n",
      "Epoch 19/100\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 9.5838e-04 - mse: 9.5838e-04 - mae: 0.0151 - val_loss: 3.3026e-04 - val_mse: 3.3026e-04 - val_mae: 0.0121\n",
      "Epoch 20/100\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 9.5191e-04 - mse: 9.5191e-04 - mae: 0.0150 - val_loss: 2.9665e-04 - val_mse: 2.9665e-04 - val_mae: 0.0108\n",
      "Epoch 21/100\n",
      "87/87 [==============================] - 8s 97ms/step - loss: 9.3246e-04 - mse: 9.3246e-04 - mae: 0.0148 - val_loss: 2.9916e-04 - val_mse: 2.9916e-04 - val_mae: 0.0110\n",
      "Epoch 22/100\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 9.1242e-04 - mse: 9.1242e-04 - mae: 0.0144 - val_loss: 2.8213e-04 - val_mse: 2.8213e-04 - val_mae: 0.0103\n",
      "Epoch 23/100\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 9.1270e-04 - mse: 9.1270e-04 - mae: 0.0143 - val_loss: 2.6048e-04 - val_mse: 2.6048e-04 - val_mae: 0.0098\n",
      "Epoch 24/100\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 9.0358e-04 - mse: 9.0358e-04 - mae: 0.0142 - val_loss: 2.5773e-04 - val_mse: 2.5773e-04 - val_mae: 0.0100\n",
      "Epoch 25/100\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 8.8793e-04 - mse: 8.8793e-04 - mae: 0.0140 - val_loss: 2.6519e-04 - val_mse: 2.6519e-04 - val_mae: 0.0097\n",
      "Epoch 26/100\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 9.1345e-04 - mse: 9.1345e-04 - mae: 0.0143 - val_loss: 2.7869e-04 - val_mse: 2.7869e-04 - val_mae: 0.0099137e-04 - mse: - ETA: 0s - loss: 8.7372e-04 - mse: 8.7372e-04 -\n",
      "Epoch 27/100\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 9.0216e-04 - mse: 9.0216e-04 - mae: 0.0140 - val_loss: 2.5750e-04 - val_mse: 2.5750e-04 - val_mae: 0.0099\n",
      "Epoch 28/100\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 8.9497e-04 - mse: 8.9497e-04 - mae: 0.0140 - val_loss: 2.5652e-04 - val_mse: 2.5652e-04 - val_mae: 0.0097\n",
      "Epoch 29/100\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 8.4661e-04 - mse: 8.4661e-04 - mae: 0.0135 - val_loss: 2.6579e-04 - val_mse: 2.6579e-04 - val_mae: 0.0102\n",
      "Epoch 30/100\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 8.7838e-04 - mse: 8.7838e-04 - mae: 0.0138 - val_loss: 2.6934e-04 - val_mse: 2.6934e-04 - val_mae: 0.0097\n",
      "Epoch 31/100\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 8.3386e-04 - mse: 8.3386e-04 - mae: 0.0134 - val_loss: 2.6734e-04 - val_mse: 2.6734e-04 - val_mae: 0.0106\n",
      "Epoch 32/100\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 8.5774e-04 - mse: 8.5774e-04 - mae: 0.0138 - val_loss: 2.6188e-04 - val_mse: 2.6188e-04 - val_mae: 0.0098\n",
      "Epoch 33/100\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 8.5920e-04 - mse: 8.5920e-04 - mae: 0.0135 - val_loss: 2.7381e-04 - val_mse: 2.7381e-04 - val_mae: 0.00998.6834e-04 - mse: 8.6834e-0\n",
      "Epoch 34/100\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 8.6122e-04 - mse: 8.6122e-04 - mae: 0.0135 - val_loss: 2.7926e-04 - val_mse: 2.7926e-04 - val_mae: 0.0101\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 8s 97ms/step - loss: 8.0999e-04 - mse: 8.0999e-04 - mae: 0.0131 - val_loss: 2.8623e-04 - val_mse: 2.8623e-04 - val_mae: 0.0106\n",
      "Epoch 36/100\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 8.2787e-04 - mse: 8.2787e-04 - mae: 0.0135 - val_loss: 2.9983e-04 - val_mse: 2.9983e-04 - val_mae: 0.0114\n",
      "Epoch 37/100\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 8.4051e-04 - mse: 8.4051e-04 - mae: 0.0134 - val_loss: 2.8835e-04 - val_mse: 2.8835e-04 - val_mae: 0.0102\n",
      "Epoch 38/100\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 8.0355e-04 - mse: 8.0355e-04 - mae: 0.0129 - val_loss: 2.8985e-04 - val_mse: 2.8985e-04 - val_mae: 0.0108\n",
      "Epoch 39/100\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 8.3656e-04 - mse: 8.3656e-04 - mae: 0.0134 - val_loss: 2.6287e-04 - val_mse: 2.6287e-04 - val_mae: 0.0104\n",
      "Epoch 40/100\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 8.0920e-04 - mse: 8.0920e-04 - mae: 0.0132 - val_loss: 2.9579e-04 - val_mse: 2.9579e-04 - val_mae: 0.0108\n",
      "Epoch 41/100\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 8.0164e-04 - mse: 8.0164e-04 - mae: 0.0130 - val_loss: 3.1501e-04 - val_mse: 3.1501e-04 - val_mae: 0.0107\n",
      "Epoch 42/100\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 8.2966e-04 - mse: 8.2966e-04 - mae: 0.0133 - val_loss: 2.7182e-04 - val_mse: 2.7182e-04 - val_mae: 0.0104\n",
      "Epoch 43/100\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 8.3910e-04 - mse: 8.3910e-04 - mae: 0.0134 - val_loss: 3.1179e-04 - val_mse: 3.1179e-04 - val_mae: 0.0109.3743e-04 - mse: 6.\n",
      "Epoch 44/100\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 8.0642e-04 - mse: 8.0642e-04 - mae: 0.0130 - val_loss: 3.4014e-04 - val_mse: 3.4014e-04 - val_mae: 0.0117\n",
      "Epoch 45/100\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 8.1177e-04 - mse: 8.1177e-04 - mae: 0.0130 - val_loss: 2.7174e-04 - val_mse: 2.7174e-04 - val_mae: 0.0101\n",
      "Epoch 46/100\n",
      "87/87 [==============================] - 8s 98ms/step - loss: 8.1053e-04 - mse: 8.1053e-04 - mae: 0.0132 - val_loss: 2.9887e-04 - val_mse: 2.9887e-04 - val_mae: 0.0106\n",
      "Epoch 47/100\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 7.9584e-04 - mse: 7.9584e-04 - mae: 0.0128 - val_loss: 2.9712e-04 - val_mse: 2.9712e-04 - val_mae: 0.0108\n",
      "Epoch 48/100\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 7.9950e-04 - mse: 7.9950e-04 - mae: 0.0131 - val_loss: 3.4519e-04 - val_mse: 3.4519e-04 - val_mae: 0.0116\n",
      "Epoch 49/100\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 7.7508e-04 - mse: 7.7508e-04 - mae: 0.0128 - val_loss: 3.7906e-04 - val_mse: 3.7906e-04 - val_mae: 0.0122\n",
      "Epoch 50/100\n",
      "87/87 [==============================] - 8s 97ms/step - loss: 8.0836e-04 - mse: 8.0836e-04 - mae: 0.0129 - val_loss: 2.9698e-04 - val_mse: 2.9698e-04 - val_mae: 0.0107\n",
      "Epoch 51/100\n",
      "87/87 [==============================] - 8s 97ms/step - loss: 7.7429e-04 - mse: 7.7429e-04 - mae: 0.0128 - val_loss: 2.9489e-04 - val_mse: 2.9489e-04 - val_mae: 0.0101\n",
      "Epoch 52/100\n",
      "87/87 [==============================] - 8s 97ms/step - loss: 7.7817e-04 - mse: 7.7817e-04 - mae: 0.0128 - val_loss: 2.9517e-04 - val_mse: 2.9517e-04 - val_mae: 0.0107\n",
      "Epoch 53/100\n",
      "87/87 [==============================] - 8s 97ms/step - loss: 7.9288e-04 - mse: 7.9288e-04 - mae: 0.0129 - val_loss: 2.9171e-04 - val_mse: 2.9171e-04 - val_mae: 0.0108\n",
      "Epoch 54/100\n",
      "87/87 [==============================] - 8s 97ms/step - loss: 7.8243e-04 - mse: 7.8243e-04 - mae: 0.0129 - val_loss: 2.9803e-04 - val_mse: 2.9803e-04 - val_mae: 0.0106\n",
      "Epoch 55/100\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 7.6817e-04 - mse: 7.6817e-04 - mae: 0.0126 - val_loss: 3.6396e-04 - val_mse: 3.6396e-04 - val_mae: 0.0117: 8.6443e-04 - mse: 8.6443e-04 - mae: 0 - ETA: 1s - loss: 8.3219e-04 - mse: 8.3219e-0\n",
      "Epoch 56/100\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 8.1468e-04 - mse: 8.1468e-04 - mae: 0.0130 - val_loss: 3.1415e-04 - val_mse: 3.1415e-04 - val_mae: 0.0106\n",
      "Epoch 57/100\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 8.0209e-04 - mse: 8.0209e-04 - mae: 0.0129 - val_loss: 2.8477e-04 - val_mse: 2.8477e-04 - val_mae: 0.0103.3119e-04 - mse: 8.3119e-04 - mae: 0\n",
      "Epoch 58/100\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 7.7418e-04 - mse: 7.7418e-04 - mae: 0.0128 - val_loss: 2.9327e-04 - val_mse: 2.9327e-04 - val_mae: 0.0107\n",
      "Epoch 59/100\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 8.1346e-04 - mse: 8.1346e-04 - mae: 0.0127 - val_loss: 3.2893e-04 - val_mse: 3.2893e-04 - val_mae: 0.0108\n",
      "Epoch 60/100\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 7.7697e-04 - mse: 7.7697e-04 - mae: 0.0128 - val_loss: 4.4148e-04 - val_mse: 4.4148e-04 - val_mae: 0.0133\n",
      "Epoch 61/100\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 8.3853e-04 - mse: 8.3853e-04 - mae: 0.0131 - val_loss: 3.1016e-04 - val_mse: 3.1016e-04 - val_mae: 0.0105\n",
      "Epoch 62/100\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 7.5570e-04 - mse: 7.5570e-04 - mae: 0.0126 - val_loss: 3.1627e-04 - val_mse: 3.1627e-04 - val_mae: 0.0112oss: 6.5529e-04 - ms\n",
      "Epoch 63/100\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 7.9023e-04 - mse: 7.9023e-04 - mae: 0.0127 - val_loss: 3.1160e-04 - val_mse: 3.1160e-04 - val_mae: 0.0110\n",
      "Epoch 64/100\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 7.9179e-04 - mse: 7.9179e-04 - mae: 0.0128 - val_loss: 3.1865e-04 - val_mse: 3.1865e-04 - val_mae: 0.0109\n",
      "Epoch 65/100\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 8.3364e-04 - mse: 8.3364e-04 - mae: 0.0129 - val_loss: 3.0612e-04 - val_mse: 3.0612e-04 - val_mae: 0.01089821e-04 - mse: - ETA: 2s - loss: 6.4719e-04 - ms\n",
      "Epoch 66/100\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 7.5883e-04 - mse: 7.5883e-04 - mae: 0.0124 - val_loss: 3.1895e-04 - val_mse: 3.1895e-04 - val_mae: 0.0106\n",
      "Epoch 67/100\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 7.3425e-04 - mse: 7.3425e-04 - mae: 0.0122 - val_loss: 3.1333e-04 - val_mse: 3.1333e-04 - val_mae: 0.0111\n",
      "Epoch 68/100\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 7.9436e-04 - mse: 7.9436e-04 - mae: 0.0128 - val_loss: 3.4330e-04 - val_mse: 3.4330e-04 - val_mae: 0.0114\n",
      "Epoch 69/100\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 7.7558e-04 - mse: 7.7558e-04 - mae: 0.0126 - val_loss: 3.5008e-04 - val_mse: 3.5008e-04 - val_mae: 0.0114\n",
      "Epoch 70/100\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 7.8379e-04 - mse: 7.8379e-04 - mae: 0.0127 - val_loss: 3.1951e-04 - val_mse: 3.1951e-04 - val_mae: 0.0112\n",
      "Epoch 71/100\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 8.2912e-04 - mse: 8.2912e-04 - mae: 0.0129 - val_loss: 2.9870e-04 - val_mse: 2.9870e-04 - val_mae: 0.0108\n",
      "Epoch 72/100\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 7.4245e-04 - mse: 7.4245e-04 - mae: 0.0125 - val_loss: 3.6775e-04 - val_mse: 3.6775e-04 - val_mae: 0.0120\n",
      "Epoch 73/100\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 7.4401e-04 - mse: 7.4401e-04 - mae: 0.0126 - val_loss: 3.1756e-04 - val_mse: 3.1756e-04 - val_mae: 0.0109\n",
      "Epoch 74/100\n",
      "87/87 [==============================] - 9s 106ms/step - loss: 7.3578e-04 - mse: 7.3578e-04 - mae: 0.0124 - val_loss: 3.5873e-04 - val_mse: 3.5873e-04 - val_mae: 0.0114\n",
      "Epoch 75/100\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 7.4630e-04 - mse: 7.4630e-04 - mae: 0.0125 - val_loss: 3.3234e-04 - val_mse: 3.3234e-04 - val_mae: 0.0121\n",
      "Epoch 76/100\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 7.7031e-04 - mse: 7.7031e-04 - mae: 0.0126 - val_loss: 3.3367e-04 - val_mse: 3.3367e-04 - val_mae: 0.0119\n",
      "Epoch 77/100\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 7.2250e-04 - mse: 7.2250e-04 - mae: 0.0121 - val_loss: 3.5621e-04 - val_mse: 3.5621e-04 - val_mae: 0.0120\n",
      "Epoch 78/100\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 7.4821e-04 - mse: 7.4821e-04 - mae: 0.0126 - val_loss: 3.1027e-04 - val_mse: 3.1027e-04 - val_mae: 0.0111\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 8s 96ms/step - loss: 7.0642e-04 - mse: 7.0642e-04 - mae: 0.0124 - val_loss: 6.0526e-04 - val_mse: 6.0526e-04 - val_mae: 0.0131\n",
      "Epoch 80/100\n",
      "87/87 [==============================] - 8s 97ms/step - loss: 6.8537e-04 - mse: 6.8537e-04 - mae: 0.0125 - val_loss: 4.0560e-04 - val_mse: 4.0560e-04 - val_mae: 0.0125\n",
      "Epoch 81/100\n",
      "87/87 [==============================] - 8s 97ms/step - loss: 7.0156e-04 - mse: 7.0156e-04 - mae: 0.0126 - val_loss: 3.7074e-04 - val_mse: 3.7074e-04 - val_mae: 0.0112\n",
      "Epoch 82/100\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 7.5150e-04 - mse: 7.5150e-04 - mae: 0.0127 - val_loss: 9.4315e-04 - val_mse: 9.4315e-04 - val_mae: 0.0125\n",
      "Epoch 83/100\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 7.0157e-04 - mse: 7.0157e-04 - mae: 0.0124 - val_loss: 4.9103e-04 - val_mse: 4.9103e-04 - val_mae: 0.0145\n",
      "Epoch 84/100\n",
      "87/87 [==============================] - 8s 97ms/step - loss: 7.2871e-04 - mse: 7.2871e-04 - mae: 0.0125 - val_loss: 3.0516e-04 - val_mse: 3.0516e-04 - val_mae: 0.0109\n",
      "Epoch 85/100\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 7.0086e-04 - mse: 7.0086e-04 - mae: 0.0123 - val_loss: 3.4683e-04 - val_mse: 3.4683e-04 - val_mae: 0.0113\n",
      "Epoch 86/100\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 7.0635e-04 - mse: 7.0635e-04 - mae: 0.0122 - val_loss: 3.6141e-04 - val_mse: 3.6141e-04 - val_mae: 0.0123\n",
      "Epoch 87/100\n",
      "87/87 [==============================] - 9s 98ms/step - loss: 6.9272e-04 - mse: 6.9272e-04 - mae: 0.0124 - val_loss: 4.6325e-04 - val_mse: 4.6325e-04 - val_mae: 0.0141\n",
      "Epoch 88/100\n",
      "87/87 [==============================] - 8s 97ms/step - loss: 6.0086e-04 - mse: 6.0086e-04 - mae: 0.0120 - val_loss: 4.1421e-04 - val_mse: 4.1421e-04 - val_mae: 0.0125ss\n",
      "Epoch 89/100\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 6.0997e-04 - mse: 6.0997e-04 - mae: 0.0121 - val_loss: 3.8463e-04 - val_mse: 3.8463e-04 - val_mae: 0.0123\n",
      "Epoch 90/100\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 6.6796e-04 - mse: 6.6796e-04 - mae: 0.0122 - val_loss: 4.0127e-04 - val_mse: 4.0127e-04 - val_mae: 0.0118\n",
      "Epoch 91/100\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 6.0142e-04 - mse: 6.0142e-04 - mae: 0.0120 - val_loss: 5.0858e-04 - val_mse: 5.0858e-04 - val_mae: 0.0141\n",
      "Epoch 92/100\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 6.9480e-04 - mse: 6.9480e-04 - mae: 0.0121 - val_loss: 3.5231e-04 - val_mse: 3.5231e-04 - val_mae: 0.0116\n",
      "Epoch 93/100\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 6.8042e-04 - mse: 6.8042e-04 - mae: 0.0121 - val_loss: 3.1243e-04 - val_mse: 3.1243e-04 - val_mae: 0.0107\n",
      "Epoch 94/100\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 7.3541e-04 - mse: 7.3541e-04 - mae: 0.0117 - val_loss: 4.0996e-04 - val_mse: 4.0996e-04 - val_mae: 0.0127\n",
      "Epoch 95/100\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 6.4873e-04 - mse: 6.4873e-04 - mae: 0.0118 - val_loss: 4.0670e-04 - val_mse: 4.0670e-04 - val_mae: 0.0130\n",
      "Epoch 96/100\n",
      "87/87 [==============================] - 8s 97ms/step - loss: 6.7867e-04 - mse: 6.7867e-04 - mae: 0.0120 - val_loss: 3.6477e-04 - val_mse: 3.6477e-04 - val_mae: 0.0126\n",
      "Epoch 97/100\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 6.8595e-04 - mse: 6.8595e-04 - mae: 0.0120 - val_loss: 3.3073e-04 - val_mse: 3.3073e-04 - val_mae: 0.0111\n",
      "Epoch 98/100\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 6.3610e-04 - mse: 6.3610e-04 - mae: 0.0115 - val_loss: 3.9453e-04 - val_mse: 3.9453e-04 - val_mae: 0.0121\n",
      "Epoch 99/100\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 6.3416e-04 - mse: 6.3416e-04 - mae: 0.0117 - val_loss: 3.9208e-04 - val_mse: 3.9208e-04 - val_mae: 0.0120\n",
      "Epoch 100/100\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 7.0371e-04 - mse: 7.0371e-04 - mae: 0.0117 - val_loss: 3.7824e-04 - val_mse: 3.7824e-04 - val_mae: 0.0123\n",
      "Epoch 1/100\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0369 - val_loss: 7.6894e-04 - val_mse: 7.6894e-04 - val_mae: 0.0179\n",
      "Epoch 2/100\n",
      "87/87 [==============================] - 8s 91ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0239 - val_loss: 5.2596e-04 - val_mse: 5.2596e-04 - val_mae: 0.0120\n",
      "Epoch 3/100\n",
      "87/87 [==============================] - 8s 93ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0212 - val_loss: 4.8580e-04 - val_mse: 4.8580e-04 - val_mae: 0.0114\n",
      "Epoch 4/100\n",
      "87/87 [==============================] - 8s 93ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0195 - val_loss: 4.1422e-04 - val_mse: 4.1422e-04 - val_mae: 0.0119\n",
      "Epoch 5/100\n",
      "87/87 [==============================] - 8s 92ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0189 - val_loss: 4.0011e-04 - val_mse: 4.0011e-04 - val_mae: 0.0123\n",
      "Epoch 6/100\n",
      "87/87 [==============================] - 8s 93ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0184 - val_loss: 4.0406e-04 - val_mse: 4.0406e-04 - val_mae: 0.0125\n",
      "Epoch 7/100\n",
      "87/87 [==============================] - 8s 92ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0178 - val_loss: 3.9353e-04 - val_mse: 3.9353e-04 - val_mae: 0.0125 ETA: 0s - loss: 0.0010 - mse: 0.0010 - m\n",
      "Epoch 8/100\n",
      "87/87 [==============================] - 8s 90ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0174 - val_loss: 4.0548e-04 - val_mse: 4.0548e-04 - val_mae: 0.0126\n",
      "Epoch 9/100\n",
      "87/87 [==============================] - 8s 91ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0170 - val_loss: 3.9245e-04 - val_mse: 3.9245e-04 - val_mae: 0.0127\n",
      "Epoch 10/100\n",
      "87/87 [==============================] - 8s 89ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0168 - val_loss: 3.7351e-04 - val_mse: 3.7351e-04 - val_mae: 0.0124\n",
      "Epoch 11/100\n",
      "87/87 [==============================] - 8s 92ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0166 - val_loss: 3.6573e-04 - val_mse: 3.6573e-04 - val_mae: 0.0120\n",
      "Epoch 12/100\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0163 - val_loss: 3.7244e-04 - val_mse: 3.7244e-04 - val_mae: 0.0121\n",
      "Epoch 13/100\n",
      "87/87 [==============================] - 8s 92ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0162 - val_loss: 3.6892e-04 - val_mse: 3.6892e-04 - val_mae: 0.0119\n",
      "Epoch 14/100\n",
      "87/87 [==============================] - 8s 93ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0161 - val_loss: 3.6342e-04 - val_mse: 3.6342e-04 - val_mae: 0.0120\n",
      "Epoch 15/100\n",
      "87/87 [==============================] - 8s 90ms/step - loss: 9.9445e-04 - mse: 9.9445e-04 - mae: 0.0157 - val_loss: 3.5556e-04 - val_mse: 3.5556e-04 - val_mae: 0.0118\n",
      "Epoch 16/100\n",
      "87/87 [==============================] - 8s 90ms/step - loss: 9.9261e-04 - mse: 9.9261e-04 - mae: 0.0159 - val_loss: 3.5486e-04 - val_mse: 3.5486e-04 - val_mae: 0.0116\n",
      "Epoch 17/100\n",
      "87/87 [==============================] - 8s 92ms/step - loss: 9.8000e-04 - mse: 9.8000e-04 - mae: 0.0156 - val_loss: 3.5397e-04 - val_mse: 3.5397e-04 - val_mae: 0.0120\n",
      "Epoch 18/100\n",
      "87/87 [==============================] - 8s 92ms/step - loss: 9.6400e-04 - mse: 9.6400e-04 - mae: 0.0155 - val_loss: 3.4547e-04 - val_mse: 3.4547e-04 - val_mae: 0.0115\n",
      "Epoch 19/100\n",
      "87/87 [==============================] - 8s 91ms/step - loss: 9.6596e-04 - mse: 9.6596e-04 - mae: 0.0155 - val_loss: 3.5070e-04 - val_mse: 3.5070e-04 - val_mae: 0.0116\n",
      "Epoch 20/100\n",
      "87/87 [==============================] - 8s 89ms/step - loss: 9.7826e-04 - mse: 9.7826e-04 - mae: 0.0155 - val_loss: 3.3640e-04 - val_mse: 3.3640e-04 - val_mae: 0.0114\n",
      "Epoch 21/100\n",
      "87/87 [==============================] - 8s 91ms/step - loss: 9.4106e-04 - mse: 9.4106e-04 - mae: 0.0151 - val_loss: 3.5051e-04 - val_mse: 3.5051e-04 - val_mae: 0.0116\n",
      "Epoch 22/100\n",
      "87/87 [==============================] - 8s 93ms/step - loss: 9.5537e-04 - mse: 9.5537e-04 - mae: 0.0152 - val_loss: 3.4927e-04 - val_mse: 3.4927e-04 - val_mae: 0.0118\n",
      "Epoch 23/100\n",
      "87/87 [==============================] - 8s 91ms/step - loss: 9.5760e-04 - mse: 9.5760e-04 - mae: 0.0152 - val_loss: 3.3757e-04 - val_mse: 3.3757e-04 - val_mae: 0.0116\n",
      "Epoch 24/100\n",
      "87/87 [==============================] - 8s 92ms/step - loss: 9.2789e-04 - mse: 9.2789e-04 - mae: 0.0150 - val_loss: 3.5199e-04 - val_mse: 3.5199e-04 - val_mae: 0.0119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100\n",
      "87/87 [==============================] - 8s 89ms/step - loss: 9.3727e-04 - mse: 9.3727e-04 - mae: 0.0150 - val_loss: 3.2777e-04 - val_mse: 3.2777e-04 - val_mae: 0.0111\n",
      "Epoch 26/100\n",
      "87/87 [==============================] - 8s 91ms/step - loss: 9.1138e-04 - mse: 9.1138e-04 - mae: 0.0148 - val_loss: 3.4880e-04 - val_mse: 3.4880e-04 - val_mae: 0.0117\n",
      "Epoch 27/100\n",
      "87/87 [==============================] - 8s 97ms/step - loss: 8.9395e-04 - mse: 8.9395e-04 - mae: 0.0145 - val_loss: 3.4316e-04 - val_mse: 3.4316e-04 - val_mae: 0.0114\n",
      "Epoch 28/100\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 8.8357e-04 - mse: 8.8357e-04 - mae: 0.0143 - val_loss: 3.2505e-04 - val_mse: 3.2505e-04 - val_mae: 0.0112\n",
      "Epoch 29/100\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 8.7920e-04 - mse: 8.7920e-04 - mae: 0.0142 - val_loss: 3.1600e-04 - val_mse: 3.1600e-04 - val_mae: 0.0114\n",
      "Epoch 30/100\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 8.5704e-04 - mse: 8.5704e-04 - mae: 0.0138 - val_loss: 2.9357e-04 - val_mse: 2.9357e-04 - val_mae: 0.0108\n",
      "Epoch 31/100\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 8.6583e-04 - mse: 8.6583e-04 - mae: 0.0137 - val_loss: 2.6654e-04 - val_mse: 2.6654e-04 - val_mae: 0.0104\n",
      "Epoch 32/100\n",
      "87/87 [==============================] - 13s 151ms/step - loss: 8.4803e-04 - mse: 8.4803e-04 - mae: 0.0137 - val_loss: 2.8599e-04 - val_mse: 2.8599e-04 - val_mae: 0.0107\n",
      "Epoch 33/100\n",
      "87/87 [==============================] - 12s 140ms/step - loss: 8.3929e-04 - mse: 8.3929e-04 - mae: 0.0135 - val_loss: 2.6669e-04 - val_mse: 2.6669e-04 - val_mae: 0.0102\n",
      "Epoch 34/100\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 8.1708e-04 - mse: 8.1708e-04 - mae: 0.0134 - val_loss: 2.6959e-04 - val_mse: 2.6959e-04 - val_mae: 0.0099\n",
      "Epoch 35/100\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 8.3181e-04 - mse: 8.3181e-04 - mae: 0.0135 - val_loss: 2.6573e-04 - val_mse: 2.6573e-04 - val_mae: 0.0107\n",
      "Epoch 36/100\n",
      "87/87 [==============================] - 12s 140ms/step - loss: 8.0800e-04 - mse: 8.0800e-04 - mae: 0.0133 - val_loss: 2.8094e-04 - val_mse: 2.8094e-04 - val_mae: 0.0102\n",
      "Epoch 37/100\n",
      "87/87 [==============================] - 12s 141ms/step - loss: 8.2860e-04 - mse: 8.2860e-04 - mae: 0.0134 - val_loss: 2.7360e-04 - val_mse: 2.7360e-04 - val_mae: 0.0105\n",
      "Epoch 38/100\n",
      "87/87 [==============================] - 11s 124ms/step - loss: 8.2524e-04 - mse: 8.2524e-04 - mae: 0.0133 - val_loss: 3.0781e-04 - val_mse: 3.0781e-04 - val_mae: 0.0114\n",
      "Epoch 39/100\n",
      "87/87 [==============================] - 11s 131ms/step - loss: 8.2749e-04 - mse: 8.2749e-04 - mae: 0.0133 - val_loss: 2.7289e-04 - val_mse: 2.7289e-04 - val_mae: 0.0105\n",
      "Epoch 40/100\n",
      "87/87 [==============================] - 11s 122ms/step - loss: 8.2600e-04 - mse: 8.2600e-04 - mae: 0.0134 - val_loss: 3.0101e-04 - val_mse: 3.0101e-04 - val_mae: 0.0113\n",
      "Epoch 41/100\n",
      "87/87 [==============================] - 12s 142ms/step - loss: 8.2104e-04 - mse: 8.2104e-04 - mae: 0.0132 - val_loss: 2.7642e-04 - val_mse: 2.7642e-04 - val_mae: 0.0102\n",
      "Epoch 42/100\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 7.9552e-04 - mse: 7.9552e-04 - mae: 0.0131 - val_loss: 3.2058e-04 - val_mse: 3.2058e-04 - val_mae: 0.0120\n",
      "Epoch 43/100\n",
      "87/87 [==============================] - 12s 132ms/step - loss: 7.8422e-04 - mse: 7.8422e-04 - mae: 0.0128 - val_loss: 3.1749e-04 - val_mse: 3.1749e-04 - val_mae: 0.0115\n",
      "Epoch 44/100\n",
      "87/87 [==============================] - 12s 141ms/step - loss: 8.0504e-04 - mse: 8.0504e-04 - mae: 0.0131 - val_loss: 2.8499e-04 - val_mse: 2.8499e-04 - val_mae: 0.0111\n",
      "Epoch 45/100\n",
      "87/87 [==============================] - 9s 107ms/step - loss: 8.0408e-04 - mse: 8.0408e-04 - mae: 0.0130 - val_loss: 2.7046e-04 - val_mse: 2.7046e-04 - val_mae: 0.0103\n",
      "Epoch 46/100\n",
      "87/87 [==============================] - 10s 114ms/step - loss: 8.0133e-04 - mse: 8.0133e-04 - mae: 0.0132 - val_loss: 3.0931e-04 - val_mse: 3.0931e-04 - val_mae: 0.0111\n",
      "Epoch 47/100\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 7.8551e-04 - mse: 7.8551e-04 - mae: 0.0128 - val_loss: 3.4378e-04 - val_mse: 3.4378e-04 - val_mae: 0.0118\n",
      "Epoch 48/100\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 8.6723e-04 - mse: 8.6723e-04 - mae: 0.0132 - val_loss: 2.8621e-04 - val_mse: 2.8621e-04 - val_mae: 0.0109\n",
      "Epoch 49/100\n",
      "87/87 [==============================] - 11s 128ms/step - loss: 7.9686e-04 - mse: 7.9686e-04 - mae: 0.0129 - val_loss: 2.7248e-04 - val_mse: 2.7248e-04 - val_mae: 0.0103\n",
      "Epoch 50/100\n",
      "87/87 [==============================] - 12s 143ms/step - loss: 7.8196e-04 - mse: 7.8196e-04 - mae: 0.0128 - val_loss: 2.7971e-04 - val_mse: 2.7971e-04 - val_mae: 0.0101\n",
      "Epoch 51/100\n",
      "87/87 [==============================] - 13s 149ms/step - loss: 7.8303e-04 - mse: 7.8303e-04 - mae: 0.0127 - val_loss: 2.9029e-04 - val_mse: 2.9029e-04 - val_mae: 0.0110\n",
      "Epoch 52/100\n",
      "87/87 [==============================] - 10s 119ms/step - loss: 7.8633e-04 - mse: 7.8633e-04 - mae: 0.0127 - val_loss: 3.4513e-04 - val_mse: 3.4513e-04 - val_mae: 0.0124\n",
      "Epoch 53/100\n",
      "87/87 [==============================] - 13s 147ms/step - loss: 8.1625e-04 - mse: 8.1625e-04 - mae: 0.0131 - val_loss: 3.2172e-04 - val_mse: 3.2172e-04 - val_mae: 0.0121\n",
      "Epoch 54/100\n",
      "87/87 [==============================] - 13s 150ms/step - loss: 8.1913e-04 - mse: 8.1913e-04 - mae: 0.0129 - val_loss: 3.1311e-04 - val_mse: 3.1311e-04 - val_mae: 0.0113\n",
      "Epoch 55/100\n",
      "87/87 [==============================] - 11s 126ms/step - loss: 8.1919e-04 - mse: 8.1919e-04 - mae: 0.0129 - val_loss: 3.2415e-04 - val_mse: 3.2415e-04 - val_mae: 0.0119\n",
      "Epoch 56/100\n",
      "87/87 [==============================] - 12s 143ms/step - loss: 8.1983e-04 - mse: 8.1983e-04 - mae: 0.0130 - val_loss: 2.8843e-04 - val_mse: 2.8843e-04 - val_mae: 0.0104\n",
      "Epoch 57/100\n",
      "87/87 [==============================] - 13s 149ms/step - loss: 7.6529e-04 - mse: 7.6529e-04 - mae: 0.0125 - val_loss: 3.5786e-04 - val_mse: 3.5786e-04 - val_mae: 0.0132\n",
      "Epoch 58/100\n",
      "87/87 [==============================] - 10s 110ms/step - loss: 8.1498e-04 - mse: 8.1498e-04 - mae: 0.0131 - val_loss: 2.9704e-04 - val_mse: 2.9704e-04 - val_mae: 0.0109\n",
      "Epoch 59/100\n",
      "87/87 [==============================] - 12s 142ms/step - loss: 8.0427e-04 - mse: 8.0427e-04 - mae: 0.0129 - val_loss: 3.0491e-04 - val_mse: 3.0491e-04 - val_mae: 0.0113\n",
      "Epoch 60/100\n",
      "87/87 [==============================] - 12s 140ms/step - loss: 7.6478e-04 - mse: 7.6478e-04 - mae: 0.0127 - val_loss: 3.4164e-04 - val_mse: 3.4164e-04 - val_mae: 0.0128\n",
      "Epoch 61/100\n",
      "87/87 [==============================] - 11s 130ms/step - loss: 8.0542e-04 - mse: 8.0542e-04 - mae: 0.0128 - val_loss: 3.3048e-04 - val_mse: 3.3048e-04 - val_mae: 0.0117\n",
      "Epoch 62/100\n",
      "87/87 [==============================] - 13s 152ms/step - loss: 7.4070e-04 - mse: 7.4070e-04 - mae: 0.0127 - val_loss: 3.0814e-04 - val_mse: 3.0814e-04 - val_mae: 0.0112\n",
      "Epoch 63/100\n",
      "87/87 [==============================] - 13s 153ms/step - loss: 7.5682e-04 - mse: 7.5682e-04 - mae: 0.0127 - val_loss: 3.1848e-04 - val_mse: 3.1848e-04 - val_mae: 0.0110\n",
      "Epoch 64/100\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 7.3247e-04 - mse: 7.3247e-04 - mae: 0.0124 - val_loss: 4.1865e-04 - val_mse: 4.1865e-04 - val_mae: 0.0132\n",
      "Epoch 65/100\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 7.6361e-04 - mse: 7.6361e-04 - mae: 0.0129 - val_loss: 3.2831e-04 - val_mse: 3.2831e-04 - val_mae: 0.0120\n",
      "Epoch 66/100\n",
      "87/87 [==============================] - 13s 154ms/step - loss: 7.3953e-04 - mse: 7.3953e-04 - mae: 0.0127 - val_loss: 2.8490e-04 - val_mse: 2.8490e-04 - val_mae: 0.0106\n",
      "Epoch 67/100\n",
      "87/87 [==============================] - 13s 154ms/step - loss: 7.8317e-04 - mse: 7.8317e-04 - mae: 0.0128 - val_loss: 4.1685e-04 - val_mse: 4.1685e-04 - val_mae: 0.0129\n",
      "Epoch 68/100\n",
      "87/87 [==============================] - 13s 154ms/step - loss: 7.7751e-04 - mse: 7.7751e-04 - mae: 0.0128 - val_loss: 3.4834e-04 - val_mse: 3.4834e-04 - val_mae: 0.0122\n",
      "Epoch 69/100\n",
      "87/87 [==============================] - 13s 154ms/step - loss: 7.2434e-04 - mse: 7.2434e-04 - mae: 0.0126 - val_loss: 3.3213e-04 - val_mse: 3.3213e-04 - val_mae: 0.0119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/100\n",
      "87/87 [==============================] - 13s 154ms/step - loss: 7.0087e-04 - mse: 7.0087e-04 - mae: 0.0123 - val_loss: 5.2488e-04 - val_mse: 5.2488e-04 - val_mae: 0.0130\n",
      "Epoch 71/100\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 7.6921e-04 - mse: 7.6921e-04 - mae: 0.0129 - val_loss: 4.3564e-04 - val_mse: 4.3564e-04 - val_mae: 0.0126\n",
      "Epoch 72/100\n",
      "87/87 [==============================] - 8s 89ms/step - loss: 6.9209e-04 - mse: 6.9209e-04 - mae: 0.0126 - val_loss: 3.7271e-04 - val_mse: 3.7271e-04 - val_mae: 0.0121\n",
      "Epoch 73/100\n",
      "87/87 [==============================] - 8s 92ms/step - loss: 7.2208e-04 - mse: 7.2208e-04 - mae: 0.0124 - val_loss: 7.9403e-04 - val_mse: 7.9403e-04 - val_mae: 0.0151\n",
      "Epoch 74/100\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 6.6323e-04 - mse: 6.6323e-04 - mae: 0.0125 - val_loss: 4.1309e-04 - val_mse: 4.1309e-04 - val_mae: 0.0129\n",
      "Epoch 75/100\n",
      "87/87 [==============================] - 11s 131ms/step - loss: 7.3741e-04 - mse: 7.3741e-04 - mae: 0.0126 - val_loss: 7.9555e-04 - val_mse: 7.9555e-04 - val_mae: 0.0156\n",
      "Epoch 76/100\n",
      "87/87 [==============================] - 11s 129ms/step - loss: 6.8054e-04 - mse: 6.8054e-04 - mae: 0.0125 - val_loss: 4.4411e-04 - val_mse: 4.4411e-04 - val_mae: 0.0127\n",
      "Epoch 77/100\n",
      "87/87 [==============================] - 12s 142ms/step - loss: 6.8513e-04 - mse: 6.8513e-04 - mae: 0.0124 - val_loss: 6.5460e-04 - val_mse: 6.5460e-04 - val_mae: 0.0128\n",
      "Epoch 78/100\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 6.7330e-04 - mse: 6.7330e-04 - mae: 0.0122 - val_loss: 3.5005e-04 - val_mse: 3.5005e-04 - val_mae: 0.0125\n",
      "Epoch 79/100\n",
      "87/87 [==============================] - 11s 122ms/step - loss: 6.8470e-04 - mse: 6.8470e-04 - mae: 0.0124 - val_loss: 3.1705e-04 - val_mse: 3.1705e-04 - val_mae: 0.0119\n",
      "Epoch 80/100\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 6.4990e-04 - mse: 6.4990e-04 - mae: 0.0122 - val_loss: 4.8324e-04 - val_mse: 4.8324e-04 - val_mae: 0.0140\n",
      "Epoch 81/100\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 6.6871e-04 - mse: 6.6871e-04 - mae: 0.0123 - val_loss: 4.3375e-04 - val_mse: 4.3375e-04 - val_mae: 0.0122\n",
      "Epoch 82/100\n",
      "87/87 [==============================] - 11s 128ms/step - loss: 6.2954e-04 - mse: 6.2954e-04 - mae: 0.0123 - val_loss: 3.7179e-04 - val_mse: 3.7179e-04 - val_mae: 0.0130\n",
      "Epoch 83/100\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 6.7869e-04 - mse: 6.7869e-04 - mae: 0.0123 - val_loss: 3.2002e-04 - val_mse: 3.2002e-04 - val_mae: 0.0111\n",
      "Epoch 84/100\n",
      "87/87 [==============================] - 13s 150ms/step - loss: 6.9574e-04 - mse: 6.9574e-04 - mae: 0.0120 - val_loss: 4.2783e-04 - val_mse: 4.2783e-04 - val_mae: 0.0134\n",
      "Epoch 85/100\n",
      "87/87 [==============================] - 11s 122ms/step - loss: 6.3220e-04 - mse: 6.3220e-04 - mae: 0.0122 - val_loss: 3.7070e-04 - val_mse: 3.7070e-04 - val_mae: 0.0125\n",
      "Epoch 86/100\n",
      "87/87 [==============================] - 13s 147ms/step - loss: 7.2648e-04 - mse: 7.2648e-04 - mae: 0.0122 - val_loss: 3.8903e-04 - val_mse: 3.8903e-04 - val_mae: 0.0127\n",
      "Epoch 87/100\n",
      "87/87 [==============================] - 13s 153ms/step - loss: 6.1785e-04 - mse: 6.1785e-04 - mae: 0.0122 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0129\n",
      "Epoch 88/100\n",
      "87/87 [==============================] - 10s 118ms/step - loss: 5.9264e-04 - mse: 5.9264e-04 - mae: 0.0120 - val_loss: 3.2658e-04 - val_mse: 3.2658e-04 - val_mae: 0.0122\n",
      "Epoch 89/100\n",
      "87/87 [==============================] - 13s 146ms/step - loss: 6.6715e-04 - mse: 6.6715e-04 - mae: 0.0119 - val_loss: 3.5275e-04 - val_mse: 3.5275e-04 - val_mae: 0.0124\n",
      "Epoch 90/100\n",
      "87/87 [==============================] - 9s 98ms/step - loss: 6.7432e-04 - mse: 6.7432e-04 - mae: 0.0123 - val_loss: 4.0141e-04 - val_mse: 4.0141e-04 - val_mae: 0.0120\n",
      "Epoch 91/100\n",
      "87/87 [==============================] - 8s 90ms/step - loss: 6.7697e-04 - mse: 6.7697e-04 - mae: 0.0119 - val_loss: 4.5331e-04 - val_mse: 4.5331e-04 - val_mae: 0.0138\n",
      "Epoch 92/100\n",
      "87/87 [==============================] - 8s 89ms/step - loss: 6.2646e-04 - mse: 6.2646e-04 - mae: 0.0120 - val_loss: 4.0269e-04 - val_mse: 4.0269e-04 - val_mae: 0.0129\n",
      "Epoch 93/100\n",
      "87/87 [==============================] - 12s 142ms/step - loss: 6.9148e-04 - mse: 6.9148e-04 - mae: 0.0121 - val_loss: 4.0160e-04 - val_mse: 4.0160e-04 - val_mae: 0.0134\n",
      "Epoch 94/100\n",
      "87/87 [==============================] - 13s 149ms/step - loss: 5.8488e-04 - mse: 5.8488e-04 - mae: 0.0118 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0141\n",
      "Epoch 95/100\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 6.6684e-04 - mse: 6.6684e-04 - mae: 0.0118 - val_loss: 3.6012e-04 - val_mse: 3.6012e-04 - val_mae: 0.0125\n",
      "Epoch 96/100\n",
      "87/87 [==============================] - 11s 131ms/step - loss: 6.1624e-04 - mse: 6.1624e-04 - mae: 0.0117 - val_loss: 8.8533e-04 - val_mse: 8.8533e-04 - val_mae: 0.0135\n",
      "Epoch 97/100\n",
      "87/87 [==============================] - 13s 147ms/step - loss: 5.8719e-04 - mse: 5.8719e-04 - mae: 0.0120 - val_loss: 6.4253e-04 - val_mse: 6.4253e-04 - val_mae: 0.0145\n",
      "Epoch 98/100\n",
      "87/87 [==============================] - 11s 129ms/step - loss: 7.1814e-04 - mse: 7.1814e-04 - mae: 0.0122 - val_loss: 3.2938e-04 - val_mse: 3.2938e-04 - val_mae: 0.0123\n",
      "Epoch 99/100\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 6.5956e-04 - mse: 6.5956e-04 - mae: 0.0121 - val_loss: 4.7237e-04 - val_mse: 4.7237e-04 - val_mae: 0.0133\n",
      "Epoch 100/100\n",
      "87/87 [==============================] - 12s 142ms/step - loss: 5.8296e-04 - mse: 5.8296e-04 - mae: 0.0116 - val_loss: 3.8669e-04 - val_mse: 3.8669e-04 - val_mae: 0.0130\n",
      "Epoch 1/100\n",
      "87/87 [==============================] - 13s 147ms/step - loss: 0.8597 - mse: 0.8597 - mae: 0.7034 - val_loss: 0.0206 - val_mse: 0.0206 - val_mae: 0.1419\n",
      "Epoch 2/100\n",
      "87/87 [==============================] - 11s 126ms/step - loss: 0.3509 - mse: 0.3509 - mae: 0.4734 - val_loss: 5.4547e-04 - val_mse: 5.4547e-04 - val_mae: 0.0123\n",
      "Epoch 3/100\n",
      "87/87 [==============================] - 10s 119ms/step - loss: 0.2464 - mse: 0.2464 - mae: 0.3941 - val_loss: 0.0139 - val_mse: 0.0139 - val_mae: 0.1160\n",
      "Epoch 4/100\n",
      "87/87 [==============================] - 13s 150ms/step - loss: 0.1723 - mse: 0.1723 - mae: 0.3322 - val_loss: 8.7616e-04 - val_mse: 8.7616e-04 - val_mae: 0.0267\n",
      "Epoch 5/100\n",
      "87/87 [==============================] - 13s 153ms/step - loss: 0.1083 - mse: 0.1083 - mae: 0.2623 - val_loss: 0.0019 - val_mse: 0.0019 - val_mae: 0.0377\n",
      "Epoch 6/100\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.0633 - mse: 0.0633 - mae: 0.2007 - val_loss: 6.1576e-04 - val_mse: 6.1576e-04 - val_mae: 0.0216\n",
      "Epoch 7/100\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.0335 - mse: 0.0335 - mae: 0.1457 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0235\n",
      "Epoch 8/100\n",
      "87/87 [==============================] - 12s 140ms/step - loss: 0.0187 - mse: 0.0187 - mae: 0.1078 - val_loss: 0.0098 - val_mse: 0.0098 - val_mae: 0.0964\n",
      "Epoch 9/100\n",
      "87/87 [==============================] - 12s 136ms/step - loss: 0.0107 - mse: 0.0107 - mae: 0.0811 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0540\n",
      "Epoch 10/100\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.0067 - mse: 0.0067 - mae: 0.0630 - val_loss: 0.0024 - val_mse: 0.0024 - val_mae: 0.0467\n",
      "Epoch 11/100\n",
      "87/87 [==============================] - 12s 140ms/step - loss: 0.0051 - mse: 0.0051 - mae: 0.0554 - val_loss: 5.3225e-04 - val_mse: 5.3225e-04 - val_mae: 0.0190\n",
      "Epoch 12/100\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0493 - val_loss: 5.1533e-04 - val_mse: 5.1533e-04 - val_mae: 0.0119\n",
      "Epoch 13/100\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0462 - val_loss: 5.6570e-04 - val_mse: 5.6570e-04 - val_mae: 0.0201\n",
      "Epoch 14/100\n",
      "87/87 [==============================] - 12s 140ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0474 - val_loss: 4.6975e-04 - val_mse: 4.6975e-04 - val_mae: 0.0151\n",
      "Epoch 15/100\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0458 - val_loss: 6.4736e-04 - val_mse: 6.4736e-04 - val_mae: 0.0148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0439 - val_loss: 4.7623e-04 - val_mse: 4.7623e-04 - val_mae: 0.0129\n",
      "Epoch 17/100\n",
      "87/87 [==============================] - 12s 142ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0445 - val_loss: 5.1114e-04 - val_mse: 5.1114e-04 - val_mae: 0.0181\n",
      "Epoch 18/100\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0472 - val_loss: 5.7299e-04 - val_mse: 5.7299e-04 - val_mae: 0.0128\n",
      "Epoch 19/100\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0465 - val_loss: 6.2503e-04 - val_mse: 6.2503e-04 - val_mae: 0.0142\n",
      "Epoch 20/100\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0446 - val_loss: 4.6800e-04 - val_mse: 4.6800e-04 - val_mae: 0.0146\n",
      "Epoch 21/100\n",
      "87/87 [==============================] - 12s 132ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0454 - val_loss: 0.0041 - val_mse: 0.0041 - val_mae: 0.0606\n",
      "Epoch 22/100\n",
      "87/87 [==============================] - 11s 127ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0437 - val_loss: 4.9464e-04 - val_mse: 4.9464e-04 - val_mae: 0.0121\n",
      "Epoch 23/100\n",
      "87/87 [==============================] - 12s 141ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0460 - val_loss: 6.5285e-04 - val_mse: 6.5285e-04 - val_mae: 0.0150\n",
      "Epoch 24/100\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0474 - val_loss: 8.6741e-04 - val_mse: 8.6741e-04 - val_mae: 0.0202\n",
      "Epoch 25/100\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0477 - val_loss: 4.7348e-04 - val_mse: 4.7348e-04 - val_mae: 0.0131\n",
      "Epoch 26/100\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0443 - val_loss: 4.9575e-04 - val_mse: 4.9575e-04 - val_mae: 0.0173\n",
      "Epoch 27/100\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0452 - val_loss: 5.0831e-04 - val_mse: 5.0831e-04 - val_mae: 0.0119\n",
      "Epoch 28/100\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0476 - val_loss: 8.5103e-04 - val_mse: 8.5103e-04 - val_mae: 0.0199\n",
      "Epoch 29/100\n",
      "87/87 [==============================] - 11s 130ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0472 - val_loss: 4.7652e-04 - val_mse: 4.7652e-04 - val_mae: 0.0129\n",
      "Epoch 30/100\n",
      "87/87 [==============================] - 11s 129ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0456 - val_loss: 4.9433e-04 - val_mse: 4.9433e-04 - val_mae: 0.0121\n",
      "Epoch 31/100\n",
      "87/87 [==============================] - 11s 128ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0456 - val_loss: 5.2723e-04 - val_mse: 5.2723e-04 - val_mae: 0.0120\n",
      "Epoch 32/100\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0454 - val_loss: 5.8492e-04 - val_mse: 5.8492e-04 - val_mae: 0.0131\n",
      "Epoch 33/100\n",
      "87/87 [==============================] - 12s 140ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0462 - val_loss: 6.7346e-04 - val_mse: 6.7346e-04 - val_mae: 0.0155\n",
      "Epoch 34/100\n",
      "87/87 [==============================] - 12s 140ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0462 - val_loss: 4.8830e-04 - val_mse: 4.8830e-04 - val_mae: 0.0169\n",
      "Epoch 35/100\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0466 - val_loss: 5.1366e-04 - val_mse: 5.1366e-04 - val_mae: 0.0119\n",
      "Epoch 36/100\n",
      "87/87 [==============================] - 11s 126ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0452 - val_loss: 5.7767e-04 - val_mse: 5.7767e-04 - val_mae: 0.0129\n",
      "Epoch 37/100\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0446 - val_loss: 4.8083e-04 - val_mse: 4.8083e-04 - val_mae: 0.0126\n",
      "Epoch 38/100\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0445 - val_loss: 4.7047e-04 - val_mse: 4.7047e-04 - val_mae: 0.0135\n",
      "Epoch 39/100\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0461 - val_loss: 4.6777e-04 - val_mse: 4.6777e-04 - val_mae: 0.0145\n",
      "Epoch 40/100\n",
      "87/87 [==============================] - 12s 136ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0444 - val_loss: 6.3074e-04 - val_mse: 6.3074e-04 - val_mae: 0.0143\n",
      "Epoch 41/100\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0450 - val_loss: 5.7265e-04 - val_mse: 5.7265e-04 - val_mae: 0.0203\n",
      "Epoch 42/100\n",
      "87/87 [==============================] - 11s 124ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0468 - val_loss: 5.8796e-04 - val_mse: 5.8796e-04 - val_mae: 0.0132\n",
      "Epoch 43/100\n",
      "87/87 [==============================] - 12s 136ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0446 - val_loss: 4.9683e-04 - val_mse: 4.9683e-04 - val_mae: 0.0120\n",
      "Epoch 44/100\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0447 - val_loss: 6.0065e-04 - val_mse: 6.0065e-04 - val_mae: 0.0212\n",
      "Epoch 45/100\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0467 - val_loss: 4.9241e-04 - val_mse: 4.9241e-04 - val_mae: 0.0122\n",
      "Epoch 46/100\n",
      "87/87 [==============================] - 12s 136ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0449 - val_loss: 4.6830e-04 - val_mse: 4.6830e-04 - val_mae: 0.0147\n",
      "Epoch 47/100\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0447 - val_loss: 5.8538e-04 - val_mse: 5.8538e-04 - val_mae: 0.0131\n",
      "Epoch 48/100\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0450 - val_loss: 5.4382e-04 - val_mse: 5.4382e-04 - val_mae: 0.0123\n",
      "Epoch 49/100\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0457 - val_loss: 4.8054e-04 - val_mse: 4.8054e-04 - val_mae: 0.0127\n",
      "Epoch 50/100\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0456 - val_loss: 6.2234e-04 - val_mse: 6.2234e-04 - val_mae: 0.0141\n",
      "Epoch 51/100\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0452 - val_loss: 5.0739e-04 - val_mse: 5.0739e-04 - val_mae: 0.0119\n",
      "Epoch 52/100\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0455 - val_loss: 5.2903e-04 - val_mse: 5.2903e-04 - val_mae: 0.0121\n",
      "Epoch 53/100\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0456 - val_loss: 5.2622e-04 - val_mse: 5.2622e-04 - val_mae: 0.0120\n",
      "Epoch 54/100\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0459 - val_loss: 5.0025e-04 - val_mse: 5.0025e-04 - val_mae: 0.0120\n",
      "Epoch 55/100\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0455 - val_loss: 4.6796e-04 - val_mse: 4.6796e-04 - val_mae: 0.0146\n",
      "Epoch 56/100\n",
      "87/87 [==============================] - 12s 141ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0446 - val_loss: 4.7906e-04 - val_mse: 4.7906e-04 - val_mae: 0.0162\n",
      "Epoch 57/100\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0468 - val_loss: 4.9666e-04 - val_mse: 4.9666e-04 - val_mae: 0.0174\n",
      "Epoch 58/100\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0461 - val_loss: 4.6909e-04 - val_mse: 4.6909e-04 - val_mae: 0.0137\n",
      "Epoch 59/100\n",
      "87/87 [==============================] - 12s 142ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0446 - val_loss: 6.0489e-04 - val_mse: 6.0489e-04 - val_mae: 0.0136\n",
      "Epoch 60/100\n",
      "87/87 [==============================] - 12s 141ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0450 - val_loss: 4.6784e-04 - val_mse: 4.6784e-04 - val_mae: 0.0141\n",
      "Epoch 61/100\n",
      "87/87 [==============================] - 11s 131ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0478 - val_loss: 5.0875e-04 - val_mse: 5.0875e-04 - val_mae: 0.0119\n",
      "Epoch 62/100\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0443 - val_loss: 5.2955e-04 - val_mse: 5.2955e-04 - val_mae: 0.0121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/100\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0453 - val_loss: 4.9328e-04 - val_mse: 4.9328e-04 - val_mae: 0.0121\n",
      "Epoch 64/100\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0463 - val_loss: 6.5773e-04 - val_mse: 6.5773e-04 - val_mae: 0.0226\n",
      "Epoch 65/100\n",
      "87/87 [==============================] - 12s 141ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0474 - val_loss: 4.8766e-04 - val_mse: 4.8766e-04 - val_mae: 0.0123\n",
      "Epoch 66/100\n",
      "87/87 [==============================] - 12s 143ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0444 - val_loss: 4.8332e-04 - val_mse: 4.8332e-04 - val_mae: 0.0125\n",
      "Epoch 67/100\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0450 - val_loss: 4.7823e-04 - val_mse: 4.7823e-04 - val_mae: 0.0128\n",
      "Epoch 68/100\n",
      "87/87 [==============================] - 11s 122ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0447 - val_loss: 4.7330e-04 - val_mse: 4.7330e-04 - val_mae: 0.0131\n",
      "Epoch 69/100\n",
      "87/87 [==============================] - 12s 140ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0458 - val_loss: 6.0420e-04 - val_mse: 6.0420e-04 - val_mae: 0.0136\n",
      "Epoch 70/100\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0445 - val_loss: 5.8022e-04 - val_mse: 5.8022e-04 - val_mae: 0.0130\n",
      "Epoch 71/100\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0456 - val_loss: 4.7534e-04 - val_mse: 4.7534e-04 - val_mae: 0.0159\n",
      "Epoch 72/100\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0476 - val_loss: 4.7701e-04 - val_mse: 4.7701e-04 - val_mae: 0.0129\n",
      "Epoch 73/100\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0463 - val_loss: 6.1601e-04 - val_mse: 6.1601e-04 - val_mae: 0.0139\n",
      "Epoch 74/100\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0461 - val_loss: 5.0198e-04 - val_mse: 5.0198e-04 - val_mae: 0.0119\n",
      "Epoch 75/100\n",
      "87/87 [==============================] - 13s 146ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0443 - val_loss: 5.1753e-04 - val_mse: 5.1753e-04 - val_mae: 0.0120\n",
      "Epoch 76/100\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0450 - val_loss: 0.0037 - val_mse: 0.0037 - val_mae: 0.0567\n",
      "Epoch 77/100\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0431 - val_loss: 0.0082 - val_mse: 0.0082 - val_mae: 0.0878\n",
      "Epoch 78/100\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0432 - val_loss: 4.9117e-04 - val_mse: 4.9117e-04 - val_mae: 0.0171\n",
      "Epoch 79/100\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0445 - val_loss: 4.7194e-04 - val_mse: 4.7194e-04 - val_mae: 0.0133\n",
      "Epoch 80/100\n",
      "87/87 [==============================] - 12s 142ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0458 - val_loss: 4.8697e-04 - val_mse: 4.8697e-04 - val_mae: 0.0124\n",
      "Epoch 81/100\n",
      "87/87 [==============================] - 12s 144ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0455 - val_loss: 5.0198e-04 - val_mse: 5.0198e-04 - val_mae: 0.0119\n",
      "Epoch 82/100\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0453 - val_loss: 6.7025e-04 - val_mse: 6.7025e-04 - val_mae: 0.0154\n",
      "Epoch 83/100\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0450 - val_loss: 5.3889e-04 - val_mse: 5.3889e-04 - val_mae: 0.0122\n",
      "Epoch 84/100\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0458 - val_loss: 5.0943e-04 - val_mse: 5.0943e-04 - val_mae: 0.0119\n",
      "Epoch 85/100\n",
      "87/87 [==============================] - 12s 144ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0461 - val_loss: 5.1307e-04 - val_mse: 5.1307e-04 - val_mae: 0.0119\n",
      "Epoch 86/100\n",
      "87/87 [==============================] - 13s 146ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0441 - val_loss: 5.3865e-04 - val_mse: 5.3865e-04 - val_mae: 0.0122\n",
      "Epoch 87/100\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0462 - val_loss: 4.7768e-04 - val_mse: 4.7768e-04 - val_mae: 0.0128\n",
      "Epoch 88/100\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0449 - val_loss: 7.0742e-04 - val_mse: 7.0742e-04 - val_mae: 0.0164\n",
      "Epoch 89/100\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0475 - val_loss: 5.1132e-04 - val_mse: 5.1132e-04 - val_mae: 0.0119\n",
      "Epoch 90/100\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0455 - val_loss: 4.9911e-04 - val_mse: 4.9911e-04 - val_mae: 0.0120\n",
      "Epoch 91/100\n",
      "87/87 [==============================] - 21s 237ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0467 - val_loss: 4.8164e-04 - val_mse: 4.8164e-04 - val_mae: 0.0126\n",
      "Epoch 92/100\n",
      "87/87 [==============================] - 418s 5s/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0454 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0308\n",
      "Epoch 93/100\n",
      "87/87 [==============================] - 11s 132ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0476 - val_loss: 5.0206e-04 - val_mse: 5.0206e-04 - val_mae: 0.0177\n",
      "Epoch 94/100\n",
      "87/87 [==============================] - 12s 136ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0465 - val_loss: 5.6217e-04 - val_mse: 5.6217e-04 - val_mae: 0.0126\n",
      "Epoch 95/100\n",
      "87/87 [==============================] - 12s 143ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0458 - val_loss: 6.0057e-04 - val_mse: 6.0057e-04 - val_mae: 0.0135\n",
      "Epoch 96/100\n",
      "87/87 [==============================] - 12s 142ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0470 - val_loss: 9.0016e-04 - val_mse: 9.0016e-04 - val_mae: 0.0210\n",
      "Epoch 97/100\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0472 - val_loss: 4.6802e-04 - val_mse: 4.6802e-04 - val_mae: 0.0140\n",
      "Epoch 98/100\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0471 - val_loss: 5.5007e-04 - val_mse: 5.5007e-04 - val_mae: 0.0124\n",
      "Epoch 99/100\n",
      "87/87 [==============================] - 10s 119ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0458 - val_loss: 5.0345e-04 - val_mse: 5.0345e-04 - val_mae: 0.0119\n",
      "Epoch 100/100\n",
      "87/87 [==============================] - 11s 128ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0453 - val_loss: 6.0265e-04 - val_mse: 6.0265e-04 - val_mae: 0.0136\n",
      "Epoch 1/100\n",
      "87/87 [==============================] - 15s 167ms/step - loss: 0.4676 - mse: 0.4676 - mae: 0.5423 - val_loss: 0.0018 - val_mse: 0.0018 - val_mae: 0.0399\n",
      "Epoch 2/100\n",
      "87/87 [==============================] - 13s 155ms/step - loss: 0.3499 - mse: 0.3499 - mae: 0.4695 - val_loss: 0.0016 - val_mse: 0.0016 - val_mae: 0.0374\n",
      "Epoch 3/100\n",
      "87/87 [==============================] - 13s 148ms/step - loss: 0.2486 - mse: 0.2486 - mae: 0.3987 - val_loss: 8.2164e-04 - val_mse: 8.2164e-04 - val_mae: 0.0192\n",
      "Epoch 4/100\n",
      "87/87 [==============================] - 13s 155ms/step - loss: 0.1588 - mse: 0.1588 - mae: 0.3174 - val_loss: 4.6780e-04 - val_mse: 4.6780e-04 - val_mae: 0.0142\n",
      "Epoch 5/100\n",
      "87/87 [==============================] - 13s 153ms/step - loss: 0.0950 - mse: 0.0950 - mae: 0.2447 - val_loss: 0.0016 - val_mse: 0.0016 - val_mae: 0.0333\n",
      "Epoch 6/100\n",
      "87/87 [==============================] - 13s 149ms/step - loss: 0.0517 - mse: 0.0517 - mae: 0.1803 - val_loss: 0.0040 - val_mse: 0.0040 - val_mae: 0.0609\n",
      "Epoch 7/100\n",
      "87/87 [==============================] - 13s 149ms/step - loss: 0.0285 - mse: 0.0285 - mae: 0.1332 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0314\n",
      "Epoch 8/100\n",
      "87/87 [==============================] - 13s 151ms/step - loss: 0.0155 - mse: 0.0155 - mae: 0.0976 - val_loss: 4.6769e-04 - val_mse: 4.6769e-04 - val_mae: 0.0143\n",
      "Epoch 9/100\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 0.0093 - mse: 0.0093 - mae: 0.0754 - val_loss: 0.0069 - val_mse: 0.0069 - val_mae: 0.0810\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 13s 147ms/step - loss: 0.0062 - mse: 0.0062 - mae: 0.0604 - val_loss: 0.0040 - val_mse: 0.0040 - val_mae: 0.0616\n",
      "Epoch 11/100\n",
      "87/87 [==============================] - 13s 150ms/step - loss: 0.0047 - mse: 0.0047 - mae: 0.0535 - val_loss: 0.0019 - val_mse: 0.0019 - val_mae: 0.0385\n",
      "Epoch 12/100\n",
      "87/87 [==============================] - 13s 153ms/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0494 - val_loss: 7.6923e-04 - val_mse: 7.6923e-04 - val_mae: 0.0179\n",
      "Epoch 13/100\n",
      "87/87 [==============================] - 13s 147ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0491 - val_loss: 6.4719e-04 - val_mse: 6.4719e-04 - val_mae: 0.0223\n",
      "Epoch 14/100\n",
      "87/87 [==============================] - 13s 154ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0485 - val_loss: 4.8720e-04 - val_mse: 4.8720e-04 - val_mae: 0.0123\n",
      "Epoch 15/100\n",
      "87/87 [==============================] - 12s 140ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0459 - val_loss: 6.1399e-04 - val_mse: 6.1399e-04 - val_mae: 0.0139\n",
      "Epoch 16/100\n",
      "87/87 [==============================] - 13s 154ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0441 - val_loss: 4.7408e-04 - val_mse: 4.7408e-04 - val_mae: 0.0157\n",
      "Epoch 17/100\n",
      "87/87 [==============================] - 13s 151ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0485 - val_loss: 5.1505e-04 - val_mse: 5.1505e-04 - val_mae: 0.0119\n",
      "Epoch 18/100\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0456 - val_loss: 4.8626e-04 - val_mse: 4.8626e-04 - val_mae: 0.0124\n",
      "Epoch 19/100\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0450 - val_loss: 5.1906e-04 - val_mse: 5.1906e-04 - val_mae: 0.0120\n",
      "Epoch 20/100\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0460 - val_loss: 5.2443e-04 - val_mse: 5.2443e-04 - val_mae: 0.0120\n",
      "Epoch 21/100\n",
      "87/87 [==============================] - 13s 149ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0461 - val_loss: 9.7218e-04 - val_mse: 9.7218e-04 - val_mae: 0.0225\n",
      "Epoch 22/100\n",
      "87/87 [==============================] - 12s 140ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0481 - val_loss: 5.7189e-04 - val_mse: 5.7189e-04 - val_mae: 0.0128\n",
      "Epoch 23/100\n",
      "87/87 [==============================] - 11s 131ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0415 - val_loss: 4.6832e-04 - val_mse: 4.6832e-04 - val_mae: 0.0139\n",
      "Epoch 24/100\n",
      "87/87 [==============================] - 12s 142ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0459 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0314\n",
      "Epoch 25/100\n",
      "87/87 [==============================] - 13s 146ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0458 - val_loss: 4.8767e-04 - val_mse: 4.8767e-04 - val_mae: 0.0123\n",
      "Epoch 26/100\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0444 - val_loss: 4.7739e-04 - val_mse: 4.7739e-04 - val_mae: 0.0161\n",
      "Epoch 27/100\n",
      "87/87 [==============================] - 13s 154ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0466 - val_loss: 5.3450e-04 - val_mse: 5.3450e-04 - val_mae: 0.0121\n",
      "Epoch 28/100\n",
      "87/87 [==============================] - 13s 147ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0467 - val_loss: 5.2540e-04 - val_mse: 5.2540e-04 - val_mae: 0.0120\n",
      "Epoch 29/100\n",
      "87/87 [==============================] - 13s 153ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0455 - val_loss: 5.8447e-04 - val_mse: 5.8447e-04 - val_mae: 0.0131\n",
      "Epoch 30/100\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0443 - val_loss: 5.7830e-04 - val_mse: 5.7830e-04 - val_mae: 0.0129\n",
      "Epoch 31/100\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0453 - val_loss: 5.6003e-04 - val_mse: 5.6003e-04 - val_mae: 0.0200\n",
      "Epoch 32/100\n",
      "87/87 [==============================] - 12s 140ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0467 - val_loss: 7.9023e-04 - val_mse: 7.9023e-04 - val_mae: 0.0184\n",
      "Epoch 33/100\n",
      "87/87 [==============================] - 12s 136ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0468 - val_loss: 4.7258e-04 - val_mse: 4.7258e-04 - val_mae: 0.0132\n",
      "Epoch 34/100\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0455 - val_loss: 5.6825e-04 - val_mse: 5.6825e-04 - val_mae: 0.0127\n",
      "Epoch 35/100\n",
      "87/87 [==============================] - 12s 136ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0459 - val_loss: 5.0161e-04 - val_mse: 5.0161e-04 - val_mae: 0.0119\n",
      "Epoch 36/100\n",
      "87/87 [==============================] - 12s 140ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0475 - val_loss: 4.9841e-04 - val_mse: 4.9841e-04 - val_mae: 0.0120\n",
      "Epoch 37/100\n",
      "87/87 [==============================] - 12s 136ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0451 - val_loss: 5.8668e-04 - val_mse: 5.8668e-04 - val_mae: 0.0132\n",
      "Epoch 38/100\n",
      "87/87 [==============================] - 13s 154ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0467 - val_loss: 6.0478e-04 - val_mse: 6.0478e-04 - val_mae: 0.0136\n",
      "Epoch 39/100\n",
      "87/87 [==============================] - 14s 156ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0439 - val_loss: 4.7148e-04 - val_mse: 4.7148e-04 - val_mae: 0.0154\n",
      "Epoch 40/100\n",
      "87/87 [==============================] - 13s 155ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0466 - val_loss: 4.7757e-04 - val_mse: 4.7757e-04 - val_mae: 0.0161\n",
      "Epoch 41/100\n",
      "87/87 [==============================] - 13s 153ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0454 - val_loss: 4.7320e-04 - val_mse: 4.7320e-04 - val_mae: 0.0156\n",
      "Epoch 42/100\n",
      "87/87 [==============================] - 14s 156ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0462 - val_loss: 4.8887e-04 - val_mse: 4.8887e-04 - val_mae: 0.0123\n",
      "Epoch 43/100\n",
      "87/87 [==============================] - 14s 156ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0457 - val_loss: 5.2840e-04 - val_mse: 5.2840e-04 - val_mae: 0.0121\n",
      "Epoch 44/100\n",
      "87/87 [==============================] - 11s 132ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0462 - val_loss: 5.3224e-04 - val_mse: 5.3224e-04 - val_mae: 0.0121\n",
      "Epoch 45/100\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0447 - val_loss: 5.6175e-04 - val_mse: 5.6175e-04 - val_mae: 0.0126\n",
      "Epoch 46/100\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0457 - val_loss: 4.6852e-04 - val_mse: 4.6852e-04 - val_mae: 0.0138\n",
      "Epoch 47/100\n",
      "87/87 [==============================] - 11s 128ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0459 - val_loss: 5.0192e-04 - val_mse: 5.0192e-04 - val_mae: 0.0119\n",
      "Epoch 48/100\n",
      "87/87 [==============================] - 13s 154ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0455 - val_loss: 5.1163e-04 - val_mse: 5.1163e-04 - val_mae: 0.0119\n",
      "Epoch 49/100\n",
      "87/87 [==============================] - 13s 155ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0463 - val_loss: 7.2476e-04 - val_mse: 7.2476e-04 - val_mae: 0.0168\n",
      "Epoch 50/100\n",
      "87/87 [==============================] - 14s 155ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0465 - val_loss: 5.3997e-04 - val_mse: 5.3997e-04 - val_mae: 0.0122\n",
      "Epoch 51/100\n",
      "87/87 [==============================] - 14s 156ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0447 - val_loss: 5.7112e-04 - val_mse: 5.7112e-04 - val_mae: 0.0128\n",
      "Epoch 52/100\n",
      "87/87 [==============================] - 14s 157ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0458 - val_loss: 5.0488e-04 - val_mse: 5.0488e-04 - val_mae: 0.0119\n",
      "Epoch 53/100\n",
      "87/87 [==============================] - 14s 156ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0453 - val_loss: 5.4754e-04 - val_mse: 5.4754e-04 - val_mae: 0.0123\n",
      "Epoch 54/100\n",
      "87/87 [==============================] - 14s 156ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0455 - val_loss: 4.8843e-04 - val_mse: 4.8843e-04 - val_mae: 0.0123\n",
      "Epoch 55/100\n",
      "87/87 [==============================] - 14s 155ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0450 - val_loss: 4.8699e-04 - val_mse: 4.8699e-04 - val_mae: 0.0124\n",
      "Epoch 56/100\n",
      "87/87 [==============================] - 14s 159ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0455 - val_loss: 4.9519e-04 - val_mse: 4.9519e-04 - val_mae: 0.0121\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 11s 132ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0448 - val_loss: 4.6770e-04 - val_mse: 4.6770e-04 - val_mae: 0.0143\n",
      "Epoch 58/100\n",
      "87/87 [==============================] - 13s 149ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0460 - val_loss: 5.1513e-04 - val_mse: 5.1513e-04 - val_mae: 0.0119\n",
      "Epoch 59/100\n",
      "87/87 [==============================] - 13s 154ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0462 - val_loss: 5.2584e-04 - val_mse: 5.2584e-04 - val_mae: 0.0120\n",
      "Epoch 60/100\n",
      "87/87 [==============================] - 13s 147ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0457 - val_loss: 5.5412e-04 - val_mse: 5.5412e-04 - val_mae: 0.0124\n",
      "Epoch 61/100\n",
      "87/87 [==============================] - 12s 141ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0443 - val_loss: 4.6849e-04 - val_mse: 4.6849e-04 - val_mae: 0.0139\n",
      "Epoch 62/100\n",
      "87/87 [==============================] - 13s 154ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0475 - val_loss: 4.7146e-04 - val_mse: 4.7146e-04 - val_mae: 0.0133\n",
      "Epoch 63/100\n",
      "87/87 [==============================] - 13s 149ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0457 - val_loss: 4.9609e-04 - val_mse: 4.9609e-04 - val_mae: 0.0121\n",
      "Epoch 64/100\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0459 - val_loss: 5.6715e-04 - val_mse: 5.6715e-04 - val_mae: 0.0202\n",
      "Epoch 65/100\n",
      "87/87 [==============================] - 13s 149ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0474 - val_loss: 6.2706e-04 - val_mse: 6.2706e-04 - val_mae: 0.0142\n",
      "Epoch 66/100\n",
      "87/87 [==============================] - 12s 132ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0461 - val_loss: 6.6202e-04 - val_mse: 6.6202e-04 - val_mae: 0.0152\n",
      "Epoch 67/100\n",
      "87/87 [==============================] - 8s 91ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0462 - val_loss: 4.7101e-04 - val_mse: 4.7101e-04 - val_mae: 0.0134\n",
      "Epoch 68/100\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0457 - val_loss: 6.8874e-04 - val_mse: 6.8874e-04 - val_mae: 0.0159\n",
      "Epoch 69/100\n",
      "87/87 [==============================] - 15s 168ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0477 - val_loss: 9.2414e-04 - val_mse: 9.2414e-04 - val_mae: 0.0215\n",
      "Epoch 70/100\n",
      "87/87 [==============================] - 16s 186ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0468 - val_loss: 5.0318e-04 - val_mse: 5.0318e-04 - val_mae: 0.0119\n",
      "Epoch 71/100\n",
      "87/87 [==============================] - 16s 186ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0469 - val_loss: 6.5658e-04 - val_mse: 6.5658e-04 - val_mae: 0.0151\n",
      "Epoch 72/100\n",
      "87/87 [==============================] - 15s 177ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0461 - val_loss: 4.9327e-04 - val_mse: 4.9327e-04 - val_mae: 0.0121\n",
      "Epoch 73/100\n",
      "87/87 [==============================] - 15s 170ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0451 - val_loss: 5.7900e-04 - val_mse: 5.7900e-04 - val_mae: 0.0130\n",
      "Epoch 74/100\n",
      "87/87 [==============================] - 18s 202ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0458 - val_loss: 6.4665e-04 - val_mse: 6.4665e-04 - val_mae: 0.0148\n",
      "Epoch 75/100\n",
      "87/87 [==============================] - 16s 186ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0440 - val_loss: 5.1230e-04 - val_mse: 5.1230e-04 - val_mae: 0.0182\n",
      "Epoch 76/100\n",
      "87/87 [==============================] - 16s 181ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0468 - val_loss: 4.6923e-04 - val_mse: 4.6923e-04 - val_mae: 0.0137\n",
      "Epoch 77/100\n",
      "87/87 [==============================] - 16s 187ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0448 - val_loss: 4.6812e-04 - val_mse: 4.6812e-04 - val_mae: 0.0140\n",
      "Epoch 78/100\n",
      "87/87 [==============================] - 16s 184ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0442 - val_loss: 4.9792e-04 - val_mse: 4.9792e-04 - val_mae: 0.0120\n",
      "Epoch 79/100\n",
      "87/87 [==============================] - 16s 185ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0434 - val_loss: 4.6922e-04 - val_mse: 4.6922e-04 - val_mae: 0.0137\n",
      "Epoch 80/100\n",
      "87/87 [==============================] - 14s 164ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0477 - val_loss: 5.5683e-04 - val_mse: 5.5683e-04 - val_mae: 0.0125\n",
      "Epoch 81/100\n",
      "87/87 [==============================] - 15s 173ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0458 - val_loss: 4.6772e-04 - val_mse: 4.6772e-04 - val_mae: 0.0142mse: 0.0036 - mae: 0.045\n",
      "Epoch 82/100\n",
      "87/87 [==============================] - 17s 198ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0471 - val_loss: 5.3696e-04 - val_mse: 5.3696e-04 - val_mae: 0.0122\n",
      "Epoch 83/100\n",
      "87/87 [==============================] - 18s 211ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0459 - val_loss: 4.9267e-04 - val_mse: 4.9267e-04 - val_mae: 0.0122\n",
      "Epoch 84/100\n",
      "87/87 [==============================] - 17s 200ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0441 - val_loss: 9.4481e-04 - val_mse: 9.4481e-04 - val_mae: 0.0279\n",
      "Epoch 85/100\n",
      "87/87 [==============================] - 16s 187ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0462 - val_loss: 4.7756e-04 - val_mse: 4.7756e-04 - val_mae: 0.0128\n",
      "Epoch 86/100\n",
      "87/87 [==============================] - 16s 182ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0466 - val_loss: 4.9382e-04 - val_mse: 4.9382e-04 - val_mae: 0.0121\n",
      "Epoch 87/100\n",
      "87/87 [==============================] - 16s 182ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0456 - val_loss: 4.9797e-04 - val_mse: 4.9797e-04 - val_mae: 0.0120\n",
      "Epoch 88/100\n",
      "87/87 [==============================] - 16s 184ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0451 - val_loss: 7.4391e-04 - val_mse: 7.4391e-04 - val_mae: 0.0173\n",
      "Epoch 89/100\n",
      "87/87 [==============================] - 16s 186ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0477 - val_loss: 5.1994e-04 - val_mse: 5.1994e-04 - val_mae: 0.0120\n",
      "Epoch 90/100\n",
      "87/87 [==============================] - 13s 153ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0451 - val_loss: 5.4396e-04 - val_mse: 5.4396e-04 - val_mae: 0.0123\n",
      "Epoch 91/100\n",
      "87/87 [==============================] - 15s 173ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0450 - val_loss: 5.1786e-04 - val_mse: 5.1786e-04 - val_mae: 0.0120\n",
      "Epoch 92/100\n",
      "87/87 [==============================] - 15s 176ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0456 - val_loss: 4.9253e-04 - val_mse: 4.9253e-04 - val_mae: 0.0122\n",
      "Epoch 93/100\n",
      "87/87 [==============================] - 18s 206ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0451 - val_loss: 5.6216e-04 - val_mse: 5.6216e-04 - val_mae: 0.0126\n",
      "Epoch 94/100\n",
      "87/87 [==============================] - 15s 176ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0449 - val_loss: 5.6553e-04 - val_mse: 5.6553e-04 - val_mae: 0.0126\n",
      "Epoch 95/100\n",
      "87/87 [==============================] - 13s 153ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0439 - val_loss: 4.7823e-04 - val_mse: 4.7823e-04 - val_mae: 0.0128\n",
      "Epoch 96/100\n",
      "87/87 [==============================] - 13s 150ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0470 - val_loss: 5.6853e-04 - val_mse: 5.6853e-04 - val_mae: 0.0127\n",
      "Epoch 97/100\n",
      "87/87 [==============================] - 13s 155ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0465 - val_loss: 6.2436e-04 - val_mse: 6.2436e-04 - val_mae: 0.0142\n",
      "Epoch 98/100\n",
      "87/87 [==============================] - 14s 162ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0445 - val_loss: 5.1272e-04 - val_mse: 5.1272e-04 - val_mae: 0.0119\n",
      "Epoch 99/100\n",
      "87/87 [==============================] - 14s 160ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0454 - val_loss: 4.9510e-04 - val_mse: 4.9510e-04 - val_mae: 0.0121\n",
      "Epoch 100/100\n",
      "87/87 [==============================] - 15s 172ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0442 - val_loss: 5.0267e-04 - val_mse: 5.0267e-04 - val_mae: 0.0177\n",
      "Epoch 1/100\n",
      "87/87 [==============================] - 17s 195ms/step - loss: 0.4942 - mse: 0.4942 - mae: 0.5585 - val_loss: 4.9544e-04 - val_mse: 4.9544e-04 - val_mae: 0.0173\n",
      "Epoch 2/100\n",
      "87/87 [==============================] - 15s 171ms/step - loss: 0.3413 - mse: 0.3413 - mae: 0.4654 - val_loss: 0.0019 - val_mse: 0.0019 - val_mae: 0.0421\n",
      "Epoch 3/100\n",
      "87/87 [==============================] - 15s 167ms/step - loss: 0.2338 - mse: 0.2338 - mae: 0.3844 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100\n",
      "87/87 [==============================] - 17s 199ms/step - loss: 0.1442 - mse: 0.1442 - mae: 0.3030 - val_loss: 4.7326e-04 - val_mse: 4.7326e-04 - val_mae: 0.0131\n",
      "Epoch 5/100\n",
      "87/87 [==============================] - 17s 197ms/step - loss: 0.0883 - mse: 0.0883 - mae: 0.2367 - val_loss: 0.0023 - val_mse: 0.0023 - val_mae: 0.0429\n",
      "Epoch 6/100\n",
      "87/87 [==============================] - 17s 200ms/step - loss: 0.0494 - mse: 0.0494 - mae: 0.1773 - val_loss: 0.0016 - val_mse: 0.0016 - val_mae: 0.0374\n",
      "Epoch 7/100\n",
      "87/87 [==============================] - 17s 198ms/step - loss: 0.0265 - mse: 0.0265 - mae: 0.1281 - val_loss: 0.0027 - val_mse: 0.0027 - val_mae: 0.0500\n",
      "Epoch 8/100\n",
      "87/87 [==============================] - 18s 203ms/step - loss: 0.0146 - mse: 0.0146 - mae: 0.0960 - val_loss: 0.0023 - val_mse: 0.0023 - val_mae: 0.0423\n",
      "Epoch 9/100\n",
      "87/87 [==============================] - 18s 204ms/step - loss: 0.0082 - mse: 0.0082 - mae: 0.0706 - val_loss: 0.0015 - val_mse: 0.0015 - val_mae: 0.0369\n",
      "Epoch 10/100\n",
      "87/87 [==============================] - 17s 200ms/step - loss: 0.0057 - mse: 0.0057 - mae: 0.0586 - val_loss: 0.0023 - val_mse: 0.0023 - val_mae: 0.0427\n",
      "Epoch 11/100\n",
      "87/87 [==============================] - 17s 200ms/step - loss: 0.0044 - mse: 0.0044 - mae: 0.0507 - val_loss: 8.8496e-04 - val_mse: 8.8496e-04 - val_mae: 0.0269\n",
      "Epoch 12/100\n",
      "87/87 [==============================] - 17s 200ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0478 - val_loss: 0.0028 - val_mse: 0.0028 - val_mae: 0.0507 ETA: 9s - loss: 0.0042 - mse: 0.0042 -  - ETA: 7s - loss - ETA: 0s - loss: 0.0039 - mse: 0.0039 - mae: 0.\n",
      "Epoch 13/100\n",
      "87/87 [==============================] - 17s 200ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0483 - val_loss: 4.6795e-04 - val_mse: 4.6795e-04 - val_mae: 0.0146\n",
      "Epoch 14/100\n",
      "87/87 [==============================] - 17s 199ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0453 - val_loss: 4.8407e-04 - val_mse: 4.8407e-04 - val_mae: 0.0125\n",
      "Epoch 15/100\n",
      "87/87 [==============================] - 17s 200ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0470 - val_loss: 5.5633e-04 - val_mse: 5.5633e-04 - val_mae: 0.0125\n",
      "Epoch 16/100\n",
      "87/87 [==============================] - 17s 192ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0443 - val_loss: 5.1587e-04 - val_mse: 5.1587e-04 - val_mae: 0.0119\n",
      "Epoch 17/100\n",
      "87/87 [==============================] - 17s 198ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0453 - val_loss: 7.2604e-04 - val_mse: 7.2604e-04 - val_mae: 0.0168\n",
      "Epoch 18/100\n",
      "87/87 [==============================] - 17s 190ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0468 - val_loss: 5.1683e-04 - val_mse: 5.1683e-04 - val_mae: 0.0120\n",
      "Epoch 19/100\n",
      "87/87 [==============================] - 12s 141ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0462 - val_loss: 4.9799e-04 - val_mse: 4.9799e-04 - val_mae: 0.0120\n",
      "Epoch 20/100\n",
      "87/87 [==============================] - 12s 140ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0456 - val_loss: 4.7217e-04 - val_mse: 4.7217e-04 - val_mae: 0.0155\n",
      "Epoch 21/100\n",
      "87/87 [==============================] - 18s 211ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0454 - val_loss: 5.2569e-04 - val_mse: 5.2569e-04 - val_mae: 0.0120\n",
      "Epoch 22/100\n",
      "87/87 [==============================] - 18s 211ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0454 - val_loss: 5.2477e-04 - val_mse: 5.2477e-04 - val_mae: 0.0120\n",
      "Epoch 23/100\n",
      "87/87 [==============================] - 18s 203ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0450 - val_loss: 5.3032e-04 - val_mse: 5.3032e-04 - val_mae: 0.0121\n",
      "Epoch 24/100\n",
      "87/87 [==============================] - 17s 200ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0455 - val_loss: 4.6906e-04 - val_mse: 4.6906e-04 - val_mae: 0.0137\n",
      "Epoch 25/100\n",
      "87/87 [==============================] - 17s 200ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0466 - val_loss: 4.8046e-04 - val_mse: 4.8046e-04 - val_mae: 0.0127\n",
      "Epoch 26/100\n",
      "87/87 [==============================] - 17s 200ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0440 - val_loss: 4.7107e-04 - val_mse: 4.7107e-04 - val_mae: 0.0134\n",
      "Epoch 27/100\n",
      "87/87 [==============================] - 17s 199ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0451 - val_loss: 4.7571e-04 - val_mse: 4.7571e-04 - val_mae: 0.0130\n",
      "Epoch 28/100\n",
      "87/87 [==============================] - 17s 191ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0454 - val_loss: 6.5683e-04 - val_mse: 6.5683e-04 - val_mae: 0.0151\n",
      "Epoch 29/100\n",
      "87/87 [==============================] - 17s 192ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0441 - val_loss: 4.9992e-04 - val_mse: 4.9992e-04 - val_mae: 0.0176\n",
      "Epoch 30/100\n",
      "78/87 [=========================>....] - ETA: 1s - loss: 0.0035 - mse: 0.0035 - mae: 0.0451"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "# Dictionary to include the parameters\n",
    "parameters = {'bias_initializer':[initializers.Zeros(),\n",
    "                                 initializers.Ones()],\n",
    "              'kernel_initializer': ['glorot_uniform',\n",
    "                                     'he_normal',\n",
    "                                     'he_uniform']\n",
    "               }\n",
    "\n",
    "all_param = ParameterGrid(parameters)\n",
    "\n",
    "# function to split data into correct shape for RNN\n",
    "def split_data(X, y, steps):\n",
    "    X_, y_ = list(), list()\n",
    "    for i in range(steps, len(y)):\n",
    "        X_.append(X[i - steps : i, :])\n",
    "        y_.append(y[i]) \n",
    "    return np.array(X_), np.array(y_)\n",
    "\n",
    "# function to cut data set so it can be divisible by the batch_size\n",
    "def cut_data(data, batch_size):\n",
    "     # see if it is divisivel\n",
    "    condition = data.shape[0] % batch_size\n",
    "    if condition == 0:\n",
    "        return data\n",
    "    else:\n",
    "        return data[: -condition]\n",
    "\n",
    "# divide features and labels\n",
    "X_train = data_train[:, 0:14] \n",
    "y_train = data_train[:, -1]\n",
    "X_test = data_test[:, 0:14] \n",
    "y_test = data_test[:, -1] \n",
    "\n",
    "# divide data into train and test \n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "         X_train, y_train, test_size = 0.15, shuffle=False)\n",
    "\n",
    "# put data into correct shape\n",
    "X_train, y_train = split_data(X_train, y_train, steps)\n",
    "X_test, y_test = split_data(X_test, y_test, steps)\n",
    "X_val, y_val = split_data(X_val, y_val, steps)\n",
    "\n",
    "X_train = cut_data(X_train, batch_size)\n",
    "y_train = cut_data(y_train, batch_size)\n",
    "X_test = cut_data(X_test, batch_size)\n",
    "y_test = cut_data(y_test, batch_size)\n",
    "X_val = cut_data(X_val, batch_size)\n",
    "y_val = cut_data(y_val, batch_size)\n",
    "\n",
    "# inverse of test set should not be inside the loop \n",
    "y_test = (y_test * sc_X.data_range_[14]) + (sc_X.data_min_[14])\n",
    "\n",
    "# smal adjustment\n",
    "y_test = pd.Series(y_test)\n",
    "y_test.replace(0, 0.0001,inplace = True)\n",
    "\n",
    "for i in range(len(all_param)):\n",
    "    \n",
    "    bias_initializer = all_param[i]['bias_initializer']\n",
    "    kernel_initializer = all_param[i]['kernel_initializer']\n",
    "\n",
    "    # design the LSTM\n",
    "    def regressor_tunning(kernel_initializer = 'he_uniform',\n",
    "                          bias_initializer = initializers.Ones()):\n",
    "        model = Sequential()\n",
    "        if n_hidden == 0:\n",
    "            model.add(LSTM(units = units,                    \n",
    "                           input_shape = (steps, features_num), \n",
    "                           kernel_initializer = kernel_initializer,\n",
    "                           bias_initializer = bias_initializer))\n",
    "            model.add(LeakyReLU(alpha = 0.2))\n",
    "            model.add(Dropout(0.2))\n",
    "        else:\n",
    "            model.add(LSTM(units = units,                    \n",
    "                           input_shape = (steps, features_num), \n",
    "                           return_sequences = True,\n",
    "                           kernel_initializer = kernel_initializer,\n",
    "                           bias_initializer = bias_initializer))\n",
    "            model.add(LeakyReLU(alpha = 0.2))\n",
    "            model.add(Dropout(0.2))\n",
    "            model.add(LSTM(units = units, \n",
    "                           input_shape = (steps, features_num), \n",
    "                           kernel_initializer = kernel_initializer,\n",
    "                           bias_initializer = bias_initializer))\n",
    "            model.add(LeakyReLU(alpha = 0.2))\n",
    "            model.add(Dropout(0.2))\n",
    "        model.add(Dense(1, activation='linear'))\n",
    "        optimizer = optimizers.RMSprop()\n",
    "        model.compile(loss = 'mse', metrics = ['mse', 'mae'], optimizer = optimizer)\n",
    "        return model\n",
    "\n",
    "    model = regressor_tunning(bias_initializer, kernel_initializer)\n",
    "\n",
    "    # fitting the LSTM to the training set\n",
    "    history = model.fit(X_train,\n",
    "                        y_train, \n",
    "                        batch_size = batch_size, \n",
    "                        epochs = 100,\n",
    "                        shuffle = False, \n",
    "                        validation_data = (X_val, y_val))\n",
    "    \n",
    "    model.reset_states()\n",
    "    \n",
    "    # make new predicitons with test set\n",
    "    y_pred = model.predict(X_test, batch_size = batch_size)\n",
    "    \n",
    "    # prices col = 15 (inverso should not be used as scalling was made with the whole data set)\n",
    "    y_pred = (y_pred * sc_X.data_range_[14]) + (sc_X.data_min_[14])\n",
    "    \n",
    "    y_pred_list.append(y_pred)\n",
    "    \n",
    "    from sklearn.metrics import mean_squared_error as mse\n",
    "    from sklearn.metrics import mean_absolute_error as mae\n",
    "\n",
    "    rmse_error = mse(y_test, y_pred, squared = False)\n",
    "    mae_error = mae(y_test, y_pred)\n",
    "    \n",
    "    rmse_gen.append(rmse_error)\n",
    "    mae_gen.append(mae_error)\n",
    "    \n",
    "    # =============================================================================\n",
    "    # Metrics evaluation on spike regions\n",
    "    # =============================================================================\n",
    "    \n",
    "    # Need to process data with spike occurences the same way as features\n",
    "    data = pd.read_csv('Spike_binary_1std.csv', index_col = 0)\n",
    "\n",
    "    # set predictive window according with tuning best results\n",
    "    data = data.loc[data.index > date, :]\n",
    "\n",
    "    # make sure shaded area will correspond to values outputed by LSTM\n",
    "    data.reset_index(drop = True, inplace = True)\n",
    "\n",
    "    # fill_nan is already made - so lets split data into test and train\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    # divide data into train and test \n",
    "    shade_train, shade_test = train_test_split(\n",
    "             data, test_size = 0.15, shuffle = False)\n",
    "\n",
    "    # reset index of testing data\n",
    "    shade_test.reset_index(drop = True, inplace = True)\n",
    "\n",
    "    # function to split data into correct shape for RNN\n",
    "    def split_data_shade(shade_test, steps):\n",
    "        y_spike_occ = list()\n",
    "        upper_lim = list()\n",
    "        lower_lim = list()\n",
    "        for i in range(steps, len(shade_test.index)):\n",
    "            y_spike_occ.append(shade_test['spike_occurance'][i])\n",
    "            upper_lim.append(shade_test['spike_upperlim'][i])\n",
    "            lower_lim.append(shade_test['spike_lowerlim'][i])\n",
    "        return np.array(y_spike_occ), np.array(upper_lim), np.array(lower_lim)\n",
    "    \n",
    "    # function to cut data set so it can be divisible by the batch_size\n",
    "    def cut_data_shade(data, batch_size):\n",
    "         # see if it is divisivel\n",
    "        condition = data.shape[0] % batch_size\n",
    "        if condition == 0:\n",
    "            return data\n",
    "        else:\n",
    "            return data[: -condition]\n",
    "    \n",
    "    # shape y_spike_occ for the right size to compare results in normal and spike regions\n",
    "    y_spike_occ, spike_upperlim, spike_lowerlim = split_data_shade(shade_test, steps)\n",
    "    y_spike_occ = cut_data_shade(y_spike_occ, batch_size)\n",
    "        \n",
    "    # continue\n",
    "    \n",
    "    # select y_pred and y_test only for regions with spikes\n",
    "    y_test_spike = (y_test.T * y_spike_occ).T\n",
    "    y_pred_spike = (y_pred.T * y_spike_occ).T\n",
    "    y_test_spike = y_test_spike[y_test_spike != 0]\n",
    "    y_pred_spike = y_pred_spike[y_pred_spike != 0]\n",
    "    \n",
    "    # calculate metric\n",
    "    rmse_spike = mse(y_test_spike, y_pred_spike, squared = False)\n",
    "    mae_spike = mae(y_test_spike, y_pred_spike)\n",
    "    \n",
    "    rmse_spi.append(rmse_spike)\n",
    "    mae_spi.append(mae_spike)\n",
    "    \n",
    "    # =============================================================================\n",
    "    # Metric evaluation on normal regions\n",
    "    # =============================================================================\n",
    "    \n",
    "    # inverse y_spike_occ so the only normal occurences are chosen\n",
    "    y_normal_occ = (y_spike_occ - 1) * (-1)\n",
    "    \n",
    "    # sanity check\n",
    "    y_normal_occ.sum() + y_spike_occ.sum() # gives the correct total \n",
    "    \n",
    "    # select y_pred and y_test only for normal regions\n",
    "    y_test_normal = (y_test.T * y_normal_occ).T\n",
    "    y_pred_normal = (y_pred.T * y_normal_occ).T\n",
    "    y_test_normal = y_test_normal[y_test_normal != 0.00]\n",
    "    y_pred_normal = y_pred_normal[y_pred_normal != 0.00]\n",
    "    \n",
    "    # calculate metric\n",
    "    rmse_normal = mse(y_test_normal, y_pred_normal, squared = False)\n",
    "    mae_normal = mae(y_test_normal, y_pred_normal)\n",
    "    \n",
    "    rmse_nor.append(rmse_normal)\n",
    "    mae_nor.append(mae_normal)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({'all_param':all_param,\n",
    "                        \n",
    "                        'rmse_general': rmse_gen, \n",
    "                 \n",
    "                        'mae_general': mae_gen,\n",
    "                        \n",
    "                        'rmse_spike': rmse_spi,\n",
    "                 \n",
    "                        'mae_spike': mae_spi,\n",
    "                        \n",
    "                        'rmse_normal': rmse_nor,\n",
    "                    \n",
    "                        'mae_normal': mae_nor})\n",
    "\n",
    "results.to_csv('Results_LSTM_5_kernel_bias.csv')\n",
    "\n",
    "y_pred = pd.DataFrame({'all_param': all_param,\n",
    "                       'Predicitons': y_pred_list})\n",
    "\n",
    "y_pred.to_csv('Pedictions_LSTM_4_kernel_bias.csv')\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({'rmse_general': rmse_gen, \n",
    "                 \n",
    "                        'mae_general': mae_gen,\n",
    "                        \n",
    "                        'rmse_spike': rmse_spi,\n",
    "                 \n",
    "                        'mae_spike': mae_spi,\n",
    "                        \n",
    "                        'rmse_normal': rmse_nor,\n",
    "                    \n",
    "                        'mae_normal': mae_nor})\n",
    "\n",
    "def highlight_min(s):\n",
    "    '''\n",
    "    highlight the maximum in a Series yellow.\n",
    "    '''\n",
    "    is_max = s == s.min()\n",
    "    return ['background-color: yellow' if v else '' for v in is_max]\n",
    "\n",
    "results.style.apply(highlight_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
