{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Parameter Tuning \n",
    "    \n",
    "    Look at n_neurons & n_hidden layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\maria\\anaconda3\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from pandas) (1.18.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from python-dateutil>=2.6.1->pandas) (1.14.0)\n",
      "Requirement already satisfied: sklearn in c:\\users\\maria\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\maria\\anaconda3\\lib\\site-packages (from sklearn) (0.22.1)\n",
      "Requirement already satisfied: numpy>=1.11.0 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.18.1)\n",
      "Requirement already satisfied: scipy>=0.17.0 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.4.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (0.14.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install sklearn\n",
    "\n",
    "import pandas as pd;\n",
    "import numpy as np;\n",
    "import sklearn\n",
    "\n",
    "# months to evaluate model on\n",
    "date = 2018090000\n",
    "\n",
    "# for later use\n",
    "features_num = 15\n",
    "\n",
    "# lists to append results\n",
    "mae_gen = []\n",
    "mae_nor = []\n",
    "mae_spi = []\n",
    "rmse_gen = []\n",
    "rmse_nor = []\n",
    "rmse_spi = []\n",
    "y_pred_list = []\n",
    "time_count = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data; set X and y; fill nan values and split in test and training  data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "data = pd.read_csv('Data_set_1_smaller.csv', index_col = 0)\n",
    "\n",
    "# 2018 data\n",
    "data = data.loc[data.index > date, :]\n",
    "\n",
    "# reset index\n",
    "data.reset_index(inplace = True)\n",
    "data.drop('index', axis = 1, inplace = True)\n",
    "\n",
    "# fill nan values\n",
    "data.fillna(method = 'ffill', inplace = True)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# divide data into train and test \n",
    "data_train, data_test = train_test_split(\n",
    "         data, test_size = 0.15, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply feature scaling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# data scaling  (including offer (y))\n",
    "sc_X = MinMaxScaler()\n",
    "data_train = sc_X.fit_transform(data_train)\n",
    "data_test = sc_X.transform(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LeakyReLU\n",
    "from keras import initializers\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Need to process data with spike occurences the same way as features and offers:\n",
    "(Required to evaluate predictions in both normal regions and spike regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 96 \n",
    "batch_size = 96\n",
    "\n",
    "# download data for shaded area\n",
    "data = pd.read_csv('Spike_binary_1std.csv', index_col = 0)\n",
    "\n",
    "# set predictive window according with tuning best results\n",
    "data = data.loc[data.index > date, :]\n",
    "\n",
    "# make sure shaded area will correspond to values outputed by LSTM\n",
    "data.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# fill_nan is already made - so lets split data into test and train\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# divide data into train and test \n",
    "shade_train, shade_test = train_test_split(\n",
    "         data, test_size = 0.15, shuffle = False)\n",
    "\n",
    "# reset index of testing data\n",
    "shade_test.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# function to split data into correct shape for RNN\n",
    "def split_data(shade_test, steps):\n",
    "    y_spike_occ = list()\n",
    "    upper_lim = list()\n",
    "    lower_lim = list()\n",
    "    for i in range(steps, len(shade_test.index)):\n",
    "        y_spike_occ.append(shade_test['spike_occurance'][i])\n",
    "        upper_lim.append(shade_test['spike_upperlim'][i])\n",
    "        lower_lim.append(shade_test['spike_lowerlim'][i])\n",
    "    return np.array(y_spike_occ), np.array(upper_lim), np.array(lower_lim)\n",
    "\n",
    "# function to cut data set so it can be divisible by the batch_size\n",
    "def cut_data(data, batch_size):\n",
    "     # see if it is divisivel\n",
    "    condition = data.shape[0] % batch_size\n",
    "    if condition == 0:\n",
    "        return data\n",
    "    else:\n",
    "        return data[: -condition]\n",
    "\n",
    "# shape y_spike_occ for the right size to compare results in normal and spike regions\n",
    "y_spike_occ, spike_upperlim, spike_lowerlim = split_data(shade_test, steps)\n",
    "y_spike_occ = cut_data(y_spike_occ, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare of data according to LSTM needs,  create regressor & tune:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/180\n",
      "65/65 [==============================] - 23s 351ms/step - loss: 0.1158 - mse: 0.1158 - mae: 0.2701 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0425\n",
      "Epoch 2/180\n",
      "65/65 [==============================] - 20s 311ms/step - loss: 0.0632 - mse: 0.0632 - mae: 0.2009 - val_loss: 0.0021 - val_mse: 0.0021 - val_mae: 0.0329\n",
      "Epoch 3/180\n",
      "65/65 [==============================] - 19s 286ms/step - loss: 0.0409 - mse: 0.0409 - mae: 0.1608 - val_loss: 0.0014 - val_mse: 0.0014 - val_mae: 0.0242\n",
      "Epoch 4/180\n",
      "65/65 [==============================] - 19s 297ms/step - loss: 0.0281 - mse: 0.0281 - mae: 0.1328 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0199\n",
      "Epoch 5/180\n",
      "65/65 [==============================] - 19s 297ms/step - loss: 0.0203 - mse: 0.0203 - mae: 0.1122 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0234\n",
      "Epoch 6/180\n",
      "65/65 [==============================] - 19s 291ms/step - loss: 0.0152 - mse: 0.0152 - mae: 0.0974 - val_loss: 0.0014 - val_mse: 0.0014 - val_mae: 0.0223\n",
      "Epoch 7/180\n",
      "65/65 [==============================] - 19s 286ms/step - loss: 0.0122 - mse: 0.0122 - mae: 0.0874 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0176\n",
      "Epoch 8/180\n",
      "65/65 [==============================] - 20s 307ms/step - loss: 0.0100 - mse: 0.0100 - mae: 0.0785 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0171\n",
      "Epoch 9/180\n",
      "65/65 [==============================] - 19s 298ms/step - loss: 0.0084 - mse: 0.0084 - mae: 0.0715 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0173\n",
      "Epoch 10/180\n",
      "65/65 [==============================] - 19s 296ms/step - loss: 0.0072 - mse: 0.0072 - mae: 0.0660 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0172\n",
      "Epoch 11/180\n",
      "65/65 [==============================] - 20s 304ms/step - loss: 0.0065 - mse: 0.0065 - mae: 0.0630 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0171\n",
      "Epoch 12/180\n",
      "65/65 [==============================] - 18s 277ms/step - loss: 0.0057 - mse: 0.0057 - mae: 0.0583 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0190\n",
      "Epoch 13/180\n",
      "65/65 [==============================] - 19s 292ms/step - loss: 0.0052 - mse: 0.0052 - mae: 0.0557 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0197\n",
      "Epoch 14/180\n",
      "65/65 [==============================] - 19s 291ms/step - loss: 0.0048 - mse: 0.0048 - mae: 0.0533 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 15/180\n",
      "65/65 [==============================] - 18s 284ms/step - loss: 0.0045 - mse: 0.0045 - mae: 0.0508 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0196\n",
      "Epoch 16/180\n",
      "65/65 [==============================] - 19s 286ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0467 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0177\n",
      "Epoch 17/180\n",
      "65/65 [==============================] - 18s 280ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0444 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0184\n",
      "Epoch 18/180\n",
      "65/65 [==============================] - 18s 272ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0422 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0207\n",
      "Epoch 19/180\n",
      "65/65 [==============================] - 18s 272ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0402 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0194\n",
      "Epoch 20/180\n",
      "65/65 [==============================] - 20s 301ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0380 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 21/180\n",
      "65/65 [==============================] - 18s 282ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0368 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0190\n",
      "Epoch 22/180\n",
      "65/65 [==============================] - 18s 270ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0349 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0203\n",
      "Epoch 23/180\n",
      "65/65 [==============================] - 18s 280ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0343 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0187\n",
      "Epoch 24/180\n",
      "65/65 [==============================] - 18s 274ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0334 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0205\n",
      "Epoch 25/180\n",
      "65/65 [==============================] - 18s 272ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0316 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0198\n",
      "Epoch 26/180\n",
      "65/65 [==============================] - 19s 289ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0306 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0192\n",
      "Epoch 27/180\n",
      "65/65 [==============================] - 18s 277ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0295 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0200\n",
      "Epoch 28/180\n",
      "65/65 [==============================] - 18s 276ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0291 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0201\n",
      "Epoch 29/180\n",
      "65/65 [==============================] - 19s 287ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0281 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0181\n",
      "Epoch 30/180\n",
      "65/65 [==============================] - 20s 309ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0270 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0182\n",
      "Epoch 31/180\n",
      "65/65 [==============================] - 20s 305ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0266 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0189\n",
      "Epoch 32/180\n",
      "65/65 [==============================] - 20s 301ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0262 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0182\n",
      "Epoch 33/180\n",
      "65/65 [==============================] - 19s 297ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0250 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0183\n",
      "Epoch 34/180\n",
      "65/65 [==============================] - 20s 303ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0243 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 35/180\n",
      "65/65 [==============================] - 19s 296ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0243 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0181\n",
      "Epoch 36/180\n",
      "65/65 [==============================] - 20s 303ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0235 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0188\n",
      "Epoch 37/180\n",
      "65/65 [==============================] - 19s 293ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0233 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0183\n",
      "Epoch 38/180\n",
      "65/65 [==============================] - 19s 295ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0230 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0192\n",
      "Epoch 39/180\n",
      "65/65 [==============================] - 19s 296ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0223 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0191\n",
      "Epoch 40/180\n",
      "65/65 [==============================] - 20s 303ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0217 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0192\n",
      "Epoch 41/180\n",
      "65/65 [==============================] - 19s 299ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0220 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0196\n",
      "Epoch 42/180\n",
      "65/65 [==============================] - 19s 296ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0213 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0191\n",
      "Epoch 43/180\n",
      "65/65 [==============================] - 19s 294ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0208 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0189\n",
      "Epoch 44/180\n",
      "65/65 [==============================] - 18s 281ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0208 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0197\n",
      "Epoch 45/180\n",
      "65/65 [==============================] - 19s 288ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0206 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0190\n",
      "Epoch 46/180\n",
      "65/65 [==============================] - 19s 292ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0203 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0190\n",
      "Epoch 47/180\n",
      "65/65 [==============================] - 19s 291ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0200 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0193\n",
      "Epoch 48/180\n",
      "65/65 [==============================] - 16s 241ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0199 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0187\n",
      "Epoch 49/180\n",
      "65/65 [==============================] - 15s 223ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0198 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0187\n",
      "Epoch 50/180\n",
      "65/65 [==============================] - 14s 208ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0197 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 51/180\n",
      "65/65 [==============================] - 14s 209ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0194 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0189\n",
      "Epoch 52/180\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0193 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 53/180\n",
      "65/65 [==============================] - 14s 209ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0193 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 54/180\n",
      "65/65 [==============================] - 14s 209ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0190 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0189\n",
      "Epoch 55/180\n",
      "65/65 [==============================] - 14s 210ms/step - loss: 9.9157e-04 - mse: 9.9157e-04 - mae: 0.0189 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 56/180\n",
      "65/65 [==============================] - 16s 240ms/step - loss: 9.8719e-04 - mse: 9.8719e-04 - mae: 0.0188 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 57/180\n",
      "65/65 [==============================] - 14s 211ms/step - loss: 9.7152e-04 - mse: 9.7152e-04 - mae: 0.0187 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 58/180\n",
      "65/65 [==============================] - 14s 208ms/step - loss: 9.6552e-04 - mse: 9.6552e-04 - mae: 0.0186 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 59/180\n",
      "65/65 [==============================] - 13s 202ms/step - loss: 9.7162e-04 - mse: 9.7162e-04 - mae: 0.0187 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 60/180\n",
      "65/65 [==============================] - 13s 201ms/step - loss: 9.6246e-04 - mse: 9.6246e-04 - mae: 0.0184 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 61/180\n",
      "65/65 [==============================] - 14s 210ms/step - loss: 9.5686e-04 - mse: 9.5686e-04 - mae: 0.0183 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0184\n",
      "Epoch 62/180\n",
      "65/65 [==============================] - 15s 228ms/step - loss: 9.6260e-04 - mse: 9.6260e-04 - mae: 0.0184 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0187\n",
      "Epoch 63/180\n",
      "65/65 [==============================] - 14s 211ms/step - loss: 9.4735e-04 - mse: 9.4735e-04 - mae: 0.0182 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0184\n",
      "Epoch 64/180\n",
      "65/65 [==============================] - 13s 201ms/step - loss: 9.5590e-04 - mse: 9.5590e-04 - mae: 0.0181 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0187\n",
      "Epoch 65/180\n",
      "65/65 [==============================] - 14s 214ms/step - loss: 9.5075e-04 - mse: 9.5075e-04 - mae: 0.0182 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0184\n",
      "Epoch 66/180\n",
      "65/65 [==============================] - 13s 207ms/step - loss: 9.4457e-04 - mse: 9.4457e-04 - mae: 0.0181 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0187\n",
      "Epoch 67/180\n",
      "65/65 [==============================] - 14s 208ms/step - loss: 9.4453e-04 - mse: 9.4453e-04 - mae: 0.0181 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 68/180\n",
      "65/65 [==============================] - 14s 211ms/step - loss: 9.4076e-04 - mse: 9.4076e-04 - mae: 0.0181 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0183\n",
      "Epoch 69/180\n",
      "65/65 [==============================] - 13s 201ms/step - loss: 9.3706e-04 - mse: 9.3706e-04 - mae: 0.0181 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 70/180\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 9.3947e-04 - mse: 9.3947e-04 - mae: 0.0181 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 71/180\n",
      "65/65 [==============================] - 13s 201ms/step - loss: 9.3563e-04 - mse: 9.3563e-04 - mae: 0.0181 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 72/180\n",
      "65/65 [==============================] - 13s 201ms/step - loss: 9.3394e-04 - mse: 9.3394e-04 - mae: 0.0181 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0184\n",
      "Epoch 73/180\n",
      "65/65 [==============================] - 14s 209ms/step - loss: 9.3195e-04 - mse: 9.3195e-04 - mae: 0.0180 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 74/180\n",
      "65/65 [==============================] - 14s 218ms/step - loss: 9.2542e-04 - mse: 9.2542e-04 - mae: 0.0180 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 75/180\n",
      "65/65 [==============================] - 13s 206ms/step - loss: 9.3291e-04 - mse: 9.3291e-04 - mae: 0.0180 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 76/180\n",
      "65/65 [==============================] - 13s 200ms/step - loss: 9.3458e-04 - mse: 9.3458e-04 - mae: 0.0181 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 77/180\n",
      "65/65 [==============================] - 17s 264ms/step - loss: 9.2650e-04 - mse: 9.2650e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 78/180\n",
      "65/65 [==============================] - 14s 212ms/step - loss: 9.3080e-04 - mse: 9.3080e-04 - mae: 0.0180 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 79/180\n",
      "65/65 [==============================] - 13s 201ms/step - loss: 9.2489e-04 - mse: 9.2489e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 80/180\n",
      "65/65 [==============================] - 13s 200ms/step - loss: 9.2888e-04 - mse: 9.2888e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 81/180\n",
      "65/65 [==============================] - 13s 200ms/step - loss: 9.2594e-04 - mse: 9.2594e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0183\n",
      "Epoch 82/180\n",
      "65/65 [==============================] - 14s 219ms/step - loss: 9.2405e-04 - mse: 9.2405e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 83/180\n",
      "65/65 [==============================] - 13s 207ms/step - loss: 9.2228e-04 - mse: 9.2228e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 84/180\n",
      "65/65 [==============================] - 17s 256ms/step - loss: 9.2071e-04 - mse: 9.2071e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 85/180\n",
      "65/65 [==============================] - 18s 279ms/step - loss: 9.2723e-04 - mse: 9.2723e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 86/180\n",
      "65/65 [==============================] - 20s 315ms/step - loss: 9.2304e-04 - mse: 9.2304e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 87/180\n",
      "65/65 [==============================] - 15s 238ms/step - loss: 9.2085e-04 - mse: 9.2085e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0184\n",
      "Epoch 88/180\n",
      "65/65 [==============================] - 15s 228ms/step - loss: 9.1822e-04 - mse: 9.1822e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 89/180\n",
      "65/65 [==============================] - 16s 240ms/step - loss: 9.1878e-04 - mse: 9.1878e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 90/180\n",
      "65/65 [==============================] - 15s 227ms/step - loss: 9.1617e-04 - mse: 9.1617e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 91/180\n",
      "65/65 [==============================] - 14s 222ms/step - loss: 9.1817e-04 - mse: 9.1817e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 92/180\n",
      "65/65 [==============================] - 15s 235ms/step - loss: 9.1426e-04 - mse: 9.1426e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0184\n",
      "Epoch 93/180\n",
      "65/65 [==============================] - 15s 232ms/step - loss: 9.1650e-04 - mse: 9.1650e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 94/180\n",
      "65/65 [==============================] - 15s 228ms/step - loss: 9.1910e-04 - mse: 9.1910e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 95/180\n",
      "65/65 [==============================] - 15s 224ms/step - loss: 9.1692e-04 - mse: 9.1693e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 96/180\n",
      "65/65 [==============================] - 14s 223ms/step - loss: 9.1571e-04 - mse: 9.1571e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 97/180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 15s 237ms/step - loss: 9.1504e-04 - mse: 9.1504e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 98/180\n",
      "65/65 [==============================] - 15s 232ms/step - loss: 9.1416e-04 - mse: 9.1416e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 99/180\n",
      "65/65 [==============================] - 15s 226ms/step - loss: 9.1485e-04 - mse: 9.1485e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 100/180\n",
      "65/65 [==============================] - 15s 231ms/step - loss: 9.1348e-04 - mse: 9.1348e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0187\n",
      "Epoch 101/180\n",
      "65/65 [==============================] - 15s 223ms/step - loss: 9.1149e-04 - mse: 9.1149e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 102/180\n",
      "65/65 [==============================] - 15s 230ms/step - loss: 9.1474e-04 - mse: 9.1474e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0187\n",
      "Epoch 103/180\n",
      "65/65 [==============================] - 16s 241ms/step - loss: 9.1349e-04 - mse: 9.1349e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 104/180\n",
      "65/65 [==============================] - 15s 235ms/step - loss: 9.1463e-04 - mse: 9.1463e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 105/180\n",
      "65/65 [==============================] - 16s 240ms/step - loss: 9.1252e-04 - mse: 9.1252e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0187\n",
      "Epoch 106/180\n",
      "65/65 [==============================] - 15s 227ms/step - loss: 9.1238e-04 - mse: 9.1238e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0187\n",
      "Epoch 107/180\n",
      "65/65 [==============================] - 15s 229ms/step - loss: 9.1208e-04 - mse: 9.1208e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0188\n",
      "Epoch 108/180\n",
      "65/65 [==============================] - 15s 223ms/step - loss: 9.1132e-04 - mse: 9.1132e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0188\n",
      "Epoch 109/180\n",
      "65/65 [==============================] - 14s 223ms/step - loss: 9.1056e-04 - mse: 9.1056e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 110/180\n",
      "65/65 [==============================] - 15s 223ms/step - loss: 9.1459e-04 - mse: 9.1459e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0187\n",
      "Epoch 111/180\n",
      "65/65 [==============================] - 15s 228ms/step - loss: 9.1039e-04 - mse: 9.1039e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 112/180\n",
      "65/65 [==============================] - 15s 228ms/step - loss: 9.0705e-04 - mse: 9.0705e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0184\n",
      "Epoch 113/180\n",
      "65/65 [==============================] - 15s 238ms/step - loss: 9.0932e-04 - mse: 9.0932e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0187\n",
      "Epoch 114/180\n",
      "65/65 [==============================] - 15s 227ms/step - loss: 9.0471e-04 - mse: 9.0471e-04 - mae: 0.0177 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0186\n",
      "Epoch 115/180\n",
      "65/65 [==============================] - 14s 222ms/step - loss: 9.0822e-04 - mse: 9.0822e-04 - mae: 0.0177 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0187\n",
      "Epoch 116/180\n",
      "65/65 [==============================] - 14s 223ms/step - loss: 9.0598e-04 - mse: 9.0598e-04 - mae: 0.0177 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0186\n",
      "Epoch 117/180\n",
      "65/65 [==============================] - 15s 234ms/step - loss: 9.0197e-04 - mse: 9.0197e-04 - mae: 0.0176 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0185\n",
      "Epoch 118/180\n",
      "65/65 [==============================] - 16s 244ms/step - loss: 9.0192e-04 - mse: 9.0192e-04 - mae: 0.0176 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0184\n",
      "Epoch 119/180\n",
      "65/65 [==============================] - 14s 221ms/step - loss: 9.0093e-04 - mse: 9.0093e-04 - mae: 0.0176 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0183\n",
      "Epoch 120/180\n",
      "65/65 [==============================] - 14s 216ms/step - loss: 8.9483e-04 - mse: 8.9483e-04 - mae: 0.0175 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0182\n",
      "Epoch 121/180\n",
      "65/65 [==============================] - 15s 236ms/step - loss: 8.9685e-04 - mse: 8.9685e-04 - mae: 0.0176 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0184\n",
      "Epoch 122/180\n",
      "65/65 [==============================] - 15s 226ms/step - loss: 8.9606e-04 - mse: 8.9606e-04 - mae: 0.0176 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0181\n",
      "Epoch 123/180\n",
      "65/65 [==============================] - 15s 226ms/step - loss: 8.9271e-04 - mse: 8.9271e-04 - mae: 0.0174 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0183\n",
      "Epoch 124/180\n",
      "65/65 [==============================] - 15s 225ms/step - loss: 8.9175e-04 - mse: 8.9175e-04 - mae: 0.0175 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0182\n",
      "Epoch 125/180\n",
      "65/65 [==============================] - 14s 219ms/step - loss: 8.9119e-04 - mse: 8.9119e-04 - mae: 0.0174 - val_loss: 9.8333e-04 - val_mse: 9.8333e-04 - val_mae: 0.0179\n",
      "Epoch 126/180\n",
      "65/65 [==============================] - 15s 227ms/step - loss: 8.8786e-04 - mse: 8.8786e-04 - mae: 0.0174 - val_loss: 9.6656e-04 - val_mse: 9.6656e-04 - val_mae: 0.0180\n",
      "Epoch 127/180\n",
      "65/65 [==============================] - 15s 228ms/step - loss: 8.8647e-04 - mse: 8.8647e-04 - mae: 0.0173 - val_loss: 9.5768e-04 - val_mse: 9.5768e-04 - val_mae: 0.0178\n",
      "Epoch 128/180\n",
      "65/65 [==============================] - 14s 218ms/step - loss: 8.8610e-04 - mse: 8.8610e-04 - mae: 0.0173 - val_loss: 9.4266e-04 - val_mse: 9.4266e-04 - val_mae: 0.0183\n",
      "Epoch 129/180\n",
      "65/65 [==============================] - 16s 246ms/step - loss: 8.7548e-04 - mse: 8.7548e-04 - mae: 0.0172 - val_loss: 9.2839e-04 - val_mse: 9.2839e-04 - val_mae: 0.0180\n",
      "Epoch 130/180\n",
      "65/65 [==============================] - 16s 241ms/step - loss: 8.7975e-04 - mse: 8.7975e-04 - mae: 0.0172 - val_loss: 9.1768e-04 - val_mse: 9.1768e-04 - val_mae: 0.0182\n",
      "Epoch 131/180\n",
      "65/65 [==============================] - 15s 236ms/step - loss: 8.7855e-04 - mse: 8.7855e-04 - mae: 0.0172 - val_loss: 9.0384e-04 - val_mse: 9.0384e-04 - val_mae: 0.0181\n",
      "Epoch 132/180\n",
      "65/65 [==============================] - 16s 239ms/step - loss: 8.7034e-04 - mse: 8.7034e-04 - mae: 0.0170 - val_loss: 8.9539e-04 - val_mse: 8.9539e-04 - val_mae: 0.0177\n",
      "Epoch 133/180\n",
      "65/65 [==============================] - 16s 248ms/step - loss: 8.7604e-04 - mse: 8.7604e-04 - mae: 0.0171 - val_loss: 8.8558e-04 - val_mse: 8.8558e-04 - val_mae: 0.0176\n",
      "Epoch 134/180\n",
      "65/65 [==============================] - 15s 233ms/step - loss: 8.7050e-04 - mse: 8.7050e-04 - mae: 0.0170 - val_loss: 8.8781e-04 - val_mse: 8.8781e-04 - val_mae: 0.0178\n",
      "Epoch 135/180\n",
      "65/65 [==============================] - 16s 250ms/step - loss: 8.6959e-04 - mse: 8.6959e-04 - mae: 0.0170 - val_loss: 8.8559e-04 - val_mse: 8.8559e-04 - val_mae: 0.0178\n",
      "Epoch 136/180\n",
      "65/65 [==============================] - 16s 245ms/step - loss: 8.7091e-04 - mse: 8.7091e-04 - mae: 0.0169 - val_loss: 8.8853e-04 - val_mse: 8.8853e-04 - val_mae: 0.0184\n",
      "Epoch 137/180\n",
      "65/65 [==============================] - 17s 258ms/step - loss: 8.6604e-04 - mse: 8.6604e-04 - mae: 0.0169 - val_loss: 8.6898e-04 - val_mse: 8.6898e-04 - val_mae: 0.0180\n",
      "Epoch 138/180\n",
      "65/65 [==============================] - 16s 248ms/step - loss: 8.6313e-04 - mse: 8.6313e-04 - mae: 0.0169 - val_loss: 8.7076e-04 - val_mse: 8.7076e-04 - val_mae: 0.0170\n",
      "Epoch 139/180\n",
      "65/65 [==============================] - 15s 224ms/step - loss: 8.6575e-04 - mse: 8.6575e-04 - mae: 0.0169 - val_loss: 8.7581e-04 - val_mse: 8.7581e-04 - val_mae: 0.0182\n",
      "Epoch 140/180\n",
      "65/65 [==============================] - 15s 224ms/step - loss: 8.6827e-04 - mse: 8.6827e-04 - mae: 0.0169 - val_loss: 8.6817e-04 - val_mse: 8.6817e-04 - val_mae: 0.0181\n",
      "Epoch 141/180\n",
      "65/65 [==============================] - 16s 249ms/step - loss: 8.5954e-04 - mse: 8.5954e-04 - mae: 0.0169 - val_loss: 8.8053e-04 - val_mse: 8.8053e-04 - val_mae: 0.0185\n",
      "Epoch 142/180\n",
      "65/65 [==============================] - 17s 263ms/step - loss: 8.6539e-04 - mse: 8.6539e-04 - mae: 0.0169 - val_loss: 8.7342e-04 - val_mse: 8.7342e-04 - val_mae: 0.0185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143/180\n",
      "65/65 [==============================] - 15s 223ms/step - loss: 8.6139e-04 - mse: 8.6139e-04 - mae: 0.0169 - val_loss: 8.4613e-04 - val_mse: 8.4613e-04 - val_mae: 0.0182\n",
      "Epoch 144/180\n",
      "65/65 [==============================] - 15s 226ms/step - loss: 8.6587e-04 - mse: 8.6587e-04 - mae: 0.0170 - val_loss: 8.6869e-04 - val_mse: 8.6869e-04 - val_mae: 0.0187\n",
      "Epoch 145/180\n",
      "65/65 [==============================] - 15s 237ms/step - loss: 8.5755e-04 - mse: 8.5755e-04 - mae: 0.0168 - val_loss: 8.7831e-04 - val_mse: 8.7831e-04 - val_mae: 0.0186\n",
      "Epoch 146/180\n",
      "65/65 [==============================] - 15s 225ms/step - loss: 8.5980e-04 - mse: 8.5980e-04 - mae: 0.0168 - val_loss: 8.4720e-04 - val_mse: 8.4720e-04 - val_mae: 0.0179\n",
      "Epoch 147/180\n",
      "65/65 [==============================] - 14s 223ms/step - loss: 8.5843e-04 - mse: 8.5843e-04 - mae: 0.0168 - val_loss: 8.6682e-04 - val_mse: 8.6682e-04 - val_mae: 0.0184\n",
      "Epoch 148/180\n",
      "65/65 [==============================] - 14s 221ms/step - loss: 8.5656e-04 - mse: 8.5656e-04 - mae: 0.0167 - val_loss: 8.6772e-04 - val_mse: 8.6772e-04 - val_mae: 0.0186\n",
      "Epoch 149/180\n",
      "65/65 [==============================] - 15s 225ms/step - loss: 8.5700e-04 - mse: 8.5700e-04 - mae: 0.0167 - val_loss: 8.6565e-04 - val_mse: 8.6565e-04 - val_mae: 0.0185\n",
      "Epoch 150/180\n",
      "65/65 [==============================] - 17s 257ms/step - loss: 8.5052e-04 - mse: 8.5052e-04 - mae: 0.0167 - val_loss: 8.4984e-04 - val_mse: 8.4984e-04 - val_mae: 0.0182\n",
      "Epoch 151/180\n",
      "65/65 [==============================] - 15s 233ms/step - loss: 8.4940e-04 - mse: 8.4940e-04 - mae: 0.0166 - val_loss: 8.5501e-04 - val_mse: 8.5501e-04 - val_mae: 0.0184\n",
      "Epoch 152/180\n",
      "65/65 [==============================] - 17s 259ms/step - loss: 8.5403e-04 - mse: 8.5403e-04 - mae: 0.0166 - val_loss: 8.7139e-04 - val_mse: 8.7139e-04 - val_mae: 0.0183\n",
      "Epoch 153/180\n",
      "65/65 [==============================] - 16s 247ms/step - loss: 8.5827e-04 - mse: 8.5827e-04 - mae: 0.0166 - val_loss: 8.9705e-04 - val_mse: 8.9705e-04 - val_mae: 0.0189\n",
      "Epoch 154/180\n",
      "65/65 [==============================] - 18s 276ms/step - loss: 8.4846e-04 - mse: 8.4846e-04 - mae: 0.0166 - val_loss: 8.8135e-04 - val_mse: 8.8135e-04 - val_mae: 0.0186\n",
      "Epoch 155/180\n",
      "65/65 [==============================] - 16s 248ms/step - loss: 8.5062e-04 - mse: 8.5062e-04 - mae: 0.0166 - val_loss: 8.8232e-04 - val_mse: 8.8232e-04 - val_mae: 0.0189\n",
      "Epoch 156/180\n",
      "65/65 [==============================] - 15s 232ms/step - loss: 8.4622e-04 - mse: 8.4622e-04 - mae: 0.0166 - val_loss: 8.9882e-04 - val_mse: 8.9882e-04 - val_mae: 0.0189\n",
      "Epoch 157/180\n",
      "65/65 [==============================] - 15s 226ms/step - loss: 8.4596e-04 - mse: 8.4596e-04 - mae: 0.0165 - val_loss: 8.8098e-04 - val_mse: 8.8098e-04 - val_mae: 0.0184\n",
      "Epoch 158/180\n",
      "65/65 [==============================] - 14s 221ms/step - loss: 8.4017e-04 - mse: 8.4017e-04 - mae: 0.0164 - val_loss: 9.1566e-04 - val_mse: 9.1566e-04 - val_mae: 0.0190\n",
      "Epoch 159/180\n",
      "65/65 [==============================] - 14s 220ms/step - loss: 8.5370e-04 - mse: 8.5370e-04 - mae: 0.0165 - val_loss: 8.9037e-04 - val_mse: 8.9037e-04 - val_mae: 0.0186\n",
      "Epoch 160/180\n",
      "65/65 [==============================] - 15s 226ms/step - loss: 8.4278e-04 - mse: 8.4278e-04 - mae: 0.0164 - val_loss: 9.0745e-04 - val_mse: 9.0745e-04 - val_mae: 0.0189\n",
      "Epoch 161/180\n",
      "65/65 [==============================] - 14s 219ms/step - loss: 8.4538e-04 - mse: 8.4538e-04 - mae: 0.0165 - val_loss: 9.0494e-04 - val_mse: 9.0494e-04 - val_mae: 0.0189\n",
      "Epoch 162/180\n",
      "65/65 [==============================] - 16s 239ms/step - loss: 8.4854e-04 - mse: 8.4854e-04 - mae: 0.0165 - val_loss: 8.8276e-04 - val_mse: 8.8276e-04 - val_mae: 0.0185\n",
      "Epoch 163/180\n",
      "65/65 [==============================] - 19s 297ms/step - loss: 8.3962e-04 - mse: 8.3962e-04 - mae: 0.0164 - val_loss: 9.2308e-04 - val_mse: 9.2308e-04 - val_mae: 0.0190\n",
      "Epoch 164/180\n",
      "65/65 [==============================] - 18s 278ms/step - loss: 8.4530e-04 - mse: 8.4530e-04 - mae: 0.0164 - val_loss: 8.9153e-04 - val_mse: 8.9153e-04 - val_mae: 0.0186\n",
      "Epoch 165/180\n",
      "65/65 [==============================] - 15s 233ms/step - loss: 8.3726e-04 - mse: 8.3726e-04 - mae: 0.0163 - val_loss: 9.1666e-04 - val_mse: 9.1666e-04 - val_mae: 0.0187\n",
      "Epoch 166/180\n",
      "65/65 [==============================] - 15s 229ms/step - loss: 8.4180e-04 - mse: 8.4180e-04 - mae: 0.0164 - val_loss: 9.5457e-04 - val_mse: 9.5457e-04 - val_mae: 0.0196\n",
      "Epoch 167/180\n",
      "65/65 [==============================] - 15s 231ms/step - loss: 8.3464e-04 - mse: 8.3464e-04 - mae: 0.0163 - val_loss: 9.1384e-04 - val_mse: 9.1384e-04 - val_mae: 0.0187\n",
      "Epoch 168/180\n",
      "65/65 [==============================] - 15s 231ms/step - loss: 8.3791e-04 - mse: 8.3791e-04 - mae: 0.0163 - val_loss: 9.2492e-04 - val_mse: 9.2492e-04 - val_mae: 0.0189\n",
      "Epoch 169/180\n",
      "65/65 [==============================] - 16s 245ms/step - loss: 8.3404e-04 - mse: 8.3404e-04 - mae: 0.0163 - val_loss: 8.9534e-04 - val_mse: 8.9534e-04 - val_mae: 0.0183\n",
      "Epoch 170/180\n",
      "65/65 [==============================] - 17s 259ms/step - loss: 8.4081e-04 - mse: 8.4081e-04 - mae: 0.0164 - val_loss: 9.3693e-04 - val_mse: 9.3693e-04 - val_mae: 0.0194\n",
      "Epoch 171/180\n",
      "65/65 [==============================] - 17s 266ms/step - loss: 8.3797e-04 - mse: 8.3797e-04 - mae: 0.0163 - val_loss: 9.1941e-04 - val_mse: 9.1941e-04 - val_mae: 0.0188\n",
      "Epoch 172/180\n",
      "65/65 [==============================] - 16s 246ms/step - loss: 8.3266e-04 - mse: 8.3266e-04 - mae: 0.0163 - val_loss: 9.3752e-04 - val_mse: 9.3752e-04 - val_mae: 0.0192\n",
      "Epoch 173/180\n",
      "65/65 [==============================] - 15s 225ms/step - loss: 8.3325e-04 - mse: 8.3325e-04 - mae: 0.0163 - val_loss: 9.1826e-04 - val_mse: 9.1826e-04 - val_mae: 0.0186\n",
      "Epoch 174/180\n",
      "65/65 [==============================] - 16s 239ms/step - loss: 8.3987e-04 - mse: 8.3987e-04 - mae: 0.0164 - val_loss: 9.2208e-04 - val_mse: 9.2208e-04 - val_mae: 0.0189\n",
      "Epoch 175/180\n",
      "65/65 [==============================] - 16s 240ms/step - loss: 8.3292e-04 - mse: 8.3292e-04 - mae: 0.0164 - val_loss: 9.1504e-04 - val_mse: 9.1504e-04 - val_mae: 0.0187\n",
      "Epoch 176/180\n",
      "65/65 [==============================] - 15s 226ms/step - loss: 8.2993e-04 - mse: 8.2993e-04 - mae: 0.0162 - val_loss: 8.8721e-04 - val_mse: 8.8721e-04 - val_mae: 0.0173\n",
      "Epoch 177/180\n",
      "65/65 [==============================] - 14s 219ms/step - loss: 8.3318e-04 - mse: 8.3318e-04 - mae: 0.0163 - val_loss: 9.2202e-04 - val_mse: 9.2202e-04 - val_mae: 0.0187\n",
      "Epoch 178/180\n",
      "65/65 [==============================] - 14s 218ms/step - loss: 8.3308e-04 - mse: 8.3308e-04 - mae: 0.0162 - val_loss: 9.3461e-04 - val_mse: 9.3461e-04 - val_mae: 0.0192\n",
      "Epoch 179/180\n",
      "65/65 [==============================] - 14s 222ms/step - loss: 8.2830e-04 - mse: 8.2830e-04 - mae: 0.0161 - val_loss: 9.2281e-04 - val_mse: 9.2281e-04 - val_mae: 0.0186\n",
      "Epoch 180/180\n",
      "65/65 [==============================] - 16s 249ms/step - loss: 8.4627e-04 - mse: 8.4627e-04 - mae: 0.0163 - val_loss: 9.0527e-04 - val_mse: 9.0527e-04 - val_mae: 0.0188\n",
      "Epoch 1/180\n",
      "65/65 [==============================] - 39s 602ms/step - loss: 0.1426 - mse: 0.1426 - mae: 0.2960 - val_loss: 0.0048 - val_mse: 0.0048 - val_mae: 0.0591\n",
      "Epoch 2/180\n",
      "65/65 [==============================] - 41s 627ms/step - loss: 0.0791 - mse: 0.0791 - mae: 0.2238 - val_loss: 0.0015 - val_mse: 0.0015 - val_mae: 0.0262\n",
      "Epoch 3/180\n",
      "65/65 [==============================] - 37s 567ms/step - loss: 0.0485 - mse: 0.0485 - mae: 0.1752 - val_loss: 0.0017 - val_mse: 0.0017 - val_mae: 0.0293\n",
      "Epoch 4/180\n",
      "65/65 [==============================] - 38s 581ms/step - loss: 0.0316 - mse: 0.0316 - mae: 0.1414 - val_loss: 0.0024 - val_mse: 0.0024 - val_mae: 0.0415\n",
      "Epoch 5/180\n",
      "65/65 [==============================] - 38s 577ms/step - loss: 0.0220 - mse: 0.0220 - mae: 0.1178 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0234\n",
      "Epoch 6/180\n",
      "65/65 [==============================] - 40s 611ms/step - loss: 0.0152 - mse: 0.0152 - mae: 0.0972 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0189\n",
      "Epoch 7/180\n",
      "65/65 [==============================] - 41s 634ms/step - loss: 0.0119 - mse: 0.0119 - mae: 0.0862 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0234\n",
      "Epoch 8/180\n",
      "65/65 [==============================] - 42s 652ms/step - loss: 0.0096 - mse: 0.0096 - mae: 0.0764 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0199\n",
      "Epoch 9/180\n",
      "65/65 [==============================] - 43s 663ms/step - loss: 0.0080 - mse: 0.0080 - mae: 0.0704 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0229\n",
      "Epoch 10/180\n",
      "65/65 [==============================] - 44s 673ms/step - loss: 0.0068 - mse: 0.0068 - mae: 0.0643 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0265\n",
      "Epoch 11/180\n",
      "65/65 [==============================] - 41s 626ms/step - loss: 0.0055 - mse: 0.0055 - mae: 0.0578 - val_loss: 0.0015 - val_mse: 0.0015 - val_mae: 0.0334\n",
      "Epoch 12/180\n",
      "65/65 [==============================] - 38s 591ms/step - loss: 0.0047 - mse: 0.0047 - mae: 0.0528 - val_loss: 0.0015 - val_mse: 0.0015 - val_mae: 0.0326\n",
      "Epoch 13/180\n",
      "65/65 [==============================] - 42s 645ms/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0499 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0292\n",
      "Epoch 14/180\n",
      "65/65 [==============================] - 40s 610ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0482 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0281\n",
      "Epoch 15/180\n",
      "65/65 [==============================] - 45s 699ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0462 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0288\n",
      "Epoch 16/180\n",
      "65/65 [==============================] - 39s 601ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0444 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0269\n",
      "Epoch 17/180\n",
      "65/65 [==============================] - 38s 587ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0423 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0246\n",
      "Epoch 18/180\n",
      "65/65 [==============================] - 38s 582ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0405 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0240\n",
      "Epoch 19/180\n",
      "65/65 [==============================] - 40s 617ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0383 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0236\n",
      "Epoch 20/180\n",
      "65/65 [==============================] - 39s 604ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0374 - val_loss: 9.2689e-04 - val_mse: 9.2689e-04 - val_mae: 0.0205\n",
      "Epoch 21/180\n",
      "65/65 [==============================] - 39s 599ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0357 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0244\n",
      "Epoch 22/180\n",
      "65/65 [==============================] - 41s 638ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0347 - val_loss: 9.4774e-04 - val_mse: 9.4774e-04 - val_mae: 0.0205\n",
      "Epoch 23/180\n",
      "65/65 [==============================] - 42s 648ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0332 - val_loss: 9.5630e-04 - val_mse: 9.5630e-04 - val_mae: 0.0213\n",
      "Epoch 24/180\n",
      "65/65 [==============================] - 36s 561ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0321 - val_loss: 9.4742e-04 - val_mse: 9.4742e-04 - val_mae: 0.0211\n",
      "Epoch 25/180\n",
      "65/65 [==============================] - 38s 586ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0308 - val_loss: 9.3907e-04 - val_mse: 9.3907e-04 - val_mae: 0.0209\n",
      "Epoch 26/180\n",
      "65/65 [==============================] - 37s 563ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0309 - val_loss: 9.6407e-04 - val_mse: 9.6407e-04 - val_mae: 0.0217\n",
      "Epoch 27/180\n",
      "65/65 [==============================] - 37s 571ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0296 - val_loss: 9.2001e-04 - val_mse: 9.2001e-04 - val_mae: 0.0199\n",
      "Epoch 28/180\n",
      "65/65 [==============================] - 45s 694ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0290 - val_loss: 9.7965e-04 - val_mse: 9.7965e-04 - val_mae: 0.0224\n",
      "Epoch 29/180\n",
      "65/65 [==============================] - 44s 682ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0276 - val_loss: 9.3414e-04 - val_mse: 9.3414e-04 - val_mae: 0.0201\n",
      "Epoch 30/180\n",
      "65/65 [==============================] - 42s 647ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0273 - val_loss: 9.5896e-04 - val_mse: 9.5896e-04 - val_mae: 0.0214\n",
      "Epoch 31/180\n",
      "65/65 [==============================] - 42s 643ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0265 - val_loss: 9.3938e-04 - val_mse: 9.3938e-04 - val_mae: 0.0204\n",
      "Epoch 32/180\n",
      "65/65 [==============================] - 41s 631ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0254 - val_loss: 9.3057e-04 - val_mse: 9.3057e-04 - val_mae: 0.0201\n",
      "Epoch 33/180\n",
      "65/65 [==============================] - 40s 614ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0253 - val_loss: 9.4192e-04 - val_mse: 9.4192e-04 - val_mae: 0.0202\n",
      "Epoch 34/180\n",
      "65/65 [==============================] - 39s 595ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0245 - val_loss: 9.7504e-04 - val_mse: 9.7504e-04 - val_mae: 0.0212\n",
      "Epoch 35/180\n",
      "65/65 [==============================] - 42s 650ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0242 - val_loss: 9.6588e-04 - val_mse: 9.6588e-04 - val_mae: 0.0200\n",
      "Epoch 36/180\n",
      "65/65 [==============================] - 39s 599ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0233 - val_loss: 9.8621e-04 - val_mse: 9.8621e-04 - val_mae: 0.0212\n",
      "Epoch 37/180\n",
      "65/65 [==============================] - 39s 597ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0233 - val_loss: 9.5272e-04 - val_mse: 9.5272e-04 - val_mae: 0.0197\n",
      "Epoch 38/180\n",
      "65/65 [==============================] - 39s 595ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0227 - val_loss: 9.6560e-04 - val_mse: 9.6560e-04 - val_mae: 0.0208\n",
      "Epoch 39/180\n",
      "65/65 [==============================] - 42s 645ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0223 - val_loss: 9.4502e-04 - val_mse: 9.4502e-04 - val_mae: 0.0190\n",
      "Epoch 40/180\n",
      "65/65 [==============================] - 41s 635ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0218 - val_loss: 9.5347e-04 - val_mse: 9.5347e-04 - val_mae: 0.0198\n",
      "Epoch 41/180\n",
      "65/65 [==============================] - 39s 600ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0214 - val_loss: 9.6437e-04 - val_mse: 9.6437e-04 - val_mae: 0.0205\n",
      "Epoch 42/180\n",
      "65/65 [==============================] - 39s 601ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0212 - val_loss: 9.6688e-04 - val_mse: 9.6688e-04 - val_mae: 0.0208\n",
      "Epoch 43/180\n",
      "65/65 [==============================] - 38s 577ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0211 - val_loss: 9.5092e-04 - val_mse: 9.5092e-04 - val_mae: 0.0191\n",
      "Epoch 44/180\n",
      "65/65 [==============================] - 39s 605ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0209 - val_loss: 9.5732e-04 - val_mse: 9.5732e-04 - val_mae: 0.0199\n",
      "Epoch 45/180\n",
      "65/65 [==============================] - 41s 625ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0205 - val_loss: 9.5484e-04 - val_mse: 9.5484e-04 - val_mae: 0.0191\n",
      "Epoch 46/180\n",
      "65/65 [==============================] - 37s 577ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0204 - val_loss: 9.7213e-04 - val_mse: 9.7213e-04 - val_mae: 0.0205\n",
      "Epoch 47/180\n",
      "65/65 [==============================] - 38s 581ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0201 - val_loss: 9.5426e-04 - val_mse: 9.5426e-04 - val_mae: 0.0196\n",
      "Epoch 48/180\n",
      "65/65 [==============================] - 39s 602ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0198 - val_loss: 9.5626e-04 - val_mse: 9.5626e-04 - val_mae: 0.0193\n",
      "Epoch 49/180\n",
      "65/65 [==============================] - 39s 600ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0197 - val_loss: 9.5331e-04 - val_mse: 9.5331e-04 - val_mae: 0.0192\n",
      "Epoch 50/180\n",
      "65/65 [==============================] - 38s 585ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0198 - val_loss: 9.5630e-04 - val_mse: 9.5630e-04 - val_mae: 0.0197\n",
      "Epoch 51/180\n",
      "65/65 [==============================] - 41s 623ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0197 - val_loss: 9.5776e-04 - val_mse: 9.5776e-04 - val_mae: 0.0194\n",
      "Epoch 52/180\n",
      "65/65 [==============================] - 44s 673ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0193 - val_loss: 9.5614e-04 - val_mse: 9.5614e-04 - val_mae: 0.0196\n",
      "Epoch 53/180\n",
      "65/65 [==============================] - 44s 682ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0193 - val_loss: 9.6185e-04 - val_mse: 9.6185e-04 - val_mae: 0.0202\n",
      "Epoch 54/180\n",
      "65/65 [==============================] - 45s 695ms/step - loss: 9.8970e-04 - mse: 9.8970e-04 - mae: 0.0190 - val_loss: 9.4856e-04 - val_mse: 9.4856e-04 - val_mae: 0.0191\n",
      "Epoch 55/180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 45s 688ms/step - loss: 9.9083e-04 - mse: 9.9083e-04 - mae: 0.0190 - val_loss: 9.5340e-04 - val_mse: 9.5340e-04 - val_mae: 0.0196\n",
      "Epoch 56/180\n",
      "65/65 [==============================] - 46s 700ms/step - loss: 9.8669e-04 - mse: 9.8669e-04 - mae: 0.0189 - val_loss: 9.4625e-04 - val_mse: 9.4625e-04 - val_mae: 0.0196\n",
      "Epoch 57/180\n",
      "65/65 [==============================] - 46s 711ms/step - loss: 9.8658e-04 - mse: 9.8658e-04 - mae: 0.0187 - val_loss: 9.5155e-04 - val_mse: 9.5155e-04 - val_mae: 0.0195\n",
      "Epoch 58/180\n",
      "65/65 [==============================] - 45s 689ms/step - loss: 9.7132e-04 - mse: 9.7132e-04 - mae: 0.0186 - val_loss: 9.4393e-04 - val_mse: 9.4393e-04 - val_mae: 0.0189\n",
      "Epoch 59/180\n",
      "65/65 [==============================] - 47s 728ms/step - loss: 9.6564e-04 - mse: 9.6564e-04 - mae: 0.0184 - val_loss: 9.4476e-04 - val_mse: 9.4476e-04 - val_mae: 0.0190\n",
      "Epoch 60/180\n",
      "65/65 [==============================] - 40s 611ms/step - loss: 9.6176e-04 - mse: 9.6176e-04 - mae: 0.0185 - val_loss: 9.5226e-04 - val_mse: 9.5226e-04 - val_mae: 0.0195\n",
      "Epoch 61/180\n",
      "65/65 [==============================] - 38s 581ms/step - loss: 9.5193e-04 - mse: 9.5193e-04 - mae: 0.0183 - val_loss: 9.5098e-04 - val_mse: 9.5098e-04 - val_mae: 0.0197\n",
      "Epoch 62/180\n",
      "65/65 [==============================] - 38s 581ms/step - loss: 9.5904e-04 - mse: 9.5904e-04 - mae: 0.0184 - val_loss: 9.5565e-04 - val_mse: 9.5565e-04 - val_mae: 0.0196\n",
      "Epoch 63/180\n",
      "65/65 [==============================] - 42s 650ms/step - loss: 9.5853e-04 - mse: 9.5853e-04 - mae: 0.0184 - val_loss: 9.5365e-04 - val_mse: 9.5365e-04 - val_mae: 0.0197\n",
      "Epoch 64/180\n",
      "65/65 [==============================] - 36s 556ms/step - loss: 9.4229e-04 - mse: 9.4229e-04 - mae: 0.0182 - val_loss: 9.5422e-04 - val_mse: 9.5422e-04 - val_mae: 0.0199\n",
      "Epoch 65/180\n",
      "65/65 [==============================] - 36s 554ms/step - loss: 9.4977e-04 - mse: 9.4977e-04 - mae: 0.0182 - val_loss: 9.5197e-04 - val_mse: 9.5197e-04 - val_mae: 0.0195\n",
      "Epoch 66/180\n",
      "65/65 [==============================] - 35s 545ms/step - loss: 9.4973e-04 - mse: 9.4973e-04 - mae: 0.0182 - val_loss: 9.4155e-04 - val_mse: 9.4155e-04 - val_mae: 0.0184\n",
      "Epoch 67/180\n",
      "65/65 [==============================] - 35s 544ms/step - loss: 9.4921e-04 - mse: 9.4921e-04 - mae: 0.0182 - val_loss: 9.4235e-04 - val_mse: 9.4235e-04 - val_mae: 0.0188\n",
      "Epoch 68/180\n",
      "65/65 [==============================] - 35s 546ms/step - loss: 9.3165e-04 - mse: 9.3165e-04 - mae: 0.0179 - val_loss: 9.3809e-04 - val_mse: 9.3809e-04 - val_mae: 0.0184\n",
      "Epoch 69/180\n",
      "65/65 [==============================] - 38s 577ms/step - loss: 9.4305e-04 - mse: 9.4305e-04 - mae: 0.0181 - val_loss: 9.4216e-04 - val_mse: 9.4216e-04 - val_mae: 0.0192\n",
      "Epoch 70/180\n",
      "65/65 [==============================] - 35s 543ms/step - loss: 9.2757e-04 - mse: 9.2757e-04 - mae: 0.0180 - val_loss: 9.5521e-04 - val_mse: 9.5521e-04 - val_mae: 0.0192\n",
      "Epoch 71/180\n",
      "65/65 [==============================] - 35s 536ms/step - loss: 9.2652e-04 - mse: 9.2652e-04 - mae: 0.0180 - val_loss: 9.5762e-04 - val_mse: 9.5762e-04 - val_mae: 0.0188\n",
      "Epoch 72/180\n",
      "65/65 [==============================] - 36s 553ms/step - loss: 9.2413e-04 - mse: 9.2413e-04 - mae: 0.0178 - val_loss: 9.4002e-04 - val_mse: 9.4002e-04 - val_mae: 0.0178\n",
      "Epoch 73/180\n",
      "65/65 [==============================] - 36s 551ms/step - loss: 9.2143e-04 - mse: 9.2143e-04 - mae: 0.0178 - val_loss: 9.4988e-04 - val_mse: 9.4988e-04 - val_mae: 0.0185\n",
      "Epoch 74/180\n",
      "65/65 [==============================] - 36s 559ms/step - loss: 9.1581e-04 - mse: 9.1581e-04 - mae: 0.0178 - val_loss: 9.4989e-04 - val_mse: 9.4989e-04 - val_mae: 0.0180\n",
      "Epoch 75/180\n",
      "65/65 [==============================] - 37s 563ms/step - loss: 9.1844e-04 - mse: 9.1844e-04 - mae: 0.0178 - val_loss: 9.5882e-04 - val_mse: 9.5882e-04 - val_mae: 0.0186\n",
      "Epoch 76/180\n",
      "65/65 [==============================] - 36s 547ms/step - loss: 9.0849e-04 - mse: 9.0849e-04 - mae: 0.0177 - val_loss: 9.5036e-04 - val_mse: 9.5036e-04 - val_mae: 0.0182\n",
      "Epoch 77/180\n",
      "65/65 [==============================] - 35s 536ms/step - loss: 9.1455e-04 - mse: 9.1455e-04 - mae: 0.0177 - val_loss: 9.4920e-04 - val_mse: 9.4920e-04 - val_mae: 0.0185\n",
      "Epoch 78/180\n",
      "65/65 [==============================] - 42s 652ms/step - loss: 8.9811e-04 - mse: 8.9811e-04 - mae: 0.0175 - val_loss: 9.5065e-04 - val_mse: 9.5065e-04 - val_mae: 0.0183\n",
      "Epoch 79/180\n",
      "65/65 [==============================] - 39s 594ms/step - loss: 9.0418e-04 - mse: 9.0418e-04 - mae: 0.0174 - val_loss: 9.4787e-04 - val_mse: 9.4787e-04 - val_mae: 0.0185\n",
      "Epoch 80/180\n",
      "65/65 [==============================] - 41s 626ms/step - loss: 9.0362e-04 - mse: 9.0362e-04 - mae: 0.0176 - val_loss: 9.4265e-04 - val_mse: 9.4265e-04 - val_mae: 0.0186\n",
      "Epoch 81/180\n",
      "65/65 [==============================] - 42s 639ms/step - loss: 9.0711e-04 - mse: 9.0711e-04 - mae: 0.0176 - val_loss: 9.7117e-04 - val_mse: 9.7117e-04 - val_mae: 0.0191\n",
      "Epoch 82/180\n",
      "65/65 [==============================] - 39s 599ms/step - loss: 9.0062e-04 - mse: 9.0062e-04 - mae: 0.0174 - val_loss: 9.4328e-04 - val_mse: 9.4328e-04 - val_mae: 0.0179\n",
      "Epoch 83/180\n",
      "65/65 [==============================] - 41s 634ms/step - loss: 8.8898e-04 - mse: 8.8898e-04 - mae: 0.0174 - val_loss: 9.4556e-04 - val_mse: 9.4556e-04 - val_mae: 0.0180\n",
      "Epoch 84/180\n",
      "65/65 [==============================] - 40s 620ms/step - loss: 9.0036e-04 - mse: 9.0036e-04 - mae: 0.0173 - val_loss: 9.4105e-04 - val_mse: 9.4105e-04 - val_mae: 0.0174\n",
      "Epoch 85/180\n",
      "65/65 [==============================] - 41s 635ms/step - loss: 8.9375e-04 - mse: 8.9375e-04 - mae: 0.0174 - val_loss: 9.4219e-04 - val_mse: 9.4219e-04 - val_mae: 0.0176\n",
      "Epoch 86/180\n",
      "65/65 [==============================] - 41s 624ms/step - loss: 8.9164e-04 - mse: 8.9164e-04 - mae: 0.0173 - val_loss: 9.6223e-04 - val_mse: 9.6223e-04 - val_mae: 0.0188\n",
      "Epoch 87/180\n",
      "65/65 [==============================] - 39s 606ms/step - loss: 8.9168e-04 - mse: 8.9168e-04 - mae: 0.0173 - val_loss: 9.6980e-04 - val_mse: 9.6980e-04 - val_mae: 0.0189\n",
      "Epoch 88/180\n",
      "65/65 [==============================] - 40s 608ms/step - loss: 8.8615e-04 - mse: 8.8615e-04 - mae: 0.0172 - val_loss: 9.5377e-04 - val_mse: 9.5377e-04 - val_mae: 0.0182\n",
      "Epoch 89/180\n",
      "65/65 [==============================] - 42s 639ms/step - loss: 8.8844e-04 - mse: 8.8844e-04 - mae: 0.0172 - val_loss: 9.4232e-04 - val_mse: 9.4232e-04 - val_mae: 0.0183\n",
      "Epoch 90/180\n",
      "65/65 [==============================] - 42s 644ms/step - loss: 8.8108e-04 - mse: 8.8108e-04 - mae: 0.0172 - val_loss: 9.8211e-04 - val_mse: 9.8211e-04 - val_mae: 0.0191\n",
      "Epoch 91/180\n",
      "65/65 [==============================] - 46s 713ms/step - loss: 8.8212e-04 - mse: 8.8212e-04 - mae: 0.0171 - val_loss: 9.7670e-04 - val_mse: 9.7670e-04 - val_mae: 0.0184\n",
      "Epoch 92/180\n",
      "65/65 [==============================] - 41s 631ms/step - loss: 8.8799e-04 - mse: 8.8799e-04 - mae: 0.0171 - val_loss: 9.6488e-04 - val_mse: 9.6488e-04 - val_mae: 0.0178\n",
      "Epoch 93/180\n",
      "65/65 [==============================] - 41s 625ms/step - loss: 8.7807e-04 - mse: 8.7807e-04 - mae: 0.0170 - val_loss: 9.8579e-04 - val_mse: 9.8579e-04 - val_mae: 0.0186\n",
      "Epoch 94/180\n",
      "65/65 [==============================] - 39s 600ms/step - loss: 8.6480e-04 - mse: 8.6480e-04 - mae: 0.0169 - val_loss: 9.4707e-04 - val_mse: 9.4707e-04 - val_mae: 0.0176\n",
      "Epoch 95/180\n",
      "65/65 [==============================] - 38s 592ms/step - loss: 8.8692e-04 - mse: 8.8692e-04 - mae: 0.0173 - val_loss: 9.6271e-04 - val_mse: 9.6271e-04 - val_mae: 0.0184\n",
      "Epoch 96/180\n",
      "65/65 [==============================] - 40s 622ms/step - loss: 8.6362e-04 - mse: 8.6362e-04 - mae: 0.0168 - val_loss: 9.7321e-04 - val_mse: 9.7321e-04 - val_mae: 0.0182\n",
      "Epoch 97/180\n",
      "65/65 [==============================] - 38s 587ms/step - loss: 8.7273e-04 - mse: 8.7273e-04 - mae: 0.0169 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0198\n",
      "Epoch 98/180\n",
      "65/65 [==============================] - 40s 616ms/step - loss: 8.6280e-04 - mse: 8.6280e-04 - mae: 0.0168 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0197\n",
      "Epoch 99/180\n",
      "65/65 [==============================] - 43s 657ms/step - loss: 8.6742e-04 - mse: 8.6742e-04 - mae: 0.0168 - val_loss: 9.8865e-04 - val_mse: 9.8865e-04 - val_mae: 0.0178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/180\n",
      "65/65 [==============================] - 41s 637ms/step - loss: 8.6611e-04 - mse: 8.6611e-04 - mae: 0.0168 - val_loss: 9.6934e-04 - val_mse: 9.6934e-04 - val_mae: 0.0173\n",
      "Epoch 101/180\n",
      "65/65 [==============================] - 40s 616ms/step - loss: 8.6857e-04 - mse: 8.6857e-04 - mae: 0.0168 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0195\n",
      "Epoch 102/180\n",
      "65/65 [==============================] - 42s 644ms/step - loss: 8.6352e-04 - mse: 8.6352e-04 - mae: 0.0167 - val_loss: 9.7369e-04 - val_mse: 9.7369e-04 - val_mae: 0.0175\n",
      "Epoch 103/180\n",
      "65/65 [==============================] - 43s 656ms/step - loss: 8.6077e-04 - mse: 8.6077e-04 - mae: 0.0167 - val_loss: 9.8669e-04 - val_mse: 9.8669e-04 - val_mae: 0.0179\n",
      "Epoch 104/180\n",
      "65/65 [==============================] - 45s 687ms/step - loss: 8.5904e-04 - mse: 8.5904e-04 - mae: 0.0167 - val_loss: 9.9508e-04 - val_mse: 9.9508e-04 - val_mae: 0.0180\n",
      "Epoch 105/180\n",
      "65/65 [==============================] - 39s 608ms/step - loss: 8.5496e-04 - mse: 8.5496e-04 - mae: 0.0166 - val_loss: 9.6121e-04 - val_mse: 9.6121e-04 - val_mae: 0.0176\n",
      "Epoch 106/180\n",
      "65/65 [==============================] - 41s 626ms/step - loss: 8.6069e-04 - mse: 8.6069e-04 - mae: 0.0166 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0185\n",
      "Epoch 107/180\n",
      "65/65 [==============================] - 41s 633ms/step - loss: 8.5577e-04 - mse: 8.5577e-04 - mae: 0.0166 - val_loss: 9.9831e-04 - val_mse: 9.9831e-04 - val_mae: 0.0180\n",
      "Epoch 108/180\n",
      "65/65 [==============================] - 41s 638ms/step - loss: 8.4906e-04 - mse: 8.4906e-04 - mae: 0.0166 - val_loss: 9.8006e-04 - val_mse: 9.8006e-04 - val_mae: 0.0180\n",
      "Epoch 109/180\n",
      "65/65 [==============================] - 41s 626ms/step - loss: 8.4533e-04 - mse: 8.4533e-04 - mae: 0.0165 - val_loss: 9.9246e-04 - val_mse: 9.9246e-04 - val_mae: 0.0181\n",
      "Epoch 110/180\n",
      "65/65 [==============================] - 44s 670ms/step - loss: 8.4694e-04 - mse: 8.4694e-04 - mae: 0.0165 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0188\n",
      "Epoch 111/180\n",
      "65/65 [==============================] - 43s 660ms/step - loss: 8.4788e-04 - mse: 8.4788e-04 - mae: 0.0166 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0188\n",
      "Epoch 112/180\n",
      "65/65 [==============================] - 43s 654ms/step - loss: 8.4057e-04 - mse: 8.4057e-04 - mae: 0.0164 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0184\n",
      "Epoch 113/180\n",
      "65/65 [==============================] - 41s 628ms/step - loss: 8.4139e-04 - mse: 8.4139e-04 - mae: 0.0164 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0187\n",
      "Epoch 114/180\n",
      "65/65 [==============================] - 38s 585ms/step - loss: 8.3892e-04 - mse: 8.3892e-04 - mae: 0.0163 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0183\n",
      "Epoch 115/180\n",
      "65/65 [==============================] - 40s 617ms/step - loss: 8.5364e-04 - mse: 8.5364e-04 - mae: 0.0167 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0211\n",
      "Epoch 116/180\n",
      "65/65 [==============================] - 45s 693ms/step - loss: 8.4759e-04 - mse: 8.4759e-04 - mae: 0.0164 - val_loss: 9.6787e-04 - val_mse: 9.6787e-04 - val_mae: 0.0191\n",
      "Epoch 117/180\n",
      "65/65 [==============================] - 45s 687ms/step - loss: 8.4750e-04 - mse: 8.4750e-04 - mae: 0.0167 - val_loss: 9.6365e-04 - val_mse: 9.6365e-04 - val_mae: 0.0174\n",
      "Epoch 118/180\n",
      "65/65 [==============================] - 43s 660ms/step - loss: 8.3597e-04 - mse: 8.3597e-04 - mae: 0.0164 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0194\n",
      "Epoch 119/180\n",
      "65/65 [==============================] - 50s 763ms/step - loss: 8.3795e-04 - mse: 8.3795e-04 - mae: 0.0164 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0180\n",
      "Epoch 120/180\n",
      "65/65 [==============================] - 45s 700ms/step - loss: 8.3709e-04 - mse: 8.3709e-04 - mae: 0.0164 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0194\n",
      "Epoch 121/180\n",
      "65/65 [==============================] - 43s 659ms/step - loss: 8.1872e-04 - mse: 8.1872e-04 - mae: 0.0161 - val_loss: 9.5750e-04 - val_mse: 9.5750e-04 - val_mae: 0.0175\n",
      "Epoch 122/180\n",
      "65/65 [==============================] - 44s 675ms/step - loss: 8.3696e-04 - mse: 8.3696e-04 - mae: 0.0164 - val_loss: 9.7630e-04 - val_mse: 9.7630e-04 - val_mae: 0.0177\n",
      "Epoch 123/180\n",
      "65/65 [==============================] - 41s 635ms/step - loss: 8.2952e-04 - mse: 8.2952e-04 - mae: 0.0162 - val_loss: 9.6699e-04 - val_mse: 9.6699e-04 - val_mae: 0.0173\n",
      "Epoch 124/180\n",
      "65/65 [==============================] - 39s 603ms/step - loss: 8.3346e-04 - mse: 8.3346e-04 - mae: 0.0163 - val_loss: 9.8734e-04 - val_mse: 9.8734e-04 - val_mae: 0.0179\n",
      "Epoch 125/180\n",
      "65/65 [==============================] - 38s 578ms/step - loss: 8.2404e-04 - mse: 8.2404e-04 - mae: 0.0162 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0196\n",
      "Epoch 126/180\n",
      "65/65 [==============================] - 39s 601ms/step - loss: 8.3041e-04 - mse: 8.3041e-04 - mae: 0.0163 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0225\n",
      "Epoch 127/180\n",
      "65/65 [==============================] - 42s 645ms/step - loss: 8.3007e-04 - mse: 8.3007e-04 - mae: 0.0162 - val_loss: 9.6357e-04 - val_mse: 9.6357e-04 - val_mae: 0.0168\n",
      "Epoch 128/180\n",
      "65/65 [==============================] - 41s 636ms/step - loss: 8.1540e-04 - mse: 8.1540e-04 - mae: 0.0163 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0182\n",
      "Epoch 129/180\n",
      "65/65 [==============================] - 41s 630ms/step - loss: 8.1789e-04 - mse: 8.1789e-04 - mae: 0.0160 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0193\n",
      "Epoch 130/180\n",
      "65/65 [==============================] - 41s 625ms/step - loss: 8.1477e-04 - mse: 8.1477e-04 - mae: 0.0160 - val_loss: 9.4901e-04 - val_mse: 9.4901e-04 - val_mae: 0.0167\n",
      "Epoch 131/180\n",
      "65/65 [==============================] - 38s 587ms/step - loss: 8.1994e-04 - mse: 8.1994e-04 - mae: 0.0161 - val_loss: 9.7651e-04 - val_mse: 9.7651e-04 - val_mae: 0.0172\n",
      "Epoch 132/180\n",
      "65/65 [==============================] - 43s 664ms/step - loss: 8.0589e-04 - mse: 8.0589e-04 - mae: 0.0160 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0173\n",
      "Epoch 133/180\n",
      "65/65 [==============================] - 39s 593ms/step - loss: 8.1409e-04 - mse: 8.1409e-04 - mae: 0.0162 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0208\n",
      "Epoch 134/180\n",
      "65/65 [==============================] - 38s 588ms/step - loss: 8.2179e-04 - mse: 8.2179e-04 - mae: 0.0160 - val_loss: 9.6491e-04 - val_mse: 9.6491e-04 - val_mae: 0.0176\n",
      "Epoch 135/180\n",
      "65/65 [==============================] - 40s 618ms/step - loss: 8.1176e-04 - mse: 8.1176e-04 - mae: 0.0160 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0175\n",
      "Epoch 136/180\n",
      "65/65 [==============================] - 42s 642ms/step - loss: 8.1112e-04 - mse: 8.1112e-04 - mae: 0.0160 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0174\n",
      "Epoch 137/180\n",
      "65/65 [==============================] - 40s 616ms/step - loss: 8.1120e-04 - mse: 8.1120e-04 - mae: 0.0160 - val_loss: 9.7465e-04 - val_mse: 9.7465e-04 - val_mae: 0.0170\n",
      "Epoch 138/180\n",
      "65/65 [==============================] - 39s 604ms/step - loss: 8.0523e-04 - mse: 8.0523e-04 - mae: 0.0159 - val_loss: 9.6899e-04 - val_mse: 9.6899e-04 - val_mae: 0.0169\n",
      "Epoch 139/180\n",
      "65/65 [==============================] - 40s 620ms/step - loss: 8.0353e-04 - mse: 8.0353e-04 - mae: 0.0158 - val_loss: 9.9097e-04 - val_mse: 9.9097e-04 - val_mae: 0.0175\n",
      "Epoch 140/180\n",
      "65/65 [==============================] - 39s 593ms/step - loss: 7.9978e-04 - mse: 7.9978e-04 - mae: 0.0158 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0179\n",
      "Epoch 141/180\n",
      "65/65 [==============================] - 38s 588ms/step - loss: 7.9485e-04 - mse: 7.9485e-04 - mae: 0.0158 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0181\n",
      "Epoch 142/180\n",
      "65/65 [==============================] - 42s 644ms/step - loss: 8.0023e-04 - mse: 8.0023e-04 - mae: 0.0158 - val_loss: 9.9281e-04 - val_mse: 9.9281e-04 - val_mae: 0.0177\n",
      "Epoch 143/180\n",
      "65/65 [==============================] - 40s 613ms/step - loss: 8.0036e-04 - mse: 8.0036e-04 - mae: 0.0158 - val_loss: 9.9069e-04 - val_mse: 9.9069e-04 - val_mae: 0.0165\n",
      "Epoch 144/180\n",
      "65/65 [==============================] - 40s 618ms/step - loss: 8.0431e-04 - mse: 8.0431e-04 - mae: 0.0159 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0192\n",
      "Epoch 145/180\n",
      "65/65 [==============================] - 41s 638ms/step - loss: 8.0501e-04 - mse: 8.0501e-04 - mae: 0.0159 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0191\n",
      "Epoch 146/180\n",
      "65/65 [==============================] - 40s 613ms/step - loss: 8.0143e-04 - mse: 8.0143e-04 - mae: 0.0158 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0183\n",
      "Epoch 147/180\n",
      "65/65 [==============================] - 39s 608ms/step - loss: 7.9866e-04 - mse: 7.9866e-04 - mae: 0.0158 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0183\n",
      "Epoch 148/180\n",
      "65/65 [==============================] - 38s 586ms/step - loss: 7.9063e-04 - mse: 7.9063e-04 - mae: 0.0158 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0183\n",
      "Epoch 149/180\n",
      "65/65 [==============================] - 37s 574ms/step - loss: 7.9625e-04 - mse: 7.9625e-04 - mae: 0.0159 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0193\n",
      "Epoch 150/180\n",
      "65/65 [==============================] - 37s 573ms/step - loss: 7.8431e-04 - mse: 7.8431e-04 - mae: 0.0157 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0176\n",
      "Epoch 151/180\n",
      "65/65 [==============================] - 38s 588ms/step - loss: 8.0560e-04 - mse: 8.0560e-04 - mae: 0.0161 - val_loss: 9.8860e-04 - val_mse: 9.8860e-04 - val_mae: 0.0174\n",
      "Epoch 152/180\n",
      "65/65 [==============================] - 37s 568ms/step - loss: 7.8834e-04 - mse: 7.8834e-04 - mae: 0.0159 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0192\n",
      "Epoch 153/180\n",
      "65/65 [==============================] - 38s 577ms/step - loss: 7.9353e-04 - mse: 7.9354e-04 - mae: 0.0157 - val_loss: 9.9855e-04 - val_mse: 9.9855e-04 - val_mae: 0.0177\n",
      "Epoch 154/180\n",
      "65/65 [==============================] - 38s 583ms/step - loss: 7.8552e-04 - mse: 7.8552e-04 - mae: 0.0159 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0178\n",
      "Epoch 155/180\n",
      "65/65 [==============================] - 36s 551ms/step - loss: 7.9513e-04 - mse: 7.9513e-04 - mae: 0.0158 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0188\n",
      "Epoch 156/180\n",
      "65/65 [==============================] - 34s 526ms/step - loss: 7.9841e-04 - mse: 7.9841e-04 - mae: 0.0157 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0178\n",
      "Epoch 157/180\n",
      "65/65 [==============================] - 35s 545ms/step - loss: 7.9557e-04 - mse: 7.9557e-04 - mae: 0.0157 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0193\n",
      "Epoch 158/180\n",
      "65/65 [==============================] - 36s 561ms/step - loss: 7.8966e-04 - mse: 7.8966e-04 - mae: 0.0157 - val_loss: 9.4493e-04 - val_mse: 9.4493e-04 - val_mae: 0.0171\n",
      "Epoch 159/180\n",
      "65/65 [==============================] - 35s 537ms/step - loss: 7.8379e-04 - mse: 7.8379e-04 - mae: 0.0157 - val_loss: 9.8121e-04 - val_mse: 9.8121e-04 - val_mae: 0.0167\n",
      "Epoch 160/180\n",
      "65/65 [==============================] - 35s 540ms/step - loss: 7.8013e-04 - mse: 7.8013e-04 - mae: 0.0156 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0170\n",
      "Epoch 161/180\n",
      "65/65 [==============================] - 36s 559ms/step - loss: 8.0251e-04 - mse: 8.0251e-04 - mae: 0.0160 - val_loss: 9.4255e-04 - val_mse: 9.4255e-04 - val_mae: 0.0162\n",
      "Epoch 162/180\n",
      "65/65 [==============================] - 35s 539ms/step - loss: 7.8750e-04 - mse: 7.8750e-04 - mae: 0.0158 - val_loss: 9.2880e-04 - val_mse: 9.2880e-04 - val_mae: 0.0169\n",
      "Epoch 163/180\n",
      "65/65 [==============================] - 36s 555ms/step - loss: 7.8385e-04 - mse: 7.8385e-04 - mae: 0.0156 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0172\n",
      "Epoch 164/180\n",
      "65/65 [==============================] - 35s 537ms/step - loss: 7.9200e-04 - mse: 7.9200e-04 - mae: 0.0157 - val_loss: 9.2889e-04 - val_mse: 9.2889e-04 - val_mae: 0.0170\n",
      "Epoch 165/180\n",
      "65/65 [==============================] - 36s 548ms/step - loss: 8.0543e-04 - mse: 8.0543e-04 - mae: 0.0159 - val_loss: 9.6425e-04 - val_mse: 9.6425e-04 - val_mae: 0.0165\n",
      "Epoch 166/180\n",
      "65/65 [==============================] - 36s 558ms/step - loss: 7.8069e-04 - mse: 7.8069e-04 - mae: 0.0156 - val_loss: 9.5959e-04 - val_mse: 9.5959e-04 - val_mae: 0.0160\n",
      "Epoch 167/180\n",
      "65/65 [==============================] - 37s 576ms/step - loss: 7.9710e-04 - mse: 7.9710e-04 - mae: 0.0159 - val_loss: 9.3984e-04 - val_mse: 9.3984e-04 - val_mae: 0.0158\n",
      "Epoch 168/180\n",
      "65/65 [==============================] - 39s 595ms/step - loss: 7.9666e-04 - mse: 7.9666e-04 - mae: 0.0160 - val_loss: 9.3704e-04 - val_mse: 9.3704e-04 - val_mae: 0.0164\n",
      "Epoch 169/180\n",
      "65/65 [==============================] - 37s 576ms/step - loss: 7.6167e-04 - mse: 7.6167e-04 - mae: 0.0156 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0180\n",
      "Epoch 170/180\n",
      "65/65 [==============================] - 38s 591ms/step - loss: 7.8986e-04 - mse: 7.8986e-04 - mae: 0.0158 - val_loss: 9.7235e-04 - val_mse: 9.7235e-04 - val_mae: 0.0170\n",
      "Epoch 171/180\n",
      "65/65 [==============================] - 36s 555ms/step - loss: 8.1284e-04 - mse: 8.1284e-04 - mae: 0.0161 - val_loss: 9.5953e-04 - val_mse: 9.5953e-04 - val_mae: 0.0181\n",
      "Epoch 172/180\n",
      "65/65 [==============================] - 37s 571ms/step - loss: 7.7328e-04 - mse: 7.7328e-04 - mae: 0.0156 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0176\n",
      "Epoch 173/180\n",
      "65/65 [==============================] - 42s 639ms/step - loss: 7.6030e-04 - mse: 7.6030e-04 - mae: 0.0155 - val_loss: 9.9045e-04 - val_mse: 9.9045e-04 - val_mae: 0.0173\n",
      "Epoch 174/180\n",
      "65/65 [==============================] - 40s 612ms/step - loss: 7.8559e-04 - mse: 7.8559e-04 - mae: 0.0158 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0171\n",
      "Epoch 175/180\n",
      "65/65 [==============================] - 37s 562ms/step - loss: 7.7398e-04 - mse: 7.7398e-04 - mae: 0.0159 - val_loss: 9.5082e-04 - val_mse: 9.5082e-04 - val_mae: 0.0178\n",
      "Epoch 176/180\n",
      "65/65 [==============================] - 37s 565ms/step - loss: 7.7822e-04 - mse: 7.7822e-04 - mae: 0.0157 - val_loss: 9.7782e-04 - val_mse: 9.7782e-04 - val_mae: 0.0170\n",
      "Epoch 177/180\n",
      "65/65 [==============================] - 37s 564ms/step - loss: 7.4854e-04 - mse: 7.4854e-04 - mae: 0.0154 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0183\n",
      "Epoch 178/180\n",
      "65/65 [==============================] - 47s 722ms/step - loss: 8.0006e-04 - mse: 8.0006e-04 - mae: 0.0160 - val_loss: 9.6454e-04 - val_mse: 9.6454e-04 - val_mae: 0.0184\n",
      "Epoch 179/180\n",
      "65/65 [==============================] - 42s 639ms/step - loss: 7.8170e-04 - mse: 7.8170e-04 - mae: 0.0159 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0197\n",
      "Epoch 180/180\n",
      "65/65 [==============================] - 40s 616ms/step - loss: 7.7982e-04 - mse: 7.7982e-04 - mae: 0.0159 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0179\n",
      "Epoch 1/180\n",
      "65/65 [==============================] - 50s 770ms/step - loss: 0.2061 - mse: 0.2061 - mae: 0.3562 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0265\n",
      "Epoch 2/180\n",
      "65/65 [==============================] - 57s 873ms/step - loss: 0.1202 - mse: 0.1202 - mae: 0.2767 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0232\n",
      "Epoch 3/180\n",
      "65/65 [==============================] - 53s 815ms/step - loss: 0.0893 - mse: 0.0893 - mae: 0.2379 - val_loss: 0.0029 - val_mse: 0.0029 - val_mae: 0.0376\n",
      "Epoch 4/180\n",
      "65/65 [==============================] - 56s 854ms/step - loss: 0.0569 - mse: 0.0569 - mae: 0.1894 - val_loss: 0.0032 - val_mse: 0.0032 - val_mae: 0.0383\n",
      "Epoch 5/180\n",
      "65/65 [==============================] - 57s 875ms/step - loss: 0.0400 - mse: 0.0400 - mae: 0.1592 - val_loss: 0.0024 - val_mse: 0.0024 - val_mae: 0.0319\n",
      "Epoch 6/180\n",
      "65/65 [==============================] - 55s 851ms/step - loss: 0.0293 - mse: 0.0293 - mae: 0.1369 - val_loss: 0.0028 - val_mse: 0.0028 - val_mae: 0.0366\n",
      "Epoch 7/180\n",
      "65/65 [==============================] - 54s 838ms/step - loss: 0.0210 - mse: 0.0210 - mae: 0.1144 - val_loss: 0.0023 - val_mse: 0.0023 - val_mae: 0.0331\n",
      "Epoch 8/180\n",
      "65/65 [==============================] - 57s 883ms/step - loss: 0.0169 - mse: 0.0169 - mae: 0.1030 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0232\n",
      "Epoch 9/180\n",
      "65/65 [==============================] - 52s 799ms/step - loss: 0.0137 - mse: 0.0137 - mae: 0.0920 - val_loss: 0.0016 - val_mse: 0.0016 - val_mae: 0.0223\n",
      "Epoch 10/180\n",
      "65/65 [==============================] - 59s 906ms/step - loss: 0.0109 - mse: 0.0109 - mae: 0.0824 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0248\n",
      "Epoch 11/180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 54s 832ms/step - loss: 0.0091 - mse: 0.0091 - mae: 0.0753 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0210\n",
      "Epoch 12/180\n",
      "65/65 [==============================] - 55s 853ms/step - loss: 0.0078 - mse: 0.0078 - mae: 0.0693 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0174\n",
      "Epoch 13/180\n",
      "65/65 [==============================] - 54s 827ms/step - loss: 0.0068 - mse: 0.0068 - mae: 0.0644 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0195\n",
      "Epoch 14/180\n",
      "65/65 [==============================] - 59s 900ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0603 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0218\n",
      "Epoch 15/180\n",
      "65/65 [==============================] - 57s 882ms/step - loss: 0.0053 - mse: 0.0053 - mae: 0.0562 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0256\n",
      "Epoch 16/180\n",
      "65/65 [==============================] - 61s 945ms/step - loss: 0.0049 - mse: 0.0049 - mae: 0.0540 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0267\n",
      "Epoch 17/180\n",
      "65/65 [==============================] - 54s 835ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0504 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0211\n",
      "Epoch 18/180\n",
      "65/65 [==============================] - 49s 758ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0465 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0281\n",
      "Epoch 19/180\n",
      "65/65 [==============================] - 50s 770ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0457 - val_loss: 0.0014 - val_mse: 0.0014 - val_mae: 0.0295\n",
      "Epoch 20/180\n",
      "65/65 [==============================] - 50s 774ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0429 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0248\n",
      "Epoch 21/180\n",
      "65/65 [==============================] - 51s 784ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0421 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0258\n",
      "Epoch 22/180\n",
      "65/65 [==============================] - 51s 779ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0389 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0249\n",
      "Epoch 23/180\n",
      "65/65 [==============================] - 50s 773ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0383 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0243\n",
      "Epoch 24/180\n",
      "65/65 [==============================] - 50s 769ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0364 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0268\n",
      "Epoch 25/180\n",
      "65/65 [==============================] - 49s 755ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0348 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0234\n",
      "Epoch 26/180\n",
      "65/65 [==============================] - 50s 775ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0343 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0238\n",
      "Epoch 27/180\n",
      "65/65 [==============================] - 49s 753ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0329 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0249\n",
      "Epoch 28/180\n",
      "65/65 [==============================] - 52s 793ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0314 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0270\n",
      "Epoch 29/180\n",
      "65/65 [==============================] - 46s 706ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0302 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0273\n",
      "Epoch 30/180\n",
      "65/65 [==============================] - 46s 711ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0300 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0271\n",
      "Epoch 31/180\n",
      "65/65 [==============================] - 46s 715ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0282 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0251\n",
      "Epoch 32/180\n",
      "65/65 [==============================] - 47s 716ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0281 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0264\n",
      "Epoch 33/180\n",
      "65/65 [==============================] - 47s 723ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0272 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0267\n",
      "Epoch 34/180\n",
      "65/65 [==============================] - 45s 688ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0262 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0252\n",
      "Epoch 35/180\n",
      "65/65 [==============================] - 45s 690ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0255 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0225\n",
      "Epoch 36/180\n",
      "65/65 [==============================] - 46s 709ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0254 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0239\n",
      "Epoch 37/180\n",
      "65/65 [==============================] - 45s 687ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0246 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0260\n",
      "Epoch 38/180\n",
      "65/65 [==============================] - 45s 686ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0241 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0237\n",
      "Epoch 39/180\n",
      "65/65 [==============================] - 45s 696ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0235 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0239\n",
      "Epoch 40/180\n",
      "65/65 [==============================] - 45s 687ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0231 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0226\n",
      "Epoch 41/180\n",
      "65/65 [==============================] - 47s 718ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0226 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0240\n",
      "Epoch 42/180\n",
      "65/65 [==============================] - 45s 700ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0222 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0225\n",
      "Epoch 43/180\n",
      "65/65 [==============================] - 46s 710ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0221 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0238\n",
      "Epoch 44/180\n",
      "65/65 [==============================] - 47s 722ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0218 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0240\n",
      "Epoch 45/180\n",
      "65/65 [==============================] - 47s 728ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0216 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0235\n",
      "Epoch 46/180\n",
      "65/65 [==============================] - 47s 726ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0215 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0230\n",
      "Epoch 47/180\n",
      "65/65 [==============================] - 46s 705ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0211 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0226\n",
      "Epoch 48/180\n",
      "65/65 [==============================] - 46s 707ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0211 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0228\n",
      "Epoch 49/180\n",
      "65/65 [==============================] - 47s 726ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0210 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0235\n",
      "Epoch 50/180\n",
      "65/65 [==============================] - 46s 704ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0208 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0229\n",
      "Epoch 51/180\n",
      "65/65 [==============================] - 47s 718ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0204 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0224\n",
      "Epoch 52/180\n",
      "65/65 [==============================] - 46s 708ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0204 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0227\n",
      "Epoch 53/180\n",
      "65/65 [==============================] - 46s 701ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0201 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0221\n",
      "Epoch 54/180\n",
      "65/65 [==============================] - 46s 715ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0202 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0222\n",
      "Epoch 55/180\n",
      "65/65 [==============================] - 46s 704ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0199 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0219\n",
      "Epoch 56/180\n",
      "65/65 [==============================] - 46s 713ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0198 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0221\n",
      "Epoch 57/180\n",
      "65/65 [==============================] - 46s 703ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0197 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0209\n",
      "Epoch 58/180\n",
      "65/65 [==============================] - 47s 725ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0197 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0210\n",
      "Epoch 59/180\n",
      "65/65 [==============================] - 46s 711ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0196 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0214\n",
      "Epoch 60/180\n",
      "65/65 [==============================] - 46s 706ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0195 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0217\n",
      "Epoch 61/180\n",
      "65/65 [==============================] - 45s 699ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0197 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0214\n",
      "Epoch 62/180\n",
      "65/65 [==============================] - 47s 717ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0193 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0216\n",
      "Epoch 63/180\n",
      "65/65 [==============================] - 46s 711ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0191 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0207\n",
      "Epoch 64/180\n",
      "65/65 [==============================] - 47s 716ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0193 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0215\n",
      "Epoch 65/180\n",
      "65/65 [==============================] - 46s 702ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0192 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0209\n",
      "Epoch 66/180\n",
      "65/65 [==============================] - 46s 714ms/step - loss: 9.9583e-04 - mse: 9.9583e-04 - mae: 0.0190 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0217\n",
      "Epoch 67/180\n",
      "65/65 [==============================] - 47s 724ms/step - loss: 9.9125e-04 - mse: 9.9125e-04 - mae: 0.0190 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0208\n",
      "Epoch 68/180\n",
      "65/65 [==============================] - 46s 707ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0191 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0220\n",
      "Epoch 69/180\n",
      "65/65 [==============================] - 46s 715ms/step - loss: 9.8444e-04 - mse: 9.8444e-04 - mae: 0.0188 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0213\n",
      "Epoch 70/180\n",
      "65/65 [==============================] - 46s 707ms/step - loss: 9.8765e-04 - mse: 9.8765e-04 - mae: 0.0189 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0211\n",
      "Epoch 71/180\n",
      "65/65 [==============================] - 49s 751ms/step - loss: 9.8513e-04 - mse: 9.8513e-04 - mae: 0.0189 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0210\n",
      "Epoch 72/180\n",
      "65/65 [==============================] - 51s 783ms/step - loss: 9.7879e-04 - mse: 9.7879e-04 - mae: 0.0186 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0212\n",
      "Epoch 73/180\n",
      "65/65 [==============================] - 46s 703ms/step - loss: 9.9705e-04 - mse: 9.9705e-04 - mae: 0.0190 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0214\n",
      "Epoch 74/180\n",
      "65/65 [==============================] - 46s 713ms/step - loss: 9.7542e-04 - mse: 9.7542e-04 - mae: 0.0187 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0212\n",
      "Epoch 75/180\n",
      "65/65 [==============================] - 46s 709ms/step - loss: 9.6110e-04 - mse: 9.6110e-04 - mae: 0.0185 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0208\n",
      "Epoch 76/180\n",
      "65/65 [==============================] - 46s 703ms/step - loss: 9.7017e-04 - mse: 9.7017e-04 - mae: 0.0185 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0209\n",
      "Epoch 77/180\n",
      "65/65 [==============================] - 46s 715ms/step - loss: 9.6439e-04 - mse: 9.6439e-04 - mae: 0.0185 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0210\n",
      "Epoch 78/180\n",
      "65/65 [==============================] - 46s 713ms/step - loss: 9.6402e-04 - mse: 9.6402e-04 - mae: 0.0185 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0212\n",
      "Epoch 79/180\n",
      "65/65 [==============================] - 46s 714ms/step - loss: 9.6048e-04 - mse: 9.6048e-04 - mae: 0.0184 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0213\n",
      "Epoch 80/180\n",
      "65/65 [==============================] - 46s 707ms/step - loss: 9.5557e-04 - mse: 9.5557e-04 - mae: 0.0183 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0213\n",
      "Epoch 81/180\n",
      "65/65 [==============================] - 46s 710ms/step - loss: 9.6348e-04 - mse: 9.6348e-04 - mae: 0.0183 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0211\n",
      "Epoch 82/180\n",
      "65/65 [==============================] - 47s 727ms/step - loss: 9.5302e-04 - mse: 9.5302e-04 - mae: 0.0183 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0211\n",
      "Epoch 83/180\n",
      "65/65 [==============================] - 48s 736ms/step - loss: 9.5699e-04 - mse: 9.5699e-04 - mae: 0.0183 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0215\n",
      "Epoch 84/180\n",
      "65/65 [==============================] - 47s 729ms/step - loss: 9.5170e-04 - mse: 9.5170e-04 - mae: 0.0183 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0212\n",
      "Epoch 85/180\n",
      "65/65 [==============================] - 46s 711ms/step - loss: 9.4646e-04 - mse: 9.4646e-04 - mae: 0.0181 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0209\n",
      "Epoch 86/180\n",
      "65/65 [==============================] - 46s 710ms/step - loss: 9.3701e-04 - mse: 9.3701e-04 - mae: 0.0180 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0210\n",
      "Epoch 87/180\n",
      "65/65 [==============================] - 47s 716ms/step - loss: 9.4490e-04 - mse: 9.4490e-04 - mae: 0.0181 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0197\n",
      "Epoch 88/180\n",
      "65/65 [==============================] - 46s 704ms/step - loss: 9.4027e-04 - mse: 9.4027e-04 - mae: 0.0180 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0199\n",
      "Epoch 89/180\n",
      "65/65 [==============================] - 46s 709ms/step - loss: 9.3628e-04 - mse: 9.3628e-04 - mae: 0.0180 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0194\n",
      "Epoch 90/180\n",
      "65/65 [==============================] - 46s 715ms/step - loss: 9.3315e-04 - mse: 9.3315e-04 - mae: 0.0179 - val_loss: 9.9642e-04 - val_mse: 9.9642e-04 - val_mae: 0.0186\n",
      "Epoch 91/180\n",
      "65/65 [==============================] - 46s 709ms/step - loss: 9.2451e-04 - mse: 9.2451e-04 - mae: 0.0177 - val_loss: 9.9031e-04 - val_mse: 9.9031e-04 - val_mae: 0.0191\n",
      "Epoch 92/180\n",
      "65/65 [==============================] - 47s 716ms/step - loss: 9.2523e-04 - mse: 9.2523e-04 - mae: 0.0178 - val_loss: 9.8996e-04 - val_mse: 9.8996e-04 - val_mae: 0.0188\n",
      "Epoch 93/180\n",
      "65/65 [==============================] - 46s 702ms/step - loss: 9.2511e-04 - mse: 9.2511e-04 - mae: 0.0178 - val_loss: 9.8524e-04 - val_mse: 9.8524e-04 - val_mae: 0.0185\n",
      "Epoch 94/180\n",
      "65/65 [==============================] - 46s 705ms/step - loss: 9.1441e-04 - mse: 9.1441e-04 - mae: 0.0177 - val_loss: 9.7957e-04 - val_mse: 9.7957e-04 - val_mae: 0.0184\n",
      "Epoch 95/180\n",
      "65/65 [==============================] - 47s 724ms/step - loss: 9.2085e-04 - mse: 9.2085e-04 - mae: 0.0176 - val_loss: 9.7962e-04 - val_mse: 9.7962e-04 - val_mae: 0.0185\n",
      "Epoch 96/180\n",
      "65/65 [==============================] - 48s 736ms/step - loss: 9.1453e-04 - mse: 9.1453e-04 - mae: 0.0176 - val_loss: 9.8085e-04 - val_mse: 9.8085e-04 - val_mae: 0.0189\n",
      "Epoch 97/180\n",
      "65/65 [==============================] - 48s 742ms/step - loss: 9.2209e-04 - mse: 9.2209e-04 - mae: 0.0177 - val_loss: 9.7854e-04 - val_mse: 9.7854e-04 - val_mae: 0.0187\n",
      "Epoch 98/180\n",
      "65/65 [==============================] - 49s 759ms/step - loss: 9.1013e-04 - mse: 9.1013e-04 - mae: 0.0176 - val_loss: 9.6793e-04 - val_mse: 9.6793e-04 - val_mae: 0.0186\n",
      "Epoch 99/180\n",
      "65/65 [==============================] - 46s 713ms/step - loss: 9.0870e-04 - mse: 9.0870e-04 - mae: 0.0175 - val_loss: 9.6622e-04 - val_mse: 9.6622e-04 - val_mae: 0.0186\n",
      "Epoch 100/180\n",
      "65/65 [==============================] - 47s 725ms/step - loss: 9.0985e-04 - mse: 9.0985e-04 - mae: 0.0176 - val_loss: 9.5817e-04 - val_mse: 9.5817e-04 - val_mae: 0.0188\n",
      "Epoch 101/180\n",
      "65/65 [==============================] - 47s 716ms/step - loss: 9.0784e-04 - mse: 9.0784e-04 - mae: 0.0176 - val_loss: 9.5709e-04 - val_mse: 9.5709e-04 - val_mae: 0.0187\n",
      "Epoch 102/180\n",
      "65/65 [==============================] - 47s 716ms/step - loss: 9.0035e-04 - mse: 9.0035e-04 - mae: 0.0175 - val_loss: 9.5097e-04 - val_mse: 9.5097e-04 - val_mae: 0.0188\n",
      "Epoch 103/180\n",
      "65/65 [==============================] - 46s 702ms/step - loss: 8.9637e-04 - mse: 8.9637e-04 - mae: 0.0174 - val_loss: 9.3206e-04 - val_mse: 9.3206e-04 - val_mae: 0.0188\n",
      "Epoch 104/180\n",
      "65/65 [==============================] - 45s 700ms/step - loss: 8.9299e-04 - mse: 8.9299e-04 - mae: 0.0173 - val_loss: 9.3328e-04 - val_mse: 9.3328e-04 - val_mae: 0.0191\n",
      "Epoch 105/180\n",
      "65/65 [==============================] - 48s 732ms/step - loss: 9.0784e-04 - mse: 9.0784e-04 - mae: 0.0176 - val_loss: 9.1231e-04 - val_mse: 9.1231e-04 - val_mae: 0.0180\n",
      "Epoch 106/180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 46s 709ms/step - loss: 9.0750e-04 - mse: 9.0750e-04 - mae: 0.0175 - val_loss: 8.9661e-04 - val_mse: 8.9661e-04 - val_mae: 0.0179\n",
      "Epoch 107/180\n",
      "65/65 [==============================] - 46s 711ms/step - loss: 8.9424e-04 - mse: 8.9424e-04 - mae: 0.0174 - val_loss: 8.9381e-04 - val_mse: 8.9381e-04 - val_mae: 0.0189\n",
      "Epoch 108/180\n",
      "65/65 [==============================] - 46s 706ms/step - loss: 9.0324e-04 - mse: 9.0324e-04 - mae: 0.0175 - val_loss: 8.8857e-04 - val_mse: 8.8857e-04 - val_mae: 0.0187\n",
      "Epoch 109/180\n",
      "65/65 [==============================] - 48s 736ms/step - loss: 8.9037e-04 - mse: 8.9037e-04 - mae: 0.0173 - val_loss: 8.8172e-04 - val_mse: 8.8172e-04 - val_mae: 0.0183\n",
      "Epoch 110/180\n",
      "65/65 [==============================] - 46s 712ms/step - loss: 8.8693e-04 - mse: 8.8693e-04 - mae: 0.0172 - val_loss: 8.9370e-04 - val_mse: 8.9370e-04 - val_mae: 0.0187\n",
      "Epoch 111/180\n",
      "65/65 [==============================] - 45s 699ms/step - loss: 8.8802e-04 - mse: 8.8802e-04 - mae: 0.0173 - val_loss: 8.8068e-04 - val_mse: 8.8068e-04 - val_mae: 0.0186\n",
      "Epoch 112/180\n",
      "65/65 [==============================] - 46s 709ms/step - loss: 8.8418e-04 - mse: 8.8418e-04 - mae: 0.0171 - val_loss: 8.8014e-04 - val_mse: 8.8014e-04 - val_mae: 0.0183\n",
      "Epoch 113/180\n",
      "65/65 [==============================] - 47s 718ms/step - loss: 8.9364e-04 - mse: 8.9364e-04 - mae: 0.0174 - val_loss: 8.7788e-04 - val_mse: 8.7788e-04 - val_mae: 0.0182\n",
      "Epoch 114/180\n",
      "65/65 [==============================] - 46s 713ms/step - loss: 8.7662e-04 - mse: 8.7662e-04 - mae: 0.0171 - val_loss: 8.8666e-04 - val_mse: 8.8666e-04 - val_mae: 0.0182\n",
      "Epoch 115/180\n",
      "65/65 [==============================] - 46s 711ms/step - loss: 8.7749e-04 - mse: 8.7749e-04 - mae: 0.0171 - val_loss: 8.7228e-04 - val_mse: 8.7228e-04 - val_mae: 0.0170\n",
      "Epoch 116/180\n",
      "65/65 [==============================] - 46s 707ms/step - loss: 8.7601e-04 - mse: 8.7601e-04 - mae: 0.0170 - val_loss: 9.1420e-04 - val_mse: 9.1420e-04 - val_mae: 0.0188\n",
      "Epoch 117/180\n",
      "65/65 [==============================] - 46s 707ms/step - loss: 8.9112e-04 - mse: 8.9112e-04 - mae: 0.0172 - val_loss: 8.4785e-04 - val_mse: 8.4785e-04 - val_mae: 0.0168\n",
      "Epoch 118/180\n",
      "65/65 [==============================] - 46s 704ms/step - loss: 8.7702e-04 - mse: 8.7702e-04 - mae: 0.0171 - val_loss: 9.1395e-04 - val_mse: 9.1395e-04 - val_mae: 0.0183\n",
      "Epoch 119/180\n",
      "65/65 [==============================] - 46s 711ms/step - loss: 8.6807e-04 - mse: 8.6807e-04 - mae: 0.0170 - val_loss: 8.7284e-04 - val_mse: 8.7284e-04 - val_mae: 0.0179\n",
      "Epoch 120/180\n",
      "65/65 [==============================] - 47s 728ms/step - loss: 8.7247e-04 - mse: 8.7247e-04 - mae: 0.0171 - val_loss: 9.7447e-04 - val_mse: 9.7447e-04 - val_mae: 0.0197\n",
      "Epoch 121/180\n",
      "65/65 [==============================] - 46s 702ms/step - loss: 8.7873e-04 - mse: 8.7873e-04 - mae: 0.0171 - val_loss: 9.8690e-04 - val_mse: 9.8690e-04 - val_mae: 0.0191\n",
      "Epoch 122/180\n",
      "65/65 [==============================] - 47s 730ms/step - loss: 8.7051e-04 - mse: 8.7051e-04 - mae: 0.0170 - val_loss: 8.8525e-04 - val_mse: 8.8525e-04 - val_mae: 0.0168\n",
      "Epoch 123/180\n",
      "65/65 [==============================] - 46s 712ms/step - loss: 8.7301e-04 - mse: 8.7301e-04 - mae: 0.0170 - val_loss: 9.4038e-04 - val_mse: 9.4038e-04 - val_mae: 0.0192\n",
      "Epoch 124/180\n",
      "65/65 [==============================] - 46s 702ms/step - loss: 8.8422e-04 - mse: 8.8422e-04 - mae: 0.0170 - val_loss: 8.5752e-04 - val_mse: 8.5752e-04 - val_mae: 0.0173\n",
      "Epoch 125/180\n",
      "65/65 [==============================] - 46s 707ms/step - loss: 8.7015e-04 - mse: 8.7015e-04 - mae: 0.0170 - val_loss: 8.8239e-04 - val_mse: 8.8239e-04 - val_mae: 0.0165\n",
      "Epoch 126/180\n",
      "65/65 [==============================] - 46s 705ms/step - loss: 8.6534e-04 - mse: 8.6534e-04 - mae: 0.0170 - val_loss: 9.5704e-04 - val_mse: 9.5704e-04 - val_mae: 0.0177\n",
      "Epoch 127/180\n",
      "65/65 [==============================] - 45s 696ms/step - loss: 8.8577e-04 - mse: 8.8577e-04 - mae: 0.0170 - val_loss: 9.2195e-04 - val_mse: 9.2195e-04 - val_mae: 0.0174\n",
      "Epoch 128/180\n",
      "65/65 [==============================] - 46s 710ms/step - loss: 8.6933e-04 - mse: 8.6933e-04 - mae: 0.0172 - val_loss: 8.8925e-04 - val_mse: 8.8925e-04 - val_mae: 0.0181\n",
      "Epoch 129/180\n",
      "65/65 [==============================] - 45s 695ms/step - loss: 8.7054e-04 - mse: 8.7054e-04 - mae: 0.0169 - val_loss: 8.4354e-04 - val_mse: 8.4354e-04 - val_mae: 0.0171\n",
      "Epoch 130/180\n",
      "65/65 [==============================] - 45s 700ms/step - loss: 8.5769e-04 - mse: 8.5769e-04 - mae: 0.0167 - val_loss: 8.6687e-04 - val_mse: 8.6687e-04 - val_mae: 0.0168\n",
      "Epoch 131/180\n",
      "65/65 [==============================] - 46s 703ms/step - loss: 8.6185e-04 - mse: 8.6185e-04 - mae: 0.0168 - val_loss: 8.5230e-04 - val_mse: 8.5230e-04 - val_mae: 0.0155\n",
      "Epoch 132/180\n",
      "65/65 [==============================] - 45s 696ms/step - loss: 8.5931e-04 - mse: 8.5931e-04 - mae: 0.0169 - val_loss: 9.5369e-04 - val_mse: 9.5369e-04 - val_mae: 0.0184\n",
      "Epoch 133/180\n",
      "65/65 [==============================] - 46s 707ms/step - loss: 8.5591e-04 - mse: 8.5591e-04 - mae: 0.0168 - val_loss: 9.0690e-04 - val_mse: 9.0690e-04 - val_mae: 0.0190\n",
      "Epoch 134/180\n",
      "65/65 [==============================] - 45s 698ms/step - loss: 8.5765e-04 - mse: 8.5765e-04 - mae: 0.0166 - val_loss: 8.7690e-04 - val_mse: 8.7690e-04 - val_mae: 0.0160\n",
      "Epoch 135/180\n",
      "65/65 [==============================] - 58s 900ms/step - loss: 8.7633e-04 - mse: 8.7633e-04 - mae: 0.0172 - val_loss: 8.9772e-04 - val_mse: 8.9772e-04 - val_mae: 0.0173\n",
      "Epoch 136/180\n",
      "65/65 [==============================] - 51s 790ms/step - loss: 8.8536e-04 - mse: 8.8536e-04 - mae: 0.0170 - val_loss: 8.8045e-04 - val_mse: 8.8045e-04 - val_mae: 0.0182\n",
      "Epoch 137/180\n",
      "65/65 [==============================] - 52s 803ms/step - loss: 8.5370e-04 - mse: 8.5370e-04 - mae: 0.0167 - val_loss: 8.4175e-04 - val_mse: 8.4175e-04 - val_mae: 0.0163\n",
      "Epoch 138/180\n",
      "65/65 [==============================] - 55s 842ms/step - loss: 8.5820e-04 - mse: 8.5820e-04 - mae: 0.0167 - val_loss: 8.7700e-04 - val_mse: 8.7700e-04 - val_mae: 0.0162\n",
      "Epoch 139/180\n",
      "65/65 [==============================] - 53s 812ms/step - loss: 8.5647e-04 - mse: 8.5647e-04 - mae: 0.0168 - val_loss: 8.6890e-04 - val_mse: 8.6890e-04 - val_mae: 0.0161\n",
      "Epoch 140/180\n",
      "65/65 [==============================] - 55s 853ms/step - loss: 8.4902e-04 - mse: 8.4902e-04 - mae: 0.0166 - val_loss: 8.9752e-04 - val_mse: 8.9752e-04 - val_mae: 0.0167\n",
      "Epoch 141/180\n",
      "65/65 [==============================] - 57s 879ms/step - loss: 8.4813e-04 - mse: 8.4813e-04 - mae: 0.0166 - val_loss: 9.2016e-04 - val_mse: 9.2016e-04 - val_mae: 0.0170\n",
      "Epoch 142/180\n",
      "65/65 [==============================] - 57s 872ms/step - loss: 8.6090e-04 - mse: 8.6090e-04 - mae: 0.0167 - val_loss: 8.9669e-04 - val_mse: 8.9669e-04 - val_mae: 0.0196\n",
      "Epoch 143/180\n",
      "65/65 [==============================] - 55s 848ms/step - loss: 8.5327e-04 - mse: 8.5327e-04 - mae: 0.0167 - val_loss: 8.4732e-04 - val_mse: 8.4732e-04 - val_mae: 0.0160\n",
      "Epoch 144/180\n",
      "65/65 [==============================] - 58s 885ms/step - loss: 8.5761e-04 - mse: 8.5761e-04 - mae: 0.0169 - val_loss: 9.4668e-04 - val_mse: 9.4668e-04 - val_mae: 0.0182\n",
      "Epoch 145/180\n",
      "65/65 [==============================] - 61s 935ms/step - loss: 8.6380e-04 - mse: 8.6380e-04 - mae: 0.0167 - val_loss: 8.5209e-04 - val_mse: 8.5209e-04 - val_mae: 0.0182\n",
      "Epoch 146/180\n",
      "65/65 [==============================] - 64s 987ms/step - loss: 8.4703e-04 - mse: 8.4703e-04 - mae: 0.0166 - val_loss: 8.2300e-04 - val_mse: 8.2300e-04 - val_mae: 0.0153\n",
      "Epoch 147/180\n",
      "65/65 [==============================] - 66s 1s/step - loss: 8.4804e-04 - mse: 8.4804e-04 - mae: 0.0166 - val_loss: 8.5802e-04 - val_mse: 8.5802e-04 - val_mae: 0.0166\n",
      "Epoch 148/180\n",
      "65/65 [==============================] - 64s 985ms/step - loss: 8.4205e-04 - mse: 8.4205e-04 - mae: 0.0164 - val_loss: 8.3518e-04 - val_mse: 8.3518e-04 - val_mae: 0.0164\n",
      "Epoch 149/180\n",
      "65/65 [==============================] - 63s 967ms/step - loss: 8.3514e-04 - mse: 8.3514e-04 - mae: 0.0165 - val_loss: 8.6668e-04 - val_mse: 8.6668e-04 - val_mae: 0.0158\n",
      "Epoch 150/180\n",
      "65/65 [==============================] - 60s 927ms/step - loss: 8.4337e-04 - mse: 8.4337e-04 - mae: 0.0166 - val_loss: 9.2294e-04 - val_mse: 9.2294e-04 - val_mae: 0.0177\n",
      "Epoch 151/180\n",
      "65/65 [==============================] - 61s 943ms/step - loss: 8.5270e-04 - mse: 8.5270e-04 - mae: 0.0166 - val_loss: 8.4232e-04 - val_mse: 8.4232e-04 - val_mae: 0.0180\n",
      "Epoch 152/180\n",
      "65/65 [==============================] - 61s 937ms/step - loss: 8.4131e-04 - mse: 8.4131e-04 - mae: 0.0164 - val_loss: 8.2860e-04 - val_mse: 8.2860e-04 - val_mae: 0.0160\n",
      "Epoch 153/180\n",
      "65/65 [==============================] - 63s 971ms/step - loss: 8.5336e-04 - mse: 8.5336e-04 - mae: 0.0167 - val_loss: 8.3559e-04 - val_mse: 8.3559e-04 - val_mae: 0.0163\n",
      "Epoch 154/180\n",
      "65/65 [==============================] - 65s 998ms/step - loss: 8.3699e-04 - mse: 8.3699e-04 - mae: 0.0166 - val_loss: 8.4454e-04 - val_mse: 8.4454e-04 - val_mae: 0.0174\n",
      "Epoch 155/180\n",
      "65/65 [==============================] - 63s 977ms/step - loss: 8.3804e-04 - mse: 8.3804e-04 - mae: 0.0163 - val_loss: 8.1627e-04 - val_mse: 8.1627e-04 - val_mae: 0.0162\n",
      "Epoch 156/180\n",
      "65/65 [==============================] - 63s 969ms/step - loss: 8.2884e-04 - mse: 8.2884e-04 - mae: 0.0162 - val_loss: 7.9754e-04 - val_mse: 7.9754e-04 - val_mae: 0.0158\n",
      "Epoch 157/180\n",
      "65/65 [==============================] - 63s 976ms/step - loss: 8.3424e-04 - mse: 8.3424e-04 - mae: 0.0163 - val_loss: 8.1411e-04 - val_mse: 8.1411e-04 - val_mae: 0.0171\n",
      "Epoch 158/180\n",
      "65/65 [==============================] - 59s 904ms/step - loss: 8.3073e-04 - mse: 8.3073e-04 - mae: 0.0161 - val_loss: 7.9243e-04 - val_mse: 7.9243e-04 - val_mae: 0.0158\n",
      "Epoch 159/180\n",
      "65/65 [==============================] - 69s 1s/step - loss: 8.2282e-04 - mse: 8.2282e-04 - mae: 0.0161 - val_loss: 8.0219e-04 - val_mse: 8.0219e-04 - val_mae: 0.0152\n",
      "Epoch 160/180\n",
      "65/65 [==============================] - 61s 942ms/step - loss: 8.3283e-04 - mse: 8.3283e-04 - mae: 0.0163 - val_loss: 7.9024e-04 - val_mse: 7.9024e-04 - val_mae: 0.0167\n",
      "Epoch 161/180\n",
      "65/65 [==============================] - 63s 969ms/step - loss: 8.3307e-04 - mse: 8.3307e-04 - mae: 0.0162 - val_loss: 8.9025e-04 - val_mse: 8.9025e-04 - val_mae: 0.0179\n",
      "Epoch 162/180\n",
      "65/65 [==============================] - 55s 850ms/step - loss: 8.3949e-04 - mse: 8.3949e-04 - mae: 0.0165 - val_loss: 8.3476e-04 - val_mse: 8.3476e-04 - val_mae: 0.0165\n",
      "Epoch 163/180\n",
      "65/65 [==============================] - 62s 948ms/step - loss: 8.5250e-04 - mse: 8.5250e-04 - mae: 0.0166 - val_loss: 8.4331e-04 - val_mse: 8.4331e-04 - val_mae: 0.0181\n",
      "Epoch 164/180\n",
      "65/65 [==============================] - 73s 1s/step - loss: 8.2105e-04 - mse: 8.2105e-04 - mae: 0.0161 - val_loss: 7.9977e-04 - val_mse: 7.9977e-04 - val_mae: 0.0155\n",
      "Epoch 165/180\n",
      "65/65 [==============================] - 62s 959ms/step - loss: 8.1800e-04 - mse: 8.1800e-04 - mae: 0.0160 - val_loss: 8.5193e-04 - val_mse: 8.5193e-04 - val_mae: 0.0157\n",
      "Epoch 166/180\n",
      "65/65 [==============================] - 63s 970ms/step - loss: 8.3381e-04 - mse: 8.3381e-04 - mae: 0.0163 - val_loss: 8.6624e-04 - val_mse: 8.6624e-04 - val_mae: 0.0173\n",
      "Epoch 167/180\n",
      "65/65 [==============================] - 65s 1s/step - loss: 8.2759e-04 - mse: 8.2759e-04 - mae: 0.0161 - val_loss: 8.0731e-04 - val_mse: 8.0731e-04 - val_mae: 0.0160\n",
      "Epoch 168/180\n",
      "65/65 [==============================] - 58s 888ms/step - loss: 8.3863e-04 - mse: 8.3863e-04 - mae: 0.0162 - val_loss: 7.5818e-04 - val_mse: 7.5818e-04 - val_mae: 0.0165\n",
      "Epoch 169/180\n",
      "65/65 [==============================] - 64s 988ms/step - loss: 8.2400e-04 - mse: 8.2400e-04 - mae: 0.0162 - val_loss: 7.7653e-04 - val_mse: 7.7653e-04 - val_mae: 0.0155\n",
      "Epoch 170/180\n",
      "65/65 [==============================] - 60s 920ms/step - loss: 8.2398e-04 - mse: 8.2398e-04 - mae: 0.0161 - val_loss: 7.7132e-04 - val_mse: 7.7132e-04 - val_mae: 0.0161\n",
      "Epoch 171/180\n",
      "65/65 [==============================] - 60s 926ms/step - loss: 8.1677e-04 - mse: 8.1677e-04 - mae: 0.0161 - val_loss: 8.0398e-04 - val_mse: 8.0398e-04 - val_mae: 0.0150\n",
      "Epoch 172/180\n",
      "65/65 [==============================] - 56s 866ms/step - loss: 8.3034e-04 - mse: 8.3034e-04 - mae: 0.0163 - val_loss: 7.8765e-04 - val_mse: 7.8765e-04 - val_mae: 0.0167\n",
      "Epoch 173/180\n",
      "65/65 [==============================] - 55s 842ms/step - loss: 8.2083e-04 - mse: 8.2083e-04 - mae: 0.0159 - val_loss: 8.1070e-04 - val_mse: 8.1070e-04 - val_mae: 0.0165\n",
      "Epoch 174/180\n",
      "65/65 [==============================] - 67s 1s/step - loss: 8.1316e-04 - mse: 8.1316e-04 - mae: 0.0160 - val_loss: 7.8803e-04 - val_mse: 7.8803e-04 - val_mae: 0.0161\n",
      "Epoch 175/180\n",
      "65/65 [==============================] - 58s 897ms/step - loss: 8.0409e-04 - mse: 8.0409e-04 - mae: 0.0158 - val_loss: 7.8647e-04 - val_mse: 7.8647e-04 - val_mae: 0.0162\n",
      "Epoch 176/180\n",
      "65/65 [==============================] - 62s 956ms/step - loss: 8.4069e-04 - mse: 8.4069e-04 - mae: 0.0162 - val_loss: 7.9377e-04 - val_mse: 7.9377e-04 - val_mae: 0.0188\n",
      "Epoch 177/180\n",
      "65/65 [==============================] - 64s 990ms/step - loss: 8.1958e-04 - mse: 8.1958e-04 - mae: 0.0162 - val_loss: 7.6579e-04 - val_mse: 7.6579e-04 - val_mae: 0.0151\n",
      "Epoch 178/180\n",
      "65/65 [==============================] - 76s 1s/step - loss: 8.1239e-04 - mse: 8.1239e-04 - mae: 0.0157 - val_loss: 7.7314e-04 - val_mse: 7.7314e-04 - val_mae: 0.0152\n",
      "Epoch 179/180\n",
      "65/65 [==============================] - 61s 946ms/step - loss: 8.0812e-04 - mse: 8.0812e-04 - mae: 0.0157 - val_loss: 7.7496e-04 - val_mse: 7.7496e-04 - val_mae: 0.0152\n",
      "Epoch 180/180\n",
      "65/65 [==============================] - 83s 1s/step - loss: 8.0079e-04 - mse: 8.0079e-04 - mae: 0.0157 - val_loss: 7.9132e-04 - val_mse: 7.9132e-04 - val_mae: 0.0157\n",
      "Epoch 1/180\n",
      "65/65 [==============================] - 166s 3s/step - loss: 0.2311 - mse: 0.2311 - mae: 0.3642 - val_loss: 0.0020 - val_mse: 0.0020 - val_mae: 0.0313\n",
      "Epoch 2/180\n",
      "65/65 [==============================] - 132s 2s/step - loss: 0.1085 - mse: 0.1085 - mae: 0.2624 - val_loss: 0.0029 - val_mse: 0.0029 - val_mae: 0.0463\n",
      "Epoch 3/180\n",
      "65/65 [==============================] - 88s 1s/step - loss: 0.0860 - mse: 0.0860 - mae: 0.2330 - val_loss: 0.0025 - val_mse: 0.0025 - val_mae: 0.0407\n",
      "Epoch 4/180\n",
      "65/65 [==============================] - 96s 1s/step - loss: 0.0638 - mse: 0.0638 - mae: 0.2010 - val_loss: 0.0026 - val_mse: 0.0026 - val_mae: 0.0430\n",
      "Epoch 5/180\n",
      "65/65 [==============================] - 95s 1s/step - loss: 0.0500 - mse: 0.0500 - mae: 0.1782 - val_loss: 0.0028 - val_mse: 0.0028 - val_mae: 0.0470\n",
      "Epoch 6/180\n",
      "65/65 [==============================] - 92s 1s/step - loss: 0.0391 - mse: 0.0391 - mae: 0.1569 - val_loss: 0.0026 - val_mse: 0.0026 - val_mae: 0.0452\n",
      "Epoch 7/180\n",
      "65/65 [==============================] - 124s 2s/step - loss: 0.0298 - mse: 0.0298 - mae: 0.1364 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0206\n",
      "Epoch 8/180\n",
      "65/65 [==============================] - 88s 1s/step - loss: 0.0252 - mse: 0.0252 - mae: 0.1265 - val_loss: 0.0017 - val_mse: 0.0017 - val_mae: 0.0359\n",
      "Epoch 9/180\n",
      "65/65 [==============================] - 91s 1s/step - loss: 0.0194 - mse: 0.0194 - mae: 0.1098 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0236\n",
      "Epoch 10/180\n",
      "65/65 [==============================] - 86s 1s/step - loss: 0.0159 - mse: 0.0159 - mae: 0.0997 - val_loss: 0.0014 - val_mse: 0.0014 - val_mae: 0.0301\n",
      "Epoch 11/180\n",
      "65/65 [==============================] - 98s 2s/step - loss: 0.0134 - mse: 0.0134 - mae: 0.0906 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0217\n",
      "Epoch 12/180\n",
      "65/65 [==============================] - 88s 1s/step - loss: 0.0112 - mse: 0.0112 - mae: 0.0834 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0202\n",
      "Epoch 13/180\n",
      "65/65 [==============================] - 96s 1s/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0813 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0165\n",
      "Epoch 14/180\n",
      "65/65 [==============================] - 97s 1s/step - loss: 0.0086 - mse: 0.0086 - mae: 0.0731 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0237\n",
      "Epoch 15/180\n",
      "65/65 [==============================] - 102s 2s/step - loss: 0.0079 - mse: 0.0079 - mae: 0.0696 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0295\n",
      "Epoch 16/180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 97s 1s/step - loss: 0.0069 - mse: 0.0069 - mae: 0.0648 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0243\n",
      "Epoch 17/180\n",
      "65/65 [==============================] - 97s 1s/step - loss: 0.0061 - mse: 0.0061 - mae: 0.0612 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0222\n",
      "Epoch 18/180\n",
      "65/65 [==============================] - 100s 2s/step - loss: 0.0055 - mse: 0.0055 - mae: 0.0573 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0274\n",
      "Epoch 19/180\n",
      "65/65 [==============================] - 99s 2s/step - loss: 0.0050 - mse: 0.0050 - mae: 0.0547 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0223\n",
      "Epoch 20/180\n",
      "65/65 [==============================] - 94s 1s/step - loss: 0.0044 - mse: 0.0044 - mae: 0.0505 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0215\n",
      "Epoch 21/180\n",
      "65/65 [==============================] - 93s 1s/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0495 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0239\n",
      "Epoch 22/180\n",
      "65/65 [==============================] - 99s 2s/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0474 - val_loss: 9.7299e-04 - val_mse: 9.7299e-04 - val_mae: 0.0194\n",
      "Epoch 23/180\n",
      "65/65 [==============================] - 97s 1s/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0443 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0206\n",
      "Epoch 24/180\n",
      "65/65 [==============================] - 101s 2s/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0438 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0242\n",
      "Epoch 25/180\n",
      "65/65 [==============================] - 100s 2s/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0414 - val_loss: 9.9614e-04 - val_mse: 9.9614e-04 - val_mae: 0.0202\n",
      "Epoch 26/180\n",
      "65/65 [==============================] - 98s 2s/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0405 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0246\n",
      "Epoch 27/180\n",
      "65/65 [==============================] - 92s 1s/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0392 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0208\n",
      "Epoch 28/180\n",
      "65/65 [==============================] - 101s 2s/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0372 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0230\n",
      "Epoch 29/180\n",
      "65/65 [==============================] - 96s 1s/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0361 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0203\n",
      "Epoch 30/180\n",
      "65/65 [==============================] - 88s 1s/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0347 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0215\n",
      "Epoch 31/180\n",
      "65/65 [==============================] - 89s 1s/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0332 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0199\n",
      "Epoch 32/180\n",
      "65/65 [==============================] - 90s 1s/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0338 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0200\n",
      "Epoch 33/180\n",
      "65/65 [==============================] - 89s 1s/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0322 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0205\n",
      "Epoch 34/180\n",
      "65/65 [==============================] - 86s 1s/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0302 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0193\n",
      "Epoch 35/180\n",
      "65/65 [==============================] - 87s 1s/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0299 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0202\n",
      "Epoch 36/180\n",
      "65/65 [==============================] - 87s 1s/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0286 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0207\n",
      "Epoch 37/180\n",
      "65/65 [==============================] - 84s 1s/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0287 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0238\n",
      "Epoch 38/180\n",
      "65/65 [==============================] - 82s 1s/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0278 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0215\n",
      "Epoch 39/180\n",
      "65/65 [==============================] - 79s 1s/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0274 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0207\n",
      "Epoch 40/180\n",
      "65/65 [==============================] - 80s 1s/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0265 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0224\n",
      "Epoch 41/180\n",
      "65/65 [==============================] - 100s 2s/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0260 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0212\n",
      "Epoch 42/180\n",
      "65/65 [==============================] - 96s 1s/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0254 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0207\n",
      "Epoch 43/180\n",
      "65/65 [==============================] - 100s 2s/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0247 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0209\n",
      "Epoch 44/180\n",
      "65/65 [==============================] - 99s 2s/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0240 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0206\n",
      "Epoch 45/180\n",
      "65/65 [==============================] - 105s 2s/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0235 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0210\n",
      "Epoch 46/180\n",
      "65/65 [==============================] - 111s 2s/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0237 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0222\n",
      "Epoch 47/180\n",
      "65/65 [==============================] - 101s 2s/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0236 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0217\n",
      "Epoch 48/180\n",
      "65/65 [==============================] - 100s 2s/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0228 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0212\n",
      "Epoch 49/180\n",
      "65/65 [==============================] - 109s 2s/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0226 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0199\n",
      "Epoch 50/180\n",
      "65/65 [==============================] - 102s 2s/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0223 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0202\n",
      "Epoch 51/180\n",
      "65/65 [==============================] - 105s 2s/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0218 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0207\n",
      "Epoch 52/180\n",
      "65/65 [==============================] - 97s 1s/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0215 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0203\n",
      "Epoch 53/180\n",
      "65/65 [==============================] - 96s 1s/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0214 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 54/180\n",
      "65/65 [==============================] - 94s 1s/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0212 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0202\n",
      "Epoch 55/180\n",
      "65/65 [==============================] - 97s 1s/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0215 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0202\n",
      "Epoch 56/180\n",
      "65/65 [==============================] - 101s 2s/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0210 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0196\n",
      "Epoch 57/180\n",
      "65/65 [==============================] - 100s 2s/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0209 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0197\n",
      "Epoch 58/180\n",
      "65/65 [==============================] - 105s 2s/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0210 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0198\n",
      "Epoch 59/180\n",
      "65/65 [==============================] - 94s 1s/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0208 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0189\n",
      "Epoch 60/180\n",
      "65/65 [==============================] - 94s 1s/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0209 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0194\n",
      "Epoch 61/180\n",
      "65/65 [==============================] - 97s 1s/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0204 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0195\n",
      "Epoch 62/180\n",
      "65/65 [==============================] - 88s 1s/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0203 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0188\n",
      "Epoch 63/180\n",
      "65/65 [==============================] - 88s 1s/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0202 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0182\n",
      "Epoch 64/180\n",
      "65/65 [==============================] - 92s 1s/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0203 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 65/180\n",
      "65/65 [==============================] - 92s 1s/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0202 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/180\n",
      "65/65 [==============================] - 93s 1s/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0200 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0189\n",
      "Epoch 67/180\n",
      "65/65 [==============================] - 94s 1s/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0200 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0193\n",
      "Epoch 68/180\n",
      "65/65 [==============================] - 92s 1s/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0197 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0188\n",
      "Epoch 69/180\n",
      "65/65 [==============================] - 96s 1s/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0195 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0183\n",
      "Epoch 70/180\n",
      "65/65 [==============================] - 94s 1s/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0195 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0182\n",
      "Epoch 71/180\n",
      "65/65 [==============================] - 93s 1s/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0198 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 72/180\n",
      "65/65 [==============================] - 96s 1s/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0196 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 73/180\n",
      "65/65 [==============================] - 100s 2s/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0195 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0193\n",
      "Epoch 74/180\n",
      "65/65 [==============================] - 94s 1s/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0195 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0194\n",
      "Epoch 75/180\n",
      "65/65 [==============================] - 94s 1s/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0194 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0199\n",
      "Epoch 76/180\n",
      "65/65 [==============================] - 95s 1s/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0191 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0193\n",
      "Epoch 77/180\n",
      "65/65 [==============================] - 92s 1s/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0193 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0194\n",
      "Epoch 78/180\n",
      "65/65 [==============================] - 92s 1s/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0191 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0201\n",
      "Epoch 79/180\n",
      "65/65 [==============================] - 92s 1s/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0191 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0198\n",
      "Epoch 80/180\n",
      "65/65 [==============================] - 94s 1s/step - loss: 9.9734e-04 - mse: 9.9734e-04 - mae: 0.0189 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0200\n",
      "Epoch 81/180\n",
      "65/65 [==============================] - 93s 1s/step - loss: 9.9080e-04 - mse: 9.9080e-04 - mae: 0.0189 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0196\n",
      "Epoch 82/180\n",
      "65/65 [==============================] - 93s 1s/step - loss: 9.8605e-04 - mse: 9.8605e-04 - mae: 0.0187 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0201\n",
      "Epoch 83/180\n",
      "65/65 [==============================] - 94s 1s/step - loss: 9.7597e-04 - mse: 9.7597e-04 - mae: 0.0186 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0200\n",
      "Epoch 84/180\n",
      "65/65 [==============================] - 89s 1s/step - loss: 9.8328e-04 - mse: 9.8328e-04 - mae: 0.0188 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0206\n",
      "Epoch 85/180\n",
      "65/65 [==============================] - 91s 1s/step - loss: 9.8119e-04 - mse: 9.8119e-04 - mae: 0.0187 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0203\n",
      "Epoch 86/180\n",
      "65/65 [==============================] - 92s 1s/step - loss: 9.6073e-04 - mse: 9.6073e-04 - mae: 0.0185 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0199\n",
      "Epoch 87/180\n",
      "65/65 [==============================] - 95s 1s/step - loss: 9.5826e-04 - mse: 9.5826e-04 - mae: 0.0184 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0201\n",
      "Epoch 88/180\n",
      "65/65 [==============================] - 99s 2s/step - loss: 9.7015e-04 - mse: 9.7015e-04 - mae: 0.0186 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0202\n",
      "Epoch 89/180\n",
      "65/65 [==============================] - 94s 1s/step - loss: 9.6530e-04 - mse: 9.6530e-04 - mae: 0.0184 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0200\n",
      "Epoch 90/180\n",
      "65/65 [==============================] - 93s 1s/step - loss: 9.5007e-04 - mse: 9.5007e-04 - mae: 0.0183 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0194\n",
      "Epoch 91/180\n",
      "65/65 [==============================] - 91s 1s/step - loss: 9.5682e-04 - mse: 9.5682e-04 - mae: 0.0183 - val_loss: 9.8577e-04 - val_mse: 9.8577e-04 - val_mae: 0.0197\n",
      "Epoch 92/180\n",
      "65/65 [==============================] - 93s 1s/step - loss: 9.6006e-04 - mse: 9.6006e-04 - mae: 0.0183 - val_loss: 9.8996e-04 - val_mse: 9.8996e-04 - val_mae: 0.0195\n",
      "Epoch 93/180\n",
      "65/65 [==============================] - 106s 2s/step - loss: 9.6010e-04 - mse: 9.6010e-04 - mae: 0.0183 - val_loss: 9.9683e-04 - val_mse: 9.9683e-04 - val_mae: 0.0190\n",
      "Epoch 94/180\n",
      "65/65 [==============================] - 103s 2s/step - loss: 9.4849e-04 - mse: 9.4849e-04 - mae: 0.0181 - val_loss: 9.9594e-04 - val_mse: 9.9594e-04 - val_mae: 0.0183\n",
      "Epoch 95/180\n",
      "65/65 [==============================] - 93s 1s/step - loss: 9.5340e-04 - mse: 9.5340e-04 - mae: 0.0182 - val_loss: 9.9189e-04 - val_mse: 9.9189e-04 - val_mae: 0.0189\n",
      "Epoch 96/180\n",
      "65/65 [==============================] - 99s 2s/step - loss: 9.4014e-04 - mse: 9.4014e-04 - mae: 0.0180 - val_loss: 9.8113e-04 - val_mse: 9.8113e-04 - val_mae: 0.0183\n",
      "Epoch 97/180\n",
      "65/65 [==============================] - 101s 2s/step - loss: 9.3738e-04 - mse: 9.3738e-04 - mae: 0.0180 - val_loss: 9.7776e-04 - val_mse: 9.7776e-04 - val_mae: 0.0185\n",
      "Epoch 98/180\n",
      "65/65 [==============================] - 96s 1s/step - loss: 9.3901e-04 - mse: 9.3901e-04 - mae: 0.0180 - val_loss: 9.7087e-04 - val_mse: 9.7087e-04 - val_mae: 0.0181\n",
      "Epoch 99/180\n",
      "65/65 [==============================] - 100s 2s/step - loss: 9.3406e-04 - mse: 9.3406e-04 - mae: 0.0179 - val_loss: 9.6526e-04 - val_mse: 9.6526e-04 - val_mae: 0.0180\n",
      "Epoch 100/180\n",
      "65/65 [==============================] - 92s 1s/step - loss: 9.2964e-04 - mse: 9.2964e-04 - mae: 0.0179 - val_loss: 9.7065e-04 - val_mse: 9.7065e-04 - val_mae: 0.0179\n",
      "Epoch 101/180\n",
      "65/65 [==============================] - 90s 1s/step - loss: 9.3728e-04 - mse: 9.3728e-04 - mae: 0.0179 - val_loss: 9.6223e-04 - val_mse: 9.6223e-04 - val_mae: 0.0180\n",
      "Epoch 102/180\n",
      "65/65 [==============================] - 107s 2s/step - loss: 9.1524e-04 - mse: 9.1524e-04 - mae: 0.0178 - val_loss: 9.5722e-04 - val_mse: 9.5722e-04 - val_mae: 0.0183\n",
      "Epoch 103/180\n",
      "65/65 [==============================] - 113s 2s/step - loss: 9.2680e-04 - mse: 9.2680e-04 - mae: 0.0178 - val_loss: 9.6231e-04 - val_mse: 9.6231e-04 - val_mae: 0.0177\n",
      "Epoch 104/180\n",
      "65/65 [==============================] - 110s 2s/step - loss: 9.2482e-04 - mse: 9.2482e-04 - mae: 0.0178 - val_loss: 9.4990e-04 - val_mse: 9.4990e-04 - val_mae: 0.0179\n",
      "Epoch 105/180\n",
      "65/65 [==============================] - 110s 2s/step - loss: 9.2223e-04 - mse: 9.2223e-04 - mae: 0.0177 - val_loss: 9.4195e-04 - val_mse: 9.4195e-04 - val_mae: 0.0180\n",
      "Epoch 106/180\n",
      "65/65 [==============================] - 96s 1s/step - loss: 9.1192e-04 - mse: 9.1192e-04 - mae: 0.0177 - val_loss: 9.3153e-04 - val_mse: 9.3153e-04 - val_mae: 0.0183\n",
      "Epoch 107/180\n",
      "65/65 [==============================] - 97s 1s/step - loss: 9.1052e-04 - mse: 9.1052e-04 - mae: 0.0176 - val_loss: 9.2754e-04 - val_mse: 9.2754e-04 - val_mae: 0.0180\n",
      "Epoch 108/180\n",
      "65/65 [==============================] - 117s 2s/step - loss: 9.1080e-04 - mse: 9.1080e-04 - mae: 0.0176 - val_loss: 9.0848e-04 - val_mse: 9.0848e-04 - val_mae: 0.0189\n",
      "Epoch 109/180\n",
      "65/65 [==============================] - 118s 2s/step - loss: 9.1071e-04 - mse: 9.1071e-04 - mae: 0.0176 - val_loss: 8.9489e-04 - val_mse: 8.9489e-04 - val_mae: 0.0183\n",
      "Epoch 110/180\n",
      "65/65 [==============================] - 114s 2s/step - loss: 9.1355e-04 - mse: 9.1355e-04 - mae: 0.0176 - val_loss: 8.9685e-04 - val_mse: 8.9685e-04 - val_mae: 0.0184\n",
      "Epoch 111/180\n",
      "65/65 [==============================] - 119s 2s/step - loss: 9.0847e-04 - mse: 9.0847e-04 - mae: 0.0175 - val_loss: 8.7983e-04 - val_mse: 8.7983e-04 - val_mae: 0.0186\n",
      "Epoch 112/180\n",
      "65/65 [==============================] - 120s 2s/step - loss: 9.0466e-04 - mse: 9.0466e-04 - mae: 0.0175 - val_loss: 9.0051e-04 - val_mse: 9.0051e-04 - val_mae: 0.0196\n",
      "Epoch 113/180\n",
      "65/65 [==============================] - 113s 2s/step - loss: 9.0687e-04 - mse: 9.0687e-04 - mae: 0.0176 - val_loss: 8.8333e-04 - val_mse: 8.8333e-04 - val_mae: 0.0186\n",
      "Epoch 114/180\n",
      "65/65 [==============================] - 122s 2s/step - loss: 9.0086e-04 - mse: 9.0086e-04 - mae: 0.0173 - val_loss: 8.7108e-04 - val_mse: 8.7108e-04 - val_mae: 0.0173\n",
      "Epoch 115/180\n",
      "65/65 [==============================] - 119s 2s/step - loss: 9.0520e-04 - mse: 9.0520e-04 - mae: 0.0174 - val_loss: 9.7005e-04 - val_mse: 9.7005e-04 - val_mae: 0.0207\n",
      "Epoch 116/180\n",
      "65/65 [==============================] - 120s 2s/step - loss: 9.0755e-04 - mse: 9.0755e-04 - mae: 0.0174 - val_loss: 8.5684e-04 - val_mse: 8.5684e-04 - val_mae: 0.0164\n",
      "Epoch 117/180\n",
      "65/65 [==============================] - 114s 2s/step - loss: 8.8840e-04 - mse: 8.8840e-04 - mae: 0.0172 - val_loss: 8.8781e-04 - val_mse: 8.8781e-04 - val_mae: 0.0177\n",
      "Epoch 118/180\n",
      "65/65 [==============================] - 121s 2s/step - loss: 8.8161e-04 - mse: 8.8161e-04 - mae: 0.0172 - val_loss: 8.9047e-04 - val_mse: 8.9047e-04 - val_mae: 0.0178\n",
      "Epoch 119/180\n",
      "65/65 [==============================] - 122s 2s/step - loss: 8.8105e-04 - mse: 8.8105e-04 - mae: 0.0171 - val_loss: 8.7106e-04 - val_mse: 8.7106e-04 - val_mae: 0.0180\n",
      "Epoch 120/180\n",
      "65/65 [==============================] - 113s 2s/step - loss: 8.8594e-04 - mse: 8.8594e-04 - mae: 0.0172 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0227\n",
      "Epoch 121/180\n",
      "65/65 [==============================] - 118s 2s/step - loss: 8.8875e-04 - mse: 8.8875e-04 - mae: 0.0172 - val_loss: 9.6698e-04 - val_mse: 9.6698e-04 - val_mae: 0.0207\n",
      "Epoch 122/180\n",
      "65/65 [==============================] - 123s 2s/step - loss: 8.8655e-04 - mse: 8.8655e-04 - mae: 0.0172 - val_loss: 8.7364e-04 - val_mse: 8.7364e-04 - val_mae: 0.0165\n",
      "Epoch 123/180\n",
      "65/65 [==============================] - 116s 2s/step - loss: 8.8010e-04 - mse: 8.8010e-04 - mae: 0.0170 - val_loss: 8.6907e-04 - val_mse: 8.6907e-04 - val_mae: 0.0164\n",
      "Epoch 124/180\n",
      "65/65 [==============================] - 118s 2s/step - loss: 8.7791e-04 - mse: 8.7791e-04 - mae: 0.0171 - val_loss: 8.9367e-04 - val_mse: 8.9367e-04 - val_mae: 0.0175\n",
      "Epoch 125/180\n",
      "65/65 [==============================] - 120s 2s/step - loss: 8.6825e-04 - mse: 8.6825e-04 - mae: 0.0169 - val_loss: 8.9040e-04 - val_mse: 8.9040e-04 - val_mae: 0.0173\n",
      "Epoch 126/180\n",
      "65/65 [==============================] - 116s 2s/step - loss: 8.6918e-04 - mse: 8.6918e-04 - mae: 0.0169 - val_loss: 8.7151e-04 - val_mse: 8.7151e-04 - val_mae: 0.0172\n",
      "Epoch 127/180\n",
      "65/65 [==============================] - 117s 2s/step - loss: 8.7191e-04 - mse: 8.7191e-04 - mae: 0.0170 - val_loss: 9.0860e-04 - val_mse: 9.0860e-04 - val_mae: 0.0187\n",
      "Epoch 128/180\n",
      "65/65 [==============================] - 127s 2s/step - loss: 8.7413e-04 - mse: 8.7413e-04 - mae: 0.0170 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0207\n",
      "Epoch 129/180\n",
      "65/65 [==============================] - 131s 2s/step - loss: 8.7279e-04 - mse: 8.7279e-04 - mae: 0.0169 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0209\n",
      "Epoch 130/180\n",
      "65/65 [==============================] - 212s 3s/step - loss: 8.6371e-04 - mse: 8.6371e-04 - mae: 0.0168 - val_loss: 8.7518e-04 - val_mse: 8.7518e-04 - val_mae: 0.0181\n",
      "Epoch 131/180\n",
      "65/65 [==============================] - 967s 15s/step - loss: 8.7580e-04 - mse: 8.7580e-04 - mae: 0.0170 - val_loss: 9.1237e-04 - val_mse: 9.1237e-04 - val_mae: 0.0209\n",
      "Epoch 132/180\n",
      "65/65 [==============================] - 115s 2s/step - loss: 8.8248e-04 - mse: 8.8248e-04 - mae: 0.0170 - val_loss: 9.1949e-04 - val_mse: 9.1949e-04 - val_mae: 0.0184\n",
      "Epoch 133/180\n",
      "65/65 [==============================] - 117s 2s/step - loss: 8.5948e-04 - mse: 8.5948e-04 - mae: 0.0168 - val_loss: 9.0257e-04 - val_mse: 9.0257e-04 - val_mae: 0.0185\n",
      "Epoch 134/180\n",
      "65/65 [==============================] - 121s 2s/step - loss: 8.5062e-04 - mse: 8.5062e-04 - mae: 0.0166 - val_loss: 8.0884e-04 - val_mse: 8.0884e-04 - val_mae: 0.0161\n",
      "Epoch 135/180\n",
      "65/65 [==============================] - 120s 2s/step - loss: 8.6388e-04 - mse: 8.6388e-04 - mae: 0.0168 - val_loss: 8.7443e-04 - val_mse: 8.7443e-04 - val_mae: 0.0179\n",
      "Epoch 136/180\n",
      "65/65 [==============================] - 118s 2s/step - loss: 8.6427e-04 - mse: 8.6427e-04 - mae: 0.0169 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0231\n",
      "Epoch 137/180\n",
      "65/65 [==============================] - 117s 2s/step - loss: 8.6253e-04 - mse: 8.6253e-04 - mae: 0.0167 - val_loss: 9.4896e-04 - val_mse: 9.4896e-04 - val_mae: 0.0182\n",
      "Epoch 138/180\n",
      "65/65 [==============================] - 123s 2s/step - loss: 8.5933e-04 - mse: 8.5933e-04 - mae: 0.0168 - val_loss: 9.5998e-04 - val_mse: 9.5998e-04 - val_mae: 0.0201\n",
      "Epoch 139/180\n",
      "65/65 [==============================] - 123s 2s/step - loss: 8.6398e-04 - mse: 8.6398e-04 - mae: 0.0167 - val_loss: 8.1974e-04 - val_mse: 8.1974e-04 - val_mae: 0.0193\n",
      "Epoch 140/180\n",
      "65/65 [==============================] - 120s 2s/step - loss: 8.5791e-04 - mse: 8.5791e-04 - mae: 0.0168 - val_loss: 9.6823e-04 - val_mse: 9.6823e-04 - val_mae: 0.0193\n",
      "Epoch 141/180\n",
      "65/65 [==============================] - 121s 2s/step - loss: 8.4131e-04 - mse: 8.4131e-04 - mae: 0.0164 - val_loss: 8.9997e-04 - val_mse: 8.9997e-04 - val_mae: 0.0180\n",
      "Epoch 142/180\n",
      "65/65 [==============================] - 122s 2s/step - loss: 8.4942e-04 - mse: 8.4942e-04 - mae: 0.0166 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0209\n",
      "Epoch 143/180\n",
      "65/65 [==============================] - 115s 2s/step - loss: 8.4795e-04 - mse: 8.4795e-04 - mae: 0.0164 - val_loss: 8.1679e-04 - val_mse: 8.1679e-04 - val_mae: 0.0152\n",
      "Epoch 144/180\n",
      "65/65 [==============================] - 126s 2s/step - loss: 8.5623e-04 - mse: 8.5623e-04 - mae: 0.0167 - val_loss: 9.4468e-04 - val_mse: 9.4468e-04 - val_mae: 0.0188\n",
      "Epoch 145/180\n",
      "65/65 [==============================] - 119s 2s/step - loss: 8.4930e-04 - mse: 8.4930e-04 - mae: 0.0165 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0213\n",
      "Epoch 146/180\n",
      "65/65 [==============================] - 123s 2s/step - loss: 8.4441e-04 - mse: 8.4441e-04 - mae: 0.0164 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0200\n",
      "Epoch 147/180\n",
      "65/65 [==============================] - 126s 2s/step - loss: 8.4167e-04 - mse: 8.4167e-04 - mae: 0.0164 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0193\n",
      "Epoch 148/180\n",
      "65/65 [==============================] - 131s 2s/step - loss: 8.4123e-04 - mse: 8.4123e-04 - mae: 0.0163 - val_loss: 8.5096e-04 - val_mse: 8.5096e-04 - val_mae: 0.0167\n",
      "Epoch 149/180\n",
      "65/65 [==============================] - 126s 2s/step - loss: 8.5772e-04 - mse: 8.5772e-04 - mae: 0.0167 - val_loss: 7.9064e-04 - val_mse: 7.9064e-04 - val_mae: 0.0183\n",
      "Epoch 150/180\n",
      "65/65 [==============================] - 132s 2s/step - loss: 8.5220e-04 - mse: 8.5220e-04 - mae: 0.0166 - val_loss: 8.7474e-04 - val_mse: 8.7474e-04 - val_mae: 0.0192\n",
      "Epoch 151/180\n",
      "65/65 [==============================] - 114s 2s/step - loss: 8.4505e-04 - mse: 8.4505e-04 - mae: 0.0164 - val_loss: 8.6550e-04 - val_mse: 8.6550e-04 - val_mae: 0.0196\n",
      "Epoch 152/180\n",
      "65/65 [==============================] - 125s 2s/step - loss: 8.4104e-04 - mse: 8.4104e-04 - mae: 0.0164 - val_loss: 8.5968e-04 - val_mse: 8.5968e-04 - val_mae: 0.0172\n",
      "Epoch 153/180\n",
      "65/65 [==============================] - 133s 2s/step - loss: 8.4522e-04 - mse: 8.4522e-04 - mae: 0.0165 - val_loss: 9.2332e-04 - val_mse: 9.2332e-04 - val_mae: 0.0199\n",
      "Epoch 154/180\n",
      "65/65 [==============================] - 133s 2s/step - loss: 8.5616e-04 - mse: 8.5616e-04 - mae: 0.0166 - val_loss: 8.8745e-04 - val_mse: 8.8745e-04 - val_mae: 0.0190\n",
      "Epoch 155/180\n",
      "65/65 [==============================] - 134s 2s/step - loss: 8.4001e-04 - mse: 8.4001e-04 - mae: 0.0163 - val_loss: 7.6353e-04 - val_mse: 7.6353e-04 - val_mae: 0.0166\n",
      "Epoch 156/180\n",
      "65/65 [==============================] - 131s 2s/step - loss: 8.4299e-04 - mse: 8.4299e-04 - mae: 0.0165 - val_loss: 9.7792e-04 - val_mse: 9.7792e-04 - val_mae: 0.0204\n",
      "Epoch 157/180\n",
      "65/65 [==============================] - 131s 2s/step - loss: 8.3963e-04 - mse: 8.3963e-04 - mae: 0.0163 - val_loss: 7.9660e-04 - val_mse: 7.9660e-04 - val_mae: 0.0158\n",
      "Epoch 158/180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 133s 2s/step - loss: 8.4509e-04 - mse: 8.4509e-04 - mae: 0.0165 - val_loss: 9.1595e-04 - val_mse: 9.1595e-04 - val_mae: 0.0195\n",
      "Epoch 159/180\n",
      "65/65 [==============================] - 131s 2s/step - loss: 8.3932e-04 - mse: 8.3932e-04 - mae: 0.0164 - val_loss: 8.1250e-04 - val_mse: 8.1250e-04 - val_mae: 0.0187\n",
      "Epoch 160/180\n",
      "65/65 [==============================] - 133s 2s/step - loss: 8.4643e-04 - mse: 8.4643e-04 - mae: 0.0165 - val_loss: 8.3870e-04 - val_mse: 8.3870e-04 - val_mae: 0.0190\n",
      "Epoch 161/180\n",
      "65/65 [==============================] - 134s 2s/step - loss: 8.3461e-04 - mse: 8.3461e-04 - mae: 0.0164 - val_loss: 8.2957e-04 - val_mse: 8.2957e-04 - val_mae: 0.0175\n",
      "Epoch 162/180\n",
      "65/65 [==============================] - 127s 2s/step - loss: 8.2889e-04 - mse: 8.2889e-04 - mae: 0.0162 - val_loss: 8.7061e-04 - val_mse: 8.7061e-04 - val_mae: 0.0182\n",
      "Epoch 163/180\n",
      "65/65 [==============================] - 127s 2s/step - loss: 8.3997e-04 - mse: 8.3997e-04 - mae: 0.0163 - val_loss: 8.1211e-04 - val_mse: 8.1211e-04 - val_mae: 0.0186\n",
      "Epoch 164/180\n",
      "65/65 [==============================] - 126s 2s/step - loss: 8.3223e-04 - mse: 8.3223e-04 - mae: 0.0163 - val_loss: 7.8518e-04 - val_mse: 7.8518e-04 - val_mae: 0.0160\n",
      "Epoch 165/180\n",
      "65/65 [==============================] - 126s 2s/step - loss: 8.3080e-04 - mse: 8.3080e-04 - mae: 0.0163 - val_loss: 8.2097e-04 - val_mse: 8.2097e-04 - val_mae: 0.0159\n",
      "Epoch 166/180\n",
      "65/65 [==============================] - 132s 2s/step - loss: 8.2991e-04 - mse: 8.2991e-04 - mae: 0.0162 - val_loss: 9.5301e-04 - val_mse: 9.5301e-04 - val_mae: 0.0190\n",
      "Epoch 167/180\n",
      "65/65 [==============================] - 132s 2s/step - loss: 8.3752e-04 - mse: 8.3752e-04 - mae: 0.0163 - val_loss: 7.9963e-04 - val_mse: 7.9963e-04 - val_mae: 0.0175\n",
      "Epoch 168/180\n",
      "65/65 [==============================] - 133s 2s/step - loss: 8.4544e-04 - mse: 8.4544e-04 - mae: 0.0163 - val_loss: 7.9659e-04 - val_mse: 7.9659e-04 - val_mae: 0.0182\n",
      "Epoch 169/180\n",
      "65/65 [==============================] - 138s 2s/step - loss: 8.3883e-04 - mse: 8.3883e-04 - mae: 0.0163 - val_loss: 9.2745e-04 - val_mse: 9.2745e-04 - val_mae: 0.0189\n",
      "Epoch 170/180\n",
      "65/65 [==============================] - 142s 2s/step - loss: 8.2303e-04 - mse: 8.2303e-04 - mae: 0.0162 - val_loss: 9.3896e-04 - val_mse: 9.3896e-04 - val_mae: 0.0196\n",
      "Epoch 171/180\n",
      "65/65 [==============================] - 142s 2s/step - loss: 8.2199e-04 - mse: 8.2199e-04 - mae: 0.0160 - val_loss: 7.3225e-04 - val_mse: 7.3225e-04 - val_mae: 0.0158\n",
      "Epoch 172/180\n",
      "65/65 [==============================] - 142s 2s/step - loss: 8.4140e-04 - mse: 8.4140e-04 - mae: 0.0163 - val_loss: 8.0646e-04 - val_mse: 8.0646e-04 - val_mae: 0.0153\n",
      "Epoch 173/180\n",
      "65/65 [==============================] - 142s 2s/step - loss: 8.4134e-04 - mse: 8.4134e-04 - mae: 0.0164 - val_loss: 8.2939e-04 - val_mse: 8.2939e-04 - val_mae: 0.0180\n",
      "Epoch 174/180\n",
      "65/65 [==============================] - 142s 2s/step - loss: 8.2237e-04 - mse: 8.2237e-04 - mae: 0.0161 - val_loss: 9.6936e-04 - val_mse: 9.6936e-04 - val_mae: 0.0192\n",
      "Epoch 175/180\n",
      "65/65 [==============================] - 141s 2s/step - loss: 8.3478e-04 - mse: 8.3478e-04 - mae: 0.0162 - val_loss: 7.9372e-04 - val_mse: 7.9372e-04 - val_mae: 0.0181\n",
      "Epoch 176/180\n",
      "65/65 [==============================] - 143s 2s/step - loss: 8.3077e-04 - mse: 8.3077e-04 - mae: 0.0162 - val_loss: 8.6273e-04 - val_mse: 8.6273e-04 - val_mae: 0.0180\n",
      "Epoch 177/180\n",
      "65/65 [==============================] - 143s 2s/step - loss: 8.2248e-04 - mse: 8.2248e-04 - mae: 0.0161 - val_loss: 9.6206e-04 - val_mse: 9.6206e-04 - val_mae: 0.0195\n",
      "Epoch 178/180\n",
      "65/65 [==============================] - 142s 2s/step - loss: 8.1846e-04 - mse: 8.1846e-04 - mae: 0.0161 - val_loss: 8.5008e-04 - val_mse: 8.5008e-04 - val_mae: 0.0178\n",
      "Epoch 179/180\n",
      "65/65 [==============================] - 142s 2s/step - loss: 8.1797e-04 - mse: 8.1797e-04 - mae: 0.0160 - val_loss: 8.9266e-04 - val_mse: 8.9266e-04 - val_mae: 0.0179\n",
      "Epoch 180/180\n",
      "65/65 [==============================] - 138s 2s/step - loss: 8.2886e-04 - mse: 8.2886e-04 - mae: 0.0162 - val_loss: 8.7382e-04 - val_mse: 8.7382e-04 - val_mae: 0.0180\n",
      "Epoch 1/180\n",
      "65/65 [==============================] - 26s 405ms/step - loss: 0.1316 - mse: 0.1316 - mae: 0.2882 - val_loss: 0.0029 - val_mse: 0.0029 - val_mae: 0.0436\n",
      "Epoch 2/180\n",
      "65/65 [==============================] - 25s 382ms/step - loss: 0.0673 - mse: 0.0673 - mae: 0.2051 - val_loss: 0.0030 - val_mse: 0.0030 - val_mae: 0.0377\n",
      "Epoch 3/180\n",
      "65/65 [==============================] - 25s 384ms/step - loss: 0.0425 - mse: 0.0425 - mae: 0.1635 - val_loss: 0.0018 - val_mse: 0.0018 - val_mae: 0.0283\n",
      "Epoch 4/180\n",
      "65/65 [==============================] - 25s 378ms/step - loss: 0.0297 - mse: 0.0297 - mae: 0.1362 - val_loss: 0.0014 - val_mse: 0.0014 - val_mae: 0.0277\n",
      "Epoch 5/180\n",
      "65/65 [==============================] - 24s 376ms/step - loss: 0.0218 - mse: 0.0218 - mae: 0.1176 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0225\n",
      "Epoch 6/180\n",
      "65/65 [==============================] - 25s 380ms/step - loss: 0.0176 - mse: 0.0176 - mae: 0.1051 - val_loss: 0.0015 - val_mse: 0.0015 - val_mae: 0.0306\n",
      "Epoch 7/180\n",
      "65/65 [==============================] - 25s 381ms/step - loss: 0.0138 - mse: 0.0138 - mae: 0.0930 - val_loss: 0.0015 - val_mse: 0.0015 - val_mae: 0.0281\n",
      "Epoch 8/180\n",
      "65/65 [==============================] - 25s 382ms/step - loss: 0.0119 - mse: 0.0119 - mae: 0.0864 - val_loss: 0.0014 - val_mse: 0.0014 - val_mae: 0.0246\n",
      "Epoch 9/180\n",
      "65/65 [==============================] - 24s 375ms/step - loss: 0.0097 - mse: 0.0097 - mae: 0.0774 - val_loss: 0.0016 - val_mse: 0.0016 - val_mae: 0.0298\n",
      "Epoch 10/180\n",
      "65/65 [==============================] - 24s 376ms/step - loss: 0.0083 - mse: 0.0083 - mae: 0.0706 - val_loss: 0.0014 - val_mse: 0.0014 - val_mae: 0.0276\n",
      "Epoch 11/180\n",
      "65/65 [==============================] - 25s 377ms/step - loss: 0.0075 - mse: 0.0075 - mae: 0.0670 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0267\n",
      "Epoch 12/180\n",
      "65/65 [==============================] - 25s 379ms/step - loss: 0.0064 - mse: 0.0064 - mae: 0.0622 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0245\n",
      "Epoch 13/180\n",
      "65/65 [==============================] - 24s 372ms/step - loss: 0.0057 - mse: 0.0057 - mae: 0.0582 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0240\n",
      "Epoch 14/180\n",
      "65/65 [==============================] - 25s 377ms/step - loss: 0.0054 - mse: 0.0054 - mae: 0.0565 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0198\n",
      "Epoch 15/180\n",
      "65/65 [==============================] - 24s 376ms/step - loss: 0.0047 - mse: 0.0047 - mae: 0.0525 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0202\n",
      "Epoch 16/180\n",
      "65/65 [==============================] - 25s 378ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0503 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0201\n",
      "Epoch 17/180\n",
      "65/65 [==============================] - 25s 378ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0477 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0209\n",
      "Epoch 18/180\n",
      "65/65 [==============================] - 24s 375ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0445 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0210\n",
      "Epoch 19/180\n",
      "65/65 [==============================] - 24s 374ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0430 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0214\n",
      "Epoch 20/180\n",
      "65/65 [==============================] - 25s 378ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0410 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0213\n",
      "Epoch 21/180\n",
      "65/65 [==============================] - 24s 373ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0396 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0229\n",
      "Epoch 22/180\n",
      "65/65 [==============================] - 24s 376ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0381 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0225\n",
      "Epoch 23/180\n",
      "65/65 [==============================] - 2343s 36s/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0367 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0218\n",
      "Epoch 24/180\n",
      "65/65 [==============================] - 27s 416ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0352 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0227\n",
      "Epoch 25/180\n",
      "65/65 [==============================] - 14s 209ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0342 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0206 0.0021 - mse: 0.0021 - mae:\n",
      "Epoch 26/180\n",
      "65/65 [==============================] - 13s 193ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0329 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0222\n",
      "Epoch 27/180\n",
      "65/65 [==============================] - 11s 168ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0324 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0220\n",
      "Epoch 28/180\n",
      "65/65 [==============================] - 11s 175ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0312 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0218\n",
      "Epoch 29/180\n",
      "65/65 [==============================] - 12s 179ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0309 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0217\n",
      "Epoch 30/180\n",
      "65/65 [==============================] - 12s 192ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0298 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0219\n",
      "Epoch 31/180\n",
      "65/65 [==============================] - 14s 218ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0287 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0214\n",
      "Epoch 32/180\n",
      "65/65 [==============================] - 14s 210ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0282 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0226\n",
      "Epoch 33/180\n",
      "65/65 [==============================] - 14s 209ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0274 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0211\n",
      "Epoch 34/180\n",
      "65/65 [==============================] - 14s 210ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0265 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0209\n",
      "Epoch 35/180\n",
      "65/65 [==============================] - 13s 207ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0266 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0207\n",
      "Epoch 36/180\n",
      "65/65 [==============================] - 14s 209ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0257 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0211\n",
      "Epoch 37/180\n",
      "65/65 [==============================] - 15s 223ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0253 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0214\n",
      "Epoch 38/180\n",
      "65/65 [==============================] - 14s 210ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0245 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0208\n",
      "Epoch 39/180\n",
      "65/65 [==============================] - 14s 210ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0241 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0211\n",
      "Epoch 40/180\n",
      "65/65 [==============================] - 14s 210ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0238 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0207\n",
      "Epoch 41/180\n",
      "65/65 [==============================] - 15s 225ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0234 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0210\n",
      "Epoch 42/180\n",
      "65/65 [==============================] - 15s 226ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0229 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0210e: 0.0012 -\n",
      "Epoch 43/180\n",
      "65/65 [==============================] - 14s 220ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0224 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0201\n",
      "Epoch 44/180\n",
      "65/65 [==============================] - 15s 235ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0224 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0202\n",
      "Epoch 45/180\n",
      "65/65 [==============================] - 15s 228ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0220 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0211\n",
      "Epoch 46/180\n",
      "65/65 [==============================] - 14s 223ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0216 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0199\n",
      "Epoch 47/180\n",
      "65/65 [==============================] - 15s 226ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0214 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0202\n",
      "Epoch 48/180\n",
      "65/65 [==============================] - 15s 230ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0209 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0200\n",
      "Epoch 49/180\n",
      "65/65 [==============================] - 14s 218ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0207 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0199\n",
      "Epoch 50/180\n",
      "65/65 [==============================] - 14s 220ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0204 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0200\n",
      "Epoch 51/180\n",
      "65/65 [==============================] - 14s 220ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0203 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0204\n",
      "Epoch 52/180\n",
      "65/65 [==============================] - 15s 230ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0199 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0201\n",
      "Epoch 53/180\n",
      "65/65 [==============================] - 16s 247ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0199 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0204\n",
      "Epoch 54/180\n",
      "65/65 [==============================] - 15s 225ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0198 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0198\n",
      "Epoch 55/180\n",
      "65/65 [==============================] - 14s 221ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0197 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0196\n",
      "Epoch 56/180\n",
      "65/65 [==============================] - 15s 225ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0195 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0198\n",
      "Epoch 57/180\n",
      "65/65 [==============================] - 15s 236ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0191 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0203\n",
      "Epoch 58/180\n",
      "65/65 [==============================] - 14s 222ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0192 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0198\n",
      "Epoch 59/180\n",
      "65/65 [==============================] - 15s 225ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0191 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0196\n",
      "Epoch 60/180\n",
      "65/65 [==============================] - 15s 225ms/step - loss: 9.9785e-04 - mse: 9.9785e-04 - mae: 0.0189 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0200\n",
      "Epoch 61/180\n",
      "65/65 [==============================] - 15s 224ms/step - loss: 9.8891e-04 - mse: 9.8891e-04 - mae: 0.0189 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0194\n",
      "Epoch 62/180\n",
      "65/65 [==============================] - 15s 229ms/step - loss: 9.6935e-04 - mse: 9.6935e-04 - mae: 0.0187 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0196\n",
      "Epoch 63/180\n",
      "65/65 [==============================] - 15s 223ms/step - loss: 9.8564e-04 - mse: 9.8564e-04 - mae: 0.0187 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0196\n",
      "Epoch 64/180\n",
      "65/65 [==============================] - 15s 231ms/step - loss: 9.6591e-04 - mse: 9.6591e-04 - mae: 0.0185 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0199\n",
      "Epoch 65/180\n",
      "65/65 [==============================] - 15s 233ms/step - loss: 9.7107e-04 - mse: 9.7107e-04 - mae: 0.0186 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0195\n",
      "Epoch 66/180\n",
      "65/65 [==============================] - 15s 228ms/step - loss: 9.6420e-04 - mse: 9.6420e-04 - mae: 0.0185 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0192\n",
      "Epoch 67/180\n",
      "65/65 [==============================] - 15s 226ms/step - loss: 9.5262e-04 - mse: 9.5262e-04 - mae: 0.0183 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0194\n",
      "Epoch 68/180\n",
      "65/65 [==============================] - 15s 227ms/step - loss: 9.6437e-04 - mse: 9.6437e-04 - mae: 0.0185 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0193\n",
      "Epoch 69/180\n",
      "65/65 [==============================] - 15s 232ms/step - loss: 9.4888e-04 - mse: 9.4888e-04 - mae: 0.0183 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0193\n",
      "Epoch 70/180\n",
      "65/65 [==============================] - 15s 226ms/step - loss: 9.5182e-04 - mse: 9.5182e-04 - mae: 0.0182 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0195\n",
      "Epoch 71/180\n",
      "65/65 [==============================] - 15s 231ms/step - loss: 9.5362e-04 - mse: 9.5362e-04 - mae: 0.0182 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0195\n",
      "Epoch 72/180\n",
      "65/65 [==============================] - 16s 247ms/step - loss: 9.5028e-04 - mse: 9.5028e-04 - mae: 0.0182 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0190\n",
      "Epoch 73/180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 17s 261ms/step - loss: 9.4301e-04 - mse: 9.4301e-04 - mae: 0.0181 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0192\n",
      "Epoch 74/180\n",
      "65/65 [==============================] - 15s 233ms/step - loss: 9.4526e-04 - mse: 9.4526e-04 - mae: 0.0182 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0191\n",
      "Epoch 75/180\n",
      "65/65 [==============================] - 15s 229ms/step - loss: 9.4196e-04 - mse: 9.4196e-04 - mae: 0.0181 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0191\n",
      "Epoch 76/180\n",
      "65/65 [==============================] - 15s 231ms/step - loss: 9.4284e-04 - mse: 9.4284e-04 - mae: 0.0181 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0190\n",
      "Epoch 77/180\n",
      "65/65 [==============================] - 15s 229ms/step - loss: 9.3784e-04 - mse: 9.3784e-04 - mae: 0.0181 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0192\n",
      "Epoch 78/180\n",
      "65/65 [==============================] - 15s 230ms/step - loss: 9.3442e-04 - mse: 9.3442e-04 - mae: 0.0181 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0188\n",
      "Epoch 79/180\n",
      "65/65 [==============================] - 15s 229ms/step - loss: 9.2661e-04 - mse: 9.2661e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0190\n",
      "Epoch 80/180\n",
      "65/65 [==============================] - 15s 230ms/step - loss: 9.2788e-04 - mse: 9.2788e-04 - mae: 0.0180 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0191\n",
      "Epoch 81/180\n",
      "65/65 [==============================] - 15s 227ms/step - loss: 9.2726e-04 - mse: 9.2726e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0190\n",
      "Epoch 82/180\n",
      "65/65 [==============================] - 15s 229ms/step - loss: 9.2676e-04 - mse: 9.2676e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0190\n",
      "Epoch 83/180\n",
      "65/65 [==============================] - 15s 232ms/step - loss: 9.3284e-04 - mse: 9.3284e-04 - mae: 0.0180 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0188\n",
      "Epoch 84/180\n",
      "65/65 [==============================] - 15s 234ms/step - loss: 9.2692e-04 - mse: 9.2692e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0190\n",
      "Epoch 85/180\n",
      "65/65 [==============================] - 16s 246ms/step - loss: 9.2979e-04 - mse: 9.2979e-04 - mae: 0.0180 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0188\n",
      "Epoch 86/180\n",
      "65/65 [==============================] - 15s 232ms/step - loss: 9.2228e-04 - mse: 9.2228e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0189\n",
      "Epoch 87/180\n",
      "65/65 [==============================] - 16s 244ms/step - loss: 9.3093e-04 - mse: 9.3093e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0189\n",
      "Epoch 88/180\n",
      "65/65 [==============================] - 15s 232ms/step - loss: 9.2347e-04 - mse: 9.2347e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0187\n",
      "Epoch 89/180\n",
      "65/65 [==============================] - 15s 229ms/step - loss: 9.2207e-04 - mse: 9.2207e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0191\n",
      "Epoch 90/180\n",
      "65/65 [==============================] - 15s 233ms/step - loss: 9.2219e-04 - mse: 9.2219e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0189\n",
      "Epoch 91/180\n",
      "65/65 [==============================] - 19s 287ms/step - loss: 9.2511e-04 - mse: 9.2511e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0190\n",
      "Epoch 92/180\n",
      "65/65 [==============================] - 21s 318ms/step - loss: 9.1845e-04 - mse: 9.1845e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0190\n",
      "Epoch 93/180\n",
      "65/65 [==============================] - 17s 268ms/step - loss: 9.1475e-04 - mse: 9.1475e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0190\n",
      "Epoch 94/180\n",
      "65/65 [==============================] - 18s 279ms/step - loss: 9.1738e-04 - mse: 9.1738e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0190\n",
      "Epoch 95/180\n",
      "65/65 [==============================] - 16s 249ms/step - loss: 9.1859e-04 - mse: 9.1859e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0191\n",
      "Epoch 96/180\n",
      "65/65 [==============================] - 16s 248ms/step - loss: 9.1505e-04 - mse: 9.1505e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0192\n",
      "Epoch 97/180\n",
      "65/65 [==============================] - 15s 236ms/step - loss: 9.1775e-04 - mse: 9.1775e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0190\n",
      "Epoch 98/180\n",
      "65/65 [==============================] - 15s 236ms/step - loss: 9.1579e-04 - mse: 9.1579e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0189\n",
      "Epoch 99/180\n",
      "65/65 [==============================] - 16s 240ms/step - loss: 9.1297e-04 - mse: 9.1297e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0190\n",
      "Epoch 100/180\n",
      "65/65 [==============================] - 16s 240ms/step - loss: 9.1484e-04 - mse: 9.1484e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0188\n",
      "Epoch 101/180\n",
      "65/65 [==============================] - 16s 249ms/step - loss: 9.1190e-04 - mse: 9.1190e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0190\n",
      "Epoch 102/180\n",
      "65/65 [==============================] - 16s 243ms/step - loss: 9.1405e-04 - mse: 9.1405e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0189\n",
      "Epoch 103/180\n",
      "65/65 [==============================] - 16s 243ms/step - loss: 9.1033e-04 - mse: 9.1033e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0190\n",
      "Epoch 104/180\n",
      "65/65 [==============================] - 16s 240ms/step - loss: 9.0940e-04 - mse: 9.0940e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0191\n",
      "Epoch 105/180\n",
      "65/65 [==============================] - 16s 241ms/step - loss: 9.1311e-04 - mse: 9.1311e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0190\n",
      "Epoch 106/180\n",
      "65/65 [==============================] - 16s 240ms/step - loss: 9.0978e-04 - mse: 9.0978e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0189\n",
      "Epoch 107/180\n",
      "65/65 [==============================] - 19s 293ms/step - loss: 9.0899e-04 - mse: 9.0899e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0192\n",
      "Epoch 108/180\n",
      "65/65 [==============================] - 16s 254ms/step - loss: 9.0491e-04 - mse: 9.0491e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0192\n",
      "Epoch 109/180\n",
      "65/65 [==============================] - 17s 260ms/step - loss: 9.0778e-04 - mse: 9.0778e-04 - mae: 0.0176 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0192\n",
      "Epoch 110/180\n",
      "65/65 [==============================] - 17s 259ms/step - loss: 9.0360e-04 - mse: 9.0360e-04 - mae: 0.0176 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0194\n",
      "Epoch 111/180\n",
      "65/65 [==============================] - 18s 283ms/step - loss: 9.0310e-04 - mse: 9.0310e-04 - mae: 0.0176 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0196\n",
      "Epoch 112/180\n",
      "65/65 [==============================] - 16s 253ms/step - loss: 9.0046e-04 - mse: 9.0046e-04 - mae: 0.0175 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0192\n",
      "Epoch 113/180\n",
      "65/65 [==============================] - 17s 263ms/step - loss: 9.0030e-04 - mse: 9.0030e-04 - mae: 0.0175 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0202\n",
      "Epoch 114/180\n",
      "65/65 [==============================] - 17s 269ms/step - loss: 8.9649e-04 - mse: 8.9649e-04 - mae: 0.0175 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0196\n",
      "Epoch 115/180\n",
      "65/65 [==============================] - 17s 265ms/step - loss: 8.9965e-04 - mse: 8.9965e-04 - mae: 0.0174 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0204\n",
      "Epoch 116/180\n",
      "65/65 [==============================] - 17s 256ms/step - loss: 8.9307e-04 - mse: 8.9307e-04 - mae: 0.0175 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0188\n",
      "Epoch 117/180\n",
      "65/65 [==============================] - 17s 269ms/step - loss: 8.9280e-04 - mse: 8.9280e-04 - mae: 0.0173 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0195\n",
      "Epoch 118/180\n",
      "65/65 [==============================] - 17s 257ms/step - loss: 8.9676e-04 - mse: 8.9676e-04 - mae: 0.0175 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0203\n",
      "Epoch 119/180\n",
      "65/65 [==============================] - 17s 257ms/step - loss: 8.8420e-04 - mse: 8.8420e-04 - mae: 0.0173 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/180\n",
      "65/65 [==============================] - 17s 259ms/step - loss: 8.9456e-04 - mse: 8.9456e-04 - mae: 0.0175 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0192\n",
      "Epoch 121/180\n",
      "65/65 [==============================] - 17s 259ms/step - loss: 8.9233e-04 - mse: 8.9233e-04 - mae: 0.0174 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0193\n",
      "Epoch 122/180\n",
      "65/65 [==============================] - 17s 254ms/step - loss: 8.8278e-04 - mse: 8.8278e-04 - mae: 0.0172 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0192\n",
      "Epoch 123/180\n",
      "65/65 [==============================] - 18s 276ms/step - loss: 8.8635e-04 - mse: 8.8635e-04 - mae: 0.0172 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0198\n",
      "Epoch 124/180\n",
      "65/65 [==============================] - 17s 264ms/step - loss: 8.9419e-04 - mse: 8.9419e-04 - mae: 0.0176 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0182\n",
      "Epoch 125/180\n",
      "65/65 [==============================] - 17s 260ms/step - loss: 8.9230e-04 - mse: 8.9230e-04 - mae: 0.0174 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0194\n",
      "Epoch 126/180\n",
      "65/65 [==============================] - 17s 258ms/step - loss: 8.8652e-04 - mse: 8.8652e-04 - mae: 0.0173 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0197\n",
      "Epoch 127/180\n",
      "65/65 [==============================] - 19s 299ms/step - loss: 8.8119e-04 - mse: 8.8119e-04 - mae: 0.0172 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0201\n",
      "Epoch 128/180\n",
      "65/65 [==============================] - 18s 273ms/step - loss: 8.8176e-04 - mse: 8.8176e-04 - mae: 0.0173 - val_loss: 9.9691e-04 - val_mse: 9.9691e-04 - val_mae: 0.0193\n",
      "Epoch 129/180\n",
      "65/65 [==============================] - 17s 263ms/step - loss: 8.7664e-04 - mse: 8.7664e-04 - mae: 0.0172 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0201\n",
      "Epoch 130/180\n",
      "65/65 [==============================] - 17s 255ms/step - loss: 8.8339e-04 - mse: 8.8339e-04 - mae: 0.0173 - val_loss: 9.8531e-04 - val_mse: 9.8531e-04 - val_mae: 0.0187\n",
      "Epoch 131/180\n",
      "65/65 [==============================] - 17s 262ms/step - loss: 8.7903e-04 - mse: 8.7903e-04 - mae: 0.0172 - val_loss: 9.8206e-04 - val_mse: 9.8206e-04 - val_mae: 0.0194\n",
      "Epoch 132/180\n",
      "65/65 [==============================] - 16s 253ms/step - loss: 8.7264e-04 - mse: 8.7264e-04 - mae: 0.0172 - val_loss: 9.7644e-04 - val_mse: 9.7644e-04 - val_mae: 0.0192\n",
      "Epoch 133/180\n",
      "65/65 [==============================] - 17s 265ms/step - loss: 8.7488e-04 - mse: 8.7488e-04 - mae: 0.0172 - val_loss: 9.7854e-04 - val_mse: 9.7854e-04 - val_mae: 0.0185\n",
      "Epoch 134/180\n",
      "65/65 [==============================] - 17s 259ms/step - loss: 8.7874e-04 - mse: 8.7874e-04 - mae: 0.0172 - val_loss: 9.7626e-04 - val_mse: 9.7626e-04 - val_mae: 0.0192\n",
      "Epoch 135/180\n",
      "65/65 [==============================] - 16s 253ms/step - loss: 8.7305e-04 - mse: 8.7305e-04 - mae: 0.0171 - val_loss: 9.7621e-04 - val_mse: 9.7621e-04 - val_mae: 0.0200\n",
      "Epoch 136/180\n",
      "65/65 [==============================] - 17s 265ms/step - loss: 8.7116e-04 - mse: 8.7116e-04 - mae: 0.0171 - val_loss: 9.6304e-04 - val_mse: 9.6304e-04 - val_mae: 0.0190\n",
      "Epoch 137/180\n",
      "65/65 [==============================] - 19s 287ms/step - loss: 8.7033e-04 - mse: 8.7033e-04 - mae: 0.0171 - val_loss: 9.6511e-04 - val_mse: 9.6511e-04 - val_mae: 0.0191\n",
      "Epoch 138/180\n",
      "65/65 [==============================] - 18s 281ms/step - loss: 8.6935e-04 - mse: 8.6935e-04 - mae: 0.0171 - val_loss: 9.5194e-04 - val_mse: 9.5194e-04 - val_mae: 0.0195\n",
      "Epoch 139/180\n",
      "65/65 [==============================] - 17s 266ms/step - loss: 8.6311e-04 - mse: 8.6311e-04 - mae: 0.0171 - val_loss: 9.5455e-04 - val_mse: 9.5455e-04 - val_mae: 0.0186\n",
      "Epoch 140/180\n",
      "65/65 [==============================] - 17s 264ms/step - loss: 8.7357e-04 - mse: 8.7357e-04 - mae: 0.0171 - val_loss: 9.4313e-04 - val_mse: 9.4313e-04 - val_mae: 0.0184\n",
      "Epoch 141/180\n",
      "65/65 [==============================] - 18s 275ms/step - loss: 8.6515e-04 - mse: 8.6515e-04 - mae: 0.0170 - val_loss: 9.5492e-04 - val_mse: 9.5492e-04 - val_mae: 0.0187\n",
      "Epoch 142/180\n",
      "65/65 [==============================] - 17s 265ms/step - loss: 8.6732e-04 - mse: 8.6732e-04 - mae: 0.0170 - val_loss: 9.4161e-04 - val_mse: 9.4161e-04 - val_mae: 0.0183\n",
      "Epoch 143/180\n",
      "65/65 [==============================] - 17s 268ms/step - loss: 8.6300e-04 - mse: 8.6300e-04 - mae: 0.0170 - val_loss: 9.4873e-04 - val_mse: 9.4873e-04 - val_mae: 0.0175\n",
      "Epoch 144/180\n",
      "65/65 [==============================] - 17s 266ms/step - loss: 8.7722e-04 - mse: 8.7722e-04 - mae: 0.0171 - val_loss: 9.5530e-04 - val_mse: 9.5530e-04 - val_mae: 0.0194\n",
      "Epoch 145/180\n",
      "65/65 [==============================] - 17s 258ms/step - loss: 8.7069e-04 - mse: 8.7069e-04 - mae: 0.0170 - val_loss: 9.4458e-04 - val_mse: 9.4458e-04 - val_mae: 0.0182\n",
      "Epoch 146/180\n",
      "65/65 [==============================] - 17s 263ms/step - loss: 8.6045e-04 - mse: 8.6045e-04 - mae: 0.0169 - val_loss: 9.2981e-04 - val_mse: 9.2981e-04 - val_mae: 0.0180\n",
      "Epoch 147/180\n",
      "65/65 [==============================] - 17s 261ms/step - loss: 8.6059e-04 - mse: 8.6059e-04 - mae: 0.0169 - val_loss: 9.4714e-04 - val_mse: 9.4714e-04 - val_mae: 0.0187\n",
      "Epoch 148/180\n",
      "65/65 [==============================] - 17s 260ms/step - loss: 8.5692e-04 - mse: 8.5692e-04 - mae: 0.0168 - val_loss: 9.4103e-04 - val_mse: 9.4103e-04 - val_mae: 0.0176\n",
      "Epoch 149/180\n",
      "65/65 [==============================] - 18s 284ms/step - loss: 8.6629e-04 - mse: 8.6629e-04 - mae: 0.0170 - val_loss: 9.4967e-04 - val_mse: 9.4967e-04 - val_mae: 0.0181\n",
      "Epoch 150/180\n",
      "65/65 [==============================] - 17s 265ms/step - loss: 8.5657e-04 - mse: 8.5657e-04 - mae: 0.0168 - val_loss: 9.4042e-04 - val_mse: 9.4042e-04 - val_mae: 0.0178\n",
      "Epoch 151/180\n",
      "65/65 [==============================] - 17s 264ms/step - loss: 8.7475e-04 - mse: 8.7475e-04 - mae: 0.0171 - val_loss: 9.5846e-04 - val_mse: 9.5846e-04 - val_mae: 0.0177\n",
      "Epoch 152/180\n",
      "65/65 [==============================] - 17s 259ms/step - loss: 8.6349e-04 - mse: 8.6349e-04 - mae: 0.0168 - val_loss: 9.5530e-04 - val_mse: 9.5530e-04 - val_mae: 0.0183\n",
      "Epoch 153/180\n",
      "65/65 [==============================] - 17s 263ms/step - loss: 8.6183e-04 - mse: 8.6183e-04 - mae: 0.0169 - val_loss: 9.5495e-04 - val_mse: 9.5495e-04 - val_mae: 0.0185\n",
      "Epoch 154/180\n",
      "65/65 [==============================] - 18s 281ms/step - loss: 8.6528e-04 - mse: 8.6528e-04 - mae: 0.0171 - val_loss: 9.5374e-04 - val_mse: 9.5374e-04 - val_mae: 0.0183\n",
      "Epoch 155/180\n",
      "65/65 [==============================] - 17s 265ms/step - loss: 8.5598e-04 - mse: 8.5598e-04 - mae: 0.0167 - val_loss: 9.3299e-04 - val_mse: 9.3299e-04 - val_mae: 0.0175\n",
      "Epoch 156/180\n",
      "65/65 [==============================] - 17s 265ms/step - loss: 8.4665e-04 - mse: 8.4665e-04 - mae: 0.0167 - val_loss: 9.4383e-04 - val_mse: 9.4383e-04 - val_mae: 0.0175\n",
      "Epoch 157/180\n",
      "65/65 [==============================] - 17s 261ms/step - loss: 8.6207e-04 - mse: 8.6207e-04 - mae: 0.0168 - val_loss: 9.4114e-04 - val_mse: 9.4114e-04 - val_mae: 0.0190\n",
      "Epoch 158/180\n",
      "65/65 [==============================] - 17s 267ms/step - loss: 8.6195e-04 - mse: 8.6195e-04 - mae: 0.0170 - val_loss: 9.6068e-04 - val_mse: 9.6068e-04 - val_mae: 0.0168\n",
      "Epoch 159/180\n",
      "65/65 [==============================] - 17s 266ms/step - loss: 8.5411e-04 - mse: 8.5411e-04 - mae: 0.0167 - val_loss: 9.4862e-04 - val_mse: 9.4862e-04 - val_mae: 0.0177\n",
      "Epoch 160/180\n",
      "65/65 [==============================] - 17s 263ms/step - loss: 8.5047e-04 - mse: 8.5047e-04 - mae: 0.0167 - val_loss: 9.5164e-04 - val_mse: 9.5164e-04 - val_mae: 0.0179\n",
      "Epoch 161/180\n",
      "65/65 [==============================] - 19s 292ms/step - loss: 8.6268e-04 - mse: 8.6268e-04 - mae: 0.0170 - val_loss: 9.3917e-04 - val_mse: 9.3917e-04 - val_mae: 0.0180\n",
      "Epoch 162/180\n",
      "65/65 [==============================] - 18s 273ms/step - loss: 8.4981e-04 - mse: 8.4981e-04 - mae: 0.0167 - val_loss: 9.4345e-04 - val_mse: 9.4345e-04 - val_mae: 0.0167\n",
      "Epoch 163/180\n",
      "65/65 [==============================] - 17s 264ms/step - loss: 8.4984e-04 - mse: 8.4984e-04 - mae: 0.0167 - val_loss: 9.5219e-04 - val_mse: 9.5219e-04 - val_mae: 0.0173\n",
      "Epoch 164/180\n",
      "65/65 [==============================] - 17s 267ms/step - loss: 8.5370e-04 - mse: 8.5370e-04 - mae: 0.0168 - val_loss: 9.4874e-04 - val_mse: 9.4874e-04 - val_mae: 0.0176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165/180\n",
      "65/65 [==============================] - 17s 266ms/step - loss: 8.5982e-04 - mse: 8.5982e-04 - mae: 0.0169 - val_loss: 9.4421e-04 - val_mse: 9.4421e-04 - val_mae: 0.0174\n",
      "Epoch 166/180\n",
      "65/65 [==============================] - 17s 264ms/step - loss: 8.4960e-04 - mse: 8.4960e-04 - mae: 0.0167 - val_loss: 9.4279e-04 - val_mse: 9.4279e-04 - val_mae: 0.0173\n",
      "Epoch 167/180\n",
      "65/65 [==============================] - 19s 289ms/step - loss: 8.4372e-04 - mse: 8.4372e-04 - mae: 0.0166 - val_loss: 9.4805e-04 - val_mse: 9.4805e-04 - val_mae: 0.0170\n",
      "Epoch 168/180\n",
      "65/65 [==============================] - 17s 267ms/step - loss: 8.5213e-04 - mse: 8.5213e-04 - mae: 0.0167 - val_loss: 9.5306e-04 - val_mse: 9.5306e-04 - val_mae: 0.0175\n",
      "Epoch 169/180\n",
      "65/65 [==============================] - 17s 266ms/step - loss: 8.4686e-04 - mse: 8.4686e-04 - mae: 0.0166 - val_loss: 9.4867e-04 - val_mse: 9.4867e-04 - val_mae: 0.0172\n",
      "Epoch 170/180\n",
      "65/65 [==============================] - 18s 273ms/step - loss: 8.4547e-04 - mse: 8.4547e-04 - mae: 0.0167 - val_loss: 9.5382e-04 - val_mse: 9.5382e-04 - val_mae: 0.0171\n",
      "Epoch 171/180\n",
      "65/65 [==============================] - 17s 269ms/step - loss: 8.4967e-04 - mse: 8.4967e-04 - mae: 0.0167 - val_loss: 9.5312e-04 - val_mse: 9.5312e-04 - val_mae: 0.0170\n",
      "Epoch 172/180\n",
      "65/65 [==============================] - 17s 267ms/step - loss: 8.4951e-04 - mse: 8.4951e-04 - mae: 0.0166 - val_loss: 9.6047e-04 - val_mse: 9.6047e-04 - val_mae: 0.0167\n",
      "Epoch 173/180\n",
      "65/65 [==============================] - 17s 264ms/step - loss: 8.4399e-04 - mse: 8.4399e-04 - mae: 0.0166 - val_loss: 9.6282e-04 - val_mse: 9.6282e-04 - val_mae: 0.0171\n",
      "Epoch 174/180\n",
      "65/65 [==============================] - 17s 264ms/step - loss: 8.4516e-04 - mse: 8.4516e-04 - mae: 0.0166 - val_loss: 9.7453e-04 - val_mse: 9.7453e-04 - val_mae: 0.0164\n",
      "Epoch 175/180\n",
      "65/65 [==============================] - 17s 265ms/step - loss: 8.3855e-04 - mse: 8.3855e-04 - mae: 0.0166 - val_loss: 9.6886e-04 - val_mse: 9.6886e-04 - val_mae: 0.0165\n",
      "Epoch 176/180\n",
      "65/65 [==============================] - 17s 264ms/step - loss: 8.4981e-04 - mse: 8.4981e-04 - mae: 0.0165 - val_loss: 9.6139e-04 - val_mse: 9.6139e-04 - val_mae: 0.0181\n",
      "Epoch 177/180\n",
      "65/65 [==============================] - 17s 261ms/step - loss: 8.4632e-04 - mse: 8.4632e-04 - mae: 0.0167 - val_loss: 9.7735e-04 - val_mse: 9.7735e-04 - val_mae: 0.0166\n",
      "Epoch 178/180\n",
      "65/65 [==============================] - 17s 264ms/step - loss: 8.3872e-04 - mse: 8.3872e-04 - mae: 0.0165 - val_loss: 9.6708e-04 - val_mse: 9.6708e-04 - val_mae: 0.0170\n",
      "Epoch 179/180\n",
      "65/65 [==============================] - 17s 264ms/step - loss: 8.4688e-04 - mse: 8.4688e-04 - mae: 0.0166 - val_loss: 9.7723e-04 - val_mse: 9.7723e-04 - val_mae: 0.0172\n",
      "Epoch 180/180\n",
      "65/65 [==============================] - 18s 280ms/step - loss: 8.4966e-04 - mse: 8.4966e-04 - mae: 0.0167 - val_loss: 9.6539e-04 - val_mse: 9.6539e-04 - val_mae: 0.0172\n",
      "Epoch 1/180\n",
      "65/65 [==============================] - 45s 698ms/step - loss: 0.2306 - mse: 0.2306 - mae: 0.3765 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0265\n",
      "Epoch 2/180\n",
      "65/65 [==============================] - 44s 680ms/step - loss: 0.1492 - mse: 0.1492 - mae: 0.3087 - val_loss: 0.0021 - val_mse: 0.0021 - val_mae: 0.0346\n",
      "Epoch 3/180\n",
      "65/65 [==============================] - 45s 693ms/step - loss: 0.1135 - mse: 0.1135 - mae: 0.2688 - val_loss: 0.0015 - val_mse: 0.0015 - val_mae: 0.0276\n",
      "Epoch 4/180\n",
      "65/65 [==============================] - 47s 717ms/step - loss: 0.0813 - mse: 0.0813 - mae: 0.2271 - val_loss: 0.0019 - val_mse: 0.0019 - val_mae: 0.0343\n",
      "Epoch 5/180\n",
      "65/65 [==============================] - 51s 785ms/step - loss: 0.0643 - mse: 0.0643 - mae: 0.2014 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0223\n",
      "Epoch 6/180\n",
      "65/65 [==============================] - 58s 888ms/step - loss: 0.0464 - mse: 0.0464 - mae: 0.1719 - val_loss: 0.0017 - val_mse: 0.0017 - val_mae: 0.0341\n",
      "Epoch 7/180\n",
      "65/65 [==============================] - 55s 850ms/step - loss: 0.0348 - mse: 0.0348 - mae: 0.1476 - val_loss: 0.0020 - val_mse: 0.0020 - val_mae: 0.0396\n",
      "Epoch 8/180\n",
      "65/65 [==============================] - 52s 795ms/step - loss: 0.0277 - mse: 0.0277 - mae: 0.1318 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0269\n",
      "Epoch 9/180\n",
      "65/65 [==============================] - 54s 829ms/step - loss: 0.0221 - mse: 0.0221 - mae: 0.1176 - val_loss: 0.0017 - val_mse: 0.0017 - val_mae: 0.0352\n",
      "Epoch 10/180\n",
      "65/65 [==============================] - 60s 917ms/step - loss: 0.0184 - mse: 0.0184 - mae: 0.1085 - val_loss: 9.6022e-04 - val_mse: 9.6022e-04 - val_mae: 0.0177\n",
      "Epoch 11/180\n",
      "65/65 [==============================] - 55s 844ms/step - loss: 0.0152 - mse: 0.0152 - mae: 0.0971 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0218\n",
      "Epoch 12/180\n",
      "65/65 [==============================] - 52s 806ms/step - loss: 0.0129 - mse: 0.0129 - mae: 0.0899 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0280\n",
      "Epoch 13/180\n",
      "65/65 [==============================] - 53s 815ms/step - loss: 0.0111 - mse: 0.0111 - mae: 0.0830 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0241\n",
      "Epoch 14/180\n",
      "65/65 [==============================] - 52s 805ms/step - loss: 0.0100 - mse: 0.0100 - mae: 0.0781 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0267\n",
      "Epoch 15/180\n",
      "65/65 [==============================] - 53s 819ms/step - loss: 0.0085 - mse: 0.0085 - mae: 0.0723 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0275\n",
      "Epoch 16/180\n",
      "65/65 [==============================] - 52s 795ms/step - loss: 0.0077 - mse: 0.0077 - mae: 0.0686 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0193\n",
      "Epoch 17/180\n",
      "65/65 [==============================] - 55s 852ms/step - loss: 0.0069 - mse: 0.0069 - mae: 0.0648 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0192\n",
      "Epoch 18/180\n",
      "65/65 [==============================] - 53s 817ms/step - loss: 0.0064 - mse: 0.0064 - mae: 0.0625 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0230\n",
      "Epoch 19/180\n",
      "65/65 [==============================] - 51s 790ms/step - loss: 0.0058 - mse: 0.0058 - mae: 0.0591 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0213\n",
      "Epoch 20/180\n",
      "65/65 [==============================] - 54s 824ms/step - loss: 0.0052 - mse: 0.0052 - mae: 0.0555 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0220\n",
      "Epoch 21/180\n",
      "65/65 [==============================] - 56s 863ms/step - loss: 0.0047 - mse: 0.0047 - mae: 0.0528 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0228\n",
      "Epoch 22/180\n",
      "65/65 [==============================] - 53s 819ms/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0503 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0189\n",
      "Epoch 23/180\n",
      "65/65 [==============================] - 55s 845ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0479 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0202\n",
      "Epoch 24/180\n",
      "65/65 [==============================] - 57s 878ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0459 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0197\n",
      "Epoch 25/180\n",
      "65/65 [==============================] - 53s 823ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0439 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0226\n",
      "Epoch 26/180\n",
      "65/65 [==============================] - 53s 823ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0416 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0217\n",
      "Epoch 27/180\n",
      "65/65 [==============================] - 53s 812ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0402 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0227\n",
      "Epoch 28/180\n",
      "65/65 [==============================] - 57s 872ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0384 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0205\n",
      "Epoch 29/180\n",
      "65/65 [==============================] - 49s 760ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0367 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0211\n",
      "Epoch 30/180\n",
      "65/65 [==============================] - 56s 857ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0354 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0215\n",
      "Epoch 31/180\n",
      "65/65 [==============================] - 54s 828ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0334 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0250\n",
      "Epoch 32/180\n",
      "65/65 [==============================] - 53s 819ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0331 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0187\n",
      "Epoch 33/180\n",
      "65/65 [==============================] - 53s 816ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0321 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0208\n",
      "Epoch 34/180\n",
      "65/65 [==============================] - 52s 800ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0308 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0206\n",
      "Epoch 35/180\n",
      "65/65 [==============================] - 52s 795ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0302 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0221\n",
      "Epoch 36/180\n",
      "65/65 [==============================] - 52s 807ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0295 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0219\n",
      "Epoch 37/180\n",
      "65/65 [==============================] - 59s 910ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0287 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0193\n",
      "Epoch 38/180\n",
      "65/65 [==============================] - 59s 914ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0277 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0217\n",
      "Epoch 39/180\n",
      "65/65 [==============================] - 63s 972ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0269 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0199\n",
      "Epoch 40/180\n",
      "65/65 [==============================] - 60s 926ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0263 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0200\n",
      "Epoch 41/180\n",
      "65/65 [==============================] - 55s 846ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0256 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0211\n",
      "Epoch 42/180\n",
      "65/65 [==============================] - 53s 808ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0254 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0201\n",
      "Epoch 43/180\n",
      "65/65 [==============================] - 53s 811ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0246 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0211\n",
      "Epoch 44/180\n",
      "65/65 [==============================] - 52s 803ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0244 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0210\n",
      "Epoch 45/180\n",
      "65/65 [==============================] - 52s 805ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0235 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0211\n",
      "Epoch 46/180\n",
      "65/65 [==============================] - 52s 800ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0234 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0212\n",
      "Epoch 47/180\n",
      "65/65 [==============================] - 55s 848ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0229 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0205\n",
      "Epoch 48/180\n",
      "65/65 [==============================] - 54s 832ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0230 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0200\n",
      "Epoch 49/180\n",
      "65/65 [==============================] - 51s 784ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0226 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0197\n",
      "Epoch 50/180\n",
      "65/65 [==============================] - 53s 813ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0222 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0194\n",
      "Epoch 51/180\n",
      "65/65 [==============================] - 53s 814ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0218 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0203\n",
      "Epoch 52/180\n",
      "65/65 [==============================] - 53s 821ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0215 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0193\n",
      "Epoch 53/180\n",
      "65/65 [==============================] - 53s 813ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0211 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0213\n",
      "Epoch 54/180\n",
      "65/65 [==============================] - 54s 837ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0212 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0208\n",
      "Epoch 55/180\n",
      "65/65 [==============================] - 54s 832ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0208 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0212\n",
      "Epoch 56/180\n",
      "65/65 [==============================] - 52s 804ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0206 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0208\n",
      "Epoch 57/180\n",
      "65/65 [==============================] - 52s 804ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0205 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0213\n",
      "Epoch 58/180\n",
      "65/65 [==============================] - 54s 827ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0206 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0211\n",
      "Epoch 59/180\n",
      "65/65 [==============================] - 54s 833ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0204 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0217\n",
      "Epoch 60/180\n",
      "65/65 [==============================] - 55s 843ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0201 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0205\n",
      "Epoch 61/180\n",
      "65/65 [==============================] - 53s 823ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0199 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0206\n",
      "Epoch 62/180\n",
      "65/65 [==============================] - 53s 821ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0196 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0201\n",
      "Epoch 63/180\n",
      "65/65 [==============================] - 53s 817ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0196 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0204\n",
      "Epoch 64/180\n",
      "65/65 [==============================] - 55s 844ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0196 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0200\n",
      "Epoch 65/180\n",
      "65/65 [==============================] - 52s 795ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0195 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0204\n",
      "Epoch 66/180\n",
      "65/65 [==============================] - 52s 793ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0193 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0197\n",
      "Epoch 67/180\n",
      "65/65 [==============================] - 50s 770ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0192 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0203\n",
      "Epoch 68/180\n",
      "65/65 [==============================] - 51s 784ms/step - loss: 9.8755e-04 - mse: 9.8755e-04 - mae: 0.0189 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0202\n",
      "Epoch 69/180\n",
      "65/65 [==============================] - 51s 790ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0192 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0199\n",
      "Epoch 70/180\n",
      "65/65 [==============================] - 50s 770ms/step - loss: 9.9927e-04 - mse: 9.9927e-04 - mae: 0.0191 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0199\n",
      "Epoch 71/180\n",
      "65/65 [==============================] - 49s 748ms/step - loss: 9.9645e-04 - mse: 9.9645e-04 - mae: 0.0191 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0201\n",
      "Epoch 72/180\n",
      "65/65 [==============================] - 54s 837ms/step - loss: 9.9578e-04 - mse: 9.9578e-04 - mae: 0.0190 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0203\n",
      "Epoch 73/180\n",
      "65/65 [==============================] - 51s 780ms/step - loss: 9.9069e-04 - mse: 9.9069e-04 - mae: 0.0189 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0202\n",
      "Epoch 74/180\n",
      "65/65 [==============================] - 48s 735ms/step - loss: 9.8858e-04 - mse: 9.8858e-04 - mae: 0.0188 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0205\n",
      "Epoch 75/180\n",
      "65/65 [==============================] - 52s 798ms/step - loss: 9.7557e-04 - mse: 9.7557e-04 - mae: 0.0184 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0198\n",
      "Epoch 76/180\n",
      "65/65 [==============================] - 50s 776ms/step - loss: 9.8584e-04 - mse: 9.8584e-04 - mae: 0.0187 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0203\n",
      "Epoch 77/180\n",
      "65/65 [==============================] - 49s 756ms/step - loss: 9.7823e-04 - mse: 9.7823e-04 - mae: 0.0187 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0195\n",
      "Epoch 78/180\n",
      "65/65 [==============================] - 47s 729ms/step - loss: 9.7936e-04 - mse: 9.7936e-04 - mae: 0.0186 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0196\n",
      "Epoch 79/180\n",
      "65/65 [==============================] - 48s 739ms/step - loss: 9.6448e-04 - mse: 9.6448e-04 - mae: 0.0184 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0194\n",
      "Epoch 80/180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 46s 713ms/step - loss: 9.7350e-04 - mse: 9.7350e-04 - mae: 0.0184 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0193\n",
      "Epoch 81/180\n",
      "65/65 [==============================] - 49s 751ms/step - loss: 9.6425e-04 - mse: 9.6425e-04 - mae: 0.0184 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0190\n",
      "Epoch 82/180\n",
      "65/65 [==============================] - 48s 740ms/step - loss: 9.6126e-04 - mse: 9.6126e-04 - mae: 0.0184 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0191\n",
      "Epoch 83/180\n",
      "65/65 [==============================] - 45s 696ms/step - loss: 9.6493e-04 - mse: 9.6493e-04 - mae: 0.0184 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0192\n",
      "Epoch 84/180\n",
      "65/65 [==============================] - 45s 687ms/step - loss: 9.6273e-04 - mse: 9.6273e-04 - mae: 0.0184 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0190\n",
      "Epoch 85/180\n",
      "65/65 [==============================] - 42s 641ms/step - loss: 9.5646e-04 - mse: 9.5646e-04 - mae: 0.0182 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0194\n",
      "Epoch 86/180\n",
      "65/65 [==============================] - 41s 634ms/step - loss: 9.4898e-04 - mse: 9.4898e-04 - mae: 0.0182 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0191\n",
      "Epoch 87/180\n",
      "65/65 [==============================] - 41s 638ms/step - loss: 9.6134e-04 - mse: 9.6134e-04 - mae: 0.0183 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0189\n",
      "Epoch 88/180\n",
      "65/65 [==============================] - 42s 653ms/step - loss: 9.4659e-04 - mse: 9.4659e-04 - mae: 0.0182 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0191\n",
      "Epoch 89/180\n",
      "65/65 [==============================] - 43s 655ms/step - loss: 9.4907e-04 - mse: 9.4907e-04 - mae: 0.0182 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0193\n",
      "Epoch 90/180\n",
      "65/65 [==============================] - 43s 657ms/step - loss: 9.4721e-04 - mse: 9.4721e-04 - mae: 0.0182 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0190\n",
      "Epoch 91/180\n",
      "65/65 [==============================] - 51s 780ms/step - loss: 9.4457e-04 - mse: 9.4457e-04 - mae: 0.0181 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0191\n",
      "Epoch 92/180\n",
      "65/65 [==============================] - 42s 648ms/step - loss: 9.4040e-04 - mse: 9.4040e-04 - mae: 0.0181 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0191\n",
      "Epoch 93/180\n",
      "65/65 [==============================] - 41s 627ms/step - loss: 9.4889e-04 - mse: 9.4889e-04 - mae: 0.0181 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0192\n",
      "Epoch 94/180\n",
      "65/65 [==============================] - 41s 626ms/step - loss: 9.3855e-04 - mse: 9.3855e-04 - mae: 0.0181 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0189\n",
      "Epoch 95/180\n",
      "65/65 [==============================] - 41s 632ms/step - loss: 9.4389e-04 - mse: 9.4389e-04 - mae: 0.0181 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0191\n",
      "Epoch 96/180\n",
      "65/65 [==============================] - 41s 635ms/step - loss: 9.3716e-04 - mse: 9.3716e-04 - mae: 0.0181 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0188\n",
      "Epoch 97/180\n",
      "65/65 [==============================] - 41s 629ms/step - loss: 9.3801e-04 - mse: 9.3801e-04 - mae: 0.0180 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0190\n",
      "Epoch 98/180\n",
      "65/65 [==============================] - 43s 667ms/step - loss: 9.4070e-04 - mse: 9.4070e-04 - mae: 0.0181 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0193\n",
      "Epoch 99/180\n",
      "65/65 [==============================] - 41s 636ms/step - loss: 9.3991e-04 - mse: 9.3991e-04 - mae: 0.0180 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0188\n",
      "Epoch 100/180\n",
      "65/65 [==============================] - 41s 625ms/step - loss: 9.3954e-04 - mse: 9.3954e-04 - mae: 0.0180 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0192\n",
      "Epoch 101/180\n",
      "65/65 [==============================] - 41s 628ms/step - loss: 9.4330e-04 - mse: 9.4330e-04 - mae: 0.0181 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0185\n",
      "Epoch 102/180\n",
      "65/65 [==============================] - 41s 636ms/step - loss: 9.3540e-04 - mse: 9.3540e-04 - mae: 0.0180 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0188\n",
      "Epoch 103/180\n",
      "65/65 [==============================] - 42s 643ms/step - loss: 9.3169e-04 - mse: 9.3169e-04 - mae: 0.0179 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0186\n",
      "Epoch 104/180\n",
      "65/65 [==============================] - 42s 650ms/step - loss: 9.3867e-04 - mse: 9.3867e-04 - mae: 0.0180 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0187\n",
      "Epoch 105/180\n",
      "65/65 [==============================] - 41s 632ms/step - loss: 9.3303e-04 - mse: 9.3303e-04 - mae: 0.0180 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0186\n",
      "Epoch 106/180\n",
      "65/65 [==============================] - 41s 634ms/step - loss: 9.3468e-04 - mse: 9.3468e-04 - mae: 0.0179 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0182\n",
      "Epoch 107/180\n",
      "65/65 [==============================] - 41s 630ms/step - loss: 9.3467e-04 - mse: 9.3467e-04 - mae: 0.0179 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0182\n",
      "Epoch 108/180\n",
      "65/65 [==============================] - 41s 632ms/step - loss: 9.2473e-04 - mse: 9.2473e-04 - mae: 0.0179 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0187\n",
      "Epoch 109/180\n",
      "65/65 [==============================] - 42s 652ms/step - loss: 9.2205e-04 - mse: 9.2205e-04 - mae: 0.0178 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0182\n",
      "Epoch 110/180\n",
      "65/65 [==============================] - 42s 645ms/step - loss: 9.2024e-04 - mse: 9.2024e-04 - mae: 0.0177 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0183\n",
      "Epoch 111/180\n",
      "65/65 [==============================] - 41s 637ms/step - loss: 9.2743e-04 - mse: 9.2743e-04 - mae: 0.0178 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0182\n",
      "Epoch 112/180\n",
      "65/65 [==============================] - 46s 707ms/step - loss: 9.1234e-04 - mse: 9.1234e-04 - mae: 0.0177 - val_loss: 9.9049e-04 - val_mse: 9.9049e-04 - val_mae: 0.0180\n",
      "Epoch 113/180\n",
      "65/65 [==============================] - 41s 636ms/step - loss: 9.1265e-04 - mse: 9.1265e-04 - mae: 0.0177 - val_loss: 9.8594e-04 - val_mse: 9.8594e-04 - val_mae: 0.0181\n",
      "Epoch 114/180\n",
      "65/65 [==============================] - 44s 684ms/step - loss: 9.1610e-04 - mse: 9.1610e-04 - mae: 0.0178 - val_loss: 9.9597e-04 - val_mse: 9.9597e-04 - val_mae: 0.0184\n",
      "Epoch 115/180\n",
      "65/65 [==============================] - 41s 633ms/step - loss: 9.0943e-04 - mse: 9.0943e-04 - mae: 0.0176 - val_loss: 9.8235e-04 - val_mse: 9.8235e-04 - val_mae: 0.0181\n",
      "Epoch 116/180\n",
      "65/65 [==============================] - 42s 641ms/step - loss: 9.0636e-04 - mse: 9.0636e-04 - mae: 0.0176 - val_loss: 9.8430e-04 - val_mse: 9.8430e-04 - val_mae: 0.0183\n",
      "Epoch 117/180\n",
      "65/65 [==============================] - 44s 674ms/step - loss: 9.1439e-04 - mse: 9.1439e-04 - mae: 0.0176 - val_loss: 9.9475e-04 - val_mse: 9.9475e-04 - val_mae: 0.0184\n",
      "Epoch 118/180\n",
      "65/65 [==============================] - 42s 641ms/step - loss: 9.1004e-04 - mse: 9.1004e-04 - mae: 0.0176 - val_loss: 9.7331e-04 - val_mse: 9.7331e-04 - val_mae: 0.0179\n",
      "Epoch 119/180\n",
      "65/65 [==============================] - 42s 647ms/step - loss: 9.0128e-04 - mse: 9.0128e-04 - mae: 0.0175 - val_loss: 9.7088e-04 - val_mse: 9.7088e-04 - val_mae: 0.0183\n",
      "Epoch 120/180\n",
      "65/65 [==============================] - 42s 648ms/step - loss: 9.0227e-04 - mse: 9.0227e-04 - mae: 0.0175 - val_loss: 9.6192e-04 - val_mse: 9.6192e-04 - val_mae: 0.0188\n",
      "Epoch 121/180\n",
      "65/65 [==============================] - 41s 634ms/step - loss: 8.9776e-04 - mse: 8.9776e-04 - mae: 0.0175 - val_loss: 9.3199e-04 - val_mse: 9.3199e-04 - val_mae: 0.0184\n",
      "Epoch 122/180\n",
      "65/65 [==============================] - 41s 630ms/step - loss: 8.9467e-04 - mse: 8.9467e-04 - mae: 0.0174 - val_loss: 9.4292e-04 - val_mse: 9.4292e-04 - val_mae: 0.0192\n",
      "Epoch 123/180\n",
      "65/65 [==============================] - 42s 639ms/step - loss: 8.9192e-04 - mse: 8.9192e-04 - mae: 0.0173 - val_loss: 9.2163e-04 - val_mse: 9.2163e-04 - val_mae: 0.0191\n",
      "Epoch 124/180\n",
      "65/65 [==============================] - 41s 638ms/step - loss: 9.0160e-04 - mse: 9.0160e-04 - mae: 0.0175 - val_loss: 8.9026e-04 - val_mse: 8.9026e-04 - val_mae: 0.0182\n",
      "Epoch 125/180\n",
      "65/65 [==============================] - 42s 652ms/step - loss: 8.8583e-04 - mse: 8.8583e-04 - mae: 0.0173 - val_loss: 8.9301e-04 - val_mse: 8.9301e-04 - val_mae: 0.0186\n",
      "Epoch 126/180\n",
      "65/65 [==============================] - 43s 667ms/step - loss: 8.9112e-04 - mse: 8.9112e-04 - mae: 0.0172 - val_loss: 9.1533e-04 - val_mse: 9.1533e-04 - val_mae: 0.0188\n",
      "Epoch 127/180\n",
      "65/65 [==============================] - 41s 631ms/step - loss: 8.8846e-04 - mse: 8.8846e-04 - mae: 0.0172 - val_loss: 9.1423e-04 - val_mse: 9.1423e-04 - val_mae: 0.0187\n",
      "Epoch 128/180\n",
      "65/65 [==============================] - 41s 629ms/step - loss: 8.8636e-04 - mse: 8.8636e-04 - mae: 0.0172 - val_loss: 9.1954e-04 - val_mse: 9.1954e-04 - val_mae: 0.0192\n",
      "Epoch 129/180\n",
      "65/65 [==============================] - 41s 632ms/step - loss: 8.8577e-04 - mse: 8.8577e-04 - mae: 0.0173 - val_loss: 9.4829e-04 - val_mse: 9.4829e-04 - val_mae: 0.0190\n",
      "Epoch 130/180\n",
      "65/65 [==============================] - 42s 648ms/step - loss: 8.8054e-04 - mse: 8.8054e-04 - mae: 0.0171 - val_loss: 9.4103e-04 - val_mse: 9.4103e-04 - val_mae: 0.0181\n",
      "Epoch 131/180\n",
      "65/65 [==============================] - 42s 639ms/step - loss: 8.7528e-04 - mse: 8.7528e-04 - mae: 0.0170 - val_loss: 9.8138e-04 - val_mse: 9.8138e-04 - val_mae: 0.0200\n",
      "Epoch 132/180\n",
      "65/65 [==============================] - 42s 640ms/step - loss: 8.7566e-04 - mse: 8.7566e-04 - mae: 0.0170 - val_loss: 9.5260e-04 - val_mse: 9.5260e-04 - val_mae: 0.0194\n",
      "Epoch 133/180\n",
      "65/65 [==============================] - 41s 638ms/step - loss: 8.6873e-04 - mse: 8.6873e-04 - mae: 0.0169 - val_loss: 9.8006e-04 - val_mse: 9.8006e-04 - val_mae: 0.0196\n",
      "Epoch 134/180\n",
      "65/65 [==============================] - 42s 643ms/step - loss: 8.6791e-04 - mse: 8.6791e-04 - mae: 0.0170 - val_loss: 9.6538e-04 - val_mse: 9.6538e-04 - val_mae: 0.0194\n",
      "Epoch 135/180\n",
      "65/65 [==============================] - 41s 633ms/step - loss: 8.7803e-04 - mse: 8.7803e-04 - mae: 0.0171 - val_loss: 9.4871e-04 - val_mse: 9.4871e-04 - val_mae: 0.0197\n",
      "Epoch 136/180\n",
      "65/65 [==============================] - 43s 657ms/step - loss: 8.7179e-04 - mse: 8.7179e-04 - mae: 0.0170 - val_loss: 9.3180e-04 - val_mse: 9.3180e-04 - val_mae: 0.0188\n",
      "Epoch 137/180\n",
      "65/65 [==============================] - 42s 639ms/step - loss: 8.6787e-04 - mse: 8.6787e-04 - mae: 0.0170 - val_loss: 9.4203e-04 - val_mse: 9.4203e-04 - val_mae: 0.0198\n",
      "Epoch 138/180\n",
      "65/65 [==============================] - 42s 642ms/step - loss: 8.7003e-04 - mse: 8.7003e-04 - mae: 0.0170 - val_loss: 9.3206e-04 - val_mse: 9.3206e-04 - val_mae: 0.0189\n",
      "Epoch 139/180\n",
      "65/65 [==============================] - 41s 636ms/step - loss: 8.6327e-04 - mse: 8.6327e-04 - mae: 0.0169 - val_loss: 9.5252e-04 - val_mse: 9.5252e-04 - val_mae: 0.0193\n",
      "Epoch 140/180\n",
      "65/65 [==============================] - 43s 668ms/step - loss: 8.6602e-04 - mse: 8.6602e-04 - mae: 0.0169 - val_loss: 9.6773e-04 - val_mse: 9.6773e-04 - val_mae: 0.0195\n",
      "Epoch 141/180\n",
      "65/65 [==============================] - 42s 648ms/step - loss: 8.5054e-04 - mse: 8.5054e-04 - mae: 0.0167 - val_loss: 9.6723e-04 - val_mse: 9.6723e-04 - val_mae: 0.0193\n",
      "Epoch 142/180\n",
      "65/65 [==============================] - 41s 633ms/step - loss: 8.7126e-04 - mse: 8.7126e-04 - mae: 0.0168 - val_loss: 9.4049e-04 - val_mse: 9.4049e-04 - val_mae: 0.0185\n",
      "Epoch 143/180\n",
      "65/65 [==============================] - 41s 632ms/step - loss: 8.5853e-04 - mse: 8.5853e-04 - mae: 0.0168 - val_loss: 9.6171e-04 - val_mse: 9.6171e-04 - val_mae: 0.0185\n",
      "Epoch 144/180\n",
      "65/65 [==============================] - 41s 637ms/step - loss: 8.5481e-04 - mse: 8.5481e-04 - mae: 0.0167 - val_loss: 9.6930e-04 - val_mse: 9.6930e-04 - val_mae: 0.0191\n",
      "Epoch 145/180\n",
      "65/65 [==============================] - 45s 687ms/step - loss: 8.4035e-04 - mse: 8.4035e-04 - mae: 0.0166 - val_loss: 9.7286e-04 - val_mse: 9.7286e-04 - val_mae: 0.0191\n",
      "Epoch 146/180\n",
      "65/65 [==============================] - 42s 639ms/step - loss: 8.5122e-04 - mse: 8.5122e-04 - mae: 0.0167 - val_loss: 9.7860e-04 - val_mse: 9.7860e-04 - val_mae: 0.0189\n",
      "Epoch 147/180\n",
      "65/65 [==============================] - 41s 631ms/step - loss: 8.6266e-04 - mse: 8.6266e-04 - mae: 0.0168 - val_loss: 9.3679e-04 - val_mse: 9.3679e-04 - val_mae: 0.0187\n",
      "Epoch 148/180\n",
      "65/65 [==============================] - 41s 631ms/step - loss: 8.5913e-04 - mse: 8.5913e-04 - mae: 0.0167 - val_loss: 9.3219e-04 - val_mse: 9.3219e-04 - val_mae: 0.0184\n",
      "Epoch 149/180\n",
      "65/65 [==============================] - 43s 657ms/step - loss: 8.4657e-04 - mse: 8.4657e-04 - mae: 0.0166 - val_loss: 9.5735e-04 - val_mse: 9.5735e-04 - val_mae: 0.0188\n",
      "Epoch 150/180\n",
      "65/65 [==============================] - 41s 631ms/step - loss: 8.4436e-04 - mse: 8.4436e-04 - mae: 0.0166 - val_loss: 9.6904e-04 - val_mse: 9.6904e-04 - val_mae: 0.0185\n",
      "Epoch 151/180\n",
      "65/65 [==============================] - 41s 631ms/step - loss: 8.5521e-04 - mse: 8.5521e-04 - mae: 0.0168 - val_loss: 9.4137e-04 - val_mse: 9.4137e-04 - val_mae: 0.0191\n",
      "Epoch 152/180\n",
      "65/65 [==============================] - 43s 660ms/step - loss: 8.4675e-04 - mse: 8.4675e-04 - mae: 0.0166 - val_loss: 9.4502e-04 - val_mse: 9.4502e-04 - val_mae: 0.0189\n",
      "Epoch 153/180\n",
      "65/65 [==============================] - 41s 637ms/step - loss: 8.4618e-04 - mse: 8.4618e-04 - mae: 0.0167 - val_loss: 9.6706e-04 - val_mse: 9.6706e-04 - val_mae: 0.0197\n",
      "Epoch 154/180\n",
      "65/65 [==============================] - 43s 668ms/step - loss: 8.3898e-04 - mse: 8.3898e-04 - mae: 0.0165 - val_loss: 9.4015e-04 - val_mse: 9.4015e-04 - val_mae: 0.0189\n",
      "Epoch 155/180\n",
      "65/65 [==============================] - 42s 653ms/step - loss: 8.5365e-04 - mse: 8.5365e-04 - mae: 0.0166 - val_loss: 9.2969e-04 - val_mse: 9.2969e-04 - val_mae: 0.0182\n",
      "Epoch 156/180\n",
      "65/65 [==============================] - 44s 677ms/step - loss: 8.4223e-04 - mse: 8.4223e-04 - mae: 0.0165 - val_loss: 9.5689e-04 - val_mse: 9.5689e-04 - val_mae: 0.0188\n",
      "Epoch 157/180\n",
      "65/65 [==============================] - 42s 642ms/step - loss: 8.4237e-04 - mse: 8.4237e-04 - mae: 0.0164 - val_loss: 9.4101e-04 - val_mse: 9.4101e-04 - val_mae: 0.0189\n",
      "Epoch 158/180\n",
      "65/65 [==============================] - 42s 646ms/step - loss: 8.4446e-04 - mse: 8.4446e-04 - mae: 0.0165 - val_loss: 9.3229e-04 - val_mse: 9.3229e-04 - val_mae: 0.0185\n",
      "Epoch 159/180\n",
      "65/65 [==============================] - 41s 629ms/step - loss: 8.4900e-04 - mse: 8.4900e-04 - mae: 0.0166 - val_loss: 9.2707e-04 - val_mse: 9.2707e-04 - val_mae: 0.0186\n",
      "Epoch 160/180\n",
      "65/65 [==============================] - 41s 628ms/step - loss: 8.3916e-04 - mse: 8.3916e-04 - mae: 0.0165 - val_loss: 9.2740e-04 - val_mse: 9.2740e-04 - val_mae: 0.0185\n",
      "Epoch 161/180\n",
      "65/65 [==============================] - 41s 626ms/step - loss: 8.3434e-04 - mse: 8.3434e-04 - mae: 0.0164 - val_loss: 9.3466e-04 - val_mse: 9.3466e-04 - val_mae: 0.0189\n",
      "Epoch 162/180\n",
      "65/65 [==============================] - 41s 627ms/step - loss: 8.3142e-04 - mse: 8.3142e-04 - mae: 0.0164 - val_loss: 9.2542e-04 - val_mse: 9.2542e-04 - val_mae: 0.0183\n",
      "Epoch 163/180\n",
      "65/65 [==============================] - 42s 644ms/step - loss: 8.4074e-04 - mse: 8.4074e-04 - mae: 0.0166 - val_loss: 9.5430e-04 - val_mse: 9.5430e-04 - val_mae: 0.0194\n",
      "Epoch 164/180\n",
      "65/65 [==============================] - 41s 630ms/step - loss: 8.3699e-04 - mse: 8.3699e-04 - mae: 0.0164 - val_loss: 9.3167e-04 - val_mse: 9.3167e-04 - val_mae: 0.0190\n",
      "Epoch 165/180\n",
      "65/65 [==============================] - 41s 623ms/step - loss: 8.3126e-04 - mse: 8.3126e-04 - mae: 0.0163 - val_loss: 9.3373e-04 - val_mse: 9.3373e-04 - val_mae: 0.0186\n",
      "Epoch 166/180\n",
      "65/65 [==============================] - 41s 633ms/step - loss: 8.4016e-04 - mse: 8.4016e-04 - mae: 0.0165 - val_loss: 9.2618e-04 - val_mse: 9.2618e-04 - val_mae: 0.0178\n",
      "Epoch 167/180\n",
      "65/65 [==============================] - 41s 629ms/step - loss: 8.3349e-04 - mse: 8.3349e-04 - mae: 0.0163 - val_loss: 9.1230e-04 - val_mse: 9.1230e-04 - val_mae: 0.0185\n",
      "Epoch 168/180\n",
      "65/65 [==============================] - 42s 646ms/step - loss: 8.3301e-04 - mse: 8.3301e-04 - mae: 0.0163 - val_loss: 9.0731e-04 - val_mse: 9.0731e-04 - val_mae: 0.0181\n",
      "Epoch 169/180\n",
      "65/65 [==============================] - 42s 651ms/step - loss: 8.4099e-04 - mse: 8.4099e-04 - mae: 0.0164 - val_loss: 9.1403e-04 - val_mse: 9.1403e-04 - val_mae: 0.0186\n",
      "Epoch 170/180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 41s 627ms/step - loss: 8.2193e-04 - mse: 8.2193e-04 - mae: 0.0162 - val_loss: 9.1555e-04 - val_mse: 9.1555e-04 - val_mae: 0.0187\n",
      "Epoch 171/180\n",
      "65/65 [==============================] - 42s 641ms/step - loss: 8.3310e-04 - mse: 8.3310e-04 - mae: 0.0163 - val_loss: 9.1290e-04 - val_mse: 9.1290e-04 - val_mae: 0.0179\n",
      "Epoch 172/180\n",
      "65/65 [==============================] - 41s 625ms/step - loss: 8.2036e-04 - mse: 8.2036e-04 - mae: 0.0162 - val_loss: 8.9707e-04 - val_mse: 8.9707e-04 - val_mae: 0.0176\n",
      "Epoch 173/180\n",
      "65/65 [==============================] - 42s 640ms/step - loss: 8.2452e-04 - mse: 8.2452e-04 - mae: 0.0161 - val_loss: 9.0832e-04 - val_mse: 9.0832e-04 - val_mae: 0.0182\n",
      "Epoch 174/180\n",
      "65/65 [==============================] - 42s 649ms/step - loss: 8.4174e-04 - mse: 8.4174e-04 - mae: 0.0165 - val_loss: 9.1364e-04 - val_mse: 9.1364e-04 - val_mae: 0.0182\n",
      "Epoch 175/180\n",
      "65/65 [==============================] - 41s 632ms/step - loss: 8.2853e-04 - mse: 8.2853e-04 - mae: 0.0163 - val_loss: 8.9764e-04 - val_mse: 8.9764e-04 - val_mae: 0.0181\n",
      "Epoch 176/180\n",
      "65/65 [==============================] - 42s 644ms/step - loss: 8.2732e-04 - mse: 8.2732e-04 - mae: 0.0161 - val_loss: 9.0336e-04 - val_mse: 9.0336e-04 - val_mae: 0.0178\n",
      "Epoch 177/180\n",
      "65/65 [==============================] - 41s 626ms/step - loss: 8.2296e-04 - mse: 8.2296e-04 - mae: 0.0161 - val_loss: 8.8801e-04 - val_mse: 8.8801e-04 - val_mae: 0.0179\n",
      "Epoch 178/180\n",
      "65/65 [==============================] - 42s 644ms/step - loss: 8.2321e-04 - mse: 8.2321e-04 - mae: 0.0161 - val_loss: 9.0193e-04 - val_mse: 9.0193e-04 - val_mae: 0.0177\n",
      "Epoch 179/180\n",
      "65/65 [==============================] - 42s 642ms/step - loss: 8.1673e-04 - mse: 8.1673e-04 - mae: 0.0161 - val_loss: 8.8886e-04 - val_mse: 8.8886e-04 - val_mae: 0.0178\n",
      "Epoch 180/180\n",
      "65/65 [==============================] - 41s 634ms/step - loss: 8.5502e-04 - mse: 8.5502e-04 - mae: 0.0166 - val_loss: 9.3892e-04 - val_mse: 9.3892e-04 - val_mae: 0.0173\n",
      "Epoch 1/180\n",
      "65/65 [==============================] - 56s 857ms/step - loss: 0.2022 - mse: 0.2022 - mae: 0.3504 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0200\n",
      "Epoch 2/180\n",
      "65/65 [==============================] - 57s 875ms/step - loss: 0.1112 - mse: 0.1112 - mae: 0.2658 - val_loss: 9.6286e-04 - val_mse: 9.6286e-04 - val_mae: 0.0202\n",
      "Epoch 3/180\n",
      "65/65 [==============================] - 55s 848ms/step - loss: 0.0763 - mse: 0.0763 - mae: 0.2193 - val_loss: 0.0022 - val_mse: 0.0022 - val_mae: 0.0335\n",
      "Epoch 4/180\n",
      "65/65 [==============================] - 55s 839ms/step - loss: 0.0517 - mse: 0.0517 - mae: 0.1802 - val_loss: 0.0014 - val_mse: 0.0014 - val_mae: 0.0236\n",
      "Epoch 5/180\n",
      "65/65 [==============================] - 55s 841ms/step - loss: 0.0366 - mse: 0.0366 - mae: 0.1524 - val_loss: 0.0023 - val_mse: 0.0023 - val_mae: 0.0318\n",
      "Epoch 6/180\n",
      "65/65 [==============================] - 55s 844ms/step - loss: 0.0261 - mse: 0.0261 - mae: 0.1283 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0224\n",
      "Epoch 7/180\n",
      "65/65 [==============================] - 57s 878ms/step - loss: 0.0198 - mse: 0.0198 - mae: 0.1114 - val_loss: 0.0018 - val_mse: 0.0018 - val_mae: 0.0253\n",
      "Epoch 8/180\n",
      "65/65 [==============================] - 56s 856ms/step - loss: 0.0152 - mse: 0.0152 - mae: 0.0983 - val_loss: 0.0017 - val_mse: 0.0017 - val_mae: 0.0236\n",
      "Epoch 9/180\n",
      "65/65 [==============================] - 56s 861ms/step - loss: 0.0121 - mse: 0.0121 - mae: 0.0870 - val_loss: 0.0016 - val_mse: 0.0016 - val_mae: 0.0212\n",
      "Epoch 10/180\n",
      "65/65 [==============================] - 56s 864ms/step - loss: 0.0096 - mse: 0.0096 - mae: 0.0773 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0231\n",
      "Epoch 11/180\n",
      "65/65 [==============================] - 56s 868ms/step - loss: 0.0084 - mse: 0.0084 - mae: 0.0718 - val_loss: 0.0014 - val_mse: 0.0014 - val_mae: 0.0254\n",
      "Epoch 12/180\n",
      "65/65 [==============================] - 55s 854ms/step - loss: 0.0072 - mse: 0.0072 - mae: 0.0665 - val_loss: 0.0014 - val_mse: 0.0014 - val_mae: 0.0232\n",
      "Epoch 13/180\n",
      "65/65 [==============================] - 59s 906ms/step - loss: 0.0062 - mse: 0.0062 - mae: 0.0616 - val_loss: 0.0015 - val_mse: 0.0015 - val_mae: 0.0278\n",
      "Epoch 14/180\n",
      "65/65 [==============================] - 55s 847ms/step - loss: 0.0053 - mse: 0.0053 - mae: 0.0569 - val_loss: 0.0014 - val_mse: 0.0014 - val_mae: 0.0254\n",
      "Epoch 15/180\n",
      "65/65 [==============================] - 55s 843ms/step - loss: 0.0049 - mse: 0.0049 - mae: 0.0546 - val_loss: 0.0014 - val_mse: 0.0014 - val_mae: 0.0276\n",
      "Epoch 16/180\n",
      "65/65 [==============================] - 56s 859ms/step - loss: 0.0044 - mse: 0.0044 - mae: 0.0511 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0266\n",
      "Epoch 17/180\n",
      "65/65 [==============================] - 55s 846ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0487 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0260\n",
      "Epoch 18/180\n",
      "65/65 [==============================] - 56s 854ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0464 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0273\n",
      "Epoch 19/180\n",
      "65/65 [==============================] - 55s 844ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0434 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0275\n",
      "Epoch 20/180\n",
      "65/65 [==============================] - 55s 853ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0419 - val_loss: 0.0014 - val_mse: 0.0014 - val_mae: 0.0298\n",
      "Epoch 21/180\n",
      "65/65 [==============================] - 56s 859ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0403 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0249\n",
      "Epoch 22/180\n",
      "65/65 [==============================] - 55s 850ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0386 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0257\n",
      "Epoch 23/180\n",
      "65/65 [==============================] - 58s 899ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0374 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0257\n",
      "Epoch 24/180\n",
      "65/65 [==============================] - 57s 884ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0356 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0214\n",
      "Epoch 25/180\n",
      "65/65 [==============================] - 55s 841ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0347 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0214\n",
      "Epoch 26/180\n",
      "65/65 [==============================] - 55s 845ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0337 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0236\n",
      "Epoch 27/180\n",
      "65/65 [==============================] - 58s 885ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0333 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0237\n",
      "Epoch 28/180\n",
      "65/65 [==============================] - 58s 897ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0310 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0219\n",
      "Epoch 29/180\n",
      "65/65 [==============================] - 55s 842ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0305 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0228\n",
      "Epoch 30/180\n",
      "65/65 [==============================] - 57s 873ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0293 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0220\n",
      "Epoch 31/180\n",
      "65/65 [==============================] - 56s 856ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0287 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0216\n",
      "Epoch 32/180\n",
      "65/65 [==============================] - 56s 860ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0278 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0225\n",
      "Epoch 33/180\n",
      "65/65 [==============================] - 56s 855ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0271 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0213\n",
      "Epoch 34/180\n",
      "65/65 [==============================] - 58s 891ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0263 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0222\n",
      "Epoch 35/180\n",
      "65/65 [==============================] - 55s 847ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0261 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0216\n",
      "Epoch 36/180\n",
      "65/65 [==============================] - 56s 863ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0253 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0217\n",
      "Epoch 37/180\n",
      "65/65 [==============================] - 56s 860ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0248 - val_loss: 9.8695e-04 - val_mse: 9.8695e-04 - val_mae: 0.0206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/180\n",
      "65/65 [==============================] - 55s 847ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0244 - val_loss: 9.8252e-04 - val_mse: 9.8252e-04 - val_mae: 0.0203\n",
      "Epoch 39/180\n",
      "65/65 [==============================] - 55s 847ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0234 - val_loss: 9.8218e-04 - val_mse: 9.8218e-04 - val_mae: 0.0203\n",
      "Epoch 40/180\n",
      "65/65 [==============================] - 56s 864ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0233 - val_loss: 9.9317e-04 - val_mse: 9.9317e-04 - val_mae: 0.0213\n",
      "Epoch 41/180\n",
      "65/65 [==============================] - 55s 846ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0228 - val_loss: 9.9180e-04 - val_mse: 9.9180e-04 - val_mae: 0.0211\n",
      "Epoch 42/180\n",
      "65/65 [==============================] - 58s 886ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0224 - val_loss: 9.7597e-04 - val_mse: 9.7597e-04 - val_mae: 0.0199\n",
      "Epoch 43/180\n",
      "65/65 [==============================] - 56s 854ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0224 - val_loss: 9.8071e-04 - val_mse: 9.8071e-04 - val_mae: 0.0204\n",
      "Epoch 44/180\n",
      "65/65 [==============================] - 59s 909ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0220 - val_loss: 9.5892e-04 - val_mse: 9.5892e-04 - val_mae: 0.0190\n",
      "Epoch 45/180\n",
      "65/65 [==============================] - 56s 868ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0217 - val_loss: 9.6644e-04 - val_mse: 9.6644e-04 - val_mae: 0.0203\n",
      "Epoch 46/180\n",
      "65/65 [==============================] - 59s 907ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0213 - val_loss: 9.5160e-04 - val_mse: 9.5160e-04 - val_mae: 0.0190\n",
      "Epoch 47/180\n",
      "65/65 [==============================] - 55s 852ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0211 - val_loss: 9.6735e-04 - val_mse: 9.6735e-04 - val_mae: 0.0205\n",
      "Epoch 48/180\n",
      "65/65 [==============================] - 56s 862ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0206 - val_loss: 9.4269e-04 - val_mse: 9.4269e-04 - val_mae: 0.0191\n",
      "Epoch 49/180\n",
      "65/65 [==============================] - 55s 853ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0206 - val_loss: 9.4017e-04 - val_mse: 9.4017e-04 - val_mae: 0.0196\n",
      "Epoch 50/180\n",
      "65/65 [==============================] - 55s 846ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0204 - val_loss: 9.3546e-04 - val_mse: 9.3546e-04 - val_mae: 0.0194\n",
      "Epoch 51/180\n",
      "65/65 [==============================] - 55s 840ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0202 - val_loss: 9.2748e-04 - val_mse: 9.2748e-04 - val_mae: 0.0190\n",
      "Epoch 52/180\n",
      "65/65 [==============================] - 56s 860ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0200 - val_loss: 9.2978e-04 - val_mse: 9.2978e-04 - val_mae: 0.0195\n",
      "Epoch 53/180\n",
      "65/65 [==============================] - 55s 852ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0200 - val_loss: 9.4349e-04 - val_mse: 9.4349e-04 - val_mae: 0.0205\n",
      "Epoch 54/180\n",
      "65/65 [==============================] - 55s 849ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0199 - val_loss: 9.2060e-04 - val_mse: 9.2060e-04 - val_mae: 0.0189\n",
      "Epoch 55/180\n",
      "65/65 [==============================] - 58s 888ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0196 - val_loss: 9.3331e-04 - val_mse: 9.3331e-04 - val_mae: 0.0201\n",
      "Epoch 56/180\n",
      "65/65 [==============================] - 56s 864ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0194 - val_loss: 9.2818e-04 - val_mse: 9.2818e-04 - val_mae: 0.0198\n",
      "Epoch 57/180\n",
      "65/65 [==============================] - 55s 845ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0192 - val_loss: 9.2683e-04 - val_mse: 9.2683e-04 - val_mae: 0.0197\n",
      "Epoch 58/180\n",
      "65/65 [==============================] - 56s 867ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0191 - val_loss: 9.2252e-04 - val_mse: 9.2252e-04 - val_mae: 0.0197\n",
      "Epoch 59/180\n",
      "65/65 [==============================] - 57s 879ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0190 - val_loss: 9.2113e-04 - val_mse: 9.2113e-04 - val_mae: 0.0195\n",
      "Epoch 60/180\n",
      "65/65 [==============================] - 58s 891ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0191 - val_loss: 9.4061e-04 - val_mse: 9.4061e-04 - val_mae: 0.0208\n",
      "Epoch 61/180\n",
      "65/65 [==============================] - 56s 860ms/step - loss: 9.8526e-04 - mse: 9.8526e-04 - mae: 0.0189 - val_loss: 9.3012e-04 - val_mse: 9.3012e-04 - val_mae: 0.0202\n",
      "Epoch 62/180\n",
      "65/65 [==============================] - 58s 890ms/step - loss: 9.7405e-04 - mse: 9.7405e-04 - mae: 0.0188 - val_loss: 9.1552e-04 - val_mse: 9.1552e-04 - val_mae: 0.0193\n",
      "Epoch 63/180\n",
      "65/65 [==============================] - 56s 856ms/step - loss: 9.7579e-04 - mse: 9.7579e-04 - mae: 0.0189 - val_loss: 9.2526e-04 - val_mse: 9.2526e-04 - val_mae: 0.0196\n",
      "Epoch 64/180\n",
      "65/65 [==============================] - 56s 868ms/step - loss: 9.8732e-04 - mse: 9.8732e-04 - mae: 0.0188 - val_loss: 9.3106e-04 - val_mse: 9.3106e-04 - val_mae: 0.0197\n",
      "Epoch 65/180\n",
      "65/65 [==============================] - 57s 878ms/step - loss: 9.7559e-04 - mse: 9.7559e-04 - mae: 0.0187 - val_loss: 9.3394e-04 - val_mse: 9.3394e-04 - val_mae: 0.0202\n",
      "Epoch 66/180\n",
      "65/65 [==============================] - 56s 867ms/step - loss: 9.6744e-04 - mse: 9.6744e-04 - mae: 0.0186 - val_loss: 9.1748e-04 - val_mse: 9.1748e-04 - val_mae: 0.0191\n",
      "Epoch 67/180\n",
      "65/65 [==============================] - 55s 848ms/step - loss: 9.7127e-04 - mse: 9.7127e-04 - mae: 0.0185 - val_loss: 9.2436e-04 - val_mse: 9.2436e-04 - val_mae: 0.0192\n",
      "Epoch 68/180\n",
      "65/65 [==============================] - 56s 861ms/step - loss: 9.7068e-04 - mse: 9.7068e-04 - mae: 0.0186 - val_loss: 9.2358e-04 - val_mse: 9.2358e-04 - val_mae: 0.0193\n",
      "Epoch 69/180\n",
      "65/65 [==============================] - 57s 879ms/step - loss: 9.6974e-04 - mse: 9.6974e-04 - mae: 0.0185 - val_loss: 9.2263e-04 - val_mse: 9.2263e-04 - val_mae: 0.0197\n",
      "Epoch 70/180\n",
      "65/65 [==============================] - 55s 852ms/step - loss: 9.6467e-04 - mse: 9.6467e-04 - mae: 0.0184 - val_loss: 9.1424e-04 - val_mse: 9.1424e-04 - val_mae: 0.0194\n",
      "Epoch 71/180\n",
      "65/65 [==============================] - 55s 847ms/step - loss: 9.6076e-04 - mse: 9.6076e-04 - mae: 0.0183 - val_loss: 9.0621e-04 - val_mse: 9.0621e-04 - val_mae: 0.0183\n",
      "Epoch 72/180\n",
      "65/65 [==============================] - 56s 859ms/step - loss: 9.5198e-04 - mse: 9.5198e-04 - mae: 0.0183 - val_loss: 9.0234e-04 - val_mse: 9.0234e-04 - val_mae: 0.0188\n",
      "Epoch 73/180\n",
      "65/65 [==============================] - 55s 847ms/step - loss: 9.4542e-04 - mse: 9.4542e-04 - mae: 0.0182 - val_loss: 9.0198e-04 - val_mse: 9.0198e-04 - val_mae: 0.0192\n",
      "Epoch 74/180\n",
      "65/65 [==============================] - 56s 862ms/step - loss: 9.4251e-04 - mse: 9.4251e-04 - mae: 0.0182 - val_loss: 8.9750e-04 - val_mse: 8.9750e-04 - val_mae: 0.0187\n",
      "Epoch 75/180\n",
      "65/65 [==============================] - 56s 863ms/step - loss: 9.5163e-04 - mse: 9.5163e-04 - mae: 0.0182 - val_loss: 9.0548e-04 - val_mse: 9.0548e-04 - val_mae: 0.0194\n",
      "Epoch 76/180\n",
      "65/65 [==============================] - 60s 929ms/step - loss: 9.4633e-04 - mse: 9.4633e-04 - mae: 0.0181 - val_loss: 9.1550e-04 - val_mse: 9.1550e-04 - val_mae: 0.0200\n",
      "Epoch 77/180\n",
      "65/65 [==============================] - 55s 844ms/step - loss: 9.3502e-04 - mse: 9.3502e-04 - mae: 0.0180 - val_loss: 9.1961e-04 - val_mse: 9.1961e-04 - val_mae: 0.0204\n",
      "Epoch 78/180\n",
      "65/65 [==============================] - 55s 849ms/step - loss: 9.3458e-04 - mse: 9.3458e-04 - mae: 0.0180 - val_loss: 9.3440e-04 - val_mse: 9.3440e-04 - val_mae: 0.0215\n",
      "Epoch 79/180\n",
      "65/65 [==============================] - 56s 857ms/step - loss: 9.3033e-04 - mse: 9.3033e-04 - mae: 0.0179 - val_loss: 8.9307e-04 - val_mse: 8.9307e-04 - val_mae: 0.0197\n",
      "Epoch 80/180\n",
      "65/65 [==============================] - 56s 862ms/step - loss: 9.3264e-04 - mse: 9.3264e-04 - mae: 0.0179 - val_loss: 9.1851e-04 - val_mse: 9.1851e-04 - val_mae: 0.0208\n",
      "Epoch 81/180\n",
      "65/65 [==============================] - 55s 851ms/step - loss: 9.2659e-04 - mse: 9.2659e-04 - mae: 0.0179 - val_loss: 9.0585e-04 - val_mse: 9.0585e-04 - val_mae: 0.0196\n",
      "Epoch 82/180\n",
      "65/65 [==============================] - 55s 852ms/step - loss: 9.3094e-04 - mse: 9.3094e-04 - mae: 0.0179 - val_loss: 9.1094e-04 - val_mse: 9.1094e-04 - val_mae: 0.0171\n",
      "Epoch 83/180\n",
      "65/65 [==============================] - 55s 846ms/step - loss: 9.5211e-04 - mse: 9.5211e-04 - mae: 0.0182 - val_loss: 9.7152e-04 - val_mse: 9.7152e-04 - val_mae: 0.0201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/180\n",
      "65/65 [==============================] - 56s 862ms/step - loss: 9.2957e-04 - mse: 9.2957e-04 - mae: 0.0180 - val_loss: 9.0537e-04 - val_mse: 9.0537e-04 - val_mae: 0.0175\n",
      "Epoch 85/180\n",
      "65/65 [==============================] - 55s 850ms/step - loss: 9.2956e-04 - mse: 9.2956e-04 - mae: 0.0178 - val_loss: 9.2763e-04 - val_mse: 9.2763e-04 - val_mae: 0.0203\n",
      "Epoch 86/180\n",
      "65/65 [==============================] - 56s 858ms/step - loss: 9.1999e-04 - mse: 9.1999e-04 - mae: 0.0178 - val_loss: 8.8586e-04 - val_mse: 8.8586e-04 - val_mae: 0.0177\n",
      "Epoch 87/180\n",
      "65/65 [==============================] - 57s 879ms/step - loss: 9.2577e-04 - mse: 9.2577e-04 - mae: 0.0178 - val_loss: 8.9825e-04 - val_mse: 8.9825e-04 - val_mae: 0.0195\n",
      "Epoch 88/180\n",
      "65/65 [==============================] - 56s 855ms/step - loss: 9.3272e-04 - mse: 9.3272e-04 - mae: 0.0178 - val_loss: 8.9980e-04 - val_mse: 8.9980e-04 - val_mae: 0.0196\n",
      "Epoch 89/180\n",
      "65/65 [==============================] - 55s 845ms/step - loss: 9.1282e-04 - mse: 9.1282e-04 - mae: 0.0176 - val_loss: 8.8391e-04 - val_mse: 8.8391e-04 - val_mae: 0.0173\n",
      "Epoch 90/180\n",
      "65/65 [==============================] - 56s 854ms/step - loss: 9.0838e-04 - mse: 9.0838e-04 - mae: 0.0176 - val_loss: 8.8025e-04 - val_mse: 8.8025e-04 - val_mae: 0.0180\n",
      "Epoch 91/180\n",
      "65/65 [==============================] - 56s 855ms/step - loss: 9.0843e-04 - mse: 9.0843e-04 - mae: 0.0176 - val_loss: 9.0456e-04 - val_mse: 9.0456e-04 - val_mae: 0.0196\n",
      "Epoch 92/180\n",
      "65/65 [==============================] - 56s 863ms/step - loss: 9.0109e-04 - mse: 9.0109e-04 - mae: 0.0175 - val_loss: 8.8609e-04 - val_mse: 8.8609e-04 - val_mae: 0.0180\n",
      "Epoch 93/180\n",
      "65/65 [==============================] - 56s 863ms/step - loss: 9.0525e-04 - mse: 9.0525e-04 - mae: 0.0175 - val_loss: 8.9511e-04 - val_mse: 8.9511e-04 - val_mae: 0.0190\n",
      "Epoch 94/180\n",
      "65/65 [==============================] - 56s 862ms/step - loss: 9.0009e-04 - mse: 9.0009e-04 - mae: 0.0174 - val_loss: 9.0032e-04 - val_mse: 9.0032e-04 - val_mae: 0.0187\n",
      "Epoch 95/180\n",
      "65/65 [==============================] - 56s 860ms/step - loss: 9.0011e-04 - mse: 9.0011e-04 - mae: 0.0174 - val_loss: 9.0502e-04 - val_mse: 9.0502e-04 - val_mae: 0.0179\n",
      "Epoch 96/180\n",
      "65/65 [==============================] - 56s 863ms/step - loss: 8.9956e-04 - mse: 8.9956e-04 - mae: 0.0175 - val_loss: 9.2254e-04 - val_mse: 9.2254e-04 - val_mae: 0.0195\n",
      "Epoch 97/180\n",
      "65/65 [==============================] - 59s 912ms/step - loss: 8.9509e-04 - mse: 8.9509e-04 - mae: 0.0173 - val_loss: 8.9977e-04 - val_mse: 8.9977e-04 - val_mae: 0.0176\n",
      "Epoch 98/180\n",
      "65/65 [==============================] - 55s 847ms/step - loss: 8.9389e-04 - mse: 8.9389e-04 - mae: 0.0173 - val_loss: 9.1974e-04 - val_mse: 9.1974e-04 - val_mae: 0.0175\n",
      "Epoch 99/180\n",
      "65/65 [==============================] - 55s 845ms/step - loss: 8.9973e-04 - mse: 8.9973e-04 - mae: 0.0174 - val_loss: 9.2487e-04 - val_mse: 9.2487e-04 - val_mae: 0.0190\n",
      "Epoch 100/180\n",
      "65/65 [==============================] - 57s 873ms/step - loss: 8.9612e-04 - mse: 8.9612e-04 - mae: 0.0173 - val_loss: 8.8224e-04 - val_mse: 8.8224e-04 - val_mae: 0.0177\n",
      "Epoch 101/180\n",
      "65/65 [==============================] - 57s 871ms/step - loss: 8.8935e-04 - mse: 8.8935e-04 - mae: 0.0173 - val_loss: 9.0218e-04 - val_mse: 9.0218e-04 - val_mae: 0.0184\n",
      "Epoch 102/180\n",
      "65/65 [==============================] - 55s 847ms/step - loss: 8.8491e-04 - mse: 8.8491e-04 - mae: 0.0173 - val_loss: 9.2467e-04 - val_mse: 9.2467e-04 - val_mae: 0.0204\n",
      "Epoch 103/180\n",
      "65/65 [==============================] - 55s 853ms/step - loss: 8.8531e-04 - mse: 8.8531e-04 - mae: 0.0171 - val_loss: 8.8795e-04 - val_mse: 8.8795e-04 - val_mae: 0.0187\n",
      "Epoch 104/180\n",
      "65/65 [==============================] - 56s 855ms/step - loss: 8.9603e-04 - mse: 8.9603e-04 - mae: 0.0173 - val_loss: 9.5228e-04 - val_mse: 9.5228e-04 - val_mae: 0.0209\n",
      "Epoch 105/180\n",
      "65/65 [==============================] - 56s 859ms/step - loss: 8.7788e-04 - mse: 8.7788e-04 - mae: 0.0171 - val_loss: 8.9267e-04 - val_mse: 8.9267e-04 - val_mae: 0.0186\n",
      "Epoch 106/180\n",
      "65/65 [==============================] - 55s 853ms/step - loss: 8.8145e-04 - mse: 8.8145e-04 - mae: 0.0172 - val_loss: 9.1026e-04 - val_mse: 9.1026e-04 - val_mae: 0.0185\n",
      "Epoch 107/180\n",
      "65/65 [==============================] - 56s 862ms/step - loss: 8.8712e-04 - mse: 8.8712e-04 - mae: 0.0172 - val_loss: 8.9202e-04 - val_mse: 8.9202e-04 - val_mae: 0.0183\n",
      "Epoch 108/180\n",
      "65/65 [==============================] - 60s 920ms/step - loss: 8.7058e-04 - mse: 8.7058e-04 - mae: 0.0168 - val_loss: 8.8628e-04 - val_mse: 8.8628e-04 - val_mae: 0.0175\n",
      "Epoch 109/180\n",
      "65/65 [==============================] - 59s 903ms/step - loss: 8.6529e-04 - mse: 8.6529e-04 - mae: 0.0170 - val_loss: 9.0812e-04 - val_mse: 9.0812e-04 - val_mae: 0.0189\n",
      "Epoch 110/180\n",
      "65/65 [==============================] - 55s 849ms/step - loss: 8.5921e-04 - mse: 8.5921e-04 - mae: 0.0168 - val_loss: 9.0326e-04 - val_mse: 9.0326e-04 - val_mae: 0.0185\n",
      "Epoch 111/180\n",
      "65/65 [==============================] - 56s 855ms/step - loss: 8.5758e-04 - mse: 8.5758e-04 - mae: 0.0167 - val_loss: 9.4596e-04 - val_mse: 9.4596e-04 - val_mae: 0.0163\n",
      "Epoch 112/180\n",
      "65/65 [==============================] - 62s 955ms/step - loss: 8.8080e-04 - mse: 8.8080e-04 - mae: 0.0172 - val_loss: 9.7788e-04 - val_mse: 9.7788e-04 - val_mae: 0.0206\n",
      "Epoch 113/180\n",
      "65/65 [==============================] - 59s 902ms/step - loss: 8.6575e-04 - mse: 8.6575e-04 - mae: 0.0168 - val_loss: 9.3595e-04 - val_mse: 9.3595e-04 - val_mae: 0.0200\n",
      "Epoch 114/180\n",
      "65/65 [==============================] - 55s 848ms/step - loss: 8.7514e-04 - mse: 8.7514e-04 - mae: 0.0169 - val_loss: 9.0967e-04 - val_mse: 9.0967e-04 - val_mae: 0.0184\n",
      "Epoch 115/180\n",
      "65/65 [==============================] - 55s 848ms/step - loss: 8.5507e-04 - mse: 8.5507e-04 - mae: 0.0167 - val_loss: 9.1181e-04 - val_mse: 9.1181e-04 - val_mae: 0.0182\n",
      "Epoch 116/180\n",
      "65/65 [==============================] - 56s 867ms/step - loss: 8.6278e-04 - mse: 8.6278e-04 - mae: 0.0168 - val_loss: 9.5111e-04 - val_mse: 9.5111e-04 - val_mae: 0.0198\n",
      "Epoch 117/180\n",
      "65/65 [==============================] - 55s 849ms/step - loss: 8.5187e-04 - mse: 8.5187e-04 - mae: 0.0166 - val_loss: 8.8302e-04 - val_mse: 8.8302e-04 - val_mae: 0.0177\n",
      "Epoch 118/180\n",
      "65/65 [==============================] - 58s 896ms/step - loss: 8.5962e-04 - mse: 8.5962e-04 - mae: 0.0168 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0211\n",
      "Epoch 119/180\n",
      "65/65 [==============================] - 55s 851ms/step - loss: 8.4916e-04 - mse: 8.4916e-04 - mae: 0.0166 - val_loss: 9.3349e-04 - val_mse: 9.3349e-04 - val_mae: 0.0197\n",
      "Epoch 120/180\n",
      "65/65 [==============================] - 56s 860ms/step - loss: 8.4350e-04 - mse: 8.4350e-04 - mae: 0.0165 - val_loss: 9.4046e-04 - val_mse: 9.4046e-04 - val_mae: 0.0195\n",
      "Epoch 121/180\n",
      "65/65 [==============================] - 56s 868ms/step - loss: 8.3704e-04 - mse: 8.3704e-04 - mae: 0.0164 - val_loss: 9.1584e-04 - val_mse: 9.1584e-04 - val_mae: 0.0175\n",
      "Epoch 122/180\n",
      "65/65 [==============================] - 56s 867ms/step - loss: 8.5914e-04 - mse: 8.5914e-04 - mae: 0.0168 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0208\n",
      "Epoch 123/180\n",
      "65/65 [==============================] - 55s 851ms/step - loss: 8.4682e-04 - mse: 8.4682e-04 - mae: 0.0165 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0207\n",
      "Epoch 124/180\n",
      "65/65 [==============================] - 58s 888ms/step - loss: 8.3913e-04 - mse: 8.3913e-04 - mae: 0.0164 - val_loss: 9.1998e-04 - val_mse: 9.1998e-04 - val_mae: 0.0192\n",
      "Epoch 125/180\n",
      "65/65 [==============================] - 56s 858ms/step - loss: 8.4728e-04 - mse: 8.4728e-04 - mae: 0.0165 - val_loss: 9.4813e-04 - val_mse: 9.4813e-04 - val_mae: 0.0203\n",
      "Epoch 126/180\n",
      "65/65 [==============================] - 57s 878ms/step - loss: 8.4010e-04 - mse: 8.4010e-04 - mae: 0.0165 - val_loss: 9.9386e-04 - val_mse: 9.9386e-04 - val_mae: 0.0205\n",
      "Epoch 127/180\n",
      "65/65 [==============================] - 56s 866ms/step - loss: 8.2731e-04 - mse: 8.2731e-04 - mae: 0.0163 - val_loss: 9.9454e-04 - val_mse: 9.9454e-04 - val_mae: 0.0206\n",
      "Epoch 128/180\n",
      "65/65 [==============================] - 57s 871ms/step - loss: 8.3527e-04 - mse: 8.3527e-04 - mae: 0.0164 - val_loss: 9.9881e-04 - val_mse: 9.9881e-04 - val_mae: 0.0204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 129/180\n",
      "65/65 [==============================] - 57s 883ms/step - loss: 8.2738e-04 - mse: 8.2738e-04 - mae: 0.0163 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0231\n",
      "Epoch 130/180\n",
      "65/65 [==============================] - 55s 847ms/step - loss: 8.3168e-04 - mse: 8.3168e-04 - mae: 0.0162 - val_loss: 9.0263e-04 - val_mse: 9.0263e-04 - val_mae: 0.0186\n",
      "Epoch 131/180\n",
      "65/65 [==============================] - 55s 842ms/step - loss: 8.4008e-04 - mse: 8.4008e-04 - mae: 0.0164 - val_loss: 9.7377e-04 - val_mse: 9.7377e-04 - val_mae: 0.0212\n",
      "Epoch 132/180\n",
      "65/65 [==============================] - 55s 852ms/step - loss: 8.4010e-04 - mse: 8.4010e-04 - mae: 0.0164 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0227\n",
      "Epoch 133/180\n",
      "65/65 [==============================] - 57s 873ms/step - loss: 8.3939e-04 - mse: 8.3939e-04 - mae: 0.0163 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0223\n",
      "Epoch 134/180\n",
      "65/65 [==============================] - 55s 844ms/step - loss: 8.4415e-04 - mse: 8.4415e-04 - mae: 0.0164 - val_loss: 9.0135e-04 - val_mse: 9.0135e-04 - val_mae: 0.0181\n",
      "Epoch 135/180\n",
      "65/65 [==============================] - 55s 844ms/step - loss: 8.2471e-04 - mse: 8.2471e-04 - mae: 0.0161 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0208\n",
      "Epoch 136/180\n",
      "65/65 [==============================] - 55s 842ms/step - loss: 8.2785e-04 - mse: 8.2785e-04 - mae: 0.0161 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0203\n",
      "Epoch 137/180\n",
      "65/65 [==============================] - 57s 871ms/step - loss: 8.1639e-04 - mse: 8.1639e-04 - mae: 0.0161 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0201\n",
      "Epoch 138/180\n",
      "65/65 [==============================] - 56s 858ms/step - loss: 8.2284e-04 - mse: 8.2284e-04 - mae: 0.0161 - val_loss: 9.0123e-04 - val_mse: 9.0123e-04 - val_mae: 0.0185\n",
      "Epoch 139/180\n",
      "65/65 [==============================] - 59s 915ms/step - loss: 8.4629e-04 - mse: 8.4629e-04 - mae: 0.0164 - val_loss: 8.9583e-04 - val_mse: 8.9583e-04 - val_mae: 0.0187\n",
      "Epoch 140/180\n",
      "65/65 [==============================] - 55s 843ms/step - loss: 8.2383e-04 - mse: 8.2383e-04 - mae: 0.0161 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0212\n",
      "Epoch 141/180\n",
      "65/65 [==============================] - 58s 889ms/step - loss: 8.1738e-04 - mse: 8.1738e-04 - mae: 0.0160 - val_loss: 9.4554e-04 - val_mse: 9.4554e-04 - val_mae: 0.0191\n",
      "Epoch 142/180\n",
      "65/65 [==============================] - 55s 849ms/step - loss: 8.1425e-04 - mse: 8.1425e-04 - mae: 0.0160 - val_loss: 9.4355e-04 - val_mse: 9.4355e-04 - val_mae: 0.0187\n",
      "Epoch 143/180\n",
      "65/65 [==============================] - 57s 871ms/step - loss: 8.1575e-04 - mse: 8.1575e-04 - mae: 0.0161 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0202\n",
      "Epoch 144/180\n",
      "65/65 [==============================] - 55s 843ms/step - loss: 8.1398e-04 - mse: 8.1398e-04 - mae: 0.0158 - val_loss: 8.6038e-04 - val_mse: 8.6038e-04 - val_mae: 0.0172\n",
      "Epoch 145/180\n",
      "65/65 [==============================] - 56s 862ms/step - loss: 8.2607e-04 - mse: 8.2607e-04 - mae: 0.0163 - val_loss: 9.1215e-04 - val_mse: 9.1215e-04 - val_mae: 0.0187\n",
      "Epoch 146/180\n",
      "65/65 [==============================] - 56s 864ms/step - loss: 8.0900e-04 - mse: 8.0900e-04 - mae: 0.0159 - val_loss: 9.3594e-04 - val_mse: 9.3594e-04 - val_mae: 0.0185\n",
      "Epoch 147/180\n",
      "65/65 [==============================] - 55s 849ms/step - loss: 8.3757e-04 - mse: 8.3757e-04 - mae: 0.0163 - val_loss: 9.3306e-04 - val_mse: 9.3306e-04 - val_mae: 0.0184\n",
      "Epoch 148/180\n",
      "65/65 [==============================] - 55s 849ms/step - loss: 8.1813e-04 - mse: 8.1813e-04 - mae: 0.0160 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0193\n",
      "Epoch 149/180\n",
      "65/65 [==============================] - 56s 863ms/step - loss: 7.9298e-04 - mse: 7.9298e-04 - mae: 0.0156 - val_loss: 9.1545e-04 - val_mse: 9.1545e-04 - val_mae: 0.0173\n",
      "Epoch 150/180\n",
      "65/65 [==============================] - 58s 892ms/step - loss: 8.1281e-04 - mse: 8.1281e-04 - mae: 0.0160 - val_loss: 9.9411e-04 - val_mse: 9.9411e-04 - val_mae: 0.0190\n",
      "Epoch 151/180\n",
      "65/65 [==============================] - 55s 845ms/step - loss: 7.9791e-04 - mse: 7.9791e-04 - mae: 0.0156 - val_loss: 8.8634e-04 - val_mse: 8.8634e-04 - val_mae: 0.0176\n",
      "Epoch 152/180\n",
      "65/65 [==============================] - 55s 846ms/step - loss: 7.9911e-04 - mse: 7.9911e-04 - mae: 0.0158 - val_loss: 8.5972e-04 - val_mse: 8.5972e-04 - val_mae: 0.0168\n",
      "Epoch 153/180\n",
      "65/65 [==============================] - 56s 868ms/step - loss: 8.0144e-04 - mse: 8.0144e-04 - mae: 0.0158 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0199\n",
      "Epoch 154/180\n",
      "65/65 [==============================] - 55s 852ms/step - loss: 7.8216e-04 - mse: 7.8216e-04 - mae: 0.0155 - val_loss: 9.8861e-04 - val_mse: 9.8861e-04 - val_mae: 0.0192\n",
      "Epoch 155/180\n",
      "65/65 [==============================] - 55s 849ms/step - loss: 8.1349e-04 - mse: 8.1349e-04 - mae: 0.0159 - val_loss: 9.9939e-04 - val_mse: 9.9939e-04 - val_mae: 0.0176\n",
      "Epoch 156/180\n",
      "65/65 [==============================] - 55s 847ms/step - loss: 7.9106e-04 - mse: 7.9106e-04 - mae: 0.0157 - val_loss: 8.2904e-04 - val_mse: 8.2904e-04 - val_mae: 0.0165\n",
      "Epoch 157/180\n",
      "65/65 [==============================] - 60s 930ms/step - loss: 8.1877e-04 - mse: 8.1877e-04 - mae: 0.0160 - val_loss: 9.2300e-04 - val_mse: 9.2300e-04 - val_mae: 0.0187\n",
      "Epoch 158/180\n",
      "65/65 [==============================] - 56s 864ms/step - loss: 7.9069e-04 - mse: 7.9069e-04 - mae: 0.0155 - val_loss: 8.4324e-04 - val_mse: 8.4324e-04 - val_mae: 0.0164\n",
      "Epoch 159/180\n",
      "65/65 [==============================] - 55s 847ms/step - loss: 8.0115e-04 - mse: 8.0115e-04 - mae: 0.0159 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0197\n",
      "Epoch 160/180\n",
      "65/65 [==============================] - 58s 889ms/step - loss: 7.8825e-04 - mse: 7.8825e-04 - mae: 0.0157 - val_loss: 9.1285e-04 - val_mse: 9.1285e-04 - val_mae: 0.0184\n",
      "Epoch 161/180\n",
      "65/65 [==============================] - 56s 867ms/step - loss: 8.2342e-04 - mse: 8.2342e-04 - mae: 0.0161 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0182\n",
      "Epoch 162/180\n",
      "65/65 [==============================] - 55s 850ms/step - loss: 8.0481e-04 - mse: 8.0481e-04 - mae: 0.0158 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0181\n",
      "Epoch 163/180\n",
      "65/65 [==============================] - 56s 859ms/step - loss: 7.8233e-04 - mse: 7.8233e-04 - mae: 0.0155 - val_loss: 9.4579e-04 - val_mse: 9.4579e-04 - val_mae: 0.0170\n",
      "Epoch 164/180\n",
      "65/65 [==============================] - 56s 858ms/step - loss: 7.9476e-04 - mse: 7.9476e-04 - mae: 0.0158 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0199\n",
      "Epoch 165/180\n",
      "65/65 [==============================] - 56s 866ms/step - loss: 7.7669e-04 - mse: 7.7669e-04 - mae: 0.0155 - val_loss: 8.5702e-04 - val_mse: 8.5702e-04 - val_mae: 0.0161\n",
      "Epoch 166/180\n",
      "65/65 [==============================] - 57s 881ms/step - loss: 7.8960e-04 - mse: 7.8960e-04 - mae: 0.0156 - val_loss: 8.3938e-04 - val_mse: 8.3938e-04 - val_mae: 0.0169\n",
      "Epoch 167/180\n",
      "65/65 [==============================] - 56s 865ms/step - loss: 7.8175e-04 - mse: 7.8175e-04 - mae: 0.0155 - val_loss: 8.8102e-04 - val_mse: 8.8102e-04 - val_mae: 0.0172\n",
      "Epoch 168/180\n",
      "65/65 [==============================] - 57s 879ms/step - loss: 7.9312e-04 - mse: 7.9312e-04 - mae: 0.0157 - val_loss: 9.8055e-04 - val_mse: 9.8055e-04 - val_mae: 0.0180\n",
      "Epoch 169/180\n",
      "65/65 [==============================] - 57s 875ms/step - loss: 8.1023e-04 - mse: 8.1023e-04 - mae: 0.0159 - val_loss: 8.6581e-04 - val_mse: 8.6581e-04 - val_mae: 0.0179\n",
      "Epoch 170/180\n",
      "65/65 [==============================] - 56s 862ms/step - loss: 7.9425e-04 - mse: 7.9425e-04 - mae: 0.0155 - val_loss: 8.4103e-04 - val_mse: 8.4103e-04 - val_mae: 0.0160\n",
      "Epoch 171/180\n",
      "65/65 [==============================] - 60s 916ms/step - loss: 7.7776e-04 - mse: 7.7776e-04 - mae: 0.0155 - val_loss: 8.1328e-04 - val_mse: 8.1328e-04 - val_mae: 0.0161\n",
      "Epoch 172/180\n",
      "65/65 [==============================] - 59s 914ms/step - loss: 7.8344e-04 - mse: 7.8344e-04 - mae: 0.0157 - val_loss: 9.9163e-04 - val_mse: 9.9163e-04 - val_mae: 0.0188\n",
      "Epoch 173/180\n",
      "65/65 [==============================] - 56s 860ms/step - loss: 7.9562e-04 - mse: 7.9562e-04 - mae: 0.0155 - val_loss: 9.7758e-04 - val_mse: 9.7758e-04 - val_mae: 0.0183\n",
      "Epoch 174/180\n",
      "65/65 [==============================] - 55s 853ms/step - loss: 7.7484e-04 - mse: 7.7484e-04 - mae: 0.0154 - val_loss: 8.7593e-04 - val_mse: 8.7593e-04 - val_mae: 0.0172\n",
      "Epoch 175/180\n",
      "65/65 [==============================] - 55s 849ms/step - loss: 7.8848e-04 - mse: 7.8848e-04 - mae: 0.0157 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0189\n",
      "Epoch 176/180\n",
      "65/65 [==============================] - 55s 847ms/step - loss: 7.7760e-04 - mse: 7.7760e-04 - mae: 0.0153 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0194\n",
      "Epoch 177/180\n",
      "65/65 [==============================] - 56s 862ms/step - loss: 7.5857e-04 - mse: 7.5857e-04 - mae: 0.0150 - val_loss: 8.5137e-04 - val_mse: 8.5137e-04 - val_mae: 0.0164\n",
      "Epoch 178/180\n",
      "65/65 [==============================] - 55s 847ms/step - loss: 7.8865e-04 - mse: 7.8865e-04 - mae: 0.0157 - val_loss: 8.5907e-04 - val_mse: 8.5907e-04 - val_mae: 0.0168\n",
      "Epoch 179/180\n",
      "65/65 [==============================] - 55s 850ms/step - loss: 7.5081e-04 - mse: 7.5081e-04 - mae: 0.0150 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0193\n",
      "Epoch 180/180\n",
      "65/65 [==============================] - 55s 850ms/step - loss: 7.7187e-04 - mse: 7.7187e-04 - mae: 0.0155 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0179\n",
      "Epoch 1/180\n",
      "65/65 [==============================] - 103s 2s/step - loss: 0.2403 - mse: 0.2403 - mae: 0.3781 - val_loss: 0.0014 - val_mse: 0.0014 - val_mae: 0.0252\n",
      "Epoch 2/180\n",
      "65/65 [==============================] - 100s 2s/step - loss: 0.1341 - mse: 0.1341 - mae: 0.2916 - val_loss: 0.0024 - val_mse: 0.0024 - val_mae: 0.0376\n",
      "Epoch 3/180\n",
      "65/65 [==============================] - 102s 2s/step - loss: 0.1032 - mse: 0.1032 - mae: 0.2553 - val_loss: 0.0031 - val_mse: 0.0031 - val_mae: 0.0446\n",
      "Epoch 4/180\n",
      "65/65 [==============================] - 102s 2s/step - loss: 0.0686 - mse: 0.0686 - mae: 0.2080 - val_loss: 0.0021 - val_mse: 0.0021 - val_mae: 0.0383\n",
      "Epoch 5/180\n",
      "65/65 [==============================] - 102s 2s/step - loss: 0.0491 - mse: 0.0491 - mae: 0.1768 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0237\n",
      "Epoch 6/180\n",
      "65/65 [==============================] - 101s 2s/step - loss: 0.0367 - mse: 0.0367 - mae: 0.1511 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0273\n",
      "Epoch 7/180\n",
      "65/65 [==============================] - 105s 2s/step - loss: 0.0266 - mse: 0.0266 - mae: 0.1290 - val_loss: 0.0014 - val_mse: 0.0014 - val_mae: 0.0228\n",
      "Epoch 8/180\n",
      "65/65 [==============================] - 102s 2s/step - loss: 0.0204 - mse: 0.0204 - mae: 0.1131 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0185\n",
      "Epoch 9/180\n",
      "65/65 [==============================] - 101s 2s/step - loss: 0.0157 - mse: 0.0157 - mae: 0.0988 - val_loss: 0.0017 - val_mse: 0.0017 - val_mae: 0.0361\n",
      "Epoch 10/180\n",
      "65/65 [==============================] - 102s 2s/step - loss: 0.0132 - mse: 0.0132 - mae: 0.0909 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0201\n",
      "Epoch 11/180\n",
      "65/65 [==============================] - 102s 2s/step - loss: 0.0109 - mse: 0.0109 - mae: 0.0816 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0290\n",
      "Epoch 12/180\n",
      "65/65 [==============================] - 110s 2s/step - loss: 0.0093 - mse: 0.0093 - mae: 0.0757 - val_loss: 0.0014 - val_mse: 0.0014 - val_mae: 0.0299\n",
      "Epoch 13/180\n",
      "65/65 [==============================] - 101s 2s/step - loss: 0.0079 - mse: 0.0079 - mae: 0.0702 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0202\n",
      "Epoch 14/180\n",
      "65/65 [==============================] - 103s 2s/step - loss: 0.0068 - mse: 0.0068 - mae: 0.0645 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0244\n",
      "Epoch 15/180\n",
      "65/65 [==============================] - 103s 2s/step - loss: 0.0061 - mse: 0.0061 - mae: 0.0606 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0244\n",
      "Epoch 16/180\n",
      "65/65 [==============================] - 103s 2s/step - loss: 0.0054 - mse: 0.0054 - mae: 0.0569 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0215\n",
      "Epoch 17/180\n",
      "65/65 [==============================] - 101s 2s/step - loss: 0.0048 - mse: 0.0048 - mae: 0.0532 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0165\n",
      "Epoch 18/180\n",
      "65/65 [==============================] - 105s 2s/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0512 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0188\n",
      "Epoch 19/180\n",
      "65/65 [==============================] - 101s 2s/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0471 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0187\n",
      "Epoch 20/180\n",
      "65/65 [==============================] - 102s 2s/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0456 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0234\n",
      "Epoch 21/180\n",
      "65/65 [==============================] - 102s 2s/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0428 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0221\n",
      "Epoch 22/180\n",
      "65/65 [==============================] - 102s 2s/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0405 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0228\n",
      "Epoch 23/180\n",
      "65/65 [==============================] - 103s 2s/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0390 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0215\n",
      "Epoch 24/180\n",
      "65/65 [==============================] - 104s 2s/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0367 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0218\n",
      "Epoch 25/180\n",
      "65/65 [==============================] - 103s 2s/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0352 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0220\n",
      "Epoch 26/180\n",
      "65/65 [==============================] - 103s 2s/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0343 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0215\n",
      "Epoch 27/180\n",
      "65/65 [==============================] - 104s 2s/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0329 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0221\n",
      "Epoch 28/180\n",
      "65/65 [==============================] - 101s 2s/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0321 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0238\n",
      "Epoch 29/180\n",
      "65/65 [==============================] - 103s 2s/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0308 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0221\n",
      "Epoch 30/180\n",
      "65/65 [==============================] - 109s 2s/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0298 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0208\n",
      "Epoch 31/180\n",
      "65/65 [==============================] - 103s 2s/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0291 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0211\n",
      "Epoch 32/180\n",
      "65/65 [==============================] - 101s 2s/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0284 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0224\n",
      "Epoch 33/180\n",
      "65/65 [==============================] - 101s 2s/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0274 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0224\n",
      "Epoch 34/180\n",
      "65/65 [==============================] - 104s 2s/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0265 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0217\n",
      "Epoch 35/180\n",
      "65/65 [==============================] - 104s 2s/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0258 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0229\n",
      "Epoch 36/180\n",
      "65/65 [==============================] - 102s 2s/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0257 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0217\n",
      "Epoch 37/180\n",
      "65/65 [==============================] - 104s 2s/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0251 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0228\n",
      "Epoch 38/180\n",
      "65/65 [==============================] - 104s 2s/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0243 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0229\n",
      "Epoch 39/180\n",
      "65/65 [==============================] - 102s 2s/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0238 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0218\n",
      "Epoch 40/180\n",
      "65/65 [==============================] - 103s 2s/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0235 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0229\n",
      "Epoch 41/180\n",
      "65/65 [==============================] - 104s 2s/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0228 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0219\n",
      "Epoch 42/180\n",
      "65/65 [==============================] - 101s 2s/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0225 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0224\n",
      "Epoch 43/180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 104s 2s/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0224 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0223\n",
      "Epoch 44/180\n",
      "65/65 [==============================] - 101s 2s/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0218 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0217\n",
      "Epoch 45/180\n",
      "65/65 [==============================] - 101s 2s/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0219 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0221\n",
      "Epoch 46/180\n",
      "65/65 [==============================] - 102s 2s/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0214 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0215\n",
      "Epoch 47/180\n",
      "65/65 [==============================] - 107s 2s/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0213 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0213\n",
      "Epoch 48/180\n",
      "65/65 [==============================] - 101s 2s/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0212 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0218\n",
      "Epoch 49/180\n",
      "65/65 [==============================] - 102s 2s/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0206 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0215\n",
      "Epoch 50/180\n",
      "65/65 [==============================] - 100s 2s/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0207 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0209\n",
      "Epoch 51/180\n",
      "65/65 [==============================] - 102s 2s/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0207 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0217\n",
      "Epoch 52/180\n",
      "65/65 [==============================] - 101s 2s/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0204 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0215\n",
      "Epoch 53/180\n",
      "65/65 [==============================] - 103s 2s/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0203 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0211\n",
      "Epoch 54/180\n",
      "65/65 [==============================] - 102s 2s/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0202 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0210\n",
      "Epoch 55/180\n",
      "65/65 [==============================] - 104s 2s/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0201 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0203\n",
      "Epoch 56/180\n",
      "65/65 [==============================] - 103s 2s/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0199 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0210\n",
      "Epoch 57/180\n",
      "65/65 [==============================] - 103s 2s/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0199 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0214\n",
      "Epoch 58/180\n",
      "65/65 [==============================] - 105s 2s/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0198 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0208\n",
      "Epoch 59/180\n",
      "65/65 [==============================] - 102s 2s/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0197 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0203\n",
      "Epoch 60/180\n",
      "65/65 [==============================] - 105s 2s/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0197 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0202\n",
      "Epoch 61/180\n",
      "65/65 [==============================] - 101s 2s/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0192 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0200\n",
      "Epoch 62/180\n",
      "65/65 [==============================] - 102s 2s/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0196 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0203\n",
      "Epoch 63/180\n",
      "65/65 [==============================] - 105s 2s/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0193 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0203\n",
      "Epoch 64/180\n",
      "65/65 [==============================] - 108s 2s/step - loss: 9.9780e-04 - mse: 9.9780e-04 - mae: 0.0191 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0199\n",
      "Epoch 65/180\n",
      "65/65 [==============================] - 107s 2s/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0191 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0196\n",
      "Epoch 66/180\n",
      "65/65 [==============================] - 104s 2s/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0192 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0201\n",
      "Epoch 67/180\n",
      "65/65 [==============================] - 103s 2s/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0191 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0201\n",
      "Epoch 68/180\n",
      "65/65 [==============================] - 101s 2s/step - loss: 9.9169e-04 - mse: 9.9169e-04 - mae: 0.0190 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0205\n",
      "Epoch 69/180\n",
      "65/65 [==============================] - 102s 2s/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0191 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0205\n",
      "Epoch 70/180\n",
      "65/65 [==============================] - 104s 2s/step - loss: 9.9225e-04 - mse: 9.9225e-04 - mae: 0.0189 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0209\n",
      "Epoch 71/180\n",
      "65/65 [==============================] - 103s 2s/step - loss: 9.9073e-04 - mse: 9.9073e-04 - mae: 0.0189 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0208\n",
      "Epoch 72/180\n",
      "65/65 [==============================] - 102s 2s/step - loss: 9.9113e-04 - mse: 9.9113e-04 - mae: 0.0188 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0213\n",
      "Epoch 73/180\n",
      "65/65 [==============================] - 104s 2s/step - loss: 9.7676e-04 - mse: 9.7676e-04 - mae: 0.0187 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0192\n",
      "Epoch 74/180\n",
      "65/65 [==============================] - 103s 2s/step - loss: 9.8527e-04 - mse: 9.8527e-04 - mae: 0.0188 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0207\n",
      "Epoch 75/180\n",
      "65/65 [==============================] - 106s 2s/step - loss: 9.7224e-04 - mse: 9.7224e-04 - mae: 0.0185 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0203\n",
      "Epoch 76/180\n",
      "65/65 [==============================] - 102s 2s/step - loss: 9.7478e-04 - mse: 9.7478e-04 - mae: 0.0186 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0207\n",
      "Epoch 77/180\n",
      "65/65 [==============================] - 102s 2s/step - loss: 9.6876e-04 - mse: 9.6876e-04 - mae: 0.0185 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0202\n",
      "Epoch 78/180\n",
      "65/65 [==============================] - 102s 2s/step - loss: 9.6748e-04 - mse: 9.6748e-04 - mae: 0.0185 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0204\n",
      "Epoch 79/180\n",
      "65/65 [==============================] - 103s 2s/step - loss: 9.7023e-04 - mse: 9.7023e-04 - mae: 0.0185 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0209\n",
      "Epoch 80/180\n",
      "65/65 [==============================] - 103s 2s/step - loss: 9.5695e-04 - mse: 9.5695e-04 - mae: 0.0185 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0207\n",
      "Epoch 81/180\n",
      "65/65 [==============================] - 107s 2s/step - loss: 9.7044e-04 - mse: 9.7044e-04 - mae: 0.0185 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0208\n",
      "Epoch 82/180\n",
      "65/65 [==============================] - 102s 2s/step - loss: 9.6490e-04 - mse: 9.6490e-04 - mae: 0.0184 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0212\n",
      "Epoch 83/180\n",
      "65/65 [==============================] - 101s 2s/step - loss: 9.6571e-04 - mse: 9.6571e-04 - mae: 0.0185 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0209\n",
      "Epoch 84/180\n",
      "65/65 [==============================] - 102s 2s/step - loss: 9.4511e-04 - mse: 9.4511e-04 - mae: 0.0182 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0198\n",
      "Epoch 85/180\n",
      "65/65 [==============================] - 101s 2s/step - loss: 9.3950e-04 - mse: 9.3950e-04 - mae: 0.0180 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0203\n",
      "Epoch 86/180\n",
      "65/65 [==============================] - 101s 2s/step - loss: 9.5141e-04 - mse: 9.5141e-04 - mae: 0.0182 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0207\n",
      "Epoch 87/180\n",
      "65/65 [==============================] - 107s 2s/step - loss: 9.5623e-04 - mse: 9.5623e-04 - mae: 0.0183 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0207\n",
      "Epoch 88/180\n",
      "65/65 [==============================] - 101s 2s/step - loss: 9.4265e-04 - mse: 9.4265e-04 - mae: 0.0182 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0203\n",
      "Epoch 89/180\n",
      "65/65 [==============================] - 103s 2s/step - loss: 9.4471e-04 - mse: 9.4471e-04 - mae: 0.0180 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0201\n",
      "Epoch 90/180\n",
      "65/65 [==============================] - 101s 2s/step - loss: 9.5022e-04 - mse: 9.5022e-04 - mae: 0.0181 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0200\n",
      "Epoch 91/180\n",
      "65/65 [==============================] - 104s 2s/step - loss: 9.5050e-04 - mse: 9.5050e-04 - mae: 0.0181 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0202\n",
      "Epoch 92/180\n",
      "65/65 [==============================] - 102s 2s/step - loss: 9.2900e-04 - mse: 9.2900e-04 - mae: 0.0179 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0199\n",
      "Epoch 93/180\n",
      "65/65 [==============================] - 108s 2s/step - loss: 9.3633e-04 - mse: 9.3633e-04 - mae: 0.0179 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0199\n",
      "Epoch 94/180\n",
      "65/65 [==============================] - 103s 2s/step - loss: 9.3447e-04 - mse: 9.3447e-04 - mae: 0.0180 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0197\n",
      "Epoch 95/180\n",
      "65/65 [==============================] - 102s 2s/step - loss: 9.3603e-04 - mse: 9.3603e-04 - mae: 0.0179 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0197\n",
      "Epoch 96/180\n",
      "65/65 [==============================] - 101s 2s/step - loss: 9.2076e-04 - mse: 9.2076e-04 - mae: 0.0177 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0198\n",
      "Epoch 97/180\n",
      "65/65 [==============================] - 105s 2s/step - loss: 9.2342e-04 - mse: 9.2342e-04 - mae: 0.0177 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0200\n",
      "Epoch 98/180\n",
      "65/65 [==============================] - 109s 2s/step - loss: 9.1650e-04 - mse: 9.1650e-04 - mae: 0.0177 - val_loss: 9.9860e-04 - val_mse: 9.9860e-04 - val_mae: 0.0199\n",
      "Epoch 99/180\n",
      "65/65 [==============================] - 106s 2s/step - loss: 9.1550e-04 - mse: 9.1550e-04 - mae: 0.0177 - val_loss: 9.9480e-04 - val_mse: 9.9480e-04 - val_mae: 0.0197\n",
      "Epoch 100/180\n",
      "65/65 [==============================] - 107s 2s/step - loss: 9.1277e-04 - mse: 9.1277e-04 - mae: 0.0176 - val_loss: 9.9911e-04 - val_mse: 9.9911e-04 - val_mae: 0.0200\n",
      "Epoch 101/180\n",
      "65/65 [==============================] - 102s 2s/step - loss: 9.1006e-04 - mse: 9.1006e-04 - mae: 0.0176 - val_loss: 9.8138e-04 - val_mse: 9.8138e-04 - val_mae: 0.0198\n",
      "Epoch 102/180\n",
      "65/65 [==============================] - 104s 2s/step - loss: 9.1623e-04 - mse: 9.1623e-04 - mae: 0.0177 - val_loss: 9.9459e-04 - val_mse: 9.9459e-04 - val_mae: 0.0199\n",
      "Epoch 103/180\n",
      "65/65 [==============================] - 104s 2s/step - loss: 9.0731e-04 - mse: 9.0731e-04 - mae: 0.0176 - val_loss: 9.6726e-04 - val_mse: 9.6726e-04 - val_mae: 0.0184\n",
      "Epoch 104/180\n",
      "65/65 [==============================] - 108s 2s/step - loss: 9.0145e-04 - mse: 9.0145e-04 - mae: 0.0175 - val_loss: 9.6314e-04 - val_mse: 9.6314e-04 - val_mae: 0.0187\n",
      "Epoch 105/180\n",
      "65/65 [==============================] - 102s 2s/step - loss: 9.0001e-04 - mse: 9.0001e-04 - mae: 0.0174 - val_loss: 9.7670e-04 - val_mse: 9.7670e-04 - val_mae: 0.0189\n",
      "Epoch 106/180\n",
      "65/65 [==============================] - 105s 2s/step - loss: 8.8944e-04 - mse: 8.8944e-04 - mae: 0.0173 - val_loss: 9.7914e-04 - val_mse: 9.7914e-04 - val_mae: 0.0168\n",
      "Epoch 107/180\n",
      "65/65 [==============================] - 104s 2s/step - loss: 8.9519e-04 - mse: 8.9519e-04 - mae: 0.0173 - val_loss: 9.7408e-04 - val_mse: 9.7408e-04 - val_mae: 0.0171\n",
      "Epoch 108/180\n",
      "65/65 [==============================] - 104s 2s/step - loss: 8.8172e-04 - mse: 8.8172e-04 - mae: 0.0170 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0162\n",
      "Epoch 109/180\n",
      "65/65 [==============================] - 102s 2s/step - loss: 8.8784e-04 - mse: 8.8784e-04 - mae: 0.0173 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0161\n",
      "Epoch 110/180\n",
      "65/65 [==============================] - 104s 2s/step - loss: 8.8264e-04 - mse: 8.8264e-04 - mae: 0.0170 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0161\n",
      "Epoch 111/180\n",
      "65/65 [==============================] - 102s 2s/step - loss: 8.7893e-04 - mse: 8.7893e-04 - mae: 0.0171 - val_loss: 9.8101e-04 - val_mse: 9.8101e-04 - val_mae: 0.0181\n",
      "Epoch 112/180\n",
      "65/65 [==============================] - 102s 2s/step - loss: 8.6185e-04 - mse: 8.6185e-04 - mae: 0.0167 - val_loss: 9.7879e-04 - val_mse: 9.7879e-04 - val_mae: 0.0164\n",
      "Epoch 113/180\n",
      "65/65 [==============================] - 103s 2s/step - loss: 8.7710e-04 - mse: 8.7710e-04 - mae: 0.0169 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0156\n",
      "Epoch 114/180\n",
      "65/65 [==============================] - 103s 2s/step - loss: 8.6447e-04 - mse: 8.6447e-04 - mae: 0.0168 - val_loss: 9.8109e-04 - val_mse: 9.8109e-04 - val_mae: 0.0163\n",
      "Epoch 115/180\n",
      "65/65 [==============================] - 110s 2s/step - loss: 8.5492e-04 - mse: 8.5492e-04 - mae: 0.0166 - val_loss: 9.6359e-04 - val_mse: 9.6359e-04 - val_mae: 0.0168\n",
      "Epoch 116/180\n",
      "65/65 [==============================] - 102s 2s/step - loss: 8.6566e-04 - mse: 8.6566e-04 - mae: 0.0168 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0172\n",
      "Epoch 117/180\n",
      "65/65 [==============================] - 102s 2s/step - loss: 8.5426e-04 - mse: 8.5426e-04 - mae: 0.0167 - val_loss: 9.9871e-04 - val_mse: 9.9871e-04 - val_mae: 0.0173\n",
      "Epoch 118/180\n",
      "65/65 [==============================] - 102s 2s/step - loss: 8.4468e-04 - mse: 8.4468e-04 - mae: 0.0164 - val_loss: 8.8300e-04 - val_mse: 8.8300e-04 - val_mae: 0.0177\n",
      "Epoch 119/180\n",
      "65/65 [==============================] - 102s 2s/step - loss: 8.5186e-04 - mse: 8.5186e-04 - mae: 0.0164 - val_loss: 9.5451e-04 - val_mse: 9.5451e-04 - val_mae: 0.0164\n",
      "Epoch 120/180\n",
      "65/65 [==============================] - 101s 2s/step - loss: 8.3685e-04 - mse: 8.3685e-04 - mae: 0.0162 - val_loss: 9.6873e-04 - val_mse: 9.6873e-04 - val_mae: 0.0156\n",
      "Epoch 121/180\n",
      "65/65 [==============================] - 105s 2s/step - loss: 8.3836e-04 - mse: 8.3836e-04 - mae: 0.0163 - val_loss: 9.9572e-04 - val_mse: 9.9572e-04 - val_mae: 0.0159\n",
      "Epoch 122/180\n",
      "65/65 [==============================] - 104s 2s/step - loss: 8.5759e-04 - mse: 8.5759e-04 - mae: 0.0167 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0159\n",
      "Epoch 123/180\n",
      "65/65 [==============================] - 102s 2s/step - loss: 8.6442e-04 - mse: 8.6442e-04 - mae: 0.0167 - val_loss: 9.9972e-04 - val_mse: 9.9972e-04 - val_mae: 0.0180\n",
      "Epoch 124/180\n",
      "65/65 [==============================] - 103s 2s/step - loss: 8.3798e-04 - mse: 8.3798e-04 - mae: 0.0164 - val_loss: 9.9704e-04 - val_mse: 9.9704e-04 - val_mae: 0.0182\n",
      "Epoch 125/180\n",
      "65/65 [==============================] - 101s 2s/step - loss: 8.3985e-04 - mse: 8.3985e-04 - mae: 0.0164 - val_loss: 9.6696e-04 - val_mse: 9.6696e-04 - val_mae: 0.0189\n",
      "Epoch 126/180\n",
      "65/65 [==============================] - 103s 2s/step - loss: 8.3976e-04 - mse: 8.3976e-04 - mae: 0.0162 - val_loss: 9.6372e-04 - val_mse: 9.6372e-04 - val_mae: 0.0168\n",
      "Epoch 127/180\n",
      "65/65 [==============================] - 104s 2s/step - loss: 8.3859e-04 - mse: 8.3859e-04 - mae: 0.0163 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0168\n",
      "Epoch 128/180\n",
      "65/65 [==============================] - 103s 2s/step - loss: 8.3159e-04 - mse: 8.3159e-04 - mae: 0.0162 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0162\n",
      "Epoch 129/180\n",
      "65/65 [==============================] - 103s 2s/step - loss: 8.2441e-04 - mse: 8.2441e-04 - mae: 0.0161 - val_loss: 9.7460e-04 - val_mse: 9.7460e-04 - val_mae: 0.0167\n",
      "Epoch 130/180\n",
      "65/65 [==============================] - 104s 2s/step - loss: 8.3432e-04 - mse: 8.3432e-04 - mae: 0.0162 - val_loss: 9.5212e-04 - val_mse: 9.5212e-04 - val_mae: 0.0185\n",
      "Epoch 131/180\n",
      "65/65 [==============================] - 102s 2s/step - loss: 8.3871e-04 - mse: 8.3871e-04 - mae: 0.0162 - val_loss: 9.7563e-04 - val_mse: 9.7563e-04 - val_mae: 0.0174\n",
      "Epoch 132/180\n",
      "65/65 [==============================] - 102s 2s/step - loss: 8.2951e-04 - mse: 8.2951e-04 - mae: 0.0161 - val_loss: 9.7263e-04 - val_mse: 9.7263e-04 - val_mae: 0.0170\n",
      "Epoch 133/180\n",
      "65/65 [==============================] - 110s 2s/step - loss: 8.2636e-04 - mse: 8.2636e-04 - mae: 0.0160 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0175\n",
      "Epoch 134/180\n",
      "65/65 [==============================] - 103s 2s/step - loss: 8.2015e-04 - mse: 8.2015e-04 - mae: 0.0160 - val_loss: 9.5682e-04 - val_mse: 9.5682e-04 - val_mae: 0.0170\n",
      "Epoch 135/180\n",
      "65/65 [==============================] - 102s 2s/step - loss: 8.1826e-04 - mse: 8.1826e-04 - mae: 0.0159 - val_loss: 9.8780e-04 - val_mse: 9.8780e-04 - val_mae: 0.0169\n",
      "Epoch 136/180\n",
      "65/65 [==============================] - 101s 2s/step - loss: 8.2455e-04 - mse: 8.2455e-04 - mae: 0.0160 - val_loss: 9.8238e-04 - val_mse: 9.8238e-04 - val_mae: 0.0173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 137/180\n",
      "65/65 [==============================] - 107s 2s/step - loss: 8.2664e-04 - mse: 8.2664e-04 - mae: 0.0161 - val_loss: 9.1325e-04 - val_mse: 9.1325e-04 - val_mae: 0.0174\n",
      "Epoch 138/180\n",
      "65/65 [==============================] - 104s 2s/step - loss: 8.2421e-04 - mse: 8.2421e-04 - mae: 0.0159 - val_loss: 9.2614e-04 - val_mse: 9.2614e-04 - val_mae: 0.0172\n",
      "Epoch 139/180\n",
      "65/65 [==============================] - 103s 2s/step - loss: 8.2325e-04 - mse: 8.2325e-04 - mae: 0.0160 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0165\n",
      "Epoch 140/180\n",
      "65/65 [==============================] - 102s 2s/step - loss: 8.1835e-04 - mse: 8.1835e-04 - mae: 0.0160 - val_loss: 9.6365e-04 - val_mse: 9.6365e-04 - val_mae: 0.0178\n",
      "Epoch 141/180\n",
      "65/65 [==============================] - 104s 2s/step - loss: 8.2139e-04 - mse: 8.2139e-04 - mae: 0.0159 - val_loss: 9.1234e-04 - val_mse: 9.1234e-04 - val_mae: 0.0174\n",
      "Epoch 142/180\n",
      "65/65 [==============================] - 104s 2s/step - loss: 8.1106e-04 - mse: 8.1106e-04 - mae: 0.0158 - val_loss: 9.9246e-04 - val_mse: 9.9246e-04 - val_mae: 0.0162\n",
      "Epoch 143/180\n",
      "65/65 [==============================] - 102s 2s/step - loss: 8.2199e-04 - mse: 8.2199e-04 - mae: 0.0160 - val_loss: 9.5854e-04 - val_mse: 9.5854e-04 - val_mae: 0.0168\n",
      "Epoch 144/180\n",
      "65/65 [==============================] - 131s 2s/step - loss: 8.2518e-04 - mse: 8.2518e-04 - mae: 0.0162 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0176\n",
      "Epoch 145/180\n",
      "65/65 [==============================] - 126s 2s/step - loss: 8.1803e-04 - mse: 8.1803e-04 - mae: 0.0160 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0163\n",
      "Epoch 146/180\n",
      "65/65 [==============================] - 97s 1s/step - loss: 8.1637e-04 - mse: 8.1637e-04 - mae: 0.0160 - val_loss: 9.6188e-04 - val_mse: 9.6188e-04 - val_mae: 0.0158\n",
      "Epoch 147/180\n",
      "65/65 [==============================] - 102s 2s/step - loss: 8.1760e-04 - mse: 8.1760e-04 - mae: 0.0161 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0161\n",
      "Epoch 148/180\n",
      "65/65 [==============================] - 103s 2s/step - loss: 8.0878e-04 - mse: 8.0878e-04 - mae: 0.0160 - val_loss: 9.8946e-04 - val_mse: 9.8946e-04 - val_mae: 0.0163\n",
      "Epoch 149/180\n",
      "65/65 [==============================] - 107s 2s/step - loss: 8.2259e-04 - mse: 8.2259e-04 - mae: 0.0160 - val_loss: 9.5779e-04 - val_mse: 9.5779e-04 - val_mae: 0.0170\n",
      "Epoch 150/180\n",
      "65/65 [==============================] - 105s 2s/step - loss: 8.1623e-04 - mse: 8.1623e-04 - mae: 0.0159 - val_loss: 9.9798e-04 - val_mse: 9.9798e-04 - val_mae: 0.0188\n",
      "Epoch 151/180\n",
      "65/65 [==============================] - 95s 1s/step - loss: 8.1706e-04 - mse: 8.1706e-04 - mae: 0.0159 - val_loss: 9.7569e-04 - val_mse: 9.7569e-04 - val_mae: 0.0188\n",
      "Epoch 152/180\n",
      "65/65 [==============================] - 94s 1s/step - loss: 8.0154e-04 - mse: 8.0154e-04 - mae: 0.0157 - val_loss: 9.1477e-04 - val_mse: 9.1477e-04 - val_mae: 0.0164\n",
      "Epoch 153/180\n",
      "65/65 [==============================] - 92s 1s/step - loss: 8.0046e-04 - mse: 8.0046e-04 - mae: 0.0156 - val_loss: 9.2801e-04 - val_mse: 9.2801e-04 - val_mae: 0.0170\n",
      "Epoch 154/180\n",
      "65/65 [==============================] - 95s 1s/step - loss: 7.9697e-04 - mse: 7.9697e-04 - mae: 0.0157 - val_loss: 9.3217e-04 - val_mse: 9.3217e-04 - val_mae: 0.0167\n",
      "Epoch 155/180\n",
      "65/65 [==============================] - 95s 1s/step - loss: 7.9452e-04 - mse: 7.9452e-04 - mae: 0.0155 - val_loss: 9.4523e-04 - val_mse: 9.4523e-04 - val_mae: 0.0171\n",
      "Epoch 156/180\n",
      "65/65 [==============================] - 94s 1s/step - loss: 7.8308e-04 - mse: 7.8308e-04 - mae: 0.0154 - val_loss: 9.4244e-04 - val_mse: 9.4244e-04 - val_mae: 0.0163\n",
      "Epoch 157/180\n",
      "65/65 [==============================] - 94s 1s/step - loss: 7.9915e-04 - mse: 7.9915e-04 - mae: 0.0157 - val_loss: 9.5378e-04 - val_mse: 9.5378e-04 - val_mae: 0.0168\n",
      "Epoch 158/180\n",
      "65/65 [==============================] - 93s 1s/step - loss: 7.8674e-04 - mse: 7.8674e-04 - mae: 0.0154 - val_loss: 9.8932e-04 - val_mse: 9.8932e-04 - val_mae: 0.0163\n",
      "Epoch 159/180\n",
      "65/65 [==============================] - 95s 1s/step - loss: 7.8915e-04 - mse: 7.8915e-04 - mae: 0.0154 - val_loss: 9.8509e-04 - val_mse: 9.8509e-04 - val_mae: 0.0178\n",
      "Epoch 160/180\n",
      "65/65 [==============================] - 97s 1s/step - loss: 7.9672e-04 - mse: 7.9672e-04 - mae: 0.0156 - val_loss: 9.8694e-04 - val_mse: 9.8694e-04 - val_mae: 0.0180\n",
      "Epoch 161/180\n",
      "65/65 [==============================] - 100s 2s/step - loss: 7.9299e-04 - mse: 7.9299e-04 - mae: 0.0156 - val_loss: 9.4912e-04 - val_mse: 9.4912e-04 - val_mae: 0.0181\n",
      "Epoch 162/180\n",
      "65/65 [==============================] - 93s 1s/step - loss: 7.9027e-04 - mse: 7.9027e-04 - mae: 0.0156 - val_loss: 9.2816e-04 - val_mse: 9.2816e-04 - val_mae: 0.0162\n",
      "Epoch 163/180\n",
      "65/65 [==============================] - 91s 1s/step - loss: 7.8924e-04 - mse: 7.8924e-04 - mae: 0.0155 - val_loss: 9.4045e-04 - val_mse: 9.4045e-04 - val_mae: 0.0176\n",
      "Epoch 164/180\n",
      "65/65 [==============================] - 94s 1s/step - loss: 7.8795e-04 - mse: 7.8795e-04 - mae: 0.0156 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0198\n",
      "Epoch 165/180\n",
      "65/65 [==============================] - 112s 2s/step - loss: 7.9844e-04 - mse: 7.9844e-04 - mae: 0.0157 - val_loss: 9.4841e-04 - val_mse: 9.4841e-04 - val_mae: 0.0171\n",
      "Epoch 166/180\n",
      "65/65 [==============================] - 95s 1s/step - loss: 7.9226e-04 - mse: 7.9226e-04 - mae: 0.0158 - val_loss: 9.4649e-04 - val_mse: 9.4649e-04 - val_mae: 0.0160\n",
      "Epoch 167/180\n",
      "65/65 [==============================] - 95s 1s/step - loss: 7.9672e-04 - mse: 7.9672e-04 - mae: 0.0156 - val_loss: 9.1479e-04 - val_mse: 9.1479e-04 - val_mae: 0.0172\n",
      "Epoch 168/180\n",
      "65/65 [==============================] - 98s 2s/step - loss: 7.9546e-04 - mse: 7.9546e-04 - mae: 0.0157 - val_loss: 9.6446e-04 - val_mse: 9.6446e-04 - val_mae: 0.0177\n",
      "Epoch 169/180\n",
      "65/65 [==============================] - 96s 1s/step - loss: 7.7767e-04 - mse: 7.7767e-04 - mae: 0.0153 - val_loss: 9.3309e-04 - val_mse: 9.3309e-04 - val_mae: 0.0165\n",
      "Epoch 170/180\n",
      "65/65 [==============================] - 93s 1s/step - loss: 7.7393e-04 - mse: 7.7393e-04 - mae: 0.0155 - val_loss: 9.2365e-04 - val_mse: 9.2365e-04 - val_mae: 0.0163\n",
      "Epoch 171/180\n",
      "65/65 [==============================] - 113s 2s/step - loss: 8.0097e-04 - mse: 8.0097e-04 - mae: 0.0158 - val_loss: 9.5289e-04 - val_mse: 9.5289e-04 - val_mae: 0.0174\n",
      "Epoch 172/180\n",
      "65/65 [==============================] - 91s 1s/step - loss: 7.6993e-04 - mse: 7.6993e-04 - mae: 0.0152 - val_loss: 9.4101e-04 - val_mse: 9.4101e-04 - val_mae: 0.0163\n",
      "Epoch 173/180\n",
      "65/65 [==============================] - 92s 1s/step - loss: 7.8166e-04 - mse: 7.8166e-04 - mae: 0.0154 - val_loss: 9.7409e-04 - val_mse: 9.7409e-04 - val_mae: 0.0181\n",
      "Epoch 174/180\n",
      "65/65 [==============================] - 94s 1s/step - loss: 7.7964e-04 - mse: 7.7964e-04 - mae: 0.0155 - val_loss: 9.2083e-04 - val_mse: 9.2083e-04 - val_mae: 0.0168\n",
      "Epoch 175/180\n",
      "65/65 [==============================] - 92s 1s/step - loss: 7.6764e-04 - mse: 7.6764e-04 - mae: 0.0153 - val_loss: 9.3610e-04 - val_mse: 9.3610e-04 - val_mae: 0.0160\n",
      "Epoch 176/180\n",
      "65/65 [==============================] - 96s 1s/step - loss: 7.7388e-04 - mse: 7.7388e-04 - mae: 0.0157 - val_loss: 9.3035e-04 - val_mse: 9.3035e-04 - val_mae: 0.0168\n",
      "Epoch 177/180\n",
      "65/65 [==============================] - 93s 1s/step - loss: 7.7159e-04 - mse: 7.7159e-04 - mae: 0.0154 - val_loss: 9.7676e-04 - val_mse: 9.7676e-04 - val_mae: 0.0165\n",
      "Epoch 178/180\n",
      "65/65 [==============================] - 94s 1s/step - loss: 7.7550e-04 - mse: 7.7550e-04 - mae: 0.0154 - val_loss: 9.3798e-04 - val_mse: 9.3798e-04 - val_mae: 0.0169\n",
      "Epoch 179/180\n",
      "65/65 [==============================] - 92s 1s/step - loss: 7.9150e-04 - mse: 7.9150e-04 - mae: 0.0158 - val_loss: 9.6019e-04 - val_mse: 9.6019e-04 - val_mae: 0.0172\n",
      "Epoch 180/180\n",
      "65/65 [==============================] - 96s 1s/step - loss: 7.7063e-04 - mse: 7.7063e-04 - mae: 0.0154 - val_loss: 9.5018e-04 - val_mse: 9.5018e-04 - val_mae: 0.0178\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "# no hidden or one hidden layer\n",
    "parameters = {'n_hidden': [1, 2],\n",
    "              'units': [50, 100, 150, 200]}\n",
    "\n",
    "all_param = ParameterGrid(parameters)\n",
    "\n",
    "# function to split data into correct shape for RNN\n",
    "def split_data(X, y, steps):\n",
    "    X_, y_ = list(), list()\n",
    "    for i in range(steps, len(y)):\n",
    "        X_.append(X[i - steps : i, :])\n",
    "        y_.append(y[i]) \n",
    "    return np.array(X_), np.array(y_)\n",
    "\n",
    "# function to cut data set so it can be divisible by the batch_size\n",
    "def cut_data(data, batch_size):\n",
    "     # see if it is divisivel\n",
    "    condition = data.shape[0] % batch_size\n",
    "    if condition == 0:\n",
    "        return data\n",
    "    else:\n",
    "        return data[: -condition]\n",
    "\n",
    "# divide features and labels\n",
    "X_train = data_train[:, 0:15] \n",
    "y_train = data_train[:, -1]\n",
    "X_test = data_test[:, 0:15] \n",
    "y_test = data_test[:, -1] \n",
    "\n",
    "# divide data into train and test \n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "         X_train, y_train, test_size = 0.15, shuffle=False)\n",
    "\n",
    "# put data into correct shape\n",
    "X_train, y_train = split_data(X_train, y_train, steps)\n",
    "X_test, y_test = split_data(X_test, y_test, steps)\n",
    "X_val, y_val = split_data(X_val, y_val, steps)\n",
    "\n",
    "X_train = cut_data(X_train, batch_size)\n",
    "y_train = cut_data(y_train, batch_size)\n",
    "X_test = cut_data(X_test, batch_size)\n",
    "y_test = cut_data(y_test, batch_size)\n",
    "X_val = cut_data(X_val, batch_size)\n",
    "y_val = cut_data(y_val, batch_size)\n",
    "\n",
    "# design the LSTM\n",
    "def regressor_tunning(kernel_initializer = 'he_normal',\n",
    "                      bias_initializer = initializers.Ones()):\n",
    "    model = Sequential()\n",
    "    if n_hidden == 0:\n",
    "        model.add(LSTM(units = units,                    \n",
    "                       batch_input_shape = (batch_size, steps, features_num), \n",
    "                       stateful = True,\n",
    "                       kernel_initializer = kernel_initializer,\n",
    "                       bias_initializer = bias_initializer))\n",
    "        model.add(LeakyReLU(alpha = 0.2))\n",
    "        model.add(Dropout(0.2))\n",
    "    else:\n",
    "        model.add(LSTM(units = units,                    \n",
    "                       batch_input_shape = (batch_size, steps, features_num), \n",
    "                       stateful = True,\n",
    "                       return_sequences = True,\n",
    "                       kernel_initializer = kernel_initializer,\n",
    "                       bias_initializer = bias_initializer))\n",
    "        model.add(LeakyReLU(alpha = 0.2))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(LSTM(units = units, \n",
    "                       batch_input_shape = (batch_size, steps, features_num), \n",
    "                       stateful = True,\n",
    "                       kernel_initializer = kernel_initializer,\n",
    "                       bias_initializer = bias_initializer))\n",
    "        model.add(LeakyReLU(alpha = 0.2))\n",
    "        model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(loss = 'mse', metrics = ['mse', 'mae'], optimizer = 'Adamax')\n",
    "    return model\n",
    "\n",
    "# inverse of test set should not be inside the loop \n",
    "y_test = (y_test * sc_X.data_range_[15]) + (sc_X.data_min_[15])\n",
    "\n",
    "for i in range(len(all_param)):\n",
    "    \n",
    "    units = all_param[i]['units']\n",
    "    n_hidden = all_param[i]['n_hidden']\n",
    "    \n",
    "    model = regressor_tunning()\n",
    "\n",
    "    # fitting the LSTM to the training set\n",
    "    history = model.fit(X_train,\n",
    "                        y_train, \n",
    "                        batch_size = batch_size, \n",
    "                        epochs = 180,\n",
    "                        shuffle = False, \n",
    "                        validation_data = (X_val, y_val))\n",
    "    \n",
    "    model.reset_states()\n",
    "    \n",
    "    # make new predicitons with test set\n",
    "    y_pred = model.predict(X_test, batch_size = batch_size)\n",
    "    \n",
    "    # prices col = 15\n",
    "    y_pred = (y_pred * sc_X.data_range_[15]) + (sc_X.data_min_[15])\n",
    "\n",
    "    y_pred_list.append(y_pred)\n",
    "    \n",
    "    from sklearn.metrics import mean_squared_error as mse\n",
    "    from sklearn.metrics import mean_absolute_error as mae\n",
    "\n",
    "    rmse_error = mse(y_test, y_pred, squared = False)\n",
    "    mae_error = mae(y_test, y_pred)\n",
    "    \n",
    "    rmse_gen.append(rmse_error)\n",
    "    mae_gen.append(mae_error)\n",
    "    \n",
    "    # =============================================================================\n",
    "    # Metrics evaluation on spike regions\n",
    "    # =============================================================================\n",
    "      \n",
    "    # smal adjustment\n",
    "    y_test = pd.Series(y_test)\n",
    "    y_test.replace(0, 0.0001,inplace = True)\n",
    "\n",
    "    # select y_pred and y_test only for regions with spikes\n",
    "    y_test_spike = (y_test.T * y_spike_occ).T\n",
    "    y_pred_spike = (y_pred.T * y_spike_occ).T\n",
    "    y_test_spike = y_test_spike[y_test_spike != 0]\n",
    "    y_pred_spike = y_pred_spike[y_pred_spike != 0]\n",
    "    \n",
    "    # calculate metric\n",
    "    rmse_spike = mse(y_test_spike, y_pred_spike, squared = False)\n",
    "    mae_spike = mae(y_test_spike, y_pred_spike)\n",
    "    \n",
    "    rmse_spi.append(rmse_spike)\n",
    "    mae_spi.append(mae_spike)\n",
    "    \n",
    "    # =============================================================================\n",
    "    # Metric evaluation on normal regions\n",
    "    # =============================================================================\n",
    "    \n",
    "    # inverse y_spike_occ so the only normal occurences are chosen\n",
    "    y_normal_occ = (y_spike_occ - 1) * (-1)\n",
    "    \n",
    "    # sanity check\n",
    "    y_normal_occ.sum() + y_spike_occ.sum() # gives the correct total \n",
    "    \n",
    "    # select y_pred and y_test only for normal regions\n",
    "    y_test_normal = (y_test.T * y_normal_occ).T\n",
    "    y_pred_normal = (y_pred.T * y_normal_occ).T\n",
    "    y_test_normal = y_test_normal[y_test_normal != 0.00]\n",
    "    y_pred_normal = y_pred_normal[y_pred_normal != 0.00]\n",
    "    \n",
    "    # calculate metric\n",
    "    rmse_normal = mse(y_test_normal, y_pred_normal, squared = False)\n",
    "    mae_normal = mae(y_test_normal, y_pred_normal)\n",
    "    \n",
    "    rmse_nor.append(rmse_normal)\n",
    "    mae_nor.append(mae_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({'all_param':all_param,\n",
    "                        \n",
    "                        'rmse_general': rmse_gen, \n",
    "                 \n",
    "                        'mae_general': mae_gen,\n",
    "                        \n",
    "                        'rmse_spike': rmse_spi,\n",
    "                 \n",
    "                        'mae_spike': mae_spi,\n",
    "                        \n",
    "                        'rmse_normal': rmse_nor,\n",
    "                    \n",
    "                        'mae_normal': mae_nor})\n",
    "\n",
    "results.to_csv('Results_LSTM_2_n_neurons_n_hidden.csv')\n",
    "\n",
    "y_pred = pd.DataFrame({'all_param':all_param,\n",
    "                       'Predicitons': y_pred_list})\n",
    "\n",
    "y_pred.to_csv('Pedictions_LSTM_2_n_neurons_n_hidden.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_e1ad1718_cfeb_11ea_beda_7cb27da2bf47row2_col1 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_e1ad1718_cfeb_11ea_beda_7cb27da2bf47row2_col5 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_e1ad1718_cfeb_11ea_beda_7cb27da2bf47row4_col0 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_e1ad1718_cfeb_11ea_beda_7cb27da2bf47row4_col4 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_e1ad1718_cfeb_11ea_beda_7cb27da2bf47row6_col2 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_e1ad1718_cfeb_11ea_beda_7cb27da2bf47row6_col3 {\n",
       "            background-color:  yellow;\n",
       "        }</style><table id=\"T_e1ad1718_cfeb_11ea_beda_7cb27da2bf47\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >rmse_general</th>        <th class=\"col_heading level0 col1\" >mae_general</th>        <th class=\"col_heading level0 col2\" >rmse_spike</th>        <th class=\"col_heading level0 col3\" >mae_spike</th>        <th class=\"col_heading level0 col4\" >rmse_normal</th>        <th class=\"col_heading level0 col5\" >mae_normal</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_e1ad1718_cfeb_11ea_beda_7cb27da2bf47level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_e1ad1718_cfeb_11ea_beda_7cb27da2bf47row0_col0\" class=\"data row0 col0\" >33.477316</td>\n",
       "                        <td id=\"T_e1ad1718_cfeb_11ea_beda_7cb27da2bf47row0_col1\" class=\"data row0 col1\" >21.932217</td>\n",
       "                        <td id=\"T_e1ad1718_cfeb_11ea_beda_7cb27da2bf47row0_col2\" class=\"data row0 col2\" >29.080643</td>\n",
       "                        <td id=\"T_e1ad1718_cfeb_11ea_beda_7cb27da2bf47row0_col3\" class=\"data row0 col3\" >19.319692</td>\n",
       "                        <td id=\"T_e1ad1718_cfeb_11ea_beda_7cb27da2bf47row0_col4\" class=\"data row0 col4\" >34.082108</td>\n",
       "                        <td id=\"T_e1ad1718_cfeb_11ea_beda_7cb27da2bf47row0_col5\" class=\"data row0 col5\" >22.320319</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e1ad1718_cfeb_11ea_beda_7cb27da2bf47level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_e1ad1718_cfeb_11ea_beda_7cb27da2bf47row1_col0\" class=\"data row1 col0\" >34.741094</td>\n",
       "                        <td id=\"T_e1ad1718_cfeb_11ea_beda_7cb27da2bf47row1_col1\" class=\"data row1 col1\" >20.918178</td>\n",
       "                        <td id=\"T_e1ad1718_cfeb_11ea_beda_7cb27da2bf47row1_col2\" class=\"data row1 col2\" >29.657271</td>\n",
       "                        <td id=\"T_e1ad1718_cfeb_11ea_beda_7cb27da2bf47row1_col3\" class=\"data row1 col3\" >19.011028</td>\n",
       "                        <td id=\"T_e1ad1718_cfeb_11ea_beda_7cb27da2bf47row1_col4\" class=\"data row1 col4\" >35.434148</td>\n",
       "                        <td id=\"T_e1ad1718_cfeb_11ea_beda_7cb27da2bf47row1_col5\" class=\"data row1 col5\" >21.201493</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e1ad1718_cfeb_11ea_beda_7cb27da2bf47level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_e1ad1718_cfeb_11ea_beda_7cb27da2bf47row2_col0\" class=\"data row2 col0\" >32.111232</td>\n",
       "                        <td id=\"T_e1ad1718_cfeb_11ea_beda_7cb27da2bf47row2_col1\" class=\"data row2 col1\" >18.291609</td>\n",
       "                        <td id=\"T_e1ad1718_cfeb_11ea_beda_7cb27da2bf47row2_col2\" class=\"data row2 col2\" >27.949053</td>\n",
       "                        <td id=\"T_e1ad1718_cfeb_11ea_beda_7cb27da2bf47row2_col3\" class=\"data row2 col3\" >17.612630</td>\n",
       "                        <td id=\"T_e1ad1718_cfeb_11ea_beda_7cb27da2bf47row2_col4\" class=\"data row2 col4\" >32.684355</td>\n",
       "                        <td id=\"T_e1ad1718_cfeb_11ea_beda_7cb27da2bf47row2_col5\" class=\"data row2 col5\" >18.392474</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e1ad1718_cfeb_11ea_beda_7cb27da2bf47level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_e1ad1718_cfeb_11ea_beda_7cb27da2bf47row3_col0\" class=\"data row3 col0\" >34.879172</td>\n",
       "                        <td id=\"T_e1ad1718_cfeb_11ea_beda_7cb27da2bf47row3_col1\" class=\"data row3 col1\" >22.396547</td>\n",
       "                        <td id=\"T_e1ad1718_cfeb_11ea_beda_7cb27da2bf47row3_col2\" class=\"data row3 col2\" >31.714437</td>\n",
       "                        <td id=\"T_e1ad1718_cfeb_11ea_beda_7cb27da2bf47row3_col3\" class=\"data row3 col3\" >21.550010</td>\n",
       "                        <td id=\"T_e1ad1718_cfeb_11ea_beda_7cb27da2bf47row3_col4\" class=\"data row3 col4\" >35.325127</td>\n",
       "                        <td id=\"T_e1ad1718_cfeb_11ea_beda_7cb27da2bf47row3_col5\" class=\"data row3 col5\" >22.522304</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e1ad1718_cfeb_11ea_beda_7cb27da2bf47level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_e1ad1718_cfeb_11ea_beda_7cb27da2bf47row4_col0\" class=\"data row4 col0\" >32.058313</td>\n",
       "                        <td id=\"T_e1ad1718_cfeb_11ea_beda_7cb27da2bf47row4_col1\" class=\"data row4 col1\" >18.684872</td>\n",
       "                        <td id=\"T_e1ad1718_cfeb_11ea_beda_7cb27da2bf47row4_col2\" class=\"data row4 col2\" >28.335476</td>\n",
       "                        <td id=\"T_e1ad1718_cfeb_11ea_beda_7cb27da2bf47row4_col3\" class=\"data row4 col3\" >17.182791</td>\n",
       "                        <td id=\"T_e1ad1718_cfeb_11ea_beda_7cb27da2bf47row4_col4\" class=\"data row4 col4\" >32.575080</td>\n",
       "                        <td id=\"T_e1ad1718_cfeb_11ea_beda_7cb27da2bf47row4_col5\" class=\"data row4 col5\" >18.908013</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e1ad1718_cfeb_11ea_beda_7cb27da2bf47level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_e1ad1718_cfeb_11ea_beda_7cb27da2bf47row5_col0\" class=\"data row5 col0\" >32.568460</td>\n",
       "                        <td id=\"T_e1ad1718_cfeb_11ea_beda_7cb27da2bf47row5_col1\" class=\"data row5 col1\" >21.469133</td>\n",
       "                        <td id=\"T_e1ad1718_cfeb_11ea_beda_7cb27da2bf47row5_col2\" class=\"data row5 col2\" >28.648769</td>\n",
       "                        <td id=\"T_e1ad1718_cfeb_11ea_beda_7cb27da2bf47row5_col3\" class=\"data row5 col3\" >20.262399</td>\n",
       "                        <td id=\"T_e1ad1718_cfeb_11ea_beda_7cb27da2bf47row5_col4\" class=\"data row5 col4\" >33.111186</td>\n",
       "                        <td id=\"T_e1ad1718_cfeb_11ea_beda_7cb27da2bf47row5_col5\" class=\"data row5 col5\" >21.648398</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e1ad1718_cfeb_11ea_beda_7cb27da2bf47level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_e1ad1718_cfeb_11ea_beda_7cb27da2bf47row6_col0\" class=\"data row6 col0\" >33.386179</td>\n",
       "                        <td id=\"T_e1ad1718_cfeb_11ea_beda_7cb27da2bf47row6_col1\" class=\"data row6 col1\" >19.919949</td>\n",
       "                        <td id=\"T_e1ad1718_cfeb_11ea_beda_7cb27da2bf47row6_col2\" class=\"data row6 col2\" >27.435225</td>\n",
       "                        <td id=\"T_e1ad1718_cfeb_11ea_beda_7cb27da2bf47row6_col3\" class=\"data row6 col3\" >16.764975</td>\n",
       "                        <td id=\"T_e1ad1718_cfeb_11ea_beda_7cb27da2bf47row6_col4\" class=\"data row6 col4\" >34.181947</td>\n",
       "                        <td id=\"T_e1ad1718_cfeb_11ea_beda_7cb27da2bf47row6_col5\" class=\"data row6 col5\" >20.388634</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e1ad1718_cfeb_11ea_beda_7cb27da2bf47level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_e1ad1718_cfeb_11ea_beda_7cb27da2bf47row7_col0\" class=\"data row7 col0\" >35.457565</td>\n",
       "                        <td id=\"T_e1ad1718_cfeb_11ea_beda_7cb27da2bf47row7_col1\" class=\"data row7 col1\" >23.046199</td>\n",
       "                        <td id=\"T_e1ad1718_cfeb_11ea_beda_7cb27da2bf47row7_col2\" class=\"data row7 col2\" >31.093783</td>\n",
       "                        <td id=\"T_e1ad1718_cfeb_11ea_beda_7cb27da2bf47row7_col3\" class=\"data row7 col3\" >20.815455</td>\n",
       "                        <td id=\"T_e1ad1718_cfeb_11ea_beda_7cb27da2bf47row7_col4\" class=\"data row7 col4\" >36.060802</td>\n",
       "                        <td id=\"T_e1ad1718_cfeb_11ea_beda_7cb27da2bf47row7_col5\" class=\"data row7 col5\" >23.377586</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2209c57b308>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({'rmse_general': rmse_gen, \n",
    "                 \n",
    "                        'mae_general': mae_gen,\n",
    "                        \n",
    "                        'rmse_spike': rmse_spi,\n",
    "                 \n",
    "                        'mae_spike': mae_spi,\n",
    "                        \n",
    "                        'rmse_normal': rmse_nor,\n",
    "                    \n",
    "                        'mae_normal': mae_nor})\n",
    "\n",
    "def highlight_min(s):\n",
    "    '''\n",
    "    highlight the maximum in a Series yellow.\n",
    "    '''\n",
    "    is_max = s == s.min()\n",
    "    return ['background-color: yellow' if v else '' for v in is_max]\n",
    "\n",
    "results.style.apply(highlight_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
