{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Parameter Tunning with Normalization\n",
    "    \n",
    "    RandomizedCV for: hidden layers, \n",
    "    neurons, optimizer, kernel initializer and bias initializer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages (1.0.5)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages (from pandas) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages (from pandas) (1.18.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas) (1.14.0)\n",
      "Requirement already satisfied: sklearn in /home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages (from sklearn) (0.23.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages (from scikit-learn->sklearn) (0.16.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.18.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages (from scikit-learn->sklearn) (2.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install sklearn\n",
    "\n",
    "import pandas as pd;\n",
    "import numpy as np;\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split, cross_validate, cross_val_predict;\n",
    "from sklearn.preprocessing import Normalizer;\n",
    "from sklearn import metrics;\n",
    "from sklearn.model_selection import TimeSeriesSplit;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data; set X and y; fill nan values and split in test and training  data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/pandas/core/generic.py:6245: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "# import data\n",
    "data = pd.read_csv('Data_set_1_smaller.csv', index_col = 0)\n",
    "\n",
    "# filter max values for offer if required\n",
    "print(data.Offers.max()) #max is 2500... no need to filter max values\n",
    "\n",
    "# 2017 & 2018 data\n",
    "data = data.loc[data.index > 2018060000, :]\n",
    "\n",
    "# reset index\n",
    "data.reset_index(inplace = True)\n",
    "data.drop('index', axis = 1, inplace = True)\n",
    "\n",
    "# Divide features and labels\n",
    "X = data.iloc[:, 0:15]\n",
    "y = data.loc[:, 'Offers']\n",
    "\n",
    "# Fill nan values (BEFORE OR AFTER TEST, TRAIN SPLIT!!!)\n",
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "X.fillna(X.mean(), inplace = True)\n",
    "y.fillna(y.mean(), inplace = True)\n",
    "\n",
    "X = X.astype('float64')\n",
    "X = X.round(20)\n",
    "\n",
    "# divide data into train and test with 20% test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "         X, y, test_size=0.1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply feature scaling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_X = Normalizer(norm = 'l2') \n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the Keras libraries and packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential # to initialise the NN\n",
    "from keras.layers import Dense # to create layers\n",
    "from keras.layers import Dropout\n",
    "import keras.optimizers\n",
    "from keras import initializers\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create regressor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# possible debug\n",
    "X_train = np.nan_to_num(X_train)\n",
    "X_test = np.nan_to_num(X_test)\n",
    "\n",
    "def regressor_tunning(n_hidden = 1, n_neurons = 11, optimizer = 'RMSprop', kernel_initializer=\"he_normal\",\n",
    "    bias_initializer= initializers.Ones()):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(output_dim = n_neurons, \n",
    "                    input_dim = 15))\n",
    "    model.add(keras.layers.LeakyReLU(alpha = 0.2))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(Dense(n_neurons))\n",
    "        model.add(keras.layers.LeakyReLU(alpha = 0.2))\n",
    "    model.add(Dense(output_dim = 1, \n",
    "                    activation = 'linear'))\n",
    "    model.compile(loss = 'mse', optimizer = optimizer, metrics = ['mse', 'mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Randomized tunning for the whole ANN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=15)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "1850/1850 [==============================] - 1s 647us/step - loss: 11580.9210 - mse: 11580.9180 - mae: 102.4698\n",
      "Epoch 2/60\n",
      "1850/1850 [==============================] - 0s 49us/step - loss: 2090.5998 - mse: 2090.5996 - mae: 33.0774\n",
      "Epoch 3/60\n",
      "1850/1850 [==============================] - 0s 48us/step - loss: 1038.2455 - mse: 1038.2454 - mae: 22.3205\n",
      "Epoch 4/60\n",
      "1850/1850 [==============================] - 0s 48us/step - loss: 1037.0094 - mse: 1037.0094 - mae: 22.4452\n",
      "Epoch 5/60\n",
      "1850/1850 [==============================] - 0s 48us/step - loss: 1033.4068 - mse: 1033.4069 - mae: 22.3420\n",
      "Epoch 6/60\n",
      "1850/1850 [==============================] - 0s 48us/step - loss: 1032.3506 - mse: 1032.3506 - mae: 22.2860\n",
      "Epoch 7/60\n",
      "1850/1850 [==============================] - 0s 48us/step - loss: 1031.3163 - mse: 1031.3162 - mae: 22.2316\n",
      "Epoch 8/60\n",
      "1850/1850 [==============================] - 0s 48us/step - loss: 1026.4194 - mse: 1026.4194 - mae: 22.1541\n",
      "Epoch 9/60\n",
      "1850/1850 [==============================] - 0s 48us/step - loss: 1026.3203 - mse: 1026.3202 - mae: 22.0183\n",
      "Epoch 10/60\n",
      "1850/1850 [==============================] - 0s 48us/step - loss: 1027.4246 - mse: 1027.4246 - mae: 22.0743\n",
      "Epoch 11/60\n",
      "1850/1850 [==============================] - 0s 48us/step - loss: 1024.9252 - mse: 1024.9253 - mae: 22.0156\n",
      "Epoch 12/60\n",
      "1850/1850 [==============================] - 0s 48us/step - loss: 1020.2535 - mse: 1020.2536 - mae: 21.9943\n",
      "Epoch 13/60\n",
      "1850/1850 [==============================] - 0s 49us/step - loss: 1024.1787 - mse: 1024.1787 - mae: 22.0303\n",
      "Epoch 14/60\n",
      "1850/1850 [==============================] - 0s 48us/step - loss: 1021.6560 - mse: 1021.6559 - mae: 21.9904\n",
      "Epoch 15/60\n",
      "1850/1850 [==============================] - 0s 48us/step - loss: 1023.1157 - mse: 1023.1158 - mae: 21.8781\n",
      "Epoch 16/60\n",
      "1850/1850 [==============================] - 0s 48us/step - loss: 1022.0107 - mse: 1022.0106 - mae: 21.9173\n",
      "Epoch 17/60\n",
      "1850/1850 [==============================] - 0s 48us/step - loss: 1016.8600 - mse: 1016.8601 - mae: 21.7576\n",
      "Epoch 18/60\n",
      "1850/1850 [==============================] - 0s 48us/step - loss: 1019.9462 - mse: 1019.9461 - mae: 21.8136\n",
      "Epoch 19/60\n",
      "1850/1850 [==============================] - 0s 49us/step - loss: 1020.5111 - mse: 1020.5112 - mae: 21.7969\n",
      "Epoch 20/60\n",
      "1850/1850 [==============================] - 0s 48us/step - loss: 1017.7401 - mse: 1017.7401 - mae: 21.8757\n",
      "Epoch 21/60\n",
      "1850/1850 [==============================] - 0s 48us/step - loss: 1017.3887 - mse: 1017.3884 - mae: 21.7675\n",
      "Epoch 22/60\n",
      "1850/1850 [==============================] - 0s 49us/step - loss: 1015.1892 - mse: 1015.1892 - mae: 21.7005\n",
      "Epoch 23/60\n",
      "1850/1850 [==============================] - 0s 48us/step - loss: 1014.9072 - mse: 1014.9071 - mae: 21.7290\n",
      "Epoch 24/60\n",
      "1850/1850 [==============================] - 0s 48us/step - loss: 1013.6650 - mse: 1013.6649 - mae: 21.7311\n",
      "Epoch 25/60\n",
      "1850/1850 [==============================] - 0s 48us/step - loss: 1011.6211 - mse: 1011.6210 - mae: 21.6064\n",
      "Epoch 26/60\n",
      "1850/1850 [==============================] - 0s 48us/step - loss: 1014.5033 - mse: 1014.5032 - mae: 21.6429\n",
      "Epoch 27/60\n",
      "1850/1850 [==============================] - 0s 48us/step - loss: 1013.7371 - mse: 1013.7369 - mae: 21.6968\n",
      "Epoch 28/60\n",
      "1850/1850 [==============================] - 0s 48us/step - loss: 1013.1041 - mse: 1013.1041 - mae: 21.5727\n",
      "Epoch 29/60\n",
      "1850/1850 [==============================] - 0s 48us/step - loss: 1014.8368 - mse: 1014.8367 - mae: 21.7130\n",
      "Epoch 30/60\n",
      "1850/1850 [==============================] - 0s 48us/step - loss: 1012.6053 - mse: 1012.6052 - mae: 21.6001\n",
      "Epoch 31/60\n",
      "1850/1850 [==============================] - 0s 48us/step - loss: 1015.5398 - mse: 1015.5397 - mae: 21.6301\n",
      "Epoch 32/60\n",
      "1850/1850 [==============================] - 0s 48us/step - loss: 1012.1902 - mse: 1012.1901 - mae: 21.5527\n",
      "Epoch 33/60\n",
      "1850/1850 [==============================] - 0s 48us/step - loss: 1014.5291 - mse: 1014.5289 - mae: 21.6448\n",
      "Epoch 34/60\n",
      "1850/1850 [==============================] - 0s 48us/step - loss: 1010.8232 - mse: 1010.8232 - mae: 21.6012\n",
      "Epoch 35/60\n",
      "1850/1850 [==============================] - 0s 48us/step - loss: 1011.0143 - mse: 1011.0143 - mae: 21.5305\n",
      "Epoch 36/60\n",
      "1850/1850 [==============================] - 0s 48us/step - loss: 1009.5743 - mse: 1009.5743 - mae: 21.5690\n",
      "Epoch 37/60\n",
      "1850/1850 [==============================] - 0s 48us/step - loss: 1012.2019 - mse: 1012.2019 - mae: 21.5764\n",
      "Epoch 38/60\n",
      "1850/1850 [==============================] - 0s 48us/step - loss: 1011.1769 - mse: 1011.1770 - mae: 21.5456\n",
      "Epoch 39/60\n",
      "1850/1850 [==============================] - 0s 48us/step - loss: 1006.6353 - mse: 1006.6353 - mae: 21.4647\n",
      "Epoch 40/60\n",
      "1850/1850 [==============================] - 0s 48us/step - loss: 1012.8720 - mse: 1012.8722 - mae: 21.5776\n",
      "Epoch 41/60\n",
      "1850/1850 [==============================] - 0s 48us/step - loss: 1011.5164 - mse: 1011.5165 - mae: 21.6070\n",
      "Epoch 42/60\n",
      "1850/1850 [==============================] - 0s 48us/step - loss: 1009.1052 - mse: 1009.1052 - mae: 21.5077\n",
      "Epoch 43/60\n",
      "1850/1850 [==============================] - 0s 48us/step - loss: 1007.8383 - mse: 1007.8382 - mae: 21.5147\n",
      "Epoch 44/60\n",
      "1850/1850 [==============================] - 0s 48us/step - loss: 1005.2905 - mse: 1005.2905 - mae: 21.4553\n",
      "Epoch 45/60\n",
      "1850/1850 [==============================] - 0s 48us/step - loss: 1011.5661 - mse: 1011.5661 - mae: 21.5752\n",
      "Epoch 46/60\n",
      "1850/1850 [==============================] - 0s 48us/step - loss: 1012.0015 - mse: 1012.0018 - mae: 21.4534\n",
      "Epoch 47/60\n",
      "1850/1850 [==============================] - 0s 47us/step - loss: 1005.5396 - mse: 1005.5399 - mae: 21.4891\n",
      "Epoch 48/60\n",
      "1850/1850 [==============================] - 0s 48us/step - loss: 1009.2638 - mse: 1009.2639 - mae: 21.4781\n",
      "Epoch 49/60\n",
      "1850/1850 [==============================] - 0s 48us/step - loss: 1004.7450 - mse: 1004.7451 - mae: 21.4071\n",
      "Epoch 50/60\n",
      "1850/1850 [==============================] - 0s 48us/step - loss: 1006.6540 - mse: 1006.6539 - mae: 21.4960\n",
      "Epoch 51/60\n",
      "1850/1850 [==============================] - 0s 47us/step - loss: 1005.8237 - mse: 1005.8239 - mae: 21.4398\n",
      "Epoch 52/60\n",
      "1850/1850 [==============================] - 0s 48us/step - loss: 1007.9687 - mse: 1007.9690 - mae: 21.4894\n",
      "Epoch 53/60\n",
      "1850/1850 [==============================] - 0s 48us/step - loss: 1004.8138 - mse: 1004.8138 - mae: 21.5059\n",
      "Epoch 54/60\n",
      "1850/1850 [==============================] - 0s 48us/step - loss: 1006.7575 - mse: 1006.7575 - mae: 21.4489\n",
      "Epoch 55/60\n",
      "1850/1850 [==============================] - 0s 48us/step - loss: 1007.6702 - mse: 1007.6702 - mae: 21.5015\n",
      "Epoch 56/60\n",
      "1850/1850 [==============================] - 0s 48us/step - loss: 1005.9163 - mse: 1005.9163 - mae: 21.4778\n",
      "Epoch 57/60\n",
      "1850/1850 [==============================] - 0s 48us/step - loss: 1005.4730 - mse: 1005.4728 - mae: 21.4371\n",
      "Epoch 58/60\n",
      "1850/1850 [==============================] - 0s 48us/step - loss: 1008.7457 - mse: 1008.7456 - mae: 21.4953\n",
      "Epoch 59/60\n",
      "1850/1850 [==============================] - 0s 48us/step - loss: 1004.3317 - mse: 1004.3318 - mae: 21.4360\n",
      "Epoch 60/60\n",
      "1850/1850 [==============================] - 0s 48us/step - loss: 1007.5953 - mse: 1007.5955 - mae: 21.4161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=15)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "3699/3699 [==============================] - 1s 301us/step - loss: 6362.1636 - mse: 6362.1650 - mae: 64.2643\n",
      "Epoch 2/60\n",
      "3699/3699 [==============================] - 0s 48us/step - loss: 1139.5512 - mse: 1139.5511 - mae: 22.7663\n",
      "Epoch 3/60\n",
      "3699/3699 [==============================] - 0s 48us/step - loss: 1138.0285 - mse: 1138.0282 - mae: 22.8165\n",
      "Epoch 4/60\n",
      "3699/3699 [==============================] - 0s 48us/step - loss: 1132.0602 - mse: 1132.0604 - mae: 22.6361\n",
      "Epoch 5/60\n",
      "3699/3699 [==============================] - 0s 49us/step - loss: 1131.5117 - mse: 1131.5118 - mae: 22.6547\n",
      "Epoch 6/60\n",
      "3699/3699 [==============================] - 0s 49us/step - loss: 1130.6898 - mse: 1130.6898 - mae: 22.6984\n",
      "Epoch 7/60\n",
      "3699/3699 [==============================] - 0s 49us/step - loss: 1134.5932 - mse: 1134.5933 - mae: 22.7119\n",
      "Epoch 8/60\n",
      "3699/3699 [==============================] - 0s 48us/step - loss: 1132.2801 - mse: 1132.2803 - mae: 22.7014\n",
      "Epoch 9/60\n",
      "3699/3699 [==============================] - 0s 49us/step - loss: 1129.8464 - mse: 1129.8464 - mae: 22.7380\n",
      "Epoch 10/60\n",
      "3699/3699 [==============================] - 0s 48us/step - loss: 1129.2470 - mse: 1129.2471 - mae: 22.7292\n",
      "Epoch 11/60\n",
      "3699/3699 [==============================] - 0s 48us/step - loss: 1128.0187 - mse: 1128.0188 - mae: 22.6030\n",
      "Epoch 12/60\n",
      "3699/3699 [==============================] - 0s 48us/step - loss: 1127.6655 - mse: 1127.6654 - mae: 22.6689\n",
      "Epoch 13/60\n",
      "3699/3699 [==============================] - 0s 48us/step - loss: 1124.8882 - mse: 1124.8883 - mae: 22.6424\n",
      "Epoch 14/60\n",
      "3699/3699 [==============================] - 0s 49us/step - loss: 1127.0153 - mse: 1127.0154 - mae: 22.6780\n",
      "Epoch 15/60\n",
      "3699/3699 [==============================] - 0s 49us/step - loss: 1128.2210 - mse: 1128.2209 - mae: 22.7367\n",
      "Epoch 16/60\n",
      "3699/3699 [==============================] - 0s 48us/step - loss: 1124.1115 - mse: 1124.1119 - mae: 22.5958\n",
      "Epoch 17/60\n",
      "3699/3699 [==============================] - 0s 49us/step - loss: 1125.0210 - mse: 1125.0209 - mae: 22.6824\n",
      "Epoch 18/60\n",
      "3699/3699 [==============================] - 0s 48us/step - loss: 1124.5670 - mse: 1124.5670 - mae: 22.6123\n",
      "Epoch 19/60\n",
      "3699/3699 [==============================] - 0s 49us/step - loss: 1124.0937 - mse: 1124.0936 - mae: 22.6526\n",
      "Epoch 20/60\n",
      "3699/3699 [==============================] - 0s 48us/step - loss: 1123.7500 - mse: 1123.7501 - mae: 22.6200\n",
      "Epoch 21/60\n",
      "3699/3699 [==============================] - 0s 48us/step - loss: 1122.9240 - mse: 1122.9240 - mae: 22.6628\n",
      "Epoch 22/60\n",
      "3699/3699 [==============================] - 0s 48us/step - loss: 1123.7494 - mse: 1123.7493 - mae: 22.6016\n",
      "Epoch 23/60\n",
      "3699/3699 [==============================] - 0s 48us/step - loss: 1123.3339 - mse: 1123.3337 - mae: 22.6415\n",
      "Epoch 24/60\n",
      "3699/3699 [==============================] - 0s 48us/step - loss: 1123.2354 - mse: 1123.2356 - mae: 22.5614\n",
      "Epoch 25/60\n",
      "3699/3699 [==============================] - 0s 49us/step - loss: 1123.8261 - mse: 1123.8263 - mae: 22.6558\n",
      "Epoch 26/60\n",
      "3699/3699 [==============================] - 0s 49us/step - loss: 1119.9241 - mse: 1119.9240 - mae: 22.5970\n",
      "Epoch 27/60\n",
      "3699/3699 [==============================] - 0s 49us/step - loss: 1121.6309 - mse: 1121.6311 - mae: 22.6485\n",
      "Epoch 28/60\n",
      "3699/3699 [==============================] - 0s 48us/step - loss: 1121.4226 - mse: 1121.4227 - mae: 22.5648\n",
      "Epoch 29/60\n",
      "3699/3699 [==============================] - 0s 48us/step - loss: 1121.4161 - mse: 1121.4155 - mae: 22.5869\n",
      "Epoch 30/60\n",
      "3699/3699 [==============================] - 0s 48us/step - loss: 1121.4771 - mse: 1121.4771 - mae: 22.6170\n",
      "Epoch 31/60\n",
      "3699/3699 [==============================] - 0s 48us/step - loss: 1121.5765 - mse: 1121.5764 - mae: 22.5255\n",
      "Epoch 32/60\n",
      "3699/3699 [==============================] - 0s 48us/step - loss: 1121.5111 - mse: 1121.5115 - mae: 22.6613\n",
      "Epoch 33/60\n",
      "3699/3699 [==============================] - 0s 48us/step - loss: 1121.9644 - mse: 1121.9642 - mae: 22.5768\n",
      "Epoch 34/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1120.6833 - mse: 1120.6835 - mae: 22.5922\n",
      "Epoch 35/60\n",
      "3699/3699 [==============================] - 0s 48us/step - loss: 1118.6644 - mse: 1118.6644 - mae: 22.5861\n",
      "Epoch 36/60\n",
      "3699/3699 [==============================] - 0s 48us/step - loss: 1123.0328 - mse: 1123.0331 - mae: 22.6533\n",
      "Epoch 37/60\n",
      "3699/3699 [==============================] - 0s 48us/step - loss: 1119.8867 - mse: 1119.8867 - mae: 22.5472\n",
      "Epoch 38/60\n",
      "3699/3699 [==============================] - 0s 48us/step - loss: 1121.6606 - mse: 1121.6608 - mae: 22.5224\n",
      "Epoch 39/60\n",
      "3699/3699 [==============================] - 0s 48us/step - loss: 1118.8131 - mse: 1118.8131 - mae: 22.4967\n",
      "Epoch 40/60\n",
      "3699/3699 [==============================] - 0s 48us/step - loss: 1120.4001 - mse: 1120.4001 - mae: 22.6605\n",
      "Epoch 41/60\n",
      "3699/3699 [==============================] - 0s 48us/step - loss: 1120.6233 - mse: 1120.6232 - mae: 22.6214\n",
      "Epoch 42/60\n",
      "3699/3699 [==============================] - 0s 48us/step - loss: 1119.0397 - mse: 1119.0398 - mae: 22.5070\n",
      "Epoch 43/60\n",
      "3699/3699 [==============================] - 0s 49us/step - loss: 1120.7408 - mse: 1120.7410 - mae: 22.5490\n",
      "Epoch 44/60\n",
      "3699/3699 [==============================] - 0s 49us/step - loss: 1119.1363 - mse: 1119.1361 - mae: 22.5386\n",
      "Epoch 45/60\n",
      "3699/3699 [==============================] - 0s 48us/step - loss: 1118.8174 - mse: 1118.8176 - mae: 22.5974\n",
      "Epoch 46/60\n",
      "3699/3699 [==============================] - 0s 48us/step - loss: 1118.1908 - mse: 1118.1912 - mae: 22.5066\n",
      "Epoch 47/60\n",
      "3699/3699 [==============================] - 0s 49us/step - loss: 1118.8713 - mse: 1118.8711 - mae: 22.4923\n",
      "Epoch 48/60\n",
      "3699/3699 [==============================] - 0s 48us/step - loss: 1115.6522 - mse: 1115.6522 - mae: 22.4905\n",
      "Epoch 49/60\n",
      "3699/3699 [==============================] - 0s 48us/step - loss: 1120.2595 - mse: 1120.2595 - mae: 22.5602\n",
      "Epoch 50/60\n",
      "3699/3699 [==============================] - 0s 48us/step - loss: 1119.0602 - mse: 1119.0602 - mae: 22.5100\n",
      "Epoch 51/60\n",
      "3699/3699 [==============================] - 0s 49us/step - loss: 1119.9839 - mse: 1119.9844 - mae: 22.5571\n",
      "Epoch 52/60\n",
      "3699/3699 [==============================] - 0s 49us/step - loss: 1120.9933 - mse: 1120.9933 - mae: 22.5432\n",
      "Epoch 53/60\n",
      "3699/3699 [==============================] - 0s 48us/step - loss: 1118.7495 - mse: 1118.7498 - mae: 22.5813\n",
      "Epoch 54/60\n",
      "3699/3699 [==============================] - 0s 49us/step - loss: 1113.1919 - mse: 1113.1918 - mae: 22.4708\n",
      "Epoch 55/60\n",
      "3699/3699 [==============================] - 0s 48us/step - loss: 1117.3936 - mse: 1117.3936 - mae: 22.5766\n",
      "Epoch 56/60\n",
      "3699/3699 [==============================] - 0s 48us/step - loss: 1119.2617 - mse: 1119.2620 - mae: 22.4839\n",
      "Epoch 57/60\n",
      "3699/3699 [==============================] - 0s 49us/step - loss: 1116.8312 - mse: 1116.8314 - mae: 22.5210\n",
      "Epoch 58/60\n",
      "3699/3699 [==============================] - 0s 48us/step - loss: 1117.2719 - mse: 1117.2720 - mae: 22.4960\n",
      "Epoch 59/60\n",
      "3699/3699 [==============================] - 0s 48us/step - loss: 1119.1654 - mse: 1119.1652 - mae: 22.5365\n",
      "Epoch 60/60\n",
      "3699/3699 [==============================] - 0s 48us/step - loss: 1119.2076 - mse: 1119.2076 - mae: 22.5210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=15)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "5548/5548 [==============================] - 1s 227us/step - loss: 5815.4958 - mse: 5815.4961 - mae: 55.5559\n",
      "Epoch 2/60\n",
      "5548/5548 [==============================] - 0s 48us/step - loss: 1710.2640 - mse: 1710.2635 - mae: 25.2728\n",
      "Epoch 3/60\n",
      "5548/5548 [==============================] - 0s 48us/step - loss: 1708.6371 - mse: 1708.6368 - mae: 25.2671\n",
      "Epoch 4/60\n",
      "5548/5548 [==============================] - 0s 48us/step - loss: 1704.7490 - mse: 1704.7489 - mae: 25.1533\n",
      "Epoch 5/60\n",
      "5548/5548 [==============================] - 0s 48us/step - loss: 1702.0723 - mse: 1702.0721 - mae: 25.1355\n",
      "Epoch 6/60\n",
      "5548/5548 [==============================] - 0s 48us/step - loss: 1699.2488 - mse: 1699.2485 - mae: 25.1611\n",
      "Epoch 7/60\n",
      "5548/5548 [==============================] - 0s 48us/step - loss: 1697.0722 - mse: 1697.0725 - mae: 25.0890\n",
      "Epoch 8/60\n",
      "5548/5548 [==============================] - 0s 48us/step - loss: 1697.6994 - mse: 1697.6993 - mae: 25.1036\n",
      "Epoch 9/60\n",
      "5548/5548 [==============================] - 0s 48us/step - loss: 1696.0411 - mse: 1696.0405 - mae: 25.0949\n",
      "Epoch 10/60\n",
      "5548/5548 [==============================] - 0s 48us/step - loss: 1690.9979 - mse: 1690.9977 - mae: 25.0394\n",
      "Epoch 11/60\n",
      "5548/5548 [==============================] - 0s 48us/step - loss: 1686.5265 - mse: 1686.5267 - mae: 25.0567\n",
      "Epoch 12/60\n",
      "5548/5548 [==============================] - 0s 49us/step - loss: 1686.7006 - mse: 1686.7001 - mae: 25.0232\n",
      "Epoch 13/60\n",
      "5548/5548 [==============================] - 0s 49us/step - loss: 1689.0003 - mse: 1689.0001 - mae: 24.9818\n",
      "Epoch 14/60\n",
      "5548/5548 [==============================] - 0s 49us/step - loss: 1687.4172 - mse: 1687.4172 - mae: 24.9762\n",
      "Epoch 15/60\n",
      "5548/5548 [==============================] - 0s 49us/step - loss: 1680.3001 - mse: 1680.3003 - mae: 25.0301\n",
      "Epoch 16/60\n",
      "5548/5548 [==============================] - 0s 49us/step - loss: 1682.1351 - mse: 1682.1348 - mae: 25.0410\n",
      "Epoch 17/60\n",
      "5548/5548 [==============================] - 0s 49us/step - loss: 1681.3677 - mse: 1681.3679 - mae: 24.9937\n",
      "Epoch 18/60\n",
      "5548/5548 [==============================] - 0s 49us/step - loss: 1677.8039 - mse: 1677.8036 - mae: 24.9464\n",
      "Epoch 19/60\n",
      "5548/5548 [==============================] - 0s 49us/step - loss: 1678.4354 - mse: 1678.4347 - mae: 24.9934\n",
      "Epoch 20/60\n",
      "5548/5548 [==============================] - 0s 49us/step - loss: 1677.3978 - mse: 1677.3983 - mae: 24.9148\n",
      "Epoch 21/60\n",
      "5548/5548 [==============================] - 0s 49us/step - loss: 1677.4907 - mse: 1677.4905 - mae: 24.9374\n",
      "Epoch 22/60\n",
      "5548/5548 [==============================] - 0s 49us/step - loss: 1679.7488 - mse: 1679.7484 - mae: 24.9997\n",
      "Epoch 23/60\n",
      "5548/5548 [==============================] - 0s 48us/step - loss: 1674.2620 - mse: 1674.2621 - mae: 24.9613\n",
      "Epoch 24/60\n",
      "5548/5548 [==============================] - 0s 49us/step - loss: 1676.3033 - mse: 1676.3032 - mae: 24.9514\n",
      "Epoch 25/60\n",
      "5548/5548 [==============================] - 0s 49us/step - loss: 1676.2837 - mse: 1676.2843 - mae: 24.9677\n",
      "Epoch 26/60\n",
      "5548/5548 [==============================] - 0s 49us/step - loss: 1673.8141 - mse: 1673.8143 - mae: 24.9511\n",
      "Epoch 27/60\n",
      "5548/5548 [==============================] - 0s 49us/step - loss: 1674.9775 - mse: 1674.9777 - mae: 24.9192\n",
      "Epoch 28/60\n",
      "5548/5548 [==============================] - 0s 48us/step - loss: 1675.0710 - mse: 1675.0708 - mae: 24.9678\n",
      "Epoch 29/60\n",
      "5548/5548 [==============================] - 0s 50us/step - loss: 1676.8578 - mse: 1676.8582 - mae: 25.0220\n",
      "Epoch 30/60\n",
      "5548/5548 [==============================] - 0s 48us/step - loss: 1676.5534 - mse: 1676.5537 - mae: 24.9795\n",
      "Epoch 31/60\n",
      "5548/5548 [==============================] - 0s 48us/step - loss: 1676.0039 - mse: 1676.0039 - mae: 24.9823\n",
      "Epoch 32/60\n",
      "5548/5548 [==============================] - 0s 49us/step - loss: 1673.7330 - mse: 1673.7333 - mae: 24.8839\n",
      "Epoch 33/60\n",
      "5548/5548 [==============================] - 0s 49us/step - loss: 1675.5899 - mse: 1675.5896 - mae: 24.9675\n",
      "Epoch 34/60\n",
      "5548/5548 [==============================] - 0s 49us/step - loss: 1674.7208 - mse: 1674.7206 - mae: 24.9767\n",
      "Epoch 35/60\n",
      "5548/5548 [==============================] - 0s 49us/step - loss: 1672.4963 - mse: 1672.4962 - mae: 24.9361\n",
      "Epoch 36/60\n",
      "5548/5548 [==============================] - 0s 49us/step - loss: 1673.4370 - mse: 1673.4368 - mae: 24.9784\n",
      "Epoch 37/60\n",
      "5548/5548 [==============================] - 0s 49us/step - loss: 1671.1716 - mse: 1671.1716 - mae: 24.9161\n",
      "Epoch 38/60\n",
      "5548/5548 [==============================] - 0s 49us/step - loss: 1672.4567 - mse: 1672.4565 - mae: 24.9218\n",
      "Epoch 39/60\n",
      "5548/5548 [==============================] - 0s 49us/step - loss: 1673.7359 - mse: 1673.7363 - mae: 24.8752\n",
      "Epoch 40/60\n",
      "5548/5548 [==============================] - 0s 49us/step - loss: 1669.6015 - mse: 1669.6017 - mae: 24.9689\n",
      "Epoch 41/60\n",
      "5548/5548 [==============================] - 0s 49us/step - loss: 1671.8028 - mse: 1671.8022 - mae: 24.9078\n",
      "Epoch 42/60\n",
      "5548/5548 [==============================] - 0s 49us/step - loss: 1672.1292 - mse: 1672.1290 - mae: 24.9205\n",
      "Epoch 43/60\n",
      "5548/5548 [==============================] - 0s 49us/step - loss: 1674.6427 - mse: 1674.6427 - mae: 25.0615\n",
      "Epoch 44/60\n",
      "5548/5548 [==============================] - 0s 51us/step - loss: 1671.5551 - mse: 1671.5549 - mae: 24.9134\n",
      "Epoch 45/60\n",
      "5548/5548 [==============================] - 0s 58us/step - loss: 1673.3207 - mse: 1673.3204 - mae: 24.9778\n",
      "Epoch 46/60\n",
      "5548/5548 [==============================] - 0s 54us/step - loss: 1672.2823 - mse: 1672.2822 - mae: 24.9426\n",
      "Epoch 47/60\n",
      "5548/5548 [==============================] - 0s 49us/step - loss: 1671.2384 - mse: 1671.2384 - mae: 24.9364\n",
      "Epoch 48/60\n",
      "5548/5548 [==============================] - 0s 48us/step - loss: 1674.0076 - mse: 1674.0072 - mae: 24.9186\n",
      "Epoch 49/60\n",
      "5548/5548 [==============================] - 0s 48us/step - loss: 1671.2337 - mse: 1671.2338 - mae: 24.9322\n",
      "Epoch 50/60\n",
      "5548/5548 [==============================] - 0s 48us/step - loss: 1668.3930 - mse: 1668.3931 - mae: 24.9065\n",
      "Epoch 51/60\n",
      "5548/5548 [==============================] - 0s 48us/step - loss: 1672.0847 - mse: 1672.0848 - mae: 24.9309\n",
      "Epoch 52/60\n",
      "5548/5548 [==============================] - 0s 48us/step - loss: 1670.6127 - mse: 1670.6127 - mae: 24.9053\n",
      "Epoch 53/60\n",
      "5548/5548 [==============================] - 0s 48us/step - loss: 1670.3987 - mse: 1670.3987 - mae: 24.8376\n",
      "Epoch 54/60\n",
      "5548/5548 [==============================] - 0s 48us/step - loss: 1672.0909 - mse: 1672.0908 - mae: 25.0232\n",
      "Epoch 55/60\n",
      "5548/5548 [==============================] - 0s 49us/step - loss: 1671.3349 - mse: 1671.3352 - mae: 24.9558\n",
      "Epoch 56/60\n",
      "5548/5548 [==============================] - 0s 48us/step - loss: 1671.9104 - mse: 1671.9104 - mae: 24.9537\n",
      "Epoch 57/60\n",
      "5548/5548 [==============================] - 0s 48us/step - loss: 1669.6785 - mse: 1669.6786 - mae: 24.9186\n",
      "Epoch 58/60\n",
      "5548/5548 [==============================] - 0s 48us/step - loss: 1669.5779 - mse: 1669.5782 - mae: 24.8818\n",
      "Epoch 59/60\n",
      "5548/5548 [==============================] - 0s 48us/step - loss: 1671.3683 - mse: 1671.3680 - mae: 24.9181\n",
      "Epoch 60/60\n",
      "5548/5548 [==============================] - 0s 48us/step - loss: 1671.7469 - mse: 1671.7471 - mae: 24.8773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=15)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "7397/7397 [==============================] - 1s 177us/step - loss: 4918.3390 - mse: 4918.3384 - mae: 49.4954\n",
      "Epoch 2/60\n",
      "7397/7397 [==============================] - 0s 49us/step - loss: 1666.1964 - mse: 1666.1962 - mae: 25.6234\n",
      "Epoch 3/60\n",
      "7397/7397 [==============================] - 0s 48us/step - loss: 1656.3755 - mse: 1656.3751 - mae: 25.5782\n",
      "Epoch 4/60\n",
      "7397/7397 [==============================] - 0s 48us/step - loss: 1650.0027 - mse: 1650.0031 - mae: 25.4945\n",
      "Epoch 5/60\n",
      "7397/7397 [==============================] - 0s 49us/step - loss: 1649.3381 - mse: 1649.3385 - mae: 25.5566\n",
      "Epoch 6/60\n",
      "7397/7397 [==============================] - 0s 48us/step - loss: 1644.3119 - mse: 1644.3119 - mae: 25.4307\n",
      "Epoch 7/60\n",
      "7397/7397 [==============================] - 0s 48us/step - loss: 1638.5956 - mse: 1638.5961 - mae: 25.4427\n",
      "Epoch 8/60\n",
      "7397/7397 [==============================] - 0s 48us/step - loss: 1638.3247 - mse: 1638.3247 - mae: 25.4832\n",
      "Epoch 9/60\n",
      "7397/7397 [==============================] - 0s 48us/step - loss: 1633.8765 - mse: 1633.8759 - mae: 25.4524\n",
      "Epoch 10/60\n",
      "7397/7397 [==============================] - 0s 48us/step - loss: 1631.0682 - mse: 1631.0680 - mae: 25.4051\n",
      "Epoch 11/60\n",
      "7397/7397 [==============================] - 0s 48us/step - loss: 1629.6320 - mse: 1629.6326 - mae: 25.3540\n",
      "Epoch 12/60\n",
      "7397/7397 [==============================] - 0s 48us/step - loss: 1628.1131 - mse: 1628.1132 - mae: 25.4132\n",
      "Epoch 13/60\n",
      "7397/7397 [==============================] - 0s 48us/step - loss: 1625.2878 - mse: 1625.2878 - mae: 25.3337\n",
      "Epoch 14/60\n",
      "7397/7397 [==============================] - 0s 48us/step - loss: 1625.1244 - mse: 1625.1250 - mae: 25.3653\n",
      "Epoch 15/60\n",
      "7397/7397 [==============================] - 0s 48us/step - loss: 1623.9992 - mse: 1623.9995 - mae: 25.3302\n",
      "Epoch 16/60\n",
      "7397/7397 [==============================] - 0s 49us/step - loss: 1621.5970 - mse: 1621.5973 - mae: 25.5096\n",
      "Epoch 17/60\n",
      "7397/7397 [==============================] - 0s 48us/step - loss: 1621.2861 - mse: 1621.2858 - mae: 25.3237\n",
      "Epoch 18/60\n",
      "7397/7397 [==============================] - 0s 48us/step - loss: 1620.3116 - mse: 1620.3119 - mae: 25.3329\n",
      "Epoch 19/60\n",
      "7397/7397 [==============================] - ETA: 0s - loss: 1681.6875 - mse: 1681.6869 - mae: 25.43 - 0s 48us/step - loss: 1620.3017 - mse: 1620.3010 - mae: 25.3215\n",
      "Epoch 20/60\n",
      "7397/7397 [==============================] - 0s 48us/step - loss: 1618.2943 - mse: 1618.2942 - mae: 25.3189\n",
      "Epoch 21/60\n",
      "7397/7397 [==============================] - 0s 49us/step - loss: 1619.3484 - mse: 1619.3481 - mae: 25.3588\n",
      "Epoch 22/60\n",
      "7397/7397 [==============================] - 0s 49us/step - loss: 1619.1423 - mse: 1619.1423 - mae: 25.3498\n",
      "Epoch 23/60\n",
      "7397/7397 [==============================] - 0s 48us/step - loss: 1620.2934 - mse: 1620.2938 - mae: 25.4181\n",
      "Epoch 24/60\n",
      "7397/7397 [==============================] - 0s 48us/step - loss: 1619.7851 - mse: 1619.7852 - mae: 25.3608\n",
      "Epoch 25/60\n",
      "7397/7397 [==============================] - 0s 48us/step - loss: 1617.5939 - mse: 1617.5934 - mae: 25.3700\n",
      "Epoch 26/60\n",
      "7397/7397 [==============================] - 0s 48us/step - loss: 1619.2462 - mse: 1619.2465 - mae: 25.3878\n",
      "Epoch 27/60\n",
      "7397/7397 [==============================] - 0s 48us/step - loss: 1620.3109 - mse: 1620.3110 - mae: 25.3624\n",
      "Epoch 28/60\n",
      "7397/7397 [==============================] - 0s 48us/step - loss: 1617.7473 - mse: 1617.7472 - mae: 25.4154\n",
      "Epoch 29/60\n",
      "7397/7397 [==============================] - 0s 48us/step - loss: 1619.7040 - mse: 1619.7047 - mae: 25.3802\n",
      "Epoch 30/60\n",
      "7397/7397 [==============================] - 0s 48us/step - loss: 1617.2354 - mse: 1617.2352 - mae: 25.3828\n",
      "Epoch 31/60\n",
      "7397/7397 [==============================] - 0s 49us/step - loss: 1619.1317 - mse: 1619.1317 - mae: 25.2756\n",
      "Epoch 32/60\n",
      "7397/7397 [==============================] - 0s 49us/step - loss: 1619.0163 - mse: 1619.0162 - mae: 25.3598\n",
      "Epoch 33/60\n",
      "7397/7397 [==============================] - 0s 49us/step - loss: 1618.9306 - mse: 1618.9305 - mae: 25.3914\n",
      "Epoch 34/60\n",
      "7397/7397 [==============================] - 0s 49us/step - loss: 1617.0318 - mse: 1617.0317 - mae: 25.2618\n",
      "Epoch 35/60\n",
      "7397/7397 [==============================] - 0s 48us/step - loss: 1619.2344 - mse: 1619.2345 - mae: 25.3810\n",
      "Epoch 36/60\n",
      "7397/7397 [==============================] - 0s 49us/step - loss: 1615.5365 - mse: 1615.5369 - mae: 25.3020\n",
      "Epoch 37/60\n",
      "7397/7397 [==============================] - 0s 48us/step - loss: 1615.8456 - mse: 1615.8457 - mae: 25.3525\n",
      "Epoch 38/60\n",
      "7397/7397 [==============================] - 0s 48us/step - loss: 1618.5361 - mse: 1618.5367 - mae: 25.3560\n",
      "Epoch 39/60\n",
      "7397/7397 [==============================] - 0s 48us/step - loss: 1618.7520 - mse: 1618.7523 - mae: 25.3475\n",
      "Epoch 40/60\n",
      "7397/7397 [==============================] - 0s 49us/step - loss: 1617.7065 - mse: 1617.7065 - mae: 25.3469\n",
      "Epoch 41/60\n",
      "7397/7397 [==============================] - 0s 49us/step - loss: 1620.1043 - mse: 1620.1044 - mae: 25.4096\n",
      "Epoch 42/60\n",
      "7397/7397 [==============================] - 0s 48us/step - loss: 1617.3600 - mse: 1617.3600 - mae: 25.3234\n",
      "Epoch 43/60\n",
      "7397/7397 [==============================] - 0s 48us/step - loss: 1616.7491 - mse: 1616.7493 - mae: 25.4009\n",
      "Epoch 44/60\n",
      "7397/7397 [==============================] - 0s 48us/step - loss: 1617.6838 - mse: 1617.6840 - mae: 25.3552\n",
      "Epoch 45/60\n",
      "7397/7397 [==============================] - 0s 48us/step - loss: 1616.0624 - mse: 1616.0621 - mae: 25.3068\n",
      "Epoch 46/60\n",
      "7397/7397 [==============================] - 0s 48us/step - loss: 1618.8588 - mse: 1618.8580 - mae: 25.3149\n",
      "Epoch 47/60\n",
      "7397/7397 [==============================] - 0s 49us/step - loss: 1616.6120 - mse: 1616.6118 - mae: 25.3602\n",
      "Epoch 48/60\n",
      "7397/7397 [==============================] - 0s 48us/step - loss: 1615.9003 - mse: 1615.9005 - mae: 25.3506\n",
      "Epoch 49/60\n",
      "7397/7397 [==============================] - 0s 48us/step - loss: 1618.0635 - mse: 1618.0636 - mae: 25.3587\n",
      "Epoch 50/60\n",
      "7397/7397 [==============================] - 0s 48us/step - loss: 1617.7476 - mse: 1617.7472 - mae: 25.3786\n",
      "Epoch 51/60\n",
      "7397/7397 [==============================] - 0s 48us/step - loss: 1617.0247 - mse: 1617.0240 - mae: 25.3603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=55)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "1850/1850 [==============================] - 1s 372us/step - loss: 11863.1208 - mse: 11863.1201 - mae: 104.0740\n",
      "Epoch 2/60\n",
      "1850/1850 [==============================] - 0s 47us/step - loss: 4341.1812 - mse: 4341.1807 - mae: 52.3048\n",
      "Epoch 3/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 1039.5134 - mse: 1039.5133 - mae: 22.4763\n",
      "Epoch 4/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 1030.1352 - mse: 1030.1350 - mae: 22.3298\n",
      "Epoch 5/60\n",
      "1850/1850 [==============================] - 0s 47us/step - loss: 1027.3776 - mse: 1027.3777 - mae: 22.2208\n",
      "Epoch 6/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 1026.2394 - mse: 1026.2394 - mae: 22.1643\n",
      "Epoch 7/60\n",
      "1850/1850 [==============================] - 0s 47us/step - loss: 1027.2194 - mse: 1027.2194 - mae: 22.2038\n",
      "Epoch 8/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 1021.1435 - mse: 1021.1437 - mae: 22.0521\n",
      "Epoch 9/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 1021.5742 - mse: 1021.5741 - mae: 22.0802\n",
      "Epoch 10/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 1028.8260 - mse: 1028.8258 - mae: 22.1603\n",
      "Epoch 11/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 1023.1609 - mse: 1023.1609 - mae: 21.9062\n",
      "Epoch 12/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 1021.7684 - mse: 1021.7686 - mae: 21.9670\n",
      "Epoch 13/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 1023.7825 - mse: 1023.7823 - mae: 21.8836\n",
      "Epoch 14/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 1016.8385 - mse: 1016.8385 - mae: 21.8495\n",
      "Epoch 15/60\n",
      "1850/1850 [==============================] - 0s 45us/step - loss: 1016.4460 - mse: 1016.4459 - mae: 21.9263\n",
      "Epoch 16/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 1019.6949 - mse: 1019.6947 - mae: 21.7631\n",
      "Epoch 17/60\n",
      "1850/1850 [==============================] - 0s 45us/step - loss: 1012.7165 - mse: 1012.7166 - mae: 21.7744\n",
      "Epoch 18/60\n",
      "1850/1850 [==============================] - 0s 45us/step - loss: 1015.0300 - mse: 1015.0298 - mae: 21.7032\n",
      "Epoch 19/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 1014.8719 - mse: 1014.8719 - mae: 21.7931\n",
      "Epoch 20/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 1011.5098 - mse: 1011.5099 - mae: 21.6995\n",
      "Epoch 21/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 1017.3578 - mse: 1017.3578 - mae: 21.6926\n",
      "Epoch 22/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 1013.0661 - mse: 1013.0663 - mae: 21.6680\n",
      "Epoch 23/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 1013.4576 - mse: 1013.4575 - mae: 21.7020\n",
      "Epoch 24/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 1014.6983 - mse: 1014.6984 - mae: 21.7147\n",
      "Epoch 25/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 1016.5681 - mse: 1016.5683 - mae: 21.6514\n",
      "Epoch 26/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 1014.3116 - mse: 1014.3116 - mae: 21.6828\n",
      "Epoch 27/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 1014.1854 - mse: 1014.1852 - mae: 21.6017\n",
      "Epoch 28/60\n",
      "1850/1850 [==============================] - 0s 47us/step - loss: 1009.0055 - mse: 1009.0052 - mae: 21.5975\n",
      "Epoch 29/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 1016.3704 - mse: 1016.3702 - mae: 21.7299\n",
      "Epoch 30/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 1007.9197 - mse: 1007.9197 - mae: 21.5664\n",
      "Epoch 31/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 1013.4944 - mse: 1013.4945 - mae: 21.6266\n",
      "Epoch 32/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 1017.3346 - mse: 1017.3346 - mae: 21.6283\n",
      "Epoch 33/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 1012.0526 - mse: 1012.0529 - mae: 21.5640\n",
      "Epoch 34/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 1013.1641 - mse: 1013.1641 - mae: 21.5897\n",
      "Epoch 35/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 1029.7707 - mse: 1029.7706 - mae: 21.7919\n",
      "Epoch 36/60\n",
      "1850/1850 [==============================] - 0s 47us/step - loss: 1010.0221 - mse: 1010.0220 - mae: 21.5327\n",
      "Epoch 37/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 1008.9453 - mse: 1008.9453 - mae: 21.5118\n",
      "Epoch 38/60\n",
      "1850/1850 [==============================] - 0s 47us/step - loss: 1009.6224 - mse: 1009.6225 - mae: 21.6243\n",
      "Epoch 39/60\n",
      "1850/1850 [==============================] - 0s 47us/step - loss: 1006.2307 - mse: 1006.2309 - mae: 21.4453\n",
      "Epoch 40/60\n",
      "1850/1850 [==============================] - 0s 47us/step - loss: 1011.7400 - mse: 1011.7401 - mae: 21.5738\n",
      "Epoch 41/60\n",
      "1850/1850 [==============================] - 0s 47us/step - loss: 1006.9286 - mse: 1006.9286 - mae: 21.4756\n",
      "Epoch 42/60\n",
      "1850/1850 [==============================] - 0s 47us/step - loss: 1008.0307 - mse: 1008.0307 - mae: 21.4594\n",
      "Epoch 43/60\n",
      "1850/1850 [==============================] - 0s 47us/step - loss: 1013.8641 - mse: 1013.8641 - mae: 21.5358\n",
      "Epoch 44/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 1014.0125 - mse: 1014.0126 - mae: 21.6101\n",
      "Epoch 45/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 1010.4422 - mse: 1010.4421 - mae: 21.5941\n",
      "Epoch 46/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 1014.6099 - mse: 1014.6098 - mae: 21.5026\n",
      "Epoch 47/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 1009.3424 - mse: 1009.3423 - mae: 21.5063\n",
      "Epoch 48/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 1010.0276 - mse: 1010.0278 - mae: 21.5647\n",
      "Epoch 49/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 1015.2476 - mse: 1015.2477 - mae: 21.4577\n",
      "Epoch 50/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 1012.5402 - mse: 1012.5402 - mae: 21.5376\n",
      "Epoch 51/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 1004.3632 - mse: 1004.3632 - mae: 21.4822\n",
      "Epoch 52/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 1004.8027 - mse: 1004.8026 - mae: 21.4795\n",
      "Epoch 53/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 1018.6232 - mse: 1018.6232 - mae: 21.5521\n",
      "Epoch 54/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 1002.3122 - mse: 1002.3123 - mae: 21.4566\n",
      "Epoch 55/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 1007.6070 - mse: 1007.6069 - mae: 21.3807\n",
      "Epoch 56/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 1007.4116 - mse: 1007.4115 - mae: 21.6071\n",
      "Epoch 57/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 1006.9994 - mse: 1006.9995 - mae: 21.4268\n",
      "Epoch 58/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 1007.4852 - mse: 1007.4853 - mae: 21.4688\n",
      "Epoch 59/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 1005.3673 - mse: 1005.3674 - mae: 21.4610\n",
      "Epoch 60/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 1009.6064 - mse: 1009.6063 - mae: 21.5024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=55)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "3699/3699 [==============================] - 1s 217us/step - loss: 7641.2744 - mse: 7641.2725 - mae: 74.2885\n",
      "Epoch 2/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1138.9680 - mse: 1138.9681 - mae: 22.8574\n",
      "Epoch 3/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1135.6776 - mse: 1135.6776 - mae: 22.8810\n",
      "Epoch 4/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1132.5365 - mse: 1132.5367 - mae: 22.7437\n",
      "Epoch 5/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1132.1831 - mse: 1132.1830 - mae: 22.8016\n",
      "Epoch 6/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1129.6700 - mse: 1129.6702 - mae: 22.7395\n",
      "Epoch 7/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1130.5250 - mse: 1130.5248 - mae: 22.6918\n",
      "Epoch 8/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1128.5103 - mse: 1128.5103 - mae: 22.8075\n",
      "Epoch 9/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1126.6189 - mse: 1126.6191 - mae: 22.6790\n",
      "Epoch 10/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1130.4107 - mse: 1130.4110 - mae: 22.6790\n",
      "Epoch 11/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1126.1960 - mse: 1126.1959 - mae: 22.6855\n",
      "Epoch 12/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1130.5617 - mse: 1130.5613 - mae: 22.6845\n",
      "Epoch 13/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1127.7481 - mse: 1127.7480 - mae: 22.6323\n",
      "Epoch 14/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1130.5453 - mse: 1130.5454 - mae: 22.8115\n",
      "Epoch 15/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1126.1312 - mse: 1126.1311 - mae: 22.6665\n",
      "Epoch 16/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1122.9225 - mse: 1122.9226 - mae: 22.6375\n",
      "Epoch 17/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1127.3492 - mse: 1127.3492 - mae: 22.6824\n",
      "Epoch 18/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1126.3183 - mse: 1126.3184 - mae: 22.6192\n",
      "Epoch 19/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1123.2915 - mse: 1123.2915 - mae: 22.6137\n",
      "Epoch 20/60\n",
      "3699/3699 [==============================] - 0s 46us/step - loss: 1123.2060 - mse: 1123.2059 - mae: 22.6007\n",
      "Epoch 21/60\n",
      "3699/3699 [==============================] - 0s 46us/step - loss: 1124.4132 - mse: 1124.4130 - mae: 22.5716\n",
      "Epoch 22/60\n",
      "3699/3699 [==============================] - 0s 46us/step - loss: 1127.4979 - mse: 1127.4979 - mae: 22.6095\n",
      "Epoch 23/60\n",
      "3699/3699 [==============================] - 0s 46us/step - loss: 1120.7206 - mse: 1120.7207 - mae: 22.5937\n",
      "Epoch 24/60\n",
      "3699/3699 [==============================] - 0s 46us/step - loss: 1123.7616 - mse: 1123.7618 - mae: 22.6111\n",
      "Epoch 25/60\n",
      "3699/3699 [==============================] - 0s 46us/step - loss: 1122.2860 - mse: 1122.2859 - mae: 22.7054\n",
      "Epoch 26/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1124.2328 - mse: 1124.2328 - mae: 22.5999\n",
      "Epoch 27/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1123.3302 - mse: 1123.3301 - mae: 22.5811\n",
      "Epoch 28/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1131.5267 - mse: 1131.5269 - mae: 22.7336\n",
      "Epoch 29/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1121.6548 - mse: 1121.6547 - mae: 22.6209\n",
      "Epoch 30/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1120.1661 - mse: 1120.1658 - mae: 22.5961\n",
      "Epoch 31/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1118.5015 - mse: 1118.5017 - mae: 22.5504\n",
      "Epoch 32/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1127.7321 - mse: 1127.7318 - mae: 22.6340\n",
      "Epoch 33/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1120.9912 - mse: 1120.9911 - mae: 22.5268\n",
      "Epoch 34/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1119.4711 - mse: 1119.4709 - mae: 22.5682\n",
      "Epoch 35/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1120.8093 - mse: 1120.8093 - mae: 22.6152\n",
      "Epoch 36/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1121.2951 - mse: 1121.2952 - mae: 22.4915\n",
      "Epoch 37/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1121.6337 - mse: 1121.6338 - mae: 22.5718\n",
      "Epoch 38/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1121.1356 - mse: 1121.1356 - mae: 22.6068\n",
      "Epoch 39/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1119.2836 - mse: 1119.2837 - mae: 22.5564\n",
      "Epoch 40/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1122.1391 - mse: 1122.1390 - mae: 22.6834\n",
      "Epoch 41/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1124.6403 - mse: 1124.6406 - mae: 22.5800\n",
      "Epoch 42/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1115.5300 - mse: 1115.5300 - mae: 22.4669\n",
      "Epoch 43/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1133.0516 - mse: 1133.0519 - mae: 22.7616\n",
      "Epoch 44/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1123.1998 - mse: 1123.1997 - mae: 22.5575\n",
      "Epoch 45/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1117.1284 - mse: 1117.1283 - mae: 22.5518\n",
      "Epoch 46/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1118.9014 - mse: 1118.9012 - mae: 22.5416\n",
      "Epoch 47/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1131.7154 - mse: 1131.7155 - mae: 22.5338\n",
      "Epoch 48/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1123.7121 - mse: 1123.7123 - mae: 22.6601\n",
      "Epoch 49/60\n",
      "3699/3699 [==============================] - 0s 46us/step - loss: 1133.5092 - mse: 1133.5092 - mae: 22.7066\n",
      "Epoch 50/60\n",
      "3699/3699 [==============================] - 0s 46us/step - loss: 1117.7338 - mse: 1117.7334 - mae: 22.5117\n",
      "Epoch 51/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1123.1274 - mse: 1123.1271 - mae: 22.7064\n",
      "Epoch 52/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1122.2812 - mse: 1122.2811 - mae: 22.4419\n",
      "Epoch 53/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1121.3681 - mse: 1121.3680 - mae: 22.6650\n",
      "Epoch 54/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1119.0623 - mse: 1119.0624 - mae: 22.4522\n",
      "Epoch 55/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1116.6450 - mse: 1116.6449 - mae: 22.5965\n",
      "Epoch 56/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1119.2658 - mse: 1119.2659 - mae: 22.4959\n",
      "Epoch 57/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1137.2721 - mse: 1137.2719 - mae: 22.5392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=55)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "5548/5548 [==============================] - 1s 160us/step - loss: 6927.8129 - mse: 6927.8125 - mae: 63.5010\n",
      "Epoch 2/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1713.1108 - mse: 1713.1101 - mae: 25.3143\n",
      "Epoch 3/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1710.4481 - mse: 1710.4482 - mae: 25.2697\n",
      "Epoch 4/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1710.0372 - mse: 1710.0374 - mae: 25.1395\n",
      "Epoch 5/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1702.5190 - mse: 1702.5184 - mae: 25.1681\n",
      "Epoch 6/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1704.8577 - mse: 1704.8578 - mae: 25.0124\n",
      "Epoch 7/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1710.6843 - mse: 1710.6844 - mae: 25.3751\n",
      "Epoch 8/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1701.2781 - mse: 1701.2783 - mae: 25.1711\n",
      "Epoch 9/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1695.6251 - mse: 1695.6248 - mae: 24.9885\n",
      "Epoch 10/60\n",
      "5548/5548 [==============================] - 0s 46us/step - loss: 1694.1584 - mse: 1694.1584 - mae: 25.0933\n",
      "Epoch 11/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1697.6429 - mse: 1697.6433 - mae: 25.1308\n",
      "Epoch 12/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1691.4844 - mse: 1691.4846 - mae: 25.0553\n",
      "Epoch 13/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1690.0933 - mse: 1690.0935 - mae: 25.0572\n",
      "Epoch 14/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1685.8919 - mse: 1685.8914 - mae: 25.0056\n",
      "Epoch 15/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1684.4343 - mse: 1684.4344 - mae: 24.9960\n",
      "Epoch 16/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1687.6636 - mse: 1687.6638 - mae: 25.0595\n",
      "Epoch 17/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1683.7550 - mse: 1683.7550 - mae: 24.9802\n",
      "Epoch 18/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1687.6634 - mse: 1687.6641 - mae: 25.0072\n",
      "Epoch 19/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1681.5446 - mse: 1681.5446 - mae: 24.9811\n",
      "Epoch 20/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1678.8562 - mse: 1678.8563 - mae: 24.9407\n",
      "Epoch 21/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1680.9987 - mse: 1680.9982 - mae: 25.0595\n",
      "Epoch 22/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1677.7291 - mse: 1677.7289 - mae: 24.9696\n",
      "Epoch 23/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1682.1746 - mse: 1682.1750 - mae: 25.0581\n",
      "Epoch 24/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1675.8587 - mse: 1675.8577 - mae: 24.9533\n",
      "Epoch 25/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1677.8701 - mse: 1677.8700 - mae: 24.9660\n",
      "Epoch 26/60\n",
      "5548/5548 [==============================] - 0s 46us/step - loss: 1673.1746 - mse: 1673.1743 - mae: 24.9303\n",
      "Epoch 27/60\n",
      "5548/5548 [==============================] - 0s 46us/step - loss: 1678.9133 - mse: 1678.9131 - mae: 24.9580\n",
      "Epoch 28/60\n",
      "5548/5548 [==============================] - 0s 46us/step - loss: 1678.1437 - mse: 1678.1433 - mae: 25.0658\n",
      "Epoch 29/60\n",
      "5548/5548 [==============================] - 0s 46us/step - loss: 1680.1498 - mse: 1680.1497 - mae: 24.9042\n",
      "Epoch 30/60\n",
      "5548/5548 [==============================] - 0s 46us/step - loss: 1676.1362 - mse: 1676.1365 - mae: 24.9544\n",
      "Epoch 31/60\n",
      "5548/5548 [==============================] - 0s 46us/step - loss: 1677.7918 - mse: 1677.7925 - mae: 24.9217\n",
      "Epoch 32/60\n",
      "5548/5548 [==============================] - 0s 46us/step - loss: 1679.7558 - mse: 1679.7560 - mae: 24.9892\n",
      "Epoch 33/60\n",
      "5548/5548 [==============================] - 0s 46us/step - loss: 1673.8599 - mse: 1673.8596 - mae: 24.9357\n",
      "Epoch 34/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1677.6651 - mse: 1677.6654 - mae: 24.9349\n",
      "Epoch 35/60\n",
      "5548/5548 [==============================] - 0s 50us/step - loss: 1676.9177 - mse: 1676.9172 - mae: 25.0118\n",
      "Epoch 36/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1676.2191 - mse: 1676.2192 - mae: 24.9570\n",
      "Epoch 37/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1671.7688 - mse: 1671.7693 - mae: 24.8585\n",
      "Epoch 38/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1676.6903 - mse: 1676.6898 - mae: 24.9988\n",
      "Epoch 39/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1671.3148 - mse: 1671.3153 - mae: 24.9081\n",
      "Epoch 40/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1677.5122 - mse: 1677.5121 - mae: 24.9778\n",
      "Epoch 41/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1678.9533 - mse: 1678.9534 - mae: 24.9890\n",
      "Epoch 42/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1675.8601 - mse: 1675.8601 - mae: 24.9694\n",
      "Epoch 43/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1671.7716 - mse: 1671.7716 - mae: 24.9486\n",
      "Epoch 44/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1679.8995 - mse: 1679.8994 - mae: 25.0703\n",
      "Epoch 45/60\n",
      "5548/5548 [==============================] - 0s 46us/step - loss: 1678.7685 - mse: 1678.7684 - mae: 24.9178\n",
      "Epoch 46/60\n",
      "5548/5548 [==============================] - 0s 46us/step - loss: 1678.1453 - mse: 1678.1451 - mae: 24.8915\n",
      "Epoch 47/60\n",
      "5548/5548 [==============================] - 0s 51us/step - loss: 1678.8409 - mse: 1678.8408 - mae: 25.0699\n",
      "Epoch 48/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1672.5639 - mse: 1672.5638 - mae: 24.8520\n",
      "Epoch 49/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1670.2061 - mse: 1670.2064 - mae: 24.8579\n",
      "Epoch 50/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1674.2711 - mse: 1674.2709 - mae: 25.0816\n",
      "Epoch 51/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1671.3100 - mse: 1671.3104 - mae: 24.7525\n",
      "Epoch 52/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1679.9710 - mse: 1679.9708 - mae: 25.0711\n",
      "Epoch 53/60\n",
      "5548/5548 [==============================] - 0s 46us/step - loss: 1674.1536 - mse: 1674.1541 - mae: 24.9127\n",
      "Epoch 54/60\n",
      "5548/5548 [==============================] - 0s 46us/step - loss: 1676.0470 - mse: 1676.0466 - mae: 24.9156\n",
      "Epoch 55/60\n",
      "5548/5548 [==============================] - 0s 46us/step - loss: 1670.5308 - mse: 1670.5303 - mae: 24.8950\n",
      "Epoch 56/60\n",
      "5548/5548 [==============================] - 0s 46us/step - loss: 1671.6271 - mse: 1671.6271 - mae: 24.8889\n",
      "Epoch 57/60\n",
      "5548/5548 [==============================] - 0s 45us/step - loss: 1673.9044 - mse: 1673.9048 - mae: 24.9868\n",
      "Epoch 58/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1669.5679 - mse: 1669.5681 - mae: 24.8688\n",
      "Epoch 59/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1672.6072 - mse: 1672.6073 - mae: 24.9515\n",
      "Epoch 60/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1677.5877 - mse: 1677.5878 - mae: 24.9791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=55)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "7397/7397 [==============================] - 1s 130us/step - loss: 5942.2371 - mse: 5942.2422 - mae: 56.7562\n",
      "Epoch 2/60\n",
      "7397/7397 [==============================] - 0s 46us/step - loss: 1652.6304 - mse: 1652.6301 - mae: 25.5541\n",
      "Epoch 3/60\n",
      "7397/7397 [==============================] - 0s 47us/step - loss: 1651.3858 - mse: 1651.3864 - mae: 25.5656\n",
      "Epoch 4/60\n",
      "7397/7397 [==============================] - 0s 46us/step - loss: 1646.4235 - mse: 1646.4233 - mae: 25.4436\n",
      "Epoch 5/60\n",
      "7397/7397 [==============================] - 0s 46us/step - loss: 1669.0640 - mse: 1669.0640 - mae: 25.9138\n",
      "Epoch 6/60\n",
      "7397/7397 [==============================] - 0s 47us/step - loss: 1640.7163 - mse: 1640.7166 - mae: 25.4855\n",
      "Epoch 7/60\n",
      "7397/7397 [==============================] - 0s 47us/step - loss: 1636.4945 - mse: 1636.4943 - mae: 25.3567\n",
      "Epoch 8/60\n",
      "7397/7397 [==============================] - 0s 47us/step - loss: 1633.1962 - mse: 1633.1962 - mae: 25.4236\n",
      "Epoch 9/60\n",
      "7397/7397 [==============================] - 0s 47us/step - loss: 1630.9182 - mse: 1630.9178 - mae: 25.3592\n",
      "Epoch 10/60\n",
      "7397/7397 [==============================] - 0s 47us/step - loss: 1633.8337 - mse: 1633.8335 - mae: 25.3290\n",
      "Epoch 11/60\n",
      "7397/7397 [==============================] - 0s 46us/step - loss: 1625.2042 - mse: 1625.2040 - mae: 25.3872\n",
      "Epoch 12/60\n",
      "7397/7397 [==============================] - 0s 46us/step - loss: 1628.6221 - mse: 1628.6215 - mae: 25.3633\n",
      "Epoch 13/60\n",
      "7397/7397 [==============================] - 0s 46us/step - loss: 1630.6947 - mse: 1630.6951 - mae: 25.4064\n",
      "Epoch 14/60\n",
      "7397/7397 [==============================] - 0s 47us/step - loss: 1623.4633 - mse: 1623.4630 - mae: 25.3493\n",
      "Epoch 15/60\n",
      "7397/7397 [==============================] - 0s 47us/step - loss: 1627.8685 - mse: 1627.8688 - mae: 25.3180\n",
      "Epoch 16/60\n",
      "7397/7397 [==============================] - 0s 47us/step - loss: 1624.4676 - mse: 1624.4670 - mae: 25.3263\n",
      "Epoch 17/60\n",
      "7397/7397 [==============================] - 0s 47us/step - loss: 1620.1414 - mse: 1620.1414 - mae: 25.4038\n",
      "Epoch 18/60\n",
      "7397/7397 [==============================] - 0s 46us/step - loss: 1624.2790 - mse: 1624.2791 - mae: 25.3356\n",
      "Epoch 19/60\n",
      "7397/7397 [==============================] - 0s 47us/step - loss: 1624.6326 - mse: 1624.6331 - mae: 25.4423\n",
      "Epoch 20/60\n",
      "7397/7397 [==============================] - 0s 46us/step - loss: 1621.6978 - mse: 1621.6982 - mae: 25.3799\n",
      "Epoch 21/60\n",
      "7397/7397 [==============================] - 0s 46us/step - loss: 1621.3545 - mse: 1621.3540 - mae: 25.3677\n",
      "Epoch 22/60\n",
      "7397/7397 [==============================] - 0s 46us/step - loss: 1620.4509 - mse: 1620.4515 - mae: 25.3934\n",
      "Epoch 23/60\n",
      "7397/7397 [==============================] - 0s 46us/step - loss: 1620.3634 - mse: 1620.3635 - mae: 25.2483\n",
      "Epoch 24/60\n",
      "7397/7397 [==============================] - 0s 46us/step - loss: 1617.6775 - mse: 1617.6777 - mae: 25.3800\n",
      "Epoch 25/60\n",
      "7397/7397 [==============================] - 0s 47us/step - loss: 1620.9111 - mse: 1620.9117 - mae: 25.3682\n",
      "Epoch 26/60\n",
      "7397/7397 [==============================] - 0s 47us/step - loss: 1632.8295 - mse: 1632.8302 - mae: 25.6325\n",
      "Epoch 27/60\n",
      "7397/7397 [==============================] - 0s 47us/step - loss: 1617.3402 - mse: 1617.3400 - mae: 25.3089\n",
      "Epoch 28/60\n",
      "7397/7397 [==============================] - 0s 47us/step - loss: 1615.2108 - mse: 1615.2106 - mae: 25.2742\n",
      "Epoch 29/60\n",
      "7397/7397 [==============================] - 0s 47us/step - loss: 1619.6130 - mse: 1619.6124 - mae: 25.3566\n",
      "Epoch 30/60\n",
      "7397/7397 [==============================] - 0s 47us/step - loss: 1621.7312 - mse: 1621.7311 - mae: 25.4782\n",
      "Epoch 31/60\n",
      "7397/7397 [==============================] - 0s 46us/step - loss: 1622.5432 - mse: 1622.5435 - mae: 25.2555\n",
      "Epoch 32/60\n",
      "7397/7397 [==============================] - 0s 46us/step - loss: 1624.3130 - mse: 1624.3125 - mae: 25.5797\n",
      "Epoch 33/60\n",
      "7397/7397 [==============================] - 0s 46us/step - loss: 1625.7727 - mse: 1625.7728 - mae: 25.2840\n",
      "Epoch 34/60\n",
      "7397/7397 [==============================] - 0s 46us/step - loss: 1618.6017 - mse: 1618.6021 - mae: 25.3914\n",
      "Epoch 35/60\n",
      "7397/7397 [==============================] - 0s 46us/step - loss: 1619.7109 - mse: 1619.7107 - mae: 25.3325\n",
      "Epoch 36/60\n",
      "7397/7397 [==============================] - 0s 46us/step - loss: 1618.4763 - mse: 1618.4758 - mae: 25.3878\n",
      "Epoch 37/60\n",
      "7397/7397 [==============================] - 0s 46us/step - loss: 1616.8737 - mse: 1616.8733 - mae: 25.4123\n",
      "Epoch 38/60\n",
      "7397/7397 [==============================] - 0s 46us/step - loss: 1618.7161 - mse: 1618.7162 - mae: 25.3097\n",
      "Epoch 39/60\n",
      "7397/7397 [==============================] - 0s 47us/step - loss: 1616.7999 - mse: 1616.7997 - mae: 25.4515\n",
      "Epoch 40/60\n",
      "7397/7397 [==============================] - 0s 47us/step - loss: 1615.6373 - mse: 1615.6377 - mae: 25.2629\n",
      "Epoch 41/60\n",
      "7397/7397 [==============================] - 0s 46us/step - loss: 1618.6950 - mse: 1618.6951 - mae: 25.3463\n",
      "Epoch 42/60\n",
      "7397/7397 [==============================] - 0s 46us/step - loss: 1617.0730 - mse: 1617.0731 - mae: 25.2892\n",
      "Epoch 43/60\n",
      "7397/7397 [==============================] - 0s 47us/step - loss: 1620.5529 - mse: 1620.5527 - mae: 25.4403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=60)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "1850/1850 [==============================] - 1s 675us/step - loss: 4433.1273 - mse: 4433.1279 - mae: 49.5409\n",
      "Epoch 2/60\n",
      "1850/1850 [==============================] - 0s 62us/step - loss: 1042.4420 - mse: 1042.4420 - mae: 22.2378\n",
      "Epoch 3/60\n",
      "1850/1850 [==============================] - 0s 63us/step - loss: 1038.9918 - mse: 1038.9917 - mae: 22.1076\n",
      "Epoch 4/60\n",
      "1850/1850 [==============================] - 0s 63us/step - loss: 1052.9916 - mse: 1052.9917 - mae: 22.1351\n",
      "Epoch 5/60\n",
      "1850/1850 [==============================] - 0s 63us/step - loss: 1028.9158 - mse: 1028.9160 - mae: 22.0423\n",
      "Epoch 6/60\n",
      "1850/1850 [==============================] - 0s 63us/step - loss: 1057.9651 - mse: 1057.9650 - mae: 22.0899\n",
      "Epoch 7/60\n",
      "1850/1850 [==============================] - 0s 63us/step - loss: 1034.7240 - mse: 1034.7239 - mae: 21.7253\n",
      "Epoch 8/60\n",
      "1850/1850 [==============================] - 0s 63us/step - loss: 1044.6129 - mse: 1044.6128 - mae: 22.0597\n",
      "Epoch 9/60\n",
      "1850/1850 [==============================] - 0s 62us/step - loss: 1031.9250 - mse: 1031.9250 - mae: 21.8413\n",
      "Epoch 10/60\n",
      "1850/1850 [==============================] - 0s 62us/step - loss: 1044.5359 - mse: 1044.5359 - mae: 21.9438\n",
      "Epoch 11/60\n",
      "1850/1850 [==============================] - 0s 62us/step - loss: 1034.9427 - mse: 1034.9427 - mae: 22.0006\n",
      "Epoch 12/60\n",
      "1850/1850 [==============================] - 0s 61us/step - loss: 1020.7722 - mse: 1020.7722 - mae: 21.6336\n",
      "Epoch 13/60\n",
      "1850/1850 [==============================] - 0s 61us/step - loss: 1034.8368 - mse: 1034.8369 - mae: 21.8319\n",
      "Epoch 14/60\n",
      "1850/1850 [==============================] - 0s 61us/step - loss: 1023.2440 - mse: 1023.2439 - mae: 21.7025\n",
      "Epoch 15/60\n",
      "1850/1850 [==============================] - 0s 62us/step - loss: 1030.7115 - mse: 1030.7115 - mae: 21.8505\n",
      "Epoch 16/60\n",
      "1850/1850 [==============================] - 0s 62us/step - loss: 1022.9615 - mse: 1022.9616 - mae: 21.6850\n",
      "Epoch 17/60\n",
      "1850/1850 [==============================] - 0s 78us/step - loss: 1020.0245 - mse: 1020.0245 - mae: 21.8185\n",
      "Epoch 18/60\n",
      "1850/1850 [==============================] - 0s 63us/step - loss: 1019.9963 - mse: 1019.9962 - mae: 21.5858\n",
      "Epoch 19/60\n",
      "1850/1850 [==============================] - 0s 63us/step - loss: 1026.3049 - mse: 1026.3048 - mae: 21.6644\n",
      "Epoch 20/60\n",
      "1850/1850 [==============================] - 0s 63us/step - loss: 1017.2928 - mse: 1017.2925 - mae: 21.6540\n",
      "Epoch 21/60\n",
      "1850/1850 [==============================] - 0s 63us/step - loss: 1047.8597 - mse: 1047.8596 - mae: 22.0177\n",
      "Epoch 22/60\n",
      "1850/1850 [==============================] - 0s 63us/step - loss: 1017.6244 - mse: 1017.6244 - mae: 21.6324\n",
      "Epoch 23/60\n",
      "1850/1850 [==============================] - 0s 63us/step - loss: 1021.7498 - mse: 1021.7496 - mae: 21.7096\n",
      "Epoch 24/60\n",
      "1850/1850 [==============================] - 0s 63us/step - loss: 1011.6562 - mse: 1011.6561 - mae: 21.5001\n",
      "Epoch 25/60\n",
      "1850/1850 [==============================] - 0s 63us/step - loss: 1012.6550 - mse: 1012.6549 - mae: 21.4558\n",
      "Epoch 26/60\n",
      "1850/1850 [==============================] - 0s 63us/step - loss: 1015.9718 - mse: 1015.9718 - mae: 21.5924\n",
      "Epoch 27/60\n",
      "1850/1850 [==============================] - 0s 63us/step - loss: 1010.1513 - mse: 1010.1514 - mae: 21.5680\n",
      "Epoch 28/60\n",
      "1850/1850 [==============================] - 0s 62us/step - loss: 1017.6291 - mse: 1017.6290 - mae: 21.5535\n",
      "Epoch 29/60\n",
      "1850/1850 [==============================] - 0s 63us/step - loss: 1006.6230 - mse: 1006.6230 - mae: 21.4541\n",
      "Epoch 30/60\n",
      "1850/1850 [==============================] - 0s 62us/step - loss: 1016.9890 - mse: 1016.9888 - mae: 21.5833\n",
      "Epoch 31/60\n",
      "1850/1850 [==============================] - 0s 62us/step - loss: 1008.8766 - mse: 1008.8765 - mae: 21.4703\n",
      "Epoch 32/60\n",
      "1850/1850 [==============================] - 0s 62us/step - loss: 1008.6238 - mse: 1008.6237 - mae: 21.5476\n",
      "Epoch 33/60\n",
      "1850/1850 [==============================] - 0s 62us/step - loss: 1012.0263 - mse: 1012.0261 - mae: 21.4007\n",
      "Epoch 34/60\n",
      "1850/1850 [==============================] - 0s 62us/step - loss: 1012.6817 - mse: 1012.6816 - mae: 21.5648\n",
      "Epoch 35/60\n",
      "1850/1850 [==============================] - 0s 62us/step - loss: 1015.1243 - mse: 1015.1243 - mae: 21.6112\n",
      "Epoch 36/60\n",
      "1850/1850 [==============================] - 0s 62us/step - loss: 999.0112 - mse: 999.0114 - mae: 21.3613\n",
      "Epoch 37/60\n",
      "1850/1850 [==============================] - 0s 62us/step - loss: 1011.3677 - mse: 1011.3679 - mae: 21.5922\n",
      "Epoch 38/60\n",
      "1850/1850 [==============================] - 0s 62us/step - loss: 1012.1520 - mse: 1012.1519 - mae: 21.5634\n",
      "Epoch 39/60\n",
      "1850/1850 [==============================] - 0s 62us/step - loss: 1003.3208 - mse: 1003.3206 - mae: 21.4133\n",
      "Epoch 40/60\n",
      "1850/1850 [==============================] - 0s 62us/step - loss: 1000.7592 - mse: 1000.7593 - mae: 21.4889\n",
      "Epoch 41/60\n",
      "1850/1850 [==============================] - 0s 62us/step - loss: 1004.2296 - mse: 1004.2294 - mae: 21.5302\n",
      "Epoch 42/60\n",
      "1850/1850 [==============================] - 0s 62us/step - loss: 994.6497 - mse: 994.6495 - mae: 21.4180\n",
      "Epoch 43/60\n",
      "1850/1850 [==============================] - 0s 62us/step - loss: 995.9488 - mse: 995.9487 - mae: 21.4021\n",
      "Epoch 44/60\n",
      "1850/1850 [==============================] - 0s 62us/step - loss: 989.6819 - mse: 989.6820 - mae: 21.3211\n",
      "Epoch 45/60\n",
      "1850/1850 [==============================] - 0s 62us/step - loss: 1009.1896 - mse: 1009.1896 - mae: 21.4781\n",
      "Epoch 46/60\n",
      "1850/1850 [==============================] - 0s 63us/step - loss: 1000.3684 - mse: 1000.3682 - mae: 21.4157\n",
      "Epoch 47/60\n",
      "1850/1850 [==============================] - 0s 63us/step - loss: 1014.2915 - mse: 1014.2914 - mae: 21.5559\n",
      "Epoch 48/60\n",
      "1850/1850 [==============================] - 0s 64us/step - loss: 991.7914 - mse: 991.7915 - mae: 21.2714\n",
      "Epoch 49/60\n",
      "1850/1850 [==============================] - 0s 63us/step - loss: 996.9604 - mse: 996.9604 - mae: 21.4115\n",
      "Epoch 50/60\n",
      "1850/1850 [==============================] - 0s 63us/step - loss: 1010.2768 - mse: 1010.2769 - mae: 21.6457\n",
      "Epoch 51/60\n",
      "1850/1850 [==============================] - 0s 63us/step - loss: 996.4362 - mse: 996.4364 - mae: 21.2761\n",
      "Epoch 52/60\n",
      "1850/1850 [==============================] - 0s 63us/step - loss: 1000.0048 - mse: 1000.0049 - mae: 21.3794\n",
      "Epoch 53/60\n",
      "1850/1850 [==============================] - 0s 63us/step - loss: 1003.8317 - mse: 1003.8318 - mae: 21.5391\n",
      "Epoch 54/60\n",
      "1850/1850 [==============================] - 0s 63us/step - loss: 994.0344 - mse: 994.0345 - mae: 21.3205\n",
      "Epoch 55/60\n",
      "1850/1850 [==============================] - 0s 63us/step - loss: 992.8168 - mse: 992.8167 - mae: 21.3371\n",
      "Epoch 56/60\n",
      "1850/1850 [==============================] - 0s 63us/step - loss: 999.9865 - mse: 999.9866 - mae: 21.3809\n",
      "Epoch 57/60\n",
      "1850/1850 [==============================] - 0s 63us/step - loss: 999.1196 - mse: 999.1196 - mae: 21.3400\n",
      "Epoch 58/60\n",
      "1850/1850 [==============================] - 0s 63us/step - loss: 995.6596 - mse: 995.6595 - mae: 21.4105\n",
      "Epoch 59/60\n",
      "1850/1850 [==============================] - 0s 63us/step - loss: 1001.5573 - mse: 1001.5574 - mae: 21.3722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=60)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "3699/3699 [==============================] - 1s 358us/step - loss: 2921.1985 - mse: 2921.1987 - mae: 36.5366\n",
      "Epoch 2/60\n",
      "3699/3699 [==============================] - 0s 61us/step - loss: 1152.3938 - mse: 1152.3938 - mae: 22.8166\n",
      "Epoch 3/60\n",
      "3699/3699 [==============================] - 0s 61us/step - loss: 1153.6915 - mse: 1153.6914 - mae: 22.9654\n",
      "Epoch 4/60\n",
      "3699/3699 [==============================] - 0s 61us/step - loss: 1152.0414 - mse: 1152.0411 - mae: 22.8676\n",
      "Epoch 5/60\n",
      "3699/3699 [==============================] - 0s 61us/step - loss: 1145.0676 - mse: 1145.0676 - mae: 22.8003\n",
      "Epoch 6/60\n",
      "3699/3699 [==============================] - 0s 60us/step - loss: 1142.2786 - mse: 1142.2783 - mae: 22.7596\n",
      "Epoch 7/60\n",
      "3699/3699 [==============================] - 0s 61us/step - loss: 1138.8849 - mse: 1138.8850 - mae: 22.8099\n",
      "Epoch 8/60\n",
      "3699/3699 [==============================] - 0s 61us/step - loss: 1140.4312 - mse: 1140.4315 - mae: 22.7398\n",
      "Epoch 9/60\n",
      "3699/3699 [==============================] - 0s 61us/step - loss: 1147.7200 - mse: 1147.7203 - mae: 22.9710\n",
      "Epoch 10/60\n",
      "3699/3699 [==============================] - 0s 61us/step - loss: 1148.6052 - mse: 1148.6051 - mae: 22.9028\n",
      "Epoch 11/60\n",
      "3699/3699 [==============================] - 0s 61us/step - loss: 1138.8516 - mse: 1138.8518 - mae: 22.7698\n",
      "Epoch 12/60\n",
      "3699/3699 [==============================] - 0s 61us/step - loss: 1138.3386 - mse: 1138.3386 - mae: 22.8161\n",
      "Epoch 13/60\n",
      "3699/3699 [==============================] - 0s 61us/step - loss: 1141.3596 - mse: 1141.3595 - mae: 22.7812\n",
      "Epoch 14/60\n",
      "3699/3699 [==============================] - 0s 60us/step - loss: 1143.7480 - mse: 1143.7480 - mae: 22.8084\n",
      "Epoch 15/60\n",
      "3699/3699 [==============================] - 0s 60us/step - loss: 1136.2383 - mse: 1136.2382 - mae: 22.7043\n",
      "Epoch 16/60\n",
      "3699/3699 [==============================] - 0s 61us/step - loss: 1132.9280 - mse: 1132.9280 - mae: 22.7667\n",
      "Epoch 17/60\n",
      "3699/3699 [==============================] - 0s 61us/step - loss: 1136.7038 - mse: 1136.7039 - mae: 22.6945\n",
      "Epoch 18/60\n",
      "3699/3699 [==============================] - 0s 60us/step - loss: 1139.5451 - mse: 1139.5449 - mae: 22.7005\n",
      "Epoch 19/60\n",
      "3699/3699 [==============================] - 0s 60us/step - loss: 1131.5624 - mse: 1131.5621 - mae: 22.7163\n",
      "Epoch 20/60\n",
      "3699/3699 [==============================] - 0s 60us/step - loss: 1133.6385 - mse: 1133.6385 - mae: 22.6657\n",
      "Epoch 21/60\n",
      "3699/3699 [==============================] - 0s 61us/step - loss: 1132.9211 - mse: 1132.9211 - mae: 22.5967\n",
      "Epoch 22/60\n",
      "3699/3699 [==============================] - 0s 61us/step - loss: 1124.8189 - mse: 1124.8188 - mae: 22.5557\n",
      "Epoch 23/60\n",
      "3699/3699 [==============================] - 0s 61us/step - loss: 1130.9106 - mse: 1130.9105 - mae: 22.5823\n",
      "Epoch 24/60\n",
      "3699/3699 [==============================] - 0s 61us/step - loss: 1131.0424 - mse: 1131.0425 - mae: 22.6413\n",
      "Epoch 25/60\n",
      "3699/3699 [==============================] - 0s 61us/step - loss: 1127.6929 - mse: 1127.6927 - mae: 22.6237\n",
      "Epoch 26/60\n",
      "3699/3699 [==============================] - 0s 61us/step - loss: 1129.1495 - mse: 1129.1495 - mae: 22.6145\n",
      "Epoch 27/60\n",
      "3699/3699 [==============================] - 0s 61us/step - loss: 1126.3230 - mse: 1126.3230 - mae: 22.6721\n",
      "Epoch 28/60\n",
      "3699/3699 [==============================] - 0s 61us/step - loss: 1125.8368 - mse: 1125.8370 - mae: 22.6173\n",
      "Epoch 29/60\n",
      "3699/3699 [==============================] - 0s 61us/step - loss: 1137.2065 - mse: 1137.2064 - mae: 22.6535\n",
      "Epoch 30/60\n",
      "3699/3699 [==============================] - 0s 62us/step - loss: 1125.5840 - mse: 1125.5840 - mae: 22.6355\n",
      "Epoch 31/60\n",
      "3699/3699 [==============================] - 0s 62us/step - loss: 1122.0177 - mse: 1122.0175 - mae: 22.5341\n",
      "Epoch 32/60\n",
      "3699/3699 [==============================] - 0s 62us/step - loss: 1122.2625 - mse: 1122.2626 - mae: 22.4539\n",
      "Epoch 33/60\n",
      "3699/3699 [==============================] - 0s 62us/step - loss: 1127.9754 - mse: 1127.9756 - mae: 22.5726\n",
      "Epoch 34/60\n",
      "3699/3699 [==============================] - 0s 62us/step - loss: 1129.6287 - mse: 1129.6285 - mae: 22.6001\n",
      "Epoch 35/60\n",
      "3699/3699 [==============================] - 0s 62us/step - loss: 1124.9842 - mse: 1124.9841 - mae: 22.6715\n",
      "Epoch 36/60\n",
      "3699/3699 [==============================] - 0s 62us/step - loss: 1121.8722 - mse: 1121.8722 - mae: 22.4702\n",
      "Epoch 37/60\n",
      "3699/3699 [==============================] - 0s 62us/step - loss: 1134.0797 - mse: 1134.0796 - mae: 22.6708\n",
      "Epoch 38/60\n",
      "3699/3699 [==============================] - 0s 62us/step - loss: 1118.2352 - mse: 1118.2350 - mae: 22.5396\n",
      "Epoch 39/60\n",
      "3699/3699 [==============================] - 0s 62us/step - loss: 1125.5048 - mse: 1125.5049 - mae: 22.5359\n",
      "Epoch 40/60\n",
      "3699/3699 [==============================] - 0s 62us/step - loss: 1123.9055 - mse: 1123.9055 - mae: 22.5485\n",
      "Epoch 41/60\n",
      "3699/3699 [==============================] - 0s 62us/step - loss: 1125.5539 - mse: 1125.5538 - mae: 22.6092\n",
      "Epoch 42/60\n",
      "3699/3699 [==============================] - 0s 62us/step - loss: 1122.5398 - mse: 1122.5400 - mae: 22.4852\n",
      "Epoch 43/60\n",
      "3699/3699 [==============================] - 0s 62us/step - loss: 1117.4300 - mse: 1117.4299 - mae: 22.4104\n",
      "Epoch 44/60\n",
      "3699/3699 [==============================] - 0s 62us/step - loss: 1117.6433 - mse: 1117.6432 - mae: 22.4726\n",
      "Epoch 45/60\n",
      "3699/3699 [==============================] - 0s 62us/step - loss: 1126.6020 - mse: 1126.6018 - mae: 22.6230\n",
      "Epoch 46/60\n",
      "3699/3699 [==============================] - 0s 62us/step - loss: 1121.4558 - mse: 1121.4558 - mae: 22.5082\n",
      "Epoch 47/60\n",
      "3699/3699 [==============================] - 0s 61us/step - loss: 1115.3976 - mse: 1115.3975 - mae: 22.5084\n",
      "Epoch 48/60\n",
      "3699/3699 [==============================] - 0s 61us/step - loss: 1113.0101 - mse: 1113.0103 - mae: 22.4434\n",
      "Epoch 49/60\n",
      "3699/3699 [==============================] - 0s 61us/step - loss: 1124.5161 - mse: 1124.5160 - mae: 22.4572\n",
      "Epoch 50/60\n",
      "3699/3699 [==============================] - 0s 61us/step - loss: 1121.4225 - mse: 1121.4224 - mae: 22.5007\n",
      "Epoch 51/60\n",
      "3699/3699 [==============================] - 0s 60us/step - loss: 1119.2244 - mse: 1119.2244 - mae: 22.5430\n",
      "Epoch 52/60\n",
      "3699/3699 [==============================] - 0s 61us/step - loss: 1117.6484 - mse: 1117.6484 - mae: 22.4380\n",
      "Epoch 53/60\n",
      "3699/3699 [==============================] - 0s 61us/step - loss: 1120.0636 - mse: 1120.0637 - mae: 22.6224\n",
      "Epoch 54/60\n",
      "3699/3699 [==============================] - 0s 62us/step - loss: 1115.1708 - mse: 1115.1708 - mae: 22.4476\n",
      "Epoch 55/60\n",
      "3699/3699 [==============================] - 0s 61us/step - loss: 1124.2994 - mse: 1124.2993 - mae: 22.4657\n",
      "Epoch 56/60\n",
      "3699/3699 [==============================] - 0s 62us/step - loss: 1112.7541 - mse: 1112.7543 - mae: 22.3712\n",
      "Epoch 57/60\n",
      "3699/3699 [==============================] - 0s 61us/step - loss: 1120.0561 - mse: 1120.0562 - mae: 22.4768\n",
      "Epoch 58/60\n",
      "3699/3699 [==============================] - 0s 61us/step - loss: 1114.3356 - mse: 1114.3354 - mae: 22.4983\n",
      "Epoch 59/60\n",
      "3699/3699 [==============================] - 0s 61us/step - loss: 1116.1916 - mse: 1116.1915 - mae: 22.4675\n",
      "Epoch 60/60\n",
      "3699/3699 [==============================] - 0s 61us/step - loss: 1118.0059 - mse: 1118.0060 - mae: 22.4967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=60)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "5548/5548 [==============================] - 1s 257us/step - loss: 2984.7288 - mse: 2984.7295 - mae: 34.5809\n",
      "Epoch 2/60\n",
      "5548/5548 [==============================] - 0s 60us/step - loss: 1732.1500 - mse: 1732.1503 - mae: 25.3669\n",
      "Epoch 3/60\n",
      "5548/5548 [==============================] - 0s 60us/step - loss: 1716.8774 - mse: 1716.8776 - mae: 25.2295\n",
      "Epoch 4/60\n",
      "5548/5548 [==============================] - 0s 60us/step - loss: 1708.7151 - mse: 1708.7153 - mae: 25.1509\n",
      "Epoch 5/60\n",
      "5548/5548 [==============================] - 0s 60us/step - loss: 1701.4528 - mse: 1701.4523 - mae: 25.1069\n",
      "Epoch 6/60\n",
      "5548/5548 [==============================] - 0s 60us/step - loss: 1701.8730 - mse: 1701.8726 - mae: 25.1777\n",
      "Epoch 7/60\n",
      "5548/5548 [==============================] - 0s 60us/step - loss: 1702.0118 - mse: 1702.0117 - mae: 25.1525\n",
      "Epoch 8/60\n",
      "5548/5548 [==============================] - 0s 60us/step - loss: 1691.4704 - mse: 1691.4702 - mae: 25.0771\n",
      "Epoch 9/60\n",
      "5548/5548 [==============================] - 0s 60us/step - loss: 1688.8991 - mse: 1688.8987 - mae: 25.0098\n",
      "Epoch 10/60\n",
      "5548/5548 [==============================] - 0s 60us/step - loss: 1691.4472 - mse: 1691.4470 - mae: 25.0387\n",
      "Epoch 11/60\n",
      "5548/5548 [==============================] - 0s 60us/step - loss: 1697.3523 - mse: 1697.3525 - mae: 25.0211\n",
      "Epoch 12/60\n",
      "5548/5548 [==============================] - 0s 60us/step - loss: 1683.3335 - mse: 1683.3333 - mae: 25.0628\n",
      "Epoch 13/60\n",
      "5548/5548 [==============================] - 0s 61us/step - loss: 1680.7489 - mse: 1680.7493 - mae: 24.9813\n",
      "Epoch 14/60\n",
      "5548/5548 [==============================] - 0s 61us/step - loss: 1677.8072 - mse: 1677.8074 - mae: 24.9143\n",
      "Epoch 15/60\n",
      "5548/5548 [==============================] - 0s 64us/step - loss: 1679.1773 - mse: 1679.1770 - mae: 24.9614\n",
      "Epoch 16/60\n",
      "5548/5548 [==============================] - 0s 61us/step - loss: 1672.1302 - mse: 1672.1305 - mae: 24.8755\n",
      "Epoch 17/60\n",
      "5548/5548 [==============================] - 0s 61us/step - loss: 1681.6967 - mse: 1681.6968 - mae: 24.9732\n",
      "Epoch 18/60\n",
      "5548/5548 [==============================] - 0s 61us/step - loss: 1671.5795 - mse: 1671.5798 - mae: 24.8852\n",
      "Epoch 19/60\n",
      "5548/5548 [==============================] - 0s 60us/step - loss: 1667.7476 - mse: 1667.7478 - mae: 24.8569\n",
      "Epoch 20/60\n",
      "5548/5548 [==============================] - 0s 60us/step - loss: 1667.2826 - mse: 1667.2822 - mae: 24.8539\n",
      "Epoch 21/60\n",
      "5548/5548 [==============================] - 0s 60us/step - loss: 1660.1265 - mse: 1660.1263 - mae: 24.6793\n",
      "Epoch 22/60\n",
      "5548/5548 [==============================] - 0s 60us/step - loss: 1670.7098 - mse: 1670.7098 - mae: 24.9250\n",
      "Epoch 23/60\n",
      "5548/5548 [==============================] - 0s 60us/step - loss: 1667.1688 - mse: 1667.1692 - mae: 24.7531\n",
      "Epoch 24/60\n",
      "5548/5548 [==============================] - 0s 60us/step - loss: 1663.9764 - mse: 1663.9764 - mae: 24.8197\n",
      "Epoch 25/60\n",
      "5548/5548 [==============================] - 0s 60us/step - loss: 1657.5432 - mse: 1657.5427 - mae: 24.6567\n",
      "Epoch 26/60\n",
      "5548/5548 [==============================] - 0s 61us/step - loss: 1663.4528 - mse: 1663.4526 - mae: 24.7489\n",
      "Epoch 27/60\n",
      "5548/5548 [==============================] - 0s 61us/step - loss: 1650.0537 - mse: 1650.0537 - mae: 24.6741\n",
      "Epoch 28/60\n",
      "5548/5548 [==============================] - 0s 61us/step - loss: 1655.7198 - mse: 1655.7195 - mae: 24.6624\n",
      "Epoch 29/60\n",
      "5548/5548 [==============================] - 0s 61us/step - loss: 1661.6132 - mse: 1661.6130 - mae: 24.7672\n",
      "Epoch 30/60\n",
      "5548/5548 [==============================] - 0s 61us/step - loss: 1653.9563 - mse: 1653.9564 - mae: 24.7611\n",
      "Epoch 31/60\n",
      "5548/5548 [==============================] - 0s 61us/step - loss: 1651.7711 - mse: 1651.7716 - mae: 24.6118\n",
      "Epoch 32/60\n",
      "5548/5548 [==============================] - 0s 61us/step - loss: 1658.0532 - mse: 1658.0530 - mae: 24.6518\n",
      "Epoch 33/60\n",
      "5548/5548 [==============================] - 0s 61us/step - loss: 1649.9192 - mse: 1649.9191 - mae: 24.6050\n",
      "Epoch 34/60\n",
      "5548/5548 [==============================] - 0s 61us/step - loss: 1645.8022 - mse: 1645.8022 - mae: 24.5931\n",
      "Epoch 35/60\n",
      "5548/5548 [==============================] - 0s 61us/step - loss: 1653.6935 - mse: 1653.6940 - mae: 24.6596\n",
      "Epoch 36/60\n",
      "5548/5548 [==============================] - 0s 60us/step - loss: 1642.3277 - mse: 1642.3279 - mae: 24.6120\n",
      "Epoch 37/60\n",
      "5548/5548 [==============================] - 0s 60us/step - loss: 1651.8104 - mse: 1651.8105 - mae: 24.6177\n",
      "Epoch 38/60\n",
      "5548/5548 [==============================] - 0s 60us/step - loss: 1642.3408 - mse: 1642.3408 - mae: 24.6138\n",
      "Epoch 39/60\n",
      "5548/5548 [==============================] - 0s 62us/step - loss: 1651.5243 - mse: 1651.5245 - mae: 24.5872\n",
      "Epoch 40/60\n",
      "5548/5548 [==============================] - 0s 60us/step - loss: 1644.0537 - mse: 1644.0541 - mae: 24.5862\n",
      "Epoch 41/60\n",
      "5548/5548 [==============================] - 0s 60us/step - loss: 1643.9491 - mse: 1643.9493 - mae: 24.6832\n",
      "Epoch 42/60\n",
      "5548/5548 [==============================] - 0s 61us/step - loss: 1643.9752 - mse: 1643.9747 - mae: 24.5498\n",
      "Epoch 43/60\n",
      "5548/5548 [==============================] - 0s 66us/step - loss: 1633.6341 - mse: 1633.6343 - mae: 24.5650\n",
      "Epoch 44/60\n",
      "5548/5548 [==============================] - 0s 71us/step - loss: 1640.9974 - mse: 1640.9971 - mae: 24.5962\n",
      "Epoch 45/60\n",
      "5548/5548 [==============================] - 0s 60us/step - loss: 1636.6461 - mse: 1636.6456 - mae: 24.5772\n",
      "Epoch 46/60\n",
      "5548/5548 [==============================] - 0s 60us/step - loss: 1633.4172 - mse: 1633.4172 - mae: 24.4172\n",
      "Epoch 47/60\n",
      "5548/5548 [==============================] - 0s 60us/step - loss: 1636.6343 - mse: 1636.6338 - mae: 24.6272\n",
      "Epoch 48/60\n",
      "5548/5548 [==============================] - 0s 59us/step - loss: 1634.8911 - mse: 1634.8914 - mae: 24.5318\n",
      "Epoch 49/60\n",
      "5548/5548 [==============================] - 0s 60us/step - loss: 1634.6067 - mse: 1634.6071 - mae: 24.5890\n",
      "Epoch 50/60\n",
      "5548/5548 [==============================] - 0s 59us/step - loss: 1633.3871 - mse: 1633.3870 - mae: 24.5736\n",
      "Epoch 51/60\n",
      "5548/5548 [==============================] - 0s 60us/step - loss: 1628.2154 - mse: 1628.2156 - mae: 24.4540\n",
      "Epoch 52/60\n",
      "5548/5548 [==============================] - 0s 61us/step - loss: 1627.8373 - mse: 1627.8376 - mae: 24.4209\n",
      "Epoch 53/60\n",
      "5548/5548 [==============================] - 0s 61us/step - loss: 1624.7319 - mse: 1624.7319 - mae: 24.4408\n",
      "Epoch 54/60\n",
      "5548/5548 [==============================] - 0s 60us/step - loss: 1627.4322 - mse: 1627.4320 - mae: 24.4556\n",
      "Epoch 55/60\n",
      "5548/5548 [==============================] - 0s 61us/step - loss: 1620.5854 - mse: 1620.5862 - mae: 24.3854\n",
      "Epoch 56/60\n",
      "5548/5548 [==============================] - 0s 61us/step - loss: 1620.2075 - mse: 1620.2072 - mae: 24.4173\n",
      "Epoch 57/60\n",
      "5548/5548 [==============================] - 0s 61us/step - loss: 1622.9749 - mse: 1622.9747 - mae: 24.4516\n",
      "Epoch 58/60\n",
      "5548/5548 [==============================] - 0s 61us/step - loss: 1624.4923 - mse: 1624.4926 - mae: 24.4648\n",
      "Epoch 59/60\n",
      "5548/5548 [==============================] - 0s 60us/step - loss: 1619.4476 - mse: 1619.4479 - mae: 24.4982\n",
      "Epoch 60/60\n",
      "5548/5548 [==============================] - 0s 60us/step - loss: 1611.5120 - mse: 1611.5121 - mae: 24.3114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=60)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "7397/7397 [==============================] - 2s 215us/step - loss: 2676.0610 - mse: 2676.0608 - mae: 32.4101\n",
      "Epoch 2/60\n",
      "7397/7397 [==============================] - 0s 62us/step - loss: 1674.3980 - mse: 1674.3979 - mae: 25.7595\n",
      "Epoch 3/60\n",
      "7397/7397 [==============================] - 0s 61us/step - loss: 1662.1657 - mse: 1662.1656 - mae: 25.6260\n",
      "Epoch 4/60\n",
      "7397/7397 [==============================] - 0s 62us/step - loss: 1650.0430 - mse: 1650.0426 - mae: 25.5309\n",
      "Epoch 5/60\n",
      "7397/7397 [==============================] - 0s 62us/step - loss: 1636.8437 - mse: 1636.8439 - mae: 25.3936\n",
      "Epoch 6/60\n",
      "7397/7397 [==============================] - 0s 61us/step - loss: 1638.0191 - mse: 1638.0190 - mae: 25.5102\n",
      "Epoch 7/60\n",
      "7397/7397 [==============================] - 0s 62us/step - loss: 1641.9977 - mse: 1641.9974 - mae: 25.4575\n",
      "Epoch 8/60\n",
      "7397/7397 [==============================] - 0s 61us/step - loss: 1631.5239 - mse: 1631.5242 - mae: 25.4671\n",
      "Epoch 9/60\n",
      "7397/7397 [==============================] - 0s 61us/step - loss: 1623.4649 - mse: 1623.4653 - mae: 25.3955\n",
      "Epoch 10/60\n",
      "7397/7397 [==============================] - 0s 61us/step - loss: 1628.4915 - mse: 1628.4915 - mae: 25.3557\n",
      "Epoch 11/60\n",
      "7397/7397 [==============================] - 0s 61us/step - loss: 1629.9844 - mse: 1629.9841 - mae: 25.3978\n",
      "Epoch 12/60\n",
      "7397/7397 [==============================] - 0s 62us/step - loss: 1623.2667 - mse: 1623.2659 - mae: 25.3660\n",
      "Epoch 13/60\n",
      "7397/7397 [==============================] - 0s 61us/step - loss: 1622.1142 - mse: 1622.1144 - mae: 25.3213\n",
      "Epoch 14/60\n",
      "7397/7397 [==============================] - 0s 61us/step - loss: 1623.3504 - mse: 1623.3502 - mae: 25.3087\n",
      "Epoch 15/60\n",
      "7397/7397 [==============================] - 0s 61us/step - loss: 1618.7518 - mse: 1618.7521 - mae: 25.2782\n",
      "Epoch 16/60\n",
      "7397/7397 [==============================] - 0s 62us/step - loss: 1612.7147 - mse: 1612.7152 - mae: 25.2211\n",
      "Epoch 17/60\n",
      "7397/7397 [==============================] - 0s 61us/step - loss: 1614.1439 - mse: 1614.1436 - mae: 25.2126\n",
      "Epoch 18/60\n",
      "7397/7397 [==============================] - 0s 62us/step - loss: 1615.3127 - mse: 1615.3129 - mae: 25.2770\n",
      "Epoch 19/60\n",
      "7397/7397 [==============================] - 0s 61us/step - loss: 1613.2391 - mse: 1613.2385 - mae: 25.2531\n",
      "Epoch 20/60\n",
      "7397/7397 [==============================] - 0s 61us/step - loss: 1610.6967 - mse: 1610.6960 - mae: 25.1479\n",
      "Epoch 21/60\n",
      "7397/7397 [==============================] - 0s 62us/step - loss: 1613.6731 - mse: 1613.6732 - mae: 25.2089\n",
      "Epoch 22/60\n",
      "7397/7397 [==============================] - 0s 61us/step - loss: 1610.1192 - mse: 1610.1198 - mae: 25.1768\n",
      "Epoch 23/60\n",
      "7397/7397 [==============================] - 0s 61us/step - loss: 1610.9308 - mse: 1610.9307 - mae: 25.1538\n",
      "Epoch 24/60\n",
      "7397/7397 [==============================] - 0s 60us/step - loss: 1602.6475 - mse: 1602.6466 - mae: 25.1665\n",
      "Epoch 25/60\n",
      "7397/7397 [==============================] - 0s 60us/step - loss: 1604.0784 - mse: 1604.0785 - mae: 25.0748\n",
      "Epoch 26/60\n",
      "7397/7397 [==============================] - 0s 60us/step - loss: 1600.9447 - mse: 1600.9449 - mae: 25.0908\n",
      "Epoch 27/60\n",
      "7397/7397 [==============================] - 0s 61us/step - loss: 1599.0924 - mse: 1599.0925 - mae: 25.0158\n",
      "Epoch 28/60\n",
      "7397/7397 [==============================] - 0s 61us/step - loss: 1602.0855 - mse: 1602.0856 - mae: 25.0930\n",
      "Epoch 29/60\n",
      "7397/7397 [==============================] - 0s 61us/step - loss: 1603.5494 - mse: 1603.5493 - mae: 25.1709\n",
      "Epoch 30/60\n",
      "7397/7397 [==============================] - 0s 61us/step - loss: 1603.5715 - mse: 1603.5715 - mae: 25.1425\n",
      "Epoch 31/60\n",
      "7397/7397 [==============================] - 0s 61us/step - loss: 1596.2158 - mse: 1596.2158 - mae: 25.0816\n",
      "Epoch 32/60\n",
      "7397/7397 [==============================] - 0s 60us/step - loss: 1602.1338 - mse: 1602.1343 - mae: 25.1384\n",
      "Epoch 33/60\n",
      "7397/7397 [==============================] - 0s 60us/step - loss: 1593.0911 - mse: 1593.0911 - mae: 25.0037\n",
      "Epoch 34/60\n",
      "7397/7397 [==============================] - 0s 60us/step - loss: 1590.0519 - mse: 1590.0521 - mae: 25.0407\n",
      "Epoch 35/60\n",
      "7397/7397 [==============================] - 0s 60us/step - loss: 1597.9550 - mse: 1597.9546 - mae: 25.0490\n",
      "Epoch 36/60\n",
      "7397/7397 [==============================] - 0s 60us/step - loss: 1599.4144 - mse: 1599.4148 - mae: 25.0367\n",
      "Epoch 37/60\n",
      "7397/7397 [==============================] - 0s 60us/step - loss: 1594.4730 - mse: 1594.4729 - mae: 24.9603\n",
      "Epoch 38/60\n",
      "7397/7397 [==============================] - 0s 60us/step - loss: 1590.9021 - mse: 1590.9020 - mae: 25.0652\n",
      "Epoch 39/60\n",
      "7397/7397 [==============================] - 0s 60us/step - loss: 1594.6533 - mse: 1594.6531 - mae: 25.0095\n",
      "Epoch 40/60\n",
      "7397/7397 [==============================] - 0s 60us/step - loss: 1589.2156 - mse: 1589.2162 - mae: 25.0406\n",
      "Epoch 41/60\n",
      "7397/7397 [==============================] - 0s 60us/step - loss: 1590.5600 - mse: 1590.5607 - mae: 24.9891\n",
      "Epoch 42/60\n",
      "7397/7397 [==============================] - 0s 61us/step - loss: 1592.1987 - mse: 1592.1982 - mae: 24.9933\n",
      "Epoch 43/60\n",
      "7397/7397 [==============================] - 0s 62us/step - loss: 1590.5964 - mse: 1590.5966 - mae: 24.9749\n",
      "Epoch 44/60\n",
      "7397/7397 [==============================] - 0s 62us/step - loss: 1586.5710 - mse: 1586.5710 - mae: 24.9949\n",
      "Epoch 45/60\n",
      "7397/7397 [==============================] - 0s 62us/step - loss: 1585.4632 - mse: 1585.4630 - mae: 24.9591\n",
      "Epoch 46/60\n",
      "7397/7397 [==============================] - 0s 62us/step - loss: 1592.5332 - mse: 1592.5333 - mae: 25.0938\n",
      "Epoch 47/60\n",
      "7397/7397 [==============================] - 0s 61us/step - loss: 1581.9637 - mse: 1581.9630 - mae: 24.8996\n",
      "Epoch 48/60\n",
      "7397/7397 [==============================] - 0s 60us/step - loss: 1583.3241 - mse: 1583.3242 - mae: 24.8967\n",
      "Epoch 49/60\n",
      "7397/7397 [==============================] - 0s 61us/step - loss: 1580.1236 - mse: 1580.1234 - mae: 24.9167\n",
      "Epoch 50/60\n",
      "7397/7397 [==============================] - 0s 62us/step - loss: 1579.9787 - mse: 1579.9788 - mae: 24.9049\n",
      "Epoch 51/60\n",
      "7397/7397 [==============================] - 0s 61us/step - loss: 1578.7940 - mse: 1578.7939 - mae: 24.8811\n",
      "Epoch 52/60\n",
      "7397/7397 [==============================] - 0s 62us/step - loss: 1578.3625 - mse: 1578.3621 - mae: 24.9030\n",
      "Epoch 53/60\n",
      "7397/7397 [==============================] - 0s 62us/step - loss: 1579.1892 - mse: 1579.1890 - mae: 24.8536\n",
      "Epoch 54/60\n",
      "7397/7397 [==============================] - 0s 61us/step - loss: 1580.6488 - mse: 1580.6493 - mae: 24.8156\n",
      "Epoch 55/60\n",
      "7397/7397 [==============================] - 0s 62us/step - loss: 1580.6142 - mse: 1580.6139 - mae: 24.9746\n",
      "Epoch 56/60\n",
      "7397/7397 [==============================] - 0s 62us/step - loss: 1576.9062 - mse: 1576.9064 - mae: 24.8993\n",
      "Epoch 57/60\n",
      "7397/7397 [==============================] - 0s 62us/step - loss: 1578.4740 - mse: 1578.4741 - mae: 24.8504\n",
      "Epoch 58/60\n",
      "7397/7397 [==============================] - 0s 62us/step - loss: 1574.3592 - mse: 1574.3593 - mae: 24.9590\n",
      "Epoch 59/60\n",
      "7397/7397 [==============================] - 0s 62us/step - loss: 1577.1579 - mse: 1577.1576 - mae: 24.9464\n",
      "Epoch 60/60\n",
      "7397/7397 [==============================] - 0s 62us/step - loss: 1571.6597 - mse: 1571.6594 - mae: 24.8718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=20)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "1850/1850 [==============================] - 1s 484us/step - loss: 10267.4358 - mse: 10267.4336 - mae: 95.2157\n",
      "Epoch 2/60\n",
      "1850/1850 [==============================] - 0s 50us/step - loss: 1443.3824 - mse: 1443.3822 - mae: 26.8432\n",
      "Epoch 3/60\n",
      "1850/1850 [==============================] - 0s 50us/step - loss: 1048.2243 - mse: 1048.2242 - mae: 22.7103\n",
      "Epoch 4/60\n",
      "1850/1850 [==============================] - 0s 50us/step - loss: 1049.3527 - mse: 1049.3528 - mae: 22.6521\n",
      "Epoch 5/60\n",
      "1850/1850 [==============================] - 0s 51us/step - loss: 1045.5087 - mse: 1045.5085 - mae: 22.3112\n",
      "Epoch 6/60\n",
      "1850/1850 [==============================] - 0s 51us/step - loss: 1039.9618 - mse: 1039.9617 - mae: 22.4150\n",
      "Epoch 7/60\n",
      "1850/1850 [==============================] - 0s 51us/step - loss: 1044.5143 - mse: 1044.5144 - mae: 22.4792\n",
      "Epoch 8/60\n",
      "1850/1850 [==============================] - 0s 51us/step - loss: 1031.3653 - mse: 1031.3655 - mae: 22.1577\n",
      "Epoch 9/60\n",
      "1850/1850 [==============================] - 0s 51us/step - loss: 1035.7497 - mse: 1035.7498 - mae: 22.1124\n",
      "Epoch 10/60\n",
      "1850/1850 [==============================] - 0s 51us/step - loss: 1031.9056 - mse: 1031.9056 - mae: 22.1102\n",
      "Epoch 11/60\n",
      "1850/1850 [==============================] - 0s 52us/step - loss: 1026.9784 - mse: 1026.9784 - mae: 22.1300\n",
      "Epoch 12/60\n",
      "1850/1850 [==============================] - 0s 52us/step - loss: 1030.0214 - mse: 1030.0214 - mae: 21.9728\n",
      "Epoch 13/60\n",
      "1850/1850 [==============================] - 0s 51us/step - loss: 1031.1411 - mse: 1031.1412 - mae: 21.9744\n",
      "Epoch 14/60\n",
      "1850/1850 [==============================] - 0s 51us/step - loss: 1023.3675 - mse: 1023.3676 - mae: 21.9010\n",
      "Epoch 15/60\n",
      "1850/1850 [==============================] - 0s 51us/step - loss: 1025.7822 - mse: 1025.7821 - mae: 21.8704\n",
      "Epoch 16/60\n",
      "1850/1850 [==============================] - 0s 51us/step - loss: 1028.5883 - mse: 1028.5881 - mae: 21.8718\n",
      "Epoch 17/60\n",
      "1850/1850 [==============================] - 0s 51us/step - loss: 1022.9409 - mse: 1022.9407 - mae: 21.8341\n",
      "Epoch 18/60\n",
      "1850/1850 [==============================] - 0s 51us/step - loss: 1021.1877 - mse: 1021.1876 - mae: 21.8788\n",
      "Epoch 19/60\n",
      "1850/1850 [==============================] - 0s 51us/step - loss: 1021.1238 - mse: 1021.1237 - mae: 21.7397\n",
      "Epoch 20/60\n",
      "1850/1850 [==============================] - 0s 51us/step - loss: 1024.9400 - mse: 1024.9402 - mae: 21.8230\n",
      "Epoch 21/60\n",
      "1850/1850 [==============================] - 0s 51us/step - loss: 1025.6032 - mse: 1025.6033 - mae: 21.7635\n",
      "Epoch 22/60\n",
      "1850/1850 [==============================] - 0s 51us/step - loss: 1018.0466 - mse: 1018.0466 - mae: 21.7801\n",
      "Epoch 23/60\n",
      "1850/1850 [==============================] - 0s 50us/step - loss: 1022.3536 - mse: 1022.3536 - mae: 21.6869\n",
      "Epoch 24/60\n",
      "1850/1850 [==============================] - 0s 51us/step - loss: 1021.0432 - mse: 1021.0430 - mae: 21.6553\n",
      "Epoch 25/60\n",
      "1850/1850 [==============================] - 0s 51us/step - loss: 1020.8591 - mse: 1020.8591 - mae: 21.7806\n",
      "Epoch 26/60\n",
      "1850/1850 [==============================] - 0s 50us/step - loss: 1016.8227 - mse: 1016.8228 - mae: 21.7295\n",
      "Epoch 27/60\n",
      "1850/1850 [==============================] - 0s 51us/step - loss: 1016.4892 - mse: 1016.4894 - mae: 21.8363\n",
      "Epoch 28/60\n",
      "1850/1850 [==============================] - 0s 50us/step - loss: 1023.3874 - mse: 1023.3875 - mae: 21.8178\n",
      "Epoch 29/60\n",
      "1850/1850 [==============================] - 0s 49us/step - loss: 1019.2148 - mse: 1019.2147 - mae: 21.7830\n",
      "Epoch 30/60\n",
      "1850/1850 [==============================] - 0s 50us/step - loss: 1022.6066 - mse: 1022.6067 - mae: 21.7485\n",
      "Epoch 31/60\n",
      "1850/1850 [==============================] - 0s 50us/step - loss: 1012.7822 - mse: 1012.7823 - mae: 21.6292\n",
      "Epoch 32/60\n",
      "1850/1850 [==============================] - 0s 51us/step - loss: 1019.3175 - mse: 1019.3174 - mae: 21.5839\n",
      "Epoch 33/60\n",
      "1850/1850 [==============================] - 0s 51us/step - loss: 1027.7345 - mse: 1027.7345 - mae: 21.8353\n",
      "Epoch 34/60\n",
      "1850/1850 [==============================] - 0s 52us/step - loss: 1014.2618 - mse: 1014.2617 - mae: 21.5564\n",
      "Epoch 35/60\n",
      "1850/1850 [==============================] - 0s 51us/step - loss: 1015.9765 - mse: 1015.9764 - mae: 21.7031\n",
      "Epoch 36/60\n",
      "1850/1850 [==============================] - 0s 51us/step - loss: 1012.1139 - mse: 1012.1141 - mae: 21.5866\n",
      "Epoch 37/60\n",
      "1850/1850 [==============================] - 0s 52us/step - loss: 1015.5244 - mse: 1015.5245 - mae: 21.5594\n",
      "Epoch 38/60\n",
      "1850/1850 [==============================] - 0s 51us/step - loss: 1022.6741 - mse: 1022.6739 - mae: 21.6622\n",
      "Epoch 39/60\n",
      "1850/1850 [==============================] - 0s 51us/step - loss: 1015.2035 - mse: 1015.2034 - mae: 21.5921\n",
      "Epoch 40/60\n",
      "1850/1850 [==============================] - 0s 51us/step - loss: 1016.1723 - mse: 1016.1724 - mae: 21.5182\n",
      "Epoch 41/60\n",
      "1850/1850 [==============================] - 0s 51us/step - loss: 1024.7341 - mse: 1024.7341 - mae: 21.7073\n",
      "Epoch 42/60\n",
      "1850/1850 [==============================] - 0s 51us/step - loss: 1009.3685 - mse: 1009.3684 - mae: 21.5821\n",
      "Epoch 43/60\n",
      "1850/1850 [==============================] - 0s 51us/step - loss: 1008.5534 - mse: 1008.5536 - mae: 21.7050\n",
      "Epoch 44/60\n",
      "1850/1850 [==============================] - 0s 50us/step - loss: 1017.0320 - mse: 1017.0319 - mae: 21.6747\n",
      "Epoch 45/60\n",
      "1850/1850 [==============================] - 0s 51us/step - loss: 1009.9200 - mse: 1009.9199 - mae: 21.4465\n",
      "Epoch 46/60\n",
      "1850/1850 [==============================] - 0s 51us/step - loss: 1005.6309 - mse: 1005.6309 - mae: 21.4078\n",
      "Epoch 47/60\n",
      "1850/1850 [==============================] - 0s 51us/step - loss: 1008.7577 - mse: 1008.7576 - mae: 21.6029\n",
      "Epoch 48/60\n",
      "1850/1850 [==============================] - 0s 51us/step - loss: 1012.6716 - mse: 1012.6716 - mae: 21.6731\n",
      "Epoch 49/60\n",
      "1850/1850 [==============================] - 0s 50us/step - loss: 1017.8245 - mse: 1017.8246 - mae: 21.5676\n",
      "Epoch 50/60\n",
      "1850/1850 [==============================] - 0s 51us/step - loss: 1018.3707 - mse: 1018.3708 - mae: 21.6436\n",
      "Epoch 51/60\n",
      "1850/1850 [==============================] - 0s 51us/step - loss: 1015.8272 - mse: 1015.8272 - mae: 21.5488\n",
      "Epoch 52/60\n",
      "1850/1850 [==============================] - 0s 51us/step - loss: 1017.0586 - mse: 1017.0587 - mae: 21.4665\n",
      "Epoch 53/60\n",
      "1850/1850 [==============================] - 0s 51us/step - loss: 1016.3844 - mse: 1016.3845 - mae: 21.5989\n",
      "Epoch 54/60\n",
      "1850/1850 [==============================] - 0s 50us/step - loss: 1008.9400 - mse: 1008.9400 - mae: 21.5152\n",
      "Epoch 55/60\n",
      "1850/1850 [==============================] - 0s 51us/step - loss: 1015.1878 - mse: 1015.1877 - mae: 21.6286\n",
      "Epoch 56/60\n",
      "1850/1850 [==============================] - 0s 51us/step - loss: 1016.5399 - mse: 1016.5400 - mae: 21.5724\n",
      "Epoch 57/60\n",
      "1850/1850 [==============================] - 0s 51us/step - loss: 1014.3941 - mse: 1014.3942 - mae: 21.4922\n",
      "Epoch 58/60\n",
      "1850/1850 [==============================] - 0s 51us/step - loss: 1009.4787 - mse: 1009.4787 - mae: 21.5823\n",
      "Epoch 59/60\n",
      "1850/1850 [==============================] - 0s 50us/step - loss: 1017.7191 - mse: 1017.7191 - mae: 21.5868\n",
      "Epoch 60/60\n",
      "1850/1850 [==============================] - 0s 50us/step - loss: 1011.7235 - mse: 1011.7235 - mae: 21.5933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=20)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "3699/3699 [==============================] - 1s 270us/step - loss: 5471.4203 - mse: 5471.4199 - mae: 57.3318\n",
      "Epoch 2/60\n",
      "3699/3699 [==============================] - 0s 50us/step - loss: 1150.0021 - mse: 1150.0023 - mae: 23.0100\n",
      "Epoch 3/60\n",
      "3699/3699 [==============================] - 0s 51us/step - loss: 1141.5576 - mse: 1141.5576 - mae: 22.8973\n",
      "Epoch 4/60\n",
      "3699/3699 [==============================] - 0s 50us/step - loss: 1142.0914 - mse: 1142.0916 - mae: 23.0035\n",
      "Epoch 5/60\n",
      "3699/3699 [==============================] - 0s 50us/step - loss: 1137.6622 - mse: 1137.6622 - mae: 22.7857\n",
      "Epoch 6/60\n",
      "3699/3699 [==============================] - 0s 50us/step - loss: 1142.3899 - mse: 1142.3899 - mae: 22.7898\n",
      "Epoch 7/60\n",
      "3699/3699 [==============================] - 0s 50us/step - loss: 1134.2855 - mse: 1134.2855 - mae: 22.8849\n",
      "Epoch 8/60\n",
      "3699/3699 [==============================] - 0s 51us/step - loss: 1139.6350 - mse: 1139.6350 - mae: 22.7587\n",
      "Epoch 9/60\n",
      "3699/3699 [==============================] - 0s 50us/step - loss: 1133.4128 - mse: 1133.4126 - mae: 22.7090\n",
      "Epoch 10/60\n",
      "3699/3699 [==============================] - 0s 50us/step - loss: 1142.2070 - mse: 1142.2068 - mae: 22.9059\n",
      "Epoch 11/60\n",
      "3699/3699 [==============================] - 0s 50us/step - loss: 1134.4702 - mse: 1134.4702 - mae: 22.7669\n",
      "Epoch 12/60\n",
      "3699/3699 [==============================] - 0s 51us/step - loss: 1130.0954 - mse: 1130.0952 - mae: 22.7081\n",
      "Epoch 13/60\n",
      "3699/3699 [==============================] - 0s 51us/step - loss: 1139.2402 - mse: 1139.2404 - mae: 22.7007\n",
      "Epoch 14/60\n",
      "3699/3699 [==============================] - 0s 51us/step - loss: 1135.8047 - mse: 1135.8046 - mae: 22.8011\n",
      "Epoch 15/60\n",
      "3699/3699 [==============================] - 0s 51us/step - loss: 1132.5912 - mse: 1132.5912 - mae: 22.7245\n",
      "Epoch 16/60\n",
      "3699/3699 [==============================] - 0s 51us/step - loss: 1135.1042 - mse: 1135.1042 - mae: 22.6748\n",
      "Epoch 17/60\n",
      "3699/3699 [==============================] - 0s 51us/step - loss: 1133.6578 - mse: 1133.6580 - mae: 22.8093\n",
      "Epoch 18/60\n",
      "3699/3699 [==============================] - 0s 51us/step - loss: 1136.5523 - mse: 1136.5521 - mae: 22.6844\n",
      "Epoch 19/60\n",
      "3699/3699 [==============================] - 0s 51us/step - loss: 1130.3298 - mse: 1130.3298 - mae: 22.7017\n",
      "Epoch 20/60\n",
      "3699/3699 [==============================] - 0s 51us/step - loss: 1134.3314 - mse: 1134.3312 - mae: 22.7010\n",
      "Epoch 21/60\n",
      "3699/3699 [==============================] - 0s 51us/step - loss: 1131.1489 - mse: 1131.1490 - mae: 22.7640\n",
      "Epoch 22/60\n",
      "3699/3699 [==============================] - 0s 51us/step - loss: 1130.0420 - mse: 1130.0417 - mae: 22.5813\n",
      "Epoch 23/60\n",
      "3699/3699 [==============================] - 0s 51us/step - loss: 1132.3420 - mse: 1132.3418 - mae: 22.6854\n",
      "Epoch 24/60\n",
      "3699/3699 [==============================] - 0s 51us/step - loss: 1137.4994 - mse: 1137.4995 - mae: 22.7502\n",
      "Epoch 25/60\n",
      "3699/3699 [==============================] - 0s 51us/step - loss: 1134.7865 - mse: 1134.7864 - mae: 22.7838\n",
      "Epoch 26/60\n",
      "3699/3699 [==============================] - 0s 51us/step - loss: 1131.6953 - mse: 1131.6953 - mae: 22.7069\n",
      "Epoch 27/60\n",
      "3699/3699 [==============================] - 0s 51us/step - loss: 1137.8830 - mse: 1137.8832 - mae: 22.6924\n",
      "Epoch 28/60\n",
      "3699/3699 [==============================] - 0s 51us/step - loss: 1132.4119 - mse: 1132.4119 - mae: 22.7027\n",
      "Epoch 29/60\n",
      "3699/3699 [==============================] - 0s 51us/step - loss: 1129.7248 - mse: 1129.7247 - mae: 22.6945\n",
      "Epoch 30/60\n",
      "3699/3699 [==============================] - 0s 51us/step - loss: 1130.6577 - mse: 1130.6578 - mae: 22.6752\n",
      "Epoch 31/60\n",
      "3699/3699 [==============================] - 0s 51us/step - loss: 1137.0156 - mse: 1137.0155 - mae: 22.8027\n",
      "Epoch 32/60\n",
      "3699/3699 [==============================] - 0s 51us/step - loss: 1133.3664 - mse: 1133.3663 - mae: 22.6712\n",
      "Epoch 33/60\n",
      "3699/3699 [==============================] - 0s 50us/step - loss: 1135.6068 - mse: 1135.6066 - mae: 22.7087\n",
      "Epoch 34/60\n",
      "3699/3699 [==============================] - 0s 50us/step - loss: 1132.9218 - mse: 1132.9219 - mae: 22.6931\n",
      "Epoch 35/60\n",
      "3699/3699 [==============================] - 0s 50us/step - loss: 1131.3108 - mse: 1131.3108 - mae: 22.6670\n",
      "Epoch 36/60\n",
      "3699/3699 [==============================] - 0s 50us/step - loss: 1126.4175 - mse: 1126.4174 - mae: 22.7150\n",
      "Epoch 37/60\n",
      "3699/3699 [==============================] - 0s 50us/step - loss: 1127.7535 - mse: 1127.7535 - mae: 22.5936\n",
      "Epoch 38/60\n",
      "3699/3699 [==============================] - 0s 50us/step - loss: 1129.9789 - mse: 1129.9788 - mae: 22.6561\n",
      "Epoch 39/60\n",
      "3699/3699 [==============================] - 0s 50us/step - loss: 1128.0459 - mse: 1128.0459 - mae: 22.6259\n",
      "Epoch 40/60\n",
      "3699/3699 [==============================] - 0s 50us/step - loss: 1135.5250 - mse: 1135.5249 - mae: 22.6616\n",
      "Epoch 41/60\n",
      "3699/3699 [==============================] - 0s 50us/step - loss: 1128.9846 - mse: 1128.9846 - mae: 22.6644\n",
      "Epoch 42/60\n",
      "3699/3699 [==============================] - 0s 50us/step - loss: 1122.7100 - mse: 1122.7101 - mae: 22.6700\n",
      "Epoch 43/60\n",
      "3699/3699 [==============================] - 0s 50us/step - loss: 1130.0988 - mse: 1130.0989 - mae: 22.5736\n",
      "Epoch 44/60\n",
      "3699/3699 [==============================] - 0s 50us/step - loss: 1130.5029 - mse: 1130.5028 - mae: 22.6723\n",
      "Epoch 45/60\n",
      "3699/3699 [==============================] - 0s 50us/step - loss: 1128.7255 - mse: 1128.7256 - mae: 22.6463\n",
      "Epoch 46/60\n",
      "3699/3699 [==============================] - 0s 50us/step - loss: 1131.9680 - mse: 1131.9680 - mae: 22.7689\n",
      "Epoch 47/60\n",
      "3699/3699 [==============================] - 0s 50us/step - loss: 1130.1056 - mse: 1130.1061 - mae: 22.6178\n",
      "Epoch 48/60\n",
      "3699/3699 [==============================] - 0s 50us/step - loss: 1132.3283 - mse: 1132.3282 - mae: 22.6791\n",
      "Epoch 49/60\n",
      "3699/3699 [==============================] - 0s 50us/step - loss: 1131.0862 - mse: 1131.0859 - mae: 22.6427\n",
      "Epoch 50/60\n",
      "3699/3699 [==============================] - 0s 50us/step - loss: 1128.2391 - mse: 1128.2390 - mae: 22.6399\n",
      "Epoch 51/60\n",
      "3699/3699 [==============================] - 0s 50us/step - loss: 1129.2372 - mse: 1129.2371 - mae: 22.6095\n",
      "Epoch 52/60\n",
      "3699/3699 [==============================] - 0s 50us/step - loss: 1126.9016 - mse: 1126.9016 - mae: 22.6041\n",
      "Epoch 53/60\n",
      "3699/3699 [==============================] - 0s 50us/step - loss: 1123.8271 - mse: 1123.8271 - mae: 22.6026\n",
      "Epoch 54/60\n",
      "3699/3699 [==============================] - 0s 50us/step - loss: 1129.3808 - mse: 1129.3807 - mae: 22.5855\n",
      "Epoch 55/60\n",
      "3699/3699 [==============================] - 0s 50us/step - loss: 1124.2133 - mse: 1124.2135 - mae: 22.6230\n",
      "Epoch 56/60\n",
      "3699/3699 [==============================] - 0s 50us/step - loss: 1123.5235 - mse: 1123.5236 - mae: 22.5579\n",
      "Epoch 57/60\n",
      "3699/3699 [==============================] - 0s 51us/step - loss: 1128.5461 - mse: 1128.5463 - mae: 22.6270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=20)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "5548/5548 [==============================] - 1s 194us/step - loss: 5670.1414 - mse: 5670.1426 - mae: 53.7869\n",
      "Epoch 2/60\n",
      "5548/5548 [==============================] - 0s 50us/step - loss: 1720.6187 - mse: 1720.6190 - mae: 25.2592\n",
      "Epoch 3/60\n",
      "5548/5548 [==============================] - 0s 50us/step - loss: 1711.2948 - mse: 1711.2949 - mae: 25.2350\n",
      "Epoch 4/60\n",
      "5548/5548 [==============================] - 0s 50us/step - loss: 1714.4239 - mse: 1714.4240 - mae: 25.1738\n",
      "Epoch 5/60\n",
      "5548/5548 [==============================] - 0s 54us/step - loss: 1714.0355 - mse: 1714.0359 - mae: 25.3214\n",
      "Epoch 6/60\n",
      "5548/5548 [==============================] - 0s 51us/step - loss: 1703.7587 - mse: 1703.7584 - mae: 25.0992\n",
      "Epoch 7/60\n",
      "5548/5548 [==============================] - 0s 50us/step - loss: 1698.2103 - mse: 1698.2102 - mae: 25.2324\n",
      "Epoch 8/60\n",
      "5548/5548 [==============================] - 0s 50us/step - loss: 1707.8500 - mse: 1707.8502 - mae: 25.2389\n",
      "Epoch 9/60\n",
      "5548/5548 [==============================] - 0s 50us/step - loss: 1699.7351 - mse: 1699.7349 - mae: 25.3069\n",
      "Epoch 10/60\n",
      "5548/5548 [==============================] - 0s 50us/step - loss: 1703.7212 - mse: 1703.7213 - mae: 25.1167\n",
      "Epoch 11/60\n",
      "5548/5548 [==============================] - 0s 50us/step - loss: 1698.6686 - mse: 1698.6686 - mae: 25.0798\n",
      "Epoch 12/60\n",
      "5548/5548 [==============================] - 0s 50us/step - loss: 1698.7433 - mse: 1698.7435 - mae: 25.1202\n",
      "Epoch 13/60\n",
      "5548/5548 [==============================] - 0s 50us/step - loss: 1696.1010 - mse: 1696.1017 - mae: 25.1728\n",
      "Epoch 14/60\n",
      "5548/5548 [==============================] - 0s 50us/step - loss: 1691.9842 - mse: 1691.9840 - mae: 25.0897\n",
      "Epoch 15/60\n",
      "5548/5548 [==============================] - 0s 50us/step - loss: 1690.7432 - mse: 1690.7433 - mae: 25.1185\n",
      "Epoch 16/60\n",
      "5548/5548 [==============================] - 0s 51us/step - loss: 1696.6756 - mse: 1696.6754 - mae: 25.1909\n",
      "Epoch 17/60\n",
      "5548/5548 [==============================] - 0s 50us/step - loss: 1693.9865 - mse: 1693.9874 - mae: 25.1219\n",
      "Epoch 18/60\n",
      "5548/5548 [==============================] - 0s 50us/step - loss: 1693.1862 - mse: 1693.1862 - mae: 24.9706\n",
      "Epoch 19/60\n",
      "5548/5548 [==============================] - 0s 50us/step - loss: 1690.4014 - mse: 1690.4010 - mae: 25.0774\n",
      "Epoch 20/60\n",
      "5548/5548 [==============================] - 0s 51us/step - loss: 1687.1219 - mse: 1687.1224 - mae: 25.0196\n",
      "Epoch 21/60\n",
      "5548/5548 [==============================] - 0s 50us/step - loss: 1685.7168 - mse: 1685.7168 - mae: 25.0902\n",
      "Epoch 22/60\n",
      "5548/5548 [==============================] - 0s 50us/step - loss: 1688.5803 - mse: 1688.5806 - mae: 25.0294\n",
      "Epoch 23/60\n",
      "5548/5548 [==============================] - 0s 50us/step - loss: 1690.8772 - mse: 1690.8772 - mae: 25.1041\n",
      "Epoch 24/60\n",
      "5548/5548 [==============================] - 0s 50us/step - loss: 1687.4722 - mse: 1687.4730 - mae: 25.0941\n",
      "Epoch 25/60\n",
      "5548/5548 [==============================] - 0s 50us/step - loss: 1687.3476 - mse: 1687.3475 - mae: 25.0712\n",
      "Epoch 26/60\n",
      "5548/5548 [==============================] - 0s 50us/step - loss: 1686.4218 - mse: 1686.4216 - mae: 25.1030\n",
      "Epoch 27/60\n",
      "5548/5548 [==============================] - 0s 50us/step - loss: 1683.5638 - mse: 1683.5638 - mae: 24.9544\n",
      "Epoch 28/60\n",
      "5548/5548 [==============================] - 0s 51us/step - loss: 1683.3050 - mse: 1683.3049 - mae: 25.1116\n",
      "Epoch 29/60\n",
      "5548/5548 [==============================] - 0s 51us/step - loss: 1686.1223 - mse: 1686.1226 - mae: 24.9897\n",
      "Epoch 30/60\n",
      "5548/5548 [==============================] - 0s 50us/step - loss: 1685.0795 - mse: 1685.0798 - mae: 24.9874\n",
      "Epoch 31/60\n",
      "5548/5548 [==============================] - 0s 50us/step - loss: 1685.0471 - mse: 1685.0470 - mae: 24.9848\n",
      "Epoch 32/60\n",
      "5548/5548 [==============================] - 0s 50us/step - loss: 1680.6098 - mse: 1680.6096 - mae: 25.0221\n",
      "Epoch 33/60\n",
      "5548/5548 [==============================] - 0s 50us/step - loss: 1684.0032 - mse: 1684.0027 - mae: 25.0422\n",
      "Epoch 34/60\n",
      "5548/5548 [==============================] - 0s 50us/step - loss: 1683.4931 - mse: 1683.4935 - mae: 24.9557\n",
      "Epoch 35/60\n",
      "5548/5548 [==============================] - 0s 50us/step - loss: 1684.9631 - mse: 1684.9633 - mae: 25.0508\n",
      "Epoch 36/60\n",
      "5548/5548 [==============================] - 0s 50us/step - loss: 1683.2746 - mse: 1683.2742 - mae: 25.0487\n",
      "Epoch 37/60\n",
      "5548/5548 [==============================] - 0s 51us/step - loss: 1675.9290 - mse: 1675.9288 - mae: 24.9118\n",
      "Epoch 38/60\n",
      "5548/5548 [==============================] - 0s 51us/step - loss: 1674.1148 - mse: 1674.1149 - mae: 24.8961\n",
      "Epoch 39/60\n",
      "5548/5548 [==============================] - 0s 51us/step - loss: 1683.7395 - mse: 1683.7394 - mae: 24.9772\n",
      "Epoch 40/60\n",
      "5548/5548 [==============================] - 0s 51us/step - loss: 1675.6680 - mse: 1675.6678 - mae: 24.9328\n",
      "Epoch 41/60\n",
      "5548/5548 [==============================] - 0s 51us/step - loss: 1681.0135 - mse: 1681.0133 - mae: 24.9447\n",
      "Epoch 42/60\n",
      "5548/5548 [==============================] - 0s 50us/step - loss: 1682.3606 - mse: 1682.3604 - mae: 24.9739\n",
      "Epoch 43/60\n",
      "5548/5548 [==============================] - 0s 50us/step - loss: 1677.3303 - mse: 1677.3306 - mae: 24.8957\n",
      "Epoch 44/60\n",
      "5548/5548 [==============================] - 0s 50us/step - loss: 1676.6428 - mse: 1676.6431 - mae: 25.0095\n",
      "Epoch 45/60\n",
      "5548/5548 [==============================] - 0s 50us/step - loss: 1677.2842 - mse: 1677.2841 - mae: 24.9563\n",
      "Epoch 46/60\n",
      "5548/5548 [==============================] - 0s 50us/step - loss: 1672.3000 - mse: 1672.3000 - mae: 24.8874\n",
      "Epoch 47/60\n",
      "5548/5548 [==============================] - 0s 50us/step - loss: 1677.1899 - mse: 1677.1899 - mae: 24.9656\n",
      "Epoch 48/60\n",
      "5548/5548 [==============================] - 0s 50us/step - loss: 1676.4101 - mse: 1676.4106 - mae: 24.9893\n",
      "Epoch 49/60\n",
      "5548/5548 [==============================] - 0s 50us/step - loss: 1679.1984 - mse: 1679.1982 - mae: 25.0084\n",
      "Epoch 50/60\n",
      "5548/5548 [==============================] - 0s 50us/step - loss: 1674.3920 - mse: 1674.3922 - mae: 24.9157\n",
      "Epoch 51/60\n",
      "5548/5548 [==============================] - 0s 50us/step - loss: 1676.7028 - mse: 1676.7026 - mae: 24.9666\n",
      "Epoch 52/60\n",
      "5548/5548 [==============================] - 0s 50us/step - loss: 1673.3697 - mse: 1673.3696 - mae: 24.9887\n",
      "Epoch 53/60\n",
      "5548/5548 [==============================] - 0s 50us/step - loss: 1672.7725 - mse: 1672.7727 - mae: 24.9384\n",
      "Epoch 54/60\n",
      "5548/5548 [==============================] - 0s 50us/step - loss: 1673.7639 - mse: 1673.7639 - mae: 24.9317\n",
      "Epoch 55/60\n",
      "5548/5548 [==============================] - 0s 50us/step - loss: 1669.6877 - mse: 1669.6876 - mae: 24.8441\n",
      "Epoch 56/60\n",
      "5548/5548 [==============================] - 0s 50us/step - loss: 1674.3693 - mse: 1674.3695 - mae: 24.9769\n",
      "Epoch 57/60\n",
      "5548/5548 [==============================] - 0s 50us/step - loss: 1673.9962 - mse: 1673.9963 - mae: 24.8891\n",
      "Epoch 58/60\n",
      "5548/5548 [==============================] - 0s 50us/step - loss: 1668.6705 - mse: 1668.6705 - mae: 24.8061\n",
      "Epoch 59/60\n",
      "5548/5548 [==============================] - 0s 50us/step - loss: 1668.7085 - mse: 1668.7080 - mae: 24.8974\n",
      "Epoch 60/60\n",
      "5548/5548 [==============================] - 0s 50us/step - loss: 1669.5737 - mse: 1669.5739 - mae: 24.8306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=20)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "7397/7397 [==============================] - 1s 161us/step - loss: 4251.7302 - mse: 4251.7314 - mae: 44.5770\n",
      "Epoch 2/60\n",
      "7397/7397 [==============================] - 0s 51us/step - loss: 1661.3640 - mse: 1661.3628 - mae: 25.7392\n",
      "Epoch 3/60\n",
      "7397/7397 [==============================] - 0s 51us/step - loss: 1661.4531 - mse: 1661.4528 - mae: 25.6451\n",
      "Epoch 4/60\n",
      "7397/7397 [==============================] - 0s 51us/step - loss: 1656.0725 - mse: 1656.0721 - mae: 25.5387\n",
      "Epoch 5/60\n",
      "7397/7397 [==============================] - 0s 51us/step - loss: 1650.4290 - mse: 1650.4291 - mae: 25.6024\n",
      "Epoch 6/60\n",
      "7397/7397 [==============================] - 0s 50us/step - loss: 1645.2144 - mse: 1645.2148 - mae: 25.4376\n",
      "Epoch 7/60\n",
      "7397/7397 [==============================] - 0s 50us/step - loss: 1646.5523 - mse: 1646.5521 - mae: 25.5667\n",
      "Epoch 8/60\n",
      "7397/7397 [==============================] - 0s 51us/step - loss: 1643.2996 - mse: 1643.2996 - mae: 25.4071\n",
      "Epoch 9/60\n",
      "7397/7397 [==============================] - 0s 50us/step - loss: 1638.2620 - mse: 1638.2617 - mae: 25.5262\n",
      "Epoch 10/60\n",
      "7397/7397 [==============================] - 0s 50us/step - loss: 1632.1081 - mse: 1632.1080 - mae: 25.5024\n",
      "Epoch 11/60\n",
      "7397/7397 [==============================] - 0s 50us/step - loss: 1627.7373 - mse: 1627.7373 - mae: 25.4379\n",
      "Epoch 12/60\n",
      "7397/7397 [==============================] - 0s 51us/step - loss: 1636.1964 - mse: 1636.1960 - mae: 25.4822\n",
      "Epoch 13/60\n",
      "7397/7397 [==============================] - 0s 51us/step - loss: 1628.3075 - mse: 1628.3077 - mae: 25.4757\n",
      "Epoch 14/60\n",
      "7397/7397 [==============================] - 0s 51us/step - loss: 1633.5314 - mse: 1633.5311 - mae: 25.3783\n",
      "Epoch 15/60\n",
      "7397/7397 [==============================] - 0s 51us/step - loss: 1629.2441 - mse: 1629.2441 - mae: 25.4631\n",
      "Epoch 16/60\n",
      "7397/7397 [==============================] - 0s 51us/step - loss: 1625.9233 - mse: 1625.9231 - mae: 25.4360\n",
      "Epoch 17/60\n",
      "7397/7397 [==============================] - 0s 51us/step - loss: 1627.3925 - mse: 1627.3922 - mae: 25.4163\n",
      "Epoch 18/60\n",
      "7397/7397 [==============================] - 0s 51us/step - loss: 1627.8085 - mse: 1627.8086 - mae: 25.4624\n",
      "Epoch 19/60\n",
      "7397/7397 [==============================] - 0s 51us/step - loss: 1625.0898 - mse: 1625.0895 - mae: 25.3733\n",
      "Epoch 20/60\n",
      "7397/7397 [==============================] - 0s 51us/step - loss: 1624.1546 - mse: 1624.1543 - mae: 25.3909\n",
      "Epoch 21/60\n",
      "7397/7397 [==============================] - 0s 51us/step - loss: 1625.1201 - mse: 1625.1196 - mae: 25.4085\n",
      "Epoch 22/60\n",
      "7397/7397 [==============================] - 0s 51us/step - loss: 1622.8300 - mse: 1622.8300 - mae: 25.4326\n",
      "Epoch 23/60\n",
      "7397/7397 [==============================] - 0s 51us/step - loss: 1621.2051 - mse: 1621.2052 - mae: 25.3427\n",
      "Epoch 24/60\n",
      "7397/7397 [==============================] - 0s 51us/step - loss: 1618.1997 - mse: 1618.1998 - mae: 25.3590\n",
      "Epoch 25/60\n",
      "7397/7397 [==============================] - 0s 51us/step - loss: 1619.5559 - mse: 1619.5560 - mae: 25.3362\n",
      "Epoch 26/60\n",
      "7397/7397 [==============================] - 0s 51us/step - loss: 1621.9895 - mse: 1621.9899 - mae: 25.3202\n",
      "Epoch 27/60\n",
      "7397/7397 [==============================] - 0s 51us/step - loss: 1620.7384 - mse: 1620.7380 - mae: 25.3706\n",
      "Epoch 28/60\n",
      "7397/7397 [==============================] - 0s 51us/step - loss: 1623.7273 - mse: 1623.7262 - mae: 25.3413\n",
      "Epoch 29/60\n",
      "7397/7397 [==============================] - 0s 51us/step - loss: 1619.8311 - mse: 1619.8314 - mae: 25.2909\n",
      "Epoch 30/60\n",
      "7397/7397 [==============================] - 0s 51us/step - loss: 1616.3031 - mse: 1616.3024 - mae: 25.2829\n",
      "Epoch 31/60\n",
      "7397/7397 [==============================] - 0s 51us/step - loss: 1622.4462 - mse: 1622.4460 - mae: 25.3118\n",
      "Epoch 32/60\n",
      "7397/7397 [==============================] - 0s 51us/step - loss: 1614.5237 - mse: 1614.5233 - mae: 25.3267\n",
      "Epoch 33/60\n",
      "7397/7397 [==============================] - 0s 51us/step - loss: 1618.2600 - mse: 1618.2596 - mae: 25.3424\n",
      "Epoch 34/60\n",
      "7397/7397 [==============================] - 0s 51us/step - loss: 1613.4284 - mse: 1613.4288 - mae: 25.3063\n",
      "Epoch 35/60\n",
      "7397/7397 [==============================] - 0s 51us/step - loss: 1616.7043 - mse: 1616.7036 - mae: 25.2806\n",
      "Epoch 36/60\n",
      "7397/7397 [==============================] - 0s 51us/step - loss: 1615.2000 - mse: 1615.2003 - mae: 25.3546\n",
      "Epoch 37/60\n",
      "7397/7397 [==============================] - 0s 51us/step - loss: 1617.3407 - mse: 1617.3407 - mae: 25.3171\n",
      "Epoch 38/60\n",
      "7397/7397 [==============================] - 0s 51us/step - loss: 1615.5054 - mse: 1615.5051 - mae: 25.2599\n",
      "Epoch 39/60\n",
      "7397/7397 [==============================] - 0s 51us/step - loss: 1617.4437 - mse: 1617.4435 - mae: 25.3998\n",
      "Epoch 40/60\n",
      "7397/7397 [==============================] - 0s 51us/step - loss: 1613.2097 - mse: 1613.2097 - mae: 25.2546\n",
      "Epoch 41/60\n",
      "7397/7397 [==============================] - 0s 51us/step - loss: 1614.1719 - mse: 1614.1724 - mae: 25.2998\n",
      "Epoch 42/60\n",
      "7397/7397 [==============================] - 0s 51us/step - loss: 1618.3241 - mse: 1618.3237 - mae: 25.4101\n",
      "Epoch 43/60\n",
      "7397/7397 [==============================] - 0s 51us/step - loss: 1615.7485 - mse: 1615.7482 - mae: 25.3228\n",
      "Epoch 44/60\n",
      "7397/7397 [==============================] - 0s 51us/step - loss: 1613.2748 - mse: 1613.2748 - mae: 25.2215\n",
      "Epoch 45/60\n",
      "7397/7397 [==============================] - 0s 51us/step - loss: 1611.5773 - mse: 1611.5770 - mae: 25.3264\n",
      "Epoch 46/60\n",
      "7397/7397 [==============================] - 0s 51us/step - loss: 1609.8394 - mse: 1609.8397 - mae: 25.2785\n",
      "Epoch 47/60\n",
      "7397/7397 [==============================] - 0s 51us/step - loss: 1613.3928 - mse: 1613.3923 - mae: 25.3312\n",
      "Epoch 48/60\n",
      "7397/7397 [==============================] - 0s 51us/step - loss: 1615.3019 - mse: 1615.3021 - mae: 25.2580\n",
      "Epoch 49/60\n",
      "7397/7397 [==============================] - 0s 51us/step - loss: 1613.4780 - mse: 1613.4779 - mae: 25.3126\n",
      "Epoch 50/60\n",
      "7397/7397 [==============================] - 0s 50us/step - loss: 1614.4358 - mse: 1614.4360 - mae: 25.2922\n",
      "Epoch 51/60\n",
      "7397/7397 [==============================] - 0s 50us/step - loss: 1608.9167 - mse: 1608.9165 - mae: 25.2594\n",
      "Epoch 52/60\n",
      "7397/7397 [==============================] - 0s 50us/step - loss: 1611.9465 - mse: 1611.9464 - mae: 25.2697\n",
      "Epoch 53/60\n",
      "7397/7397 [==============================] - 0s 50us/step - loss: 1610.4693 - mse: 1610.4691 - mae: 25.3200\n",
      "Epoch 54/60\n",
      "7397/7397 [==============================] - 0s 51us/step - loss: 1605.7745 - mse: 1605.7751 - mae: 25.2090\n",
      "Epoch 55/60\n",
      "7397/7397 [==============================] - 0s 50us/step - loss: 1610.4233 - mse: 1610.4231 - mae: 25.1618\n",
      "Epoch 56/60\n",
      "7397/7397 [==============================] - 0s 50us/step - loss: 1610.3298 - mse: 1610.3297 - mae: 25.2661\n",
      "Epoch 57/60\n",
      "7397/7397 [==============================] - 0s 50us/step - loss: 1607.7167 - mse: 1607.7166 - mae: 25.1164\n",
      "Epoch 58/60\n",
      "7397/7397 [==============================] - 0s 50us/step - loss: 1610.6336 - mse: 1610.6334 - mae: 25.2048\n",
      "Epoch 59/60\n",
      "7397/7397 [==============================] - 0s 51us/step - loss: 1612.2303 - mse: 1612.2305 - mae: 25.2272\n",
      "Epoch 60/60\n",
      "7397/7397 [==============================] - 0s 51us/step - loss: 1606.7157 - mse: 1606.7159 - mae: 25.1163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=95)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "1850/1850 [==============================] - 1s 536us/step - loss: 6264.5728 - mse: 6264.5723 - mae: 63.7098\n",
      "Epoch 2/60\n",
      "1850/1850 [==============================] - 0s 69us/step - loss: 1056.2868 - mse: 1056.2867 - mae: 22.4364\n",
      "Epoch 3/60\n",
      "1850/1850 [==============================] - 0s 69us/step - loss: 1018.0756 - mse: 1018.0757 - mae: 21.9722\n",
      "Epoch 4/60\n",
      "1850/1850 [==============================] - 0s 68us/step - loss: 1015.2549 - mse: 1015.2551 - mae: 21.8971\n",
      "Epoch 5/60\n",
      "1850/1850 [==============================] - 0s 70us/step - loss: 1016.7707 - mse: 1016.7709 - mae: 21.8233\n",
      "Epoch 6/60\n",
      "1850/1850 [==============================] - 0s 69us/step - loss: 1017.6977 - mse: 1017.6977 - mae: 21.7353\n",
      "Epoch 7/60\n",
      "1850/1850 [==============================] - 0s 69us/step - loss: 1029.8761 - mse: 1029.8760 - mae: 21.9794\n",
      "Epoch 8/60\n",
      "1850/1850 [==============================] - 0s 69us/step - loss: 1026.8033 - mse: 1026.8032 - mae: 21.8871\n",
      "Epoch 9/60\n",
      "1850/1850 [==============================] - 0s 69us/step - loss: 1031.2287 - mse: 1031.2286 - mae: 21.8226\n",
      "Epoch 10/60\n",
      "1850/1850 [==============================] - 0s 69us/step - loss: 1026.7697 - mse: 1026.7698 - mae: 21.6712\n",
      "Epoch 11/60\n",
      "1850/1850 [==============================] - 0s 70us/step - loss: 1027.0019 - mse: 1027.0018 - mae: 21.8009\n",
      "Epoch 12/60\n",
      "1850/1850 [==============================] - 0s 69us/step - loss: 1009.6217 - mse: 1009.6218 - mae: 21.5634\n",
      "Epoch 13/60\n",
      "1850/1850 [==============================] - 0s 69us/step - loss: 1026.7944 - mse: 1026.7944 - mae: 21.7974\n",
      "Epoch 14/60\n",
      "1850/1850 [==============================] - 0s 69us/step - loss: 1038.8683 - mse: 1038.8683 - mae: 21.8577\n",
      "Epoch 15/60\n",
      "1850/1850 [==============================] - 0s 68us/step - loss: 1032.9222 - mse: 1032.9221 - mae: 21.8531\n",
      "Epoch 16/60\n",
      "1850/1850 [==============================] - 0s 68us/step - loss: 1043.5854 - mse: 1043.5854 - mae: 21.9356\n",
      "Epoch 17/60\n",
      "1850/1850 [==============================] - 0s 68us/step - loss: 1021.7413 - mse: 1021.7413 - mae: 21.6291\n",
      "Epoch 18/60\n",
      "1850/1850 [==============================] - 0s 69us/step - loss: 1028.6744 - mse: 1028.6744 - mae: 21.9670\n",
      "Epoch 19/60\n",
      "1850/1850 [==============================] - 0s 69us/step - loss: 1022.4748 - mse: 1022.4748 - mae: 21.6213\n",
      "Epoch 20/60\n",
      "1850/1850 [==============================] - 0s 69us/step - loss: 1017.3520 - mse: 1017.3521 - mae: 21.6120\n",
      "Epoch 21/60\n",
      "1850/1850 [==============================] - 0s 70us/step - loss: 1032.3453 - mse: 1032.3452 - mae: 21.9040\n",
      "Epoch 22/60\n",
      "1850/1850 [==============================] - 0s 69us/step - loss: 1029.9294 - mse: 1029.9294 - mae: 21.8051\n",
      "Epoch 23/60\n",
      "1850/1850 [==============================] - 0s 70us/step - loss: 1030.3641 - mse: 1030.3640 - mae: 21.8202\n",
      "Epoch 24/60\n",
      "1850/1850 [==============================] - 0s 70us/step - loss: 1012.2611 - mse: 1012.2611 - mae: 21.5022\n",
      "Epoch 25/60\n",
      "1850/1850 [==============================] - 0s 70us/step - loss: 1010.2074 - mse: 1010.2073 - mae: 21.6167\n",
      "Epoch 26/60\n",
      "1850/1850 [==============================] - 0s 70us/step - loss: 1014.5769 - mse: 1014.5768 - mae: 21.5229\n",
      "Epoch 27/60\n",
      "1850/1850 [==============================] - 0s 71us/step - loss: 1013.2305 - mse: 1013.2305 - mae: 21.5567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=95)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "3699/3699 [==============================] - 1s 312us/step - loss: 3471.1591 - mse: 3471.1604 - mae: 41.7512\n",
      "Epoch 2/60\n",
      "3699/3699 [==============================] - 0s 69us/step - loss: 1135.2289 - mse: 1135.2289 - mae: 22.7473\n",
      "Epoch 3/60\n",
      "3699/3699 [==============================] - 0s 69us/step - loss: 1134.9350 - mse: 1134.9353 - mae: 22.7752\n",
      "Epoch 4/60\n",
      "3699/3699 [==============================] - 0s 69us/step - loss: 1147.7449 - mse: 1147.7452 - mae: 22.9246\n",
      "Epoch 5/60\n",
      "3699/3699 [==============================] - 0s 69us/step - loss: 1135.2127 - mse: 1135.2126 - mae: 22.7617\n",
      "Epoch 6/60\n",
      "3699/3699 [==============================] - 0s 69us/step - loss: 1129.0283 - mse: 1129.0283 - mae: 22.7183\n",
      "Epoch 7/60\n",
      "3699/3699 [==============================] - 0s 69us/step - loss: 1127.4877 - mse: 1127.4879 - mae: 22.6974\n",
      "Epoch 8/60\n",
      "3699/3699 [==============================] - 0s 69us/step - loss: 1136.3952 - mse: 1136.3953 - mae: 22.7317\n",
      "Epoch 9/60\n",
      "3699/3699 [==============================] - 0s 69us/step - loss: 1139.7933 - mse: 1139.7936 - mae: 22.7074\n",
      "Epoch 10/60\n",
      "3699/3699 [==============================] - 0s 69us/step - loss: 1154.0700 - mse: 1154.0701 - mae: 22.9760\n",
      "Epoch 11/60\n",
      "3699/3699 [==============================] - 0s 69us/step - loss: 1134.9888 - mse: 1134.9886 - mae: 22.6302\n",
      "Epoch 12/60\n",
      "3699/3699 [==============================] - 0s 69us/step - loss: 1133.5028 - mse: 1133.5027 - mae: 22.7785\n",
      "Epoch 13/60\n",
      "3699/3699 [==============================] - 0s 69us/step - loss: 1125.4576 - mse: 1125.4576 - mae: 22.6893\n",
      "Epoch 14/60\n",
      "3699/3699 [==============================] - 0s 68us/step - loss: 1147.9789 - mse: 1147.9790 - mae: 22.7928\n",
      "Epoch 15/60\n",
      "3699/3699 [==============================] - 0s 68us/step - loss: 1139.9684 - mse: 1139.9680 - mae: 22.7887\n",
      "Epoch 16/60\n",
      "3699/3699 [==============================] - 0s 69us/step - loss: 1124.1516 - mse: 1124.1519 - mae: 22.5901\n",
      "Epoch 17/60\n",
      "3699/3699 [==============================] - 0s 68us/step - loss: 1128.5105 - mse: 1128.5106 - mae: 22.6546\n",
      "Epoch 18/60\n",
      "3699/3699 [==============================] - 0s 69us/step - loss: 1131.3041 - mse: 1131.3040 - mae: 22.6279\n",
      "Epoch 19/60\n",
      "3699/3699 [==============================] - 0s 69us/step - loss: 1124.3515 - mse: 1124.3512 - mae: 22.5428\n",
      "Epoch 20/60\n",
      "3699/3699 [==============================] - 0s 69us/step - loss: 1148.1570 - mse: 1148.1570 - mae: 22.8557\n",
      "Epoch 21/60\n",
      "3699/3699 [==============================] - 0s 69us/step - loss: 1137.1272 - mse: 1137.1271 - mae: 22.8057\n",
      "Epoch 22/60\n",
      "3699/3699 [==============================] - 0s 69us/step - loss: 1142.8376 - mse: 1142.8376 - mae: 22.7157\n",
      "Epoch 23/60\n",
      "3699/3699 [==============================] - 0s 69us/step - loss: 1131.3528 - mse: 1131.3525 - mae: 22.6666\n",
      "Epoch 24/60\n",
      "3699/3699 [==============================] - 0s 69us/step - loss: 1164.8702 - mse: 1164.8701 - mae: 23.1877\n",
      "Epoch 25/60\n",
      "3699/3699 [==============================] - 0s 69us/step - loss: 1120.2310 - mse: 1120.2312 - mae: 22.5176\n",
      "Epoch 26/60\n",
      "3699/3699 [==============================] - 0s 69us/step - loss: 1128.2872 - mse: 1128.2874 - mae: 22.6384\n",
      "Epoch 27/60\n",
      "3699/3699 [==============================] - 0s 68us/step - loss: 1149.5910 - mse: 1149.5909 - mae: 22.8307\n",
      "Epoch 28/60\n",
      "3699/3699 [==============================] - 0s 69us/step - loss: 1124.5029 - mse: 1124.5029 - mae: 22.6272\n",
      "Epoch 29/60\n",
      "3699/3699 [==============================] - 0s 69us/step - loss: 1145.4568 - mse: 1145.4569 - mae: 22.8401\n",
      "Epoch 30/60\n",
      "3699/3699 [==============================] - 0s 69us/step - loss: 1131.8993 - mse: 1131.8994 - mae: 22.5850\n",
      "Epoch 31/60\n",
      "3699/3699 [==============================] - 0s 69us/step - loss: 1128.8230 - mse: 1128.8232 - mae: 22.5662\n",
      "Epoch 32/60\n",
      "3699/3699 [==============================] - 0s 69us/step - loss: 1112.2774 - mse: 1112.2772 - mae: 22.4410\n",
      "Epoch 33/60\n",
      "3699/3699 [==============================] - 0s 69us/step - loss: 1129.7302 - mse: 1129.7305 - mae: 22.6885\n",
      "Epoch 34/60\n",
      "3699/3699 [==============================] - 0s 69us/step - loss: 1114.3634 - mse: 1114.3632 - mae: 22.5238\n",
      "Epoch 35/60\n",
      "3699/3699 [==============================] - 0s 69us/step - loss: 1129.0630 - mse: 1129.0626 - mae: 22.4603\n",
      "Epoch 36/60\n",
      "3699/3699 [==============================] - 0s 69us/step - loss: 1134.8967 - mse: 1134.8967 - mae: 22.7442\n",
      "Epoch 37/60\n",
      "3699/3699 [==============================] - 0s 69us/step - loss: 1114.1169 - mse: 1114.1168 - mae: 22.4112\n",
      "Epoch 38/60\n",
      "3699/3699 [==============================] - 0s 69us/step - loss: 1121.6200 - mse: 1121.6200 - mae: 22.5021\n",
      "Epoch 39/60\n",
      "3699/3699 [==============================] - 0s 69us/step - loss: 1136.0703 - mse: 1136.0702 - mae: 22.7164\n",
      "Epoch 40/60\n",
      "3699/3699 [==============================] - 0s 69us/step - loss: 1145.0753 - mse: 1145.0752 - mae: 22.8645\n",
      "Epoch 41/60\n",
      "3699/3699 [==============================] - 0s 69us/step - loss: 1138.7354 - mse: 1138.7352 - mae: 22.6335\n",
      "Epoch 42/60\n",
      "3699/3699 [==============================] - 0s 69us/step - loss: 1140.2201 - mse: 1140.2200 - mae: 22.7803\n",
      "Epoch 43/60\n",
      "3699/3699 [==============================] - 0s 69us/step - loss: 1131.1797 - mse: 1131.1796 - mae: 22.7111\n",
      "Epoch 44/60\n",
      "3699/3699 [==============================] - 0s 69us/step - loss: 1132.0275 - mse: 1132.0276 - mae: 22.6521\n",
      "Epoch 45/60\n",
      "3699/3699 [==============================] - 0s 69us/step - loss: 1134.5162 - mse: 1134.5162 - mae: 22.6623\n",
      "Epoch 46/60\n",
      "3699/3699 [==============================] - 0s 69us/step - loss: 1140.6429 - mse: 1140.6427 - mae: 22.7566\n",
      "Epoch 47/60\n",
      "3699/3699 [==============================] - 0s 69us/step - loss: 1128.1232 - mse: 1128.1232 - mae: 22.5322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=95)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "5548/5548 [==============================] - 1s 223us/step - loss: 3484.8705 - mse: 3484.8694 - mae: 38.4318\n",
      "Epoch 2/60\n",
      "5548/5548 [==============================] - 0s 70us/step - loss: 1718.7917 - mse: 1718.7916 - mae: 25.2574\n",
      "Epoch 3/60\n",
      "5548/5548 [==============================] - 0s 70us/step - loss: 1723.4177 - mse: 1723.4175 - mae: 25.2803\n",
      "Epoch 4/60\n",
      "5548/5548 [==============================] - 0s 70us/step - loss: 1717.2312 - mse: 1717.2318 - mae: 25.3308\n",
      "Epoch 5/60\n",
      "5548/5548 [==============================] - 0s 70us/step - loss: 1714.0736 - mse: 1714.0739 - mae: 25.1377\n",
      "Epoch 6/60\n",
      "5548/5548 [==============================] - 0s 70us/step - loss: 1714.0236 - mse: 1714.0234 - mae: 25.2765\n",
      "Epoch 7/60\n",
      "5548/5548 [==============================] - 0s 70us/step - loss: 1697.8380 - mse: 1697.8376 - mae: 25.0686\n",
      "Epoch 8/60\n",
      "5548/5548 [==============================] - 0s 69us/step - loss: 1702.9311 - mse: 1702.9308 - mae: 25.1869\n",
      "Epoch 9/60\n",
      "5548/5548 [==============================] - 0s 70us/step - loss: 1700.3635 - mse: 1700.3627 - mae: 25.1617\n",
      "Epoch 10/60\n",
      "5548/5548 [==============================] - 0s 68us/step - loss: 1703.5956 - mse: 1703.5959 - mae: 25.0854\n",
      "Epoch 11/60\n",
      "5548/5548 [==============================] - 0s 69us/step - loss: 1692.4999 - mse: 1692.4996 - mae: 25.0451\n",
      "Epoch 12/60\n",
      "5548/5548 [==============================] - 0s 70us/step - loss: 1691.3806 - mse: 1691.3801 - mae: 25.0510\n",
      "Epoch 13/60\n",
      "5548/5548 [==============================] - 0s 69us/step - loss: 1691.1505 - mse: 1691.1501 - mae: 25.0688\n",
      "Epoch 14/60\n",
      "5548/5548 [==============================] - 0s 69us/step - loss: 1681.8654 - mse: 1681.8646 - mae: 24.9597\n",
      "Epoch 15/60\n",
      "5548/5548 [==============================] - 0s 69us/step - loss: 1672.3589 - mse: 1672.3585 - mae: 24.9442\n",
      "Epoch 16/60\n",
      "5548/5548 [==============================] - 0s 69us/step - loss: 1678.6715 - mse: 1678.6718 - mae: 24.9956\n",
      "Epoch 17/60\n",
      "5548/5548 [==============================] - 0s 69us/step - loss: 1686.2413 - mse: 1686.2416 - mae: 25.0321\n",
      "Epoch 18/60\n",
      "5548/5548 [==============================] - 0s 68us/step - loss: 1674.3699 - mse: 1674.3699 - mae: 24.9296\n",
      "Epoch 19/60\n",
      "5548/5548 [==============================] - 0s 69us/step - loss: 1668.6165 - mse: 1668.6162 - mae: 24.8580\n",
      "Epoch 20/60\n",
      "5548/5548 [==============================] - 0s 69us/step - loss: 1679.9973 - mse: 1679.9967 - mae: 24.9992\n",
      "Epoch 21/60\n",
      "5548/5548 [==============================] - 0s 69us/step - loss: 1675.3691 - mse: 1675.3688 - mae: 24.9604\n",
      "Epoch 22/60\n",
      "5548/5548 [==============================] - 0s 69us/step - loss: 1670.3227 - mse: 1670.3230 - mae: 24.9470\n",
      "Epoch 23/60\n",
      "5548/5548 [==============================] - 0s 69us/step - loss: 1672.0455 - mse: 1672.0453 - mae: 24.9037\n",
      "Epoch 24/60\n",
      "5548/5548 [==============================] - 0s 69us/step - loss: 1668.2871 - mse: 1668.2864 - mae: 24.8503\n",
      "Epoch 25/60\n",
      "5548/5548 [==============================] - 0s 69us/step - loss: 1668.4564 - mse: 1668.4562 - mae: 24.8824\n",
      "Epoch 26/60\n",
      "5548/5548 [==============================] - 0s 69us/step - loss: 1676.9501 - mse: 1676.9502 - mae: 24.8531\n",
      "Epoch 27/60\n",
      "5548/5548 [==============================] - 0s 69us/step - loss: 1665.3281 - mse: 1665.3280 - mae: 24.7586\n",
      "Epoch 28/60\n",
      "5548/5548 [==============================] - 0s 69us/step - loss: 1678.3220 - mse: 1678.3214 - mae: 24.9413\n",
      "Epoch 29/60\n",
      "5548/5548 [==============================] - 0s 69us/step - loss: 1684.7597 - mse: 1684.7598 - mae: 25.0494\n",
      "Epoch 30/60\n",
      "5548/5548 [==============================] - 0s 69us/step - loss: 1670.4682 - mse: 1670.4679 - mae: 24.7882\n",
      "Epoch 31/60\n",
      "5548/5548 [==============================] - 0s 69us/step - loss: 1661.1229 - mse: 1661.1233 - mae: 24.7490\n",
      "Epoch 32/60\n",
      "5548/5548 [==============================] - 0s 69us/step - loss: 1660.0165 - mse: 1660.0171 - mae: 24.6926\n",
      "Epoch 33/60\n",
      "5548/5548 [==============================] - 0s 70us/step - loss: 1672.4285 - mse: 1672.4279 - mae: 24.7656\n",
      "Epoch 34/60\n",
      "5548/5548 [==============================] - 0s 70us/step - loss: 1670.1897 - mse: 1670.1895 - mae: 24.7841\n",
      "Epoch 35/60\n",
      "5548/5548 [==============================] - 0s 69us/step - loss: 1661.8614 - mse: 1661.8617 - mae: 24.8108\n",
      "Epoch 36/60\n",
      "5548/5548 [==============================] - 0s 69us/step - loss: 1670.7653 - mse: 1670.7656 - mae: 24.8136\n",
      "Epoch 37/60\n",
      "5548/5548 [==============================] - 0s 69us/step - loss: 1661.8974 - mse: 1661.8975 - mae: 24.6150\n",
      "Epoch 38/60\n",
      "5548/5548 [==============================] - 0s 68us/step - loss: 1664.8221 - mse: 1664.8221 - mae: 24.8447\n",
      "Epoch 39/60\n",
      "5548/5548 [==============================] - 0s 69us/step - loss: 1656.6832 - mse: 1656.6827 - mae: 24.6675\n",
      "Epoch 40/60\n",
      "5548/5548 [==============================] - 0s 68us/step - loss: 1658.8792 - mse: 1658.8796 - mae: 24.6788\n",
      "Epoch 41/60\n",
      "5548/5548 [==============================] - 0s 68us/step - loss: 1659.9152 - mse: 1659.9154 - mae: 24.7235\n",
      "Epoch 42/60\n",
      "5548/5548 [==============================] - 0s 68us/step - loss: 1656.7638 - mse: 1656.7639 - mae: 24.7290\n",
      "Epoch 43/60\n",
      "5548/5548 [==============================] - 0s 68us/step - loss: 1671.3292 - mse: 1671.3291 - mae: 25.0015\n",
      "Epoch 44/60\n",
      "5548/5548 [==============================] - 0s 69us/step - loss: 1662.1208 - mse: 1662.1206 - mae: 24.6485\n",
      "Epoch 45/60\n",
      "5548/5548 [==============================] - 0s 70us/step - loss: 1672.2459 - mse: 1672.2458 - mae: 24.8736\n",
      "Epoch 46/60\n",
      "5548/5548 [==============================] - 0s 70us/step - loss: 1653.3431 - mse: 1653.3435 - mae: 24.7103\n",
      "Epoch 47/60\n",
      "5548/5548 [==============================] - 0s 70us/step - loss: 1662.8981 - mse: 1662.8982 - mae: 24.7589\n",
      "Epoch 48/60\n",
      "5548/5548 [==============================] - 0s 70us/step - loss: 1653.3880 - mse: 1653.3883 - mae: 24.6592\n",
      "Epoch 49/60\n",
      "5548/5548 [==============================] - 0s 70us/step - loss: 1657.0676 - mse: 1657.0677 - mae: 24.7842\n",
      "Epoch 50/60\n",
      "5548/5548 [==============================] - 0s 70us/step - loss: 1659.3666 - mse: 1659.3665 - mae: 24.7629\n",
      "Epoch 51/60\n",
      "5548/5548 [==============================] - 0s 70us/step - loss: 1644.8004 - mse: 1644.8008 - mae: 24.6558\n",
      "Epoch 52/60\n",
      "5548/5548 [==============================] - 0s 70us/step - loss: 1649.6075 - mse: 1649.6073 - mae: 24.6663\n",
      "Epoch 53/60\n",
      "5548/5548 [==============================] - 0s 69us/step - loss: 1661.8820 - mse: 1661.8820 - mae: 24.6874\n",
      "Epoch 54/60\n",
      "5548/5548 [==============================] - 0s 69us/step - loss: 1653.1149 - mse: 1653.1143 - mae: 24.7456\n",
      "Epoch 55/60\n",
      "5548/5548 [==============================] - 0s 70us/step - loss: 1652.7454 - mse: 1652.7454 - mae: 24.6159\n",
      "Epoch 56/60\n",
      "5548/5548 [==============================] - 0s 70us/step - loss: 1648.0404 - mse: 1648.0398 - mae: 24.6069\n",
      "Epoch 57/60\n",
      "5548/5548 [==============================] - 0s 70us/step - loss: 1657.0454 - mse: 1657.0454 - mae: 24.6935\n",
      "Epoch 58/60\n",
      "5548/5548 [==============================] - 0s 70us/step - loss: 1648.5484 - mse: 1648.5487 - mae: 24.7407\n",
      "Epoch 59/60\n",
      "5548/5548 [==============================] - 0s 69us/step - loss: 1641.7322 - mse: 1641.7323 - mae: 24.4866\n",
      "Epoch 60/60\n",
      "5548/5548 [==============================] - 0s 70us/step - loss: 1645.4028 - mse: 1645.4028 - mae: 24.6677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=95)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "7397/7397 [==============================] - 1s 184us/step - loss: 3102.9490 - mse: 3102.9504 - mae: 36.3003\n",
      "Epoch 2/60\n",
      "7397/7397 [==============================] - 1s 69us/step - loss: 1645.9802 - mse: 1645.9799 - mae: 25.4585\n",
      "Epoch 3/60\n",
      "7397/7397 [==============================] - 1s 70us/step - loss: 1651.5240 - mse: 1651.5237 - mae: 25.4646\n",
      "Epoch 4/60\n",
      "7397/7397 [==============================] - 1s 69us/step - loss: 1650.8137 - mse: 1650.8135 - mae: 25.5571\n",
      "Epoch 5/60\n",
      "7397/7397 [==============================] - 1s 69us/step - loss: 1655.1005 - mse: 1655.0997 - mae: 25.5630\n",
      "Epoch 6/60\n",
      "7397/7397 [==============================] - 1s 71us/step - loss: 1647.7925 - mse: 1647.7925 - mae: 25.6391\n",
      "Epoch 7/60\n",
      "7397/7397 [==============================] - 1s 70us/step - loss: 1672.2292 - mse: 1672.2294 - mae: 25.7425\n",
      "Epoch 8/60\n",
      "7397/7397 [==============================] - 1s 69us/step - loss: 1626.8758 - mse: 1626.8760 - mae: 25.3470\n",
      "Epoch 9/60\n",
      "7397/7397 [==============================] - 1s 70us/step - loss: 1632.1327 - mse: 1632.1324 - mae: 25.4410\n",
      "Epoch 10/60\n",
      "7397/7397 [==============================] - 1s 69us/step - loss: 1643.5262 - mse: 1643.5258 - mae: 25.5023\n",
      "Epoch 11/60\n",
      "7397/7397 [==============================] - 1s 68us/step - loss: 1624.9554 - mse: 1624.9554 - mae: 25.3121\n",
      "Epoch 12/60\n",
      "7397/7397 [==============================] - 1s 68us/step - loss: 1622.6882 - mse: 1622.6886 - mae: 25.3430\n",
      "Epoch 13/60\n",
      "7397/7397 [==============================] - 1s 68us/step - loss: 1614.8568 - mse: 1614.8569 - mae: 25.2494\n",
      "Epoch 14/60\n",
      "7397/7397 [==============================] - 1s 68us/step - loss: 1623.4591 - mse: 1623.4587 - mae: 25.4101\n",
      "Epoch 15/60\n",
      "7397/7397 [==============================] - 1s 68us/step - loss: 1618.2723 - mse: 1618.2719 - mae: 25.2971\n",
      "Epoch 16/60\n",
      "7397/7397 [==============================] - 1s 72us/step - loss: 1608.6399 - mse: 1608.6403 - mae: 25.1386\n",
      "Epoch 17/60\n",
      "7397/7397 [==============================] - 1s 71us/step - loss: 1623.0125 - mse: 1623.0122 - mae: 25.4984\n",
      "Epoch 18/60\n",
      "7397/7397 [==============================] - 1s 68us/step - loss: 1619.4336 - mse: 1619.4336 - mae: 25.3229\n",
      "Epoch 19/60\n",
      "7397/7397 [==============================] - 1s 68us/step - loss: 1604.9078 - mse: 1604.9082 - mae: 25.2093\n",
      "Epoch 20/60\n",
      "7397/7397 [==============================] - 1s 68us/step - loss: 1613.2137 - mse: 1613.2140 - mae: 25.1964\n",
      "Epoch 21/60\n",
      "7397/7397 [==============================] - 1s 68us/step - loss: 1613.1047 - mse: 1613.1046 - mae: 25.2672\n",
      "Epoch 22/60\n",
      "7397/7397 [==============================] - 1s 68us/step - loss: 1612.4913 - mse: 1612.4915 - mae: 25.2641\n",
      "Epoch 23/60\n",
      "7397/7397 [==============================] - 1s 68us/step - loss: 1614.4580 - mse: 1614.4578 - mae: 25.3067\n",
      "Epoch 24/60\n",
      "7397/7397 [==============================] - 1s 68us/step - loss: 1614.4933 - mse: 1614.4938 - mae: 25.2261\n",
      "Epoch 25/60\n",
      "7397/7397 [==============================] - 1s 68us/step - loss: 1630.5652 - mse: 1630.5653 - mae: 25.3861\n",
      "Epoch 26/60\n",
      "7397/7397 [==============================] - 1s 68us/step - loss: 1609.9294 - mse: 1609.9288 - mae: 25.2595\n",
      "Epoch 27/60\n",
      "7397/7397 [==============================] - 1s 68us/step - loss: 1610.1500 - mse: 1610.1505 - mae: 25.1786\n",
      "Epoch 28/60\n",
      "7397/7397 [==============================] - 1s 69us/step - loss: 1607.4881 - mse: 1607.4882 - mae: 25.2487\n",
      "Epoch 29/60\n",
      "7397/7397 [==============================] - 1s 69us/step - loss: 1596.3422 - mse: 1596.3423 - mae: 25.1369\n",
      "Epoch 30/60\n",
      "7397/7397 [==============================] - 1s 70us/step - loss: 1605.6446 - mse: 1605.6440 - mae: 25.1394\n",
      "Epoch 31/60\n",
      "7397/7397 [==============================] - 1s 69us/step - loss: 1603.6635 - mse: 1603.6638 - mae: 25.1363\n",
      "Epoch 32/60\n",
      "7397/7397 [==============================] - 1s 68us/step - loss: 1595.8477 - mse: 1595.8479 - mae: 25.1504\n",
      "Epoch 33/60\n",
      "7397/7397 [==============================] - 1s 68us/step - loss: 1609.0515 - mse: 1609.0520 - mae: 25.1387\n",
      "Epoch 34/60\n",
      "7397/7397 [==============================] - 1s 68us/step - loss: 1596.5978 - mse: 1596.5983 - mae: 25.1529\n",
      "Epoch 35/60\n",
      "7397/7397 [==============================] - 1s 68us/step - loss: 1592.1735 - mse: 1592.1733 - mae: 25.1242\n",
      "Epoch 36/60\n",
      "7397/7397 [==============================] - 1s 70us/step - loss: 1601.4161 - mse: 1601.4161 - mae: 25.1180\n",
      "Epoch 37/60\n",
      "7397/7397 [==============================] - 1s 69us/step - loss: 1614.1464 - mse: 1614.1460 - mae: 25.2382\n",
      "Epoch 38/60\n",
      "7397/7397 [==============================] - 1s 69us/step - loss: 1597.6241 - mse: 1597.6234 - mae: 25.0845\n",
      "Epoch 39/60\n",
      "7397/7397 [==============================] - 1s 69us/step - loss: 1605.6273 - mse: 1605.6272 - mae: 25.1691\n",
      "Epoch 40/60\n",
      "7397/7397 [==============================] - 1s 70us/step - loss: 1599.8616 - mse: 1599.8612 - mae: 25.1144\n",
      "Epoch 41/60\n",
      "7397/7397 [==============================] - 1s 70us/step - loss: 1596.4167 - mse: 1596.4165 - mae: 25.0272\n",
      "Epoch 42/60\n",
      "7397/7397 [==============================] - 1s 70us/step - loss: 1584.7020 - mse: 1584.7028 - mae: 24.9786\n",
      "Epoch 43/60\n",
      "7397/7397 [==============================] - 1s 70us/step - loss: 1593.5812 - mse: 1593.5820 - mae: 25.0251\n",
      "Epoch 44/60\n",
      "7397/7397 [==============================] - 1s 70us/step - loss: 1591.8225 - mse: 1591.8223 - mae: 25.1915\n",
      "Epoch 45/60\n",
      "7397/7397 [==============================] - 1s 70us/step - loss: 1588.7211 - mse: 1588.7211 - mae: 25.0070\n",
      "Epoch 46/60\n",
      "7397/7397 [==============================] - 1s 70us/step - loss: 1587.3231 - mse: 1587.3235 - mae: 24.9579\n",
      "Epoch 47/60\n",
      "7397/7397 [==============================] - 1s 70us/step - loss: 1587.4314 - mse: 1587.4314 - mae: 25.1379\n",
      "Epoch 48/60\n",
      "7397/7397 [==============================] - 1s 69us/step - loss: 1582.2226 - mse: 1582.2224 - mae: 25.0492\n",
      "Epoch 49/60\n",
      "7397/7397 [==============================] - 1s 68us/step - loss: 1589.0478 - mse: 1589.0477 - mae: 25.0650\n",
      "Epoch 50/60\n",
      "7397/7397 [==============================] - 1s 69us/step - loss: 1579.6454 - mse: 1579.6450 - mae: 24.9437\n",
      "Epoch 51/60\n",
      "7397/7397 [==============================] - 1s 70us/step - loss: 1583.1025 - mse: 1583.1027 - mae: 25.0180\n",
      "Epoch 52/60\n",
      "7397/7397 [==============================] - 1s 70us/step - loss: 1604.9120 - mse: 1604.9119 - mae: 25.1006\n",
      "Epoch 53/60\n",
      "7397/7397 [==============================] - 1s 70us/step - loss: 1582.3023 - mse: 1582.3027 - mae: 24.9800\n",
      "Epoch 54/60\n",
      "7397/7397 [==============================] - 1s 70us/step - loss: 1586.8830 - mse: 1586.8833 - mae: 25.0506\n",
      "Epoch 55/60\n",
      "7397/7397 [==============================] - 1s 69us/step - loss: 1577.4764 - mse: 1577.4766 - mae: 24.9255\n",
      "Epoch 56/60\n",
      "7397/7397 [==============================] - 1s 70us/step - loss: 1575.4743 - mse: 1575.4747 - mae: 24.9032\n",
      "Epoch 57/60\n",
      "7397/7397 [==============================] - 1s 70us/step - loss: 1580.4045 - mse: 1580.4045 - mae: 24.8841\n",
      "Epoch 58/60\n",
      "7397/7397 [==============================] - 1s 70us/step - loss: 1576.1083 - mse: 1576.1083 - mae: 24.8641\n",
      "Epoch 59/60\n",
      "7397/7397 [==============================] - 1s 69us/step - loss: 1585.3379 - mse: 1585.3383 - mae: 25.0187\n",
      "Epoch 60/60\n",
      "7397/7397 [==============================] - 1s 68us/step - loss: 1576.2488 - mse: 1576.2480 - mae: 24.9230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=75)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "1850/1850 [==============================] - 1s 644us/step - loss: 6183.0669 - mse: 6183.0688 - mae: 63.7234\n",
      "Epoch 2/60\n",
      "1850/1850 [==============================] - 0s 68us/step - loss: 1062.5607 - mse: 1062.5607 - mae: 22.6734\n",
      "Epoch 3/60\n",
      "1850/1850 [==============================] - 0s 68us/step - loss: 1027.1544 - mse: 1027.1544 - mae: 21.9267\n",
      "Epoch 4/60\n",
      "1850/1850 [==============================] - 0s 68us/step - loss: 1029.3212 - mse: 1029.3210 - mae: 21.8720\n",
      "Epoch 5/60\n",
      "1850/1850 [==============================] - 0s 68us/step - loss: 1020.9803 - mse: 1020.9803 - mae: 21.7021\n",
      "Epoch 6/60\n",
      "1850/1850 [==============================] - 0s 67us/step - loss: 1025.8230 - mse: 1025.8229 - mae: 21.8726\n",
      "Epoch 7/60\n",
      "1850/1850 [==============================] - 0s 68us/step - loss: 1032.6331 - mse: 1032.6331 - mae: 21.6902\n",
      "Epoch 8/60\n",
      "1850/1850 [==============================] - 0s 69us/step - loss: 1026.4103 - mse: 1026.4104 - mae: 21.7100\n",
      "Epoch 9/60\n",
      "1850/1850 [==============================] - 0s 69us/step - loss: 1032.5290 - mse: 1032.5293 - mae: 21.9123\n",
      "Epoch 10/60\n",
      "1850/1850 [==============================] - 0s 77us/step - loss: 1030.4248 - mse: 1030.4247 - mae: 21.6567\n",
      "Epoch 11/60\n",
      "1850/1850 [==============================] - 0s 71us/step - loss: 1028.7193 - mse: 1028.7192 - mae: 21.8201\n",
      "Epoch 12/60\n",
      "1850/1850 [==============================] - 0s 69us/step - loss: 1018.1119 - mse: 1018.1119 - mae: 21.6012\n",
      "Epoch 13/60\n",
      "1850/1850 [==============================] - 0s 67us/step - loss: 1031.4731 - mse: 1031.4733 - mae: 21.9554\n",
      "Epoch 14/60\n",
      "1850/1850 [==============================] - 0s 68us/step - loss: 1022.5670 - mse: 1022.5670 - mae: 21.6008\n",
      "Epoch 15/60\n",
      "1850/1850 [==============================] - 0s 69us/step - loss: 1029.9194 - mse: 1029.9193 - mae: 21.8314\n",
      "Epoch 16/60\n",
      "1850/1850 [==============================] - 0s 69us/step - loss: 1019.1963 - mse: 1019.1964 - mae: 21.5325\n",
      "Epoch 17/60\n",
      "1850/1850 [==============================] - 0s 69us/step - loss: 1059.8385 - mse: 1059.8385 - mae: 22.2774\n",
      "Epoch 18/60\n",
      "1850/1850 [==============================] - 0s 69us/step - loss: 1038.9444 - mse: 1038.9446 - mae: 21.7547\n",
      "Epoch 19/60\n",
      "1850/1850 [==============================] - 0s 69us/step - loss: 1005.0946 - mse: 1005.0944 - mae: 21.3897\n",
      "Epoch 20/60\n",
      "1850/1850 [==============================] - 0s 69us/step - loss: 1022.8980 - mse: 1022.8981 - mae: 21.5598\n",
      "Epoch 21/60\n",
      "1850/1850 [==============================] - 0s 69us/step - loss: 1027.1946 - mse: 1027.1943 - mae: 21.6804\n",
      "Epoch 22/60\n",
      "1850/1850 [==============================] - 0s 69us/step - loss: 1044.3182 - mse: 1044.3181 - mae: 21.9243\n",
      "Epoch 23/60\n",
      "1850/1850 [==============================] - 0s 69us/step - loss: 1025.9343 - mse: 1025.9343 - mae: 21.7259\n",
      "Epoch 24/60\n",
      "1850/1850 [==============================] - 0s 70us/step - loss: 1048.6682 - mse: 1048.6682 - mae: 22.0185\n",
      "Epoch 25/60\n",
      "1850/1850 [==============================] - 0s 69us/step - loss: 1012.8876 - mse: 1012.8878 - mae: 21.4899\n",
      "Epoch 26/60\n",
      "1850/1850 [==============================] - 0s 70us/step - loss: 1026.4187 - mse: 1026.4188 - mae: 21.7479\n",
      "Epoch 27/60\n",
      "1850/1850 [==============================] - 0s 69us/step - loss: 1008.8248 - mse: 1008.8248 - mae: 21.4087\n",
      "Epoch 28/60\n",
      "1850/1850 [==============================] - 0s 69us/step - loss: 1018.6098 - mse: 1018.6099 - mae: 21.4879\n",
      "Epoch 29/60\n",
      "1850/1850 [==============================] - 0s 69us/step - loss: 1002.2998 - mse: 1002.2998 - mae: 21.4090\n",
      "Epoch 30/60\n",
      "1850/1850 [==============================] - 0s 69us/step - loss: 1020.3534 - mse: 1020.3534 - mae: 21.4819\n",
      "Epoch 31/60\n",
      "1850/1850 [==============================] - 0s 69us/step - loss: 1038.8531 - mse: 1038.8531 - mae: 21.9351\n",
      "Epoch 32/60\n",
      "1850/1850 [==============================] - 0s 68us/step - loss: 999.4944 - mse: 999.4943 - mae: 21.1936\n",
      "Epoch 33/60\n",
      "1850/1850 [==============================] - 0s 68us/step - loss: 997.8260 - mse: 997.8260 - mae: 21.2225\n",
      "Epoch 34/60\n",
      "1850/1850 [==============================] - 0s 68us/step - loss: 1007.5564 - mse: 1007.5563 - mae: 21.5429\n",
      "Epoch 35/60\n",
      "1850/1850 [==============================] - 0s 69us/step - loss: 1007.1227 - mse: 1007.1229 - mae: 21.5791\n",
      "Epoch 36/60\n",
      "1850/1850 [==============================] - 0s 69us/step - loss: 1004.6502 - mse: 1004.6503 - mae: 21.4061\n",
      "Epoch 37/60\n",
      "1850/1850 [==============================] - 0s 69us/step - loss: 1003.4124 - mse: 1003.4124 - mae: 21.3248\n",
      "Epoch 38/60\n",
      "1850/1850 [==============================] - 0s 69us/step - loss: 997.2869 - mse: 997.2869 - mae: 21.4165\n",
      "Epoch 39/60\n",
      "1850/1850 [==============================] - 0s 68us/step - loss: 1031.0353 - mse: 1031.0352 - mae: 21.7838\n",
      "Epoch 40/60\n",
      "1850/1850 [==============================] - 0s 67us/step - loss: 1009.1136 - mse: 1009.1135 - mae: 21.4943\n",
      "Epoch 41/60\n",
      "1850/1850 [==============================] - 0s 68us/step - loss: 1000.6603 - mse: 1000.6604 - mae: 21.3501\n",
      "Epoch 42/60\n",
      "1850/1850 [==============================] - 0s 68us/step - loss: 1034.2516 - mse: 1034.2517 - mae: 22.0022\n",
      "Epoch 43/60\n",
      "1850/1850 [==============================] - 0s 67us/step - loss: 1006.9163 - mse: 1006.9164 - mae: 21.5917\n",
      "Epoch 44/60\n",
      "1850/1850 [==============================] - 0s 67us/step - loss: 1006.2521 - mse: 1006.2520 - mae: 21.4826\n",
      "Epoch 45/60\n",
      "1850/1850 [==============================] - 0s 67us/step - loss: 1024.9819 - mse: 1024.9819 - mae: 21.6082\n",
      "Epoch 46/60\n",
      "1850/1850 [==============================] - 0s 68us/step - loss: 994.5551 - mse: 994.5551 - mae: 21.4292\n",
      "Epoch 47/60\n",
      "1850/1850 [==============================] - 0s 69us/step - loss: 1026.8495 - mse: 1026.8495 - mae: 21.8654\n",
      "Epoch 48/60\n",
      "1850/1850 [==============================] - 0s 68us/step - loss: 990.4284 - mse: 990.4282 - mae: 21.3192\n",
      "Epoch 49/60\n",
      "1850/1850 [==============================] - 0s 69us/step - loss: 999.4704 - mse: 999.4704 - mae: 21.3739\n",
      "Epoch 50/60\n",
      "1850/1850 [==============================] - 0s 68us/step - loss: 994.2844 - mse: 994.2844 - mae: 21.3711\n",
      "Epoch 51/60\n",
      "1850/1850 [==============================] - 0s 69us/step - loss: 993.4404 - mse: 993.4404 - mae: 21.4030\n",
      "Epoch 52/60\n",
      "1850/1850 [==============================] - 0s 69us/step - loss: 992.3219 - mse: 992.3220 - mae: 21.3470\n",
      "Epoch 53/60\n",
      "1850/1850 [==============================] - 0s 69us/step - loss: 997.3646 - mse: 997.3646 - mae: 21.3522\n",
      "Epoch 54/60\n",
      "1850/1850 [==============================] - 0s 69us/step - loss: 989.7902 - mse: 989.7904 - mae: 21.4319\n",
      "Epoch 55/60\n",
      "1850/1850 [==============================] - 0s 69us/step - loss: 1008.1931 - mse: 1008.1931 - mae: 21.4353\n",
      "Epoch 56/60\n",
      "1850/1850 [==============================] - 0s 69us/step - loss: 1023.8140 - mse: 1023.8142 - mae: 21.7416\n",
      "Epoch 57/60\n",
      "1850/1850 [==============================] - 0s 69us/step - loss: 1012.2698 - mse: 1012.2698 - mae: 21.7068\n",
      "Epoch 58/60\n",
      "1850/1850 [==============================] - 0s 68us/step - loss: 1007.6669 - mse: 1007.6671 - mae: 21.4857\n",
      "Epoch 59/60\n",
      "1850/1850 [==============================] - 0s 69us/step - loss: 1007.5061 - mse: 1007.5062 - mae: 21.4909\n",
      "Epoch 60/60\n",
      "1850/1850 [==============================] - 0s 68us/step - loss: 996.7270 - mse: 996.7268 - mae: 21.6768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=75)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "3699/3699 [==============================] - 1s 358us/step - loss: 3678.3260 - mse: 3678.3257 - mae: 43.0961\n",
      "Epoch 2/60\n",
      "3699/3699 [==============================] - 0s 68us/step - loss: 1148.4782 - mse: 1148.4783 - mae: 22.8721\n",
      "Epoch 3/60\n",
      "3699/3699 [==============================] - 0s 68us/step - loss: 1145.7598 - mse: 1145.7598 - mae: 22.8657\n",
      "Epoch 4/60\n",
      "3699/3699 [==============================] - 0s 68us/step - loss: 1153.5550 - mse: 1153.5549 - mae: 22.9840\n",
      "Epoch 5/60\n",
      "3699/3699 [==============================] - 0s 68us/step - loss: 1138.1793 - mse: 1138.1791 - mae: 22.7036\n",
      "Epoch 6/60\n",
      "3699/3699 [==============================] - 0s 67us/step - loss: 1136.8365 - mse: 1136.8364 - mae: 22.7487\n",
      "Epoch 7/60\n",
      "3699/3699 [==============================] - 0s 67us/step - loss: 1153.4165 - mse: 1153.4166 - mae: 22.9168\n",
      "Epoch 8/60\n",
      "3699/3699 [==============================] - 0s 67us/step - loss: 1137.8338 - mse: 1137.8340 - mae: 22.7710\n",
      "Epoch 9/60\n",
      "3699/3699 [==============================] - 0s 67us/step - loss: 1146.1613 - mse: 1146.1613 - mae: 22.9251\n",
      "Epoch 10/60\n",
      "3699/3699 [==============================] - 0s 67us/step - loss: 1129.3095 - mse: 1129.3096 - mae: 22.6727\n",
      "Epoch 11/60\n",
      "3699/3699 [==============================] - 0s 69us/step - loss: 1147.6133 - mse: 1147.6136 - mae: 22.7461\n",
      "Epoch 12/60\n",
      "3699/3699 [==============================] - 0s 68us/step - loss: 1149.2464 - mse: 1149.2465 - mae: 22.8891\n",
      "Epoch 13/60\n",
      "3699/3699 [==============================] - 0s 67us/step - loss: 1133.7772 - mse: 1133.7772 - mae: 22.7023\n",
      "Epoch 14/60\n",
      "3699/3699 [==============================] - 0s 67us/step - loss: 1136.8088 - mse: 1136.8086 - mae: 22.6917\n",
      "Epoch 15/60\n",
      "3699/3699 [==============================] - 0s 67us/step - loss: 1159.3441 - mse: 1159.3442 - mae: 23.1521\n",
      "Epoch 16/60\n",
      "3699/3699 [==============================] - 0s 67us/step - loss: 1159.8661 - mse: 1159.8663 - mae: 23.0293\n",
      "Epoch 17/60\n",
      "3699/3699 [==============================] - 0s 67us/step - loss: 1129.3865 - mse: 1129.3866 - mae: 22.7056\n",
      "Epoch 18/60\n",
      "3699/3699 [==============================] - 0s 67us/step - loss: 1178.2039 - mse: 1178.2040 - mae: 23.1747\n",
      "Epoch 19/60\n",
      "3699/3699 [==============================] - 0s 67us/step - loss: 1137.5444 - mse: 1137.5443 - mae: 22.6533\n",
      "Epoch 20/60\n",
      "3699/3699 [==============================] - 0s 67us/step - loss: 1135.2172 - mse: 1135.2168 - mae: 22.8131\n",
      "Epoch 21/60\n",
      "3699/3699 [==============================] - 0s 66us/step - loss: 1125.2247 - mse: 1125.2245 - mae: 22.5018\n",
      "Epoch 22/60\n",
      "3699/3699 [==============================] - 0s 67us/step - loss: 1119.6814 - mse: 1119.6813 - mae: 22.4976\n",
      "Epoch 23/60\n",
      "3699/3699 [==============================] - 0s 67us/step - loss: 1137.2562 - mse: 1137.2562 - mae: 22.7838\n",
      "Epoch 24/60\n",
      "3699/3699 [==============================] - 0s 67us/step - loss: 1122.8239 - mse: 1122.8239 - mae: 22.5110\n",
      "Epoch 25/60\n",
      "3699/3699 [==============================] - 0s 67us/step - loss: 1153.9589 - mse: 1153.9587 - mae: 22.8505\n",
      "Epoch 26/60\n",
      "3699/3699 [==============================] - 0s 67us/step - loss: 1130.3740 - mse: 1130.3739 - mae: 22.5963\n",
      "Epoch 27/60\n",
      "3699/3699 [==============================] - 0s 67us/step - loss: 1145.5035 - mse: 1145.5034 - mae: 22.7469\n",
      "Epoch 28/60\n",
      "3699/3699 [==============================] - 0s 67us/step - loss: 1127.3670 - mse: 1127.3668 - mae: 22.6830\n",
      "Epoch 29/60\n",
      "3699/3699 [==============================] - 0s 68us/step - loss: 1123.0407 - mse: 1123.0409 - mae: 22.5169\n",
      "Epoch 30/60\n",
      "3699/3699 [==============================] - 0s 68us/step - loss: 1132.6601 - mse: 1132.6604 - mae: 22.6853\n",
      "Epoch 31/60\n",
      "3699/3699 [==============================] - 0s 67us/step - loss: 1132.9706 - mse: 1132.9707 - mae: 22.7721\n",
      "Epoch 32/60\n",
      "3699/3699 [==============================] - 0s 67us/step - loss: 1123.7037 - mse: 1123.7037 - mae: 22.4594\n",
      "Epoch 33/60\n",
      "3699/3699 [==============================] - 0s 68us/step - loss: 1133.6239 - mse: 1133.6239 - mae: 22.7016\n",
      "Epoch 34/60\n",
      "3699/3699 [==============================] - 0s 68us/step - loss: 1156.3624 - mse: 1156.3625 - mae: 22.8829\n",
      "Epoch 35/60\n",
      "3699/3699 [==============================] - 0s 68us/step - loss: 1128.3877 - mse: 1128.3876 - mae: 22.6183\n",
      "Epoch 36/60\n",
      "3699/3699 [==============================] - 0s 68us/step - loss: 1133.1192 - mse: 1133.1194 - mae: 22.6207\n",
      "Epoch 37/60\n",
      "3699/3699 [==============================] - 0s 68us/step - loss: 1128.7069 - mse: 1128.7069 - mae: 22.6466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=75)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "5548/5548 [==============================] - 1s 269us/step - loss: 3657.6507 - mse: 3657.6504 - mae: 39.9236\n",
      "Epoch 2/60\n",
      "5548/5548 [==============================] - 0s 68us/step - loss: 1706.7874 - mse: 1706.7870 - mae: 25.1487\n",
      "Epoch 3/60\n",
      "5548/5548 [==============================] - 0s 68us/step - loss: 1717.9665 - mse: 1717.9667 - mae: 25.2426\n",
      "Epoch 4/60\n",
      "5548/5548 [==============================] - 0s 68us/step - loss: 1710.3006 - mse: 1710.3010 - mae: 25.2605\n",
      "Epoch 5/60\n",
      "5548/5548 [==============================] - 0s 68us/step - loss: 1722.2491 - mse: 1722.2489 - mae: 25.2067\n",
      "Epoch 6/60\n",
      "5548/5548 [==============================] - 0s 68us/step - loss: 1709.0003 - mse: 1709.0004 - mae: 25.2114\n",
      "Epoch 7/60\n",
      "5548/5548 [==============================] - 0s 68us/step - loss: 1712.2279 - mse: 1712.2281 - mae: 25.1901\n",
      "Epoch 8/60\n",
      "5548/5548 [==============================] - 0s 68us/step - loss: 1692.7206 - mse: 1692.7209 - mae: 24.9333\n",
      "Epoch 9/60\n",
      "5548/5548 [==============================] - 0s 68us/step - loss: 1707.0965 - mse: 1707.0959 - mae: 25.1884\n",
      "Epoch 10/60\n",
      "5548/5548 [==============================] - 0s 68us/step - loss: 1695.6101 - mse: 1695.6100 - mae: 25.0012\n",
      "Epoch 11/60\n",
      "5548/5548 [==============================] - 0s 68us/step - loss: 1689.2092 - mse: 1689.2095 - mae: 24.9784\n",
      "Epoch 12/60\n",
      "5548/5548 [==============================] - 0s 68us/step - loss: 1685.9154 - mse: 1685.9156 - mae: 24.9975\n",
      "Epoch 13/60\n",
      "5548/5548 [==============================] - 0s 68us/step - loss: 1688.6478 - mse: 1688.6475 - mae: 25.1010\n",
      "Epoch 14/60\n",
      "5548/5548 [==============================] - 0s 69us/step - loss: 1689.7119 - mse: 1689.7119 - mae: 25.0637\n",
      "Epoch 15/60\n",
      "5548/5548 [==============================] - 0s 69us/step - loss: 1695.2547 - mse: 1695.2546 - mae: 24.9710\n",
      "Epoch 16/60\n",
      "5548/5548 [==============================] - 0s 68us/step - loss: 1680.9255 - mse: 1680.9254 - mae: 24.9043\n",
      "Epoch 17/60\n",
      "5548/5548 [==============================] - 0s 67us/step - loss: 1685.3356 - mse: 1685.3358 - mae: 24.9548\n",
      "Epoch 18/60\n",
      "5548/5548 [==============================] - 0s 67us/step - loss: 1687.9139 - mse: 1687.9144 - mae: 24.9784\n",
      "Epoch 19/60\n",
      "5548/5548 [==============================] - 0s 67us/step - loss: 1690.9582 - mse: 1690.9581 - mae: 25.0070\n",
      "Epoch 20/60\n",
      "5548/5548 [==============================] - 0s 67us/step - loss: 1675.2707 - mse: 1675.2711 - mae: 24.9088\n",
      "Epoch 21/60\n",
      "5548/5548 [==============================] - 0s 67us/step - loss: 1689.3886 - mse: 1689.3885 - mae: 25.0854\n",
      "Epoch 22/60\n",
      "5548/5548 [==============================] - 0s 68us/step - loss: 1680.0752 - mse: 1680.0752 - mae: 24.9807\n",
      "Epoch 23/60\n",
      "5548/5548 [==============================] - 0s 68us/step - loss: 1683.7504 - mse: 1683.7504 - mae: 24.9810\n",
      "Epoch 24/60\n",
      "5548/5548 [==============================] - 0s 68us/step - loss: 1693.7965 - mse: 1693.7970 - mae: 24.9783\n",
      "Epoch 25/60\n",
      "5548/5548 [==============================] - 0s 68us/step - loss: 1664.6478 - mse: 1664.6475 - mae: 24.8054\n",
      "Epoch 26/60\n",
      "5548/5548 [==============================] - 0s 68us/step - loss: 1682.5482 - mse: 1682.5480 - mae: 24.9693\n",
      "Epoch 27/60\n",
      "5548/5548 [==============================] - 0s 69us/step - loss: 1676.3102 - mse: 1676.3101 - mae: 25.0049\n",
      "Epoch 28/60\n",
      "5548/5548 [==============================] - 0s 68us/step - loss: 1667.5398 - mse: 1667.5404 - mae: 24.8830\n",
      "Epoch 29/60\n",
      "5548/5548 [==============================] - 0s 68us/step - loss: 1696.1307 - mse: 1696.1310 - mae: 25.0943\n",
      "Epoch 30/60\n",
      "5548/5548 [==============================] - 0s 68us/step - loss: 1668.3531 - mse: 1668.3531 - mae: 24.8363\n",
      "Epoch 31/60\n",
      "5548/5548 [==============================] - 0s 69us/step - loss: 1674.7425 - mse: 1674.7426 - mae: 24.8541\n",
      "Epoch 32/60\n",
      "5548/5548 [==============================] - 0s 68us/step - loss: 1687.6305 - mse: 1687.6304 - mae: 24.9779\n",
      "Epoch 33/60\n",
      "5548/5548 [==============================] - 0s 68us/step - loss: 1689.3099 - mse: 1689.3108 - mae: 24.8708\n",
      "Epoch 34/60\n",
      "5548/5548 [==============================] - 0s 67us/step - loss: 1669.2369 - mse: 1669.2368 - mae: 24.7784\n",
      "Epoch 35/60\n",
      "5548/5548 [==============================] - 0s 68us/step - loss: 1677.6448 - mse: 1677.6453 - mae: 24.8389\n",
      "Epoch 36/60\n",
      "5548/5548 [==============================] - 0s 67us/step - loss: 1666.7367 - mse: 1666.7365 - mae: 24.8574\n",
      "Epoch 37/60\n",
      "5548/5548 [==============================] - 0s 67us/step - loss: 1663.3319 - mse: 1663.3322 - mae: 24.7489\n",
      "Epoch 38/60\n",
      "5548/5548 [==============================] - 0s 67us/step - loss: 1661.4238 - mse: 1661.4244 - mae: 24.8894\n",
      "Epoch 39/60\n",
      "5548/5548 [==============================] - 0s 68us/step - loss: 1662.5875 - mse: 1662.5876 - mae: 24.8360\n",
      "Epoch 40/60\n",
      "5548/5548 [==============================] - 0s 67us/step - loss: 1659.5113 - mse: 1659.5114 - mae: 24.7666\n",
      "Epoch 41/60\n",
      "5548/5548 [==============================] - 0s 67us/step - loss: 1654.7669 - mse: 1654.7662 - mae: 24.6635\n",
      "Epoch 42/60\n",
      "5548/5548 [==============================] - 0s 67us/step - loss: 1645.7441 - mse: 1645.7444 - mae: 24.6263\n",
      "Epoch 43/60\n",
      "5548/5548 [==============================] - 0s 67us/step - loss: 1659.2201 - mse: 1659.2201 - mae: 24.7227\n",
      "Epoch 44/60\n",
      "5548/5548 [==============================] - 0s 67us/step - loss: 1663.7360 - mse: 1663.7357 - mae: 24.8871\n",
      "Epoch 45/60\n",
      "5548/5548 [==============================] - 0s 68us/step - loss: 1665.4154 - mse: 1665.4158 - mae: 24.7400\n",
      "Epoch 46/60\n",
      "5548/5548 [==============================] - 0s 67us/step - loss: 1647.6202 - mse: 1647.6204 - mae: 24.6276\n",
      "Epoch 47/60\n",
      "5548/5548 [==============================] - 0s 67us/step - loss: 1652.0950 - mse: 1652.0950 - mae: 24.7143\n",
      "Epoch 48/60\n",
      "5548/5548 [==============================] - 0s 67us/step - loss: 1657.9456 - mse: 1657.9456 - mae: 24.6624\n",
      "Epoch 49/60\n",
      "5548/5548 [==============================] - 0s 68us/step - loss: 1650.3509 - mse: 1650.3510 - mae: 24.7133\n",
      "Epoch 50/60\n",
      "5548/5548 [==============================] - 0s 67us/step - loss: 1653.1859 - mse: 1653.1860 - mae: 24.7303\n",
      "Epoch 51/60\n",
      "5548/5548 [==============================] - 0s 67us/step - loss: 1641.1794 - mse: 1641.1793 - mae: 24.6332\n",
      "Epoch 52/60\n",
      "5548/5548 [==============================] - 0s 67us/step - loss: 1661.6465 - mse: 1661.6464 - mae: 24.8779\n",
      "Epoch 53/60\n",
      "5548/5548 [==============================] - 0s 68us/step - loss: 1640.6004 - mse: 1640.6002 - mae: 24.5927\n",
      "Epoch 54/60\n",
      "5548/5548 [==============================] - 0s 68us/step - loss: 1645.4168 - mse: 1645.4171 - mae: 24.5968\n",
      "Epoch 55/60\n",
      "5548/5548 [==============================] - 0s 67us/step - loss: 1636.9072 - mse: 1636.9069 - mae: 24.4340\n",
      "Epoch 56/60\n",
      "5548/5548 [==============================] - 0s 67us/step - loss: 1653.6704 - mse: 1653.6705 - mae: 24.7530\n",
      "Epoch 57/60\n",
      "5548/5548 [==============================] - 0s 68us/step - loss: 1630.4667 - mse: 1630.4663 - mae: 24.5345\n",
      "Epoch 58/60\n",
      "5548/5548 [==============================] - 0s 68us/step - loss: 1625.0840 - mse: 1625.0840 - mae: 24.4241\n",
      "Epoch 59/60\n",
      "5548/5548 [==============================] - 0s 68us/step - loss: 1635.1831 - mse: 1635.1833 - mae: 24.6344\n",
      "Epoch 60/60\n",
      "5548/5548 [==============================] - 0s 69us/step - loss: 1634.0230 - mse: 1634.0222 - mae: 24.4707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=75)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "7397/7397 [==============================] - 2s 216us/step - loss: 3272.5023 - mse: 3272.5015 - mae: 37.5034\n",
      "Epoch 2/60\n",
      "7397/7397 [==============================] - 0s 67us/step - loss: 1663.4391 - mse: 1663.4392 - mae: 25.7033\n",
      "Epoch 3/60\n",
      "7397/7397 [==============================] - 0s 67us/step - loss: 1657.9739 - mse: 1657.9740 - mae: 25.6400\n",
      "Epoch 4/60\n",
      "7397/7397 [==============================] - 1s 68us/step - loss: 1664.2552 - mse: 1664.2543 - mae: 25.5801\n",
      "Epoch 5/60\n",
      "7397/7397 [==============================] - 0s 68us/step - loss: 1636.6204 - mse: 1636.6199 - mae: 25.4736\n",
      "Epoch 6/60\n",
      "7397/7397 [==============================] - 0s 67us/step - loss: 1634.7527 - mse: 1634.7522 - mae: 25.4253\n",
      "Epoch 7/60\n",
      "7397/7397 [==============================] - 1s 68us/step - loss: 1638.9550 - mse: 1638.9554 - mae: 25.4279\n",
      "Epoch 8/60\n",
      "7397/7397 [==============================] - 1s 69us/step - loss: 1638.7770 - mse: 1638.7772 - mae: 25.6038\n",
      "Epoch 9/60\n",
      "7397/7397 [==============================] - 1s 69us/step - loss: 1654.2967 - mse: 1654.2968 - mae: 25.6447\n",
      "Epoch 10/60\n",
      "7397/7397 [==============================] - 0s 68us/step - loss: 1640.3816 - mse: 1640.3820 - mae: 25.4948\n",
      "Epoch 11/60\n",
      "7397/7397 [==============================] - 1s 72us/step - loss: 1637.4517 - mse: 1637.4515 - mae: 25.4729\n",
      "Epoch 12/60\n",
      "7397/7397 [==============================] - 1s 69us/step - loss: 1624.5248 - mse: 1624.5248 - mae: 25.4536\n",
      "Epoch 13/60\n",
      "7397/7397 [==============================] - 1s 68us/step - loss: 1627.5402 - mse: 1627.5400 - mae: 25.3420\n",
      "Epoch 14/60\n",
      "7397/7397 [==============================] - 1s 69us/step - loss: 1634.3507 - mse: 1634.3500 - mae: 25.5130\n",
      "Epoch 15/60\n",
      "7397/7397 [==============================] - 1s 68us/step - loss: 1620.6490 - mse: 1620.6493 - mae: 25.3550\n",
      "Epoch 16/60\n",
      "7397/7397 [==============================] - 1s 68us/step - loss: 1616.4582 - mse: 1616.4583 - mae: 25.2355\n",
      "Epoch 17/60\n",
      "7397/7397 [==============================] - 1s 68us/step - loss: 1631.6774 - mse: 1631.6771 - mae: 25.4765\n",
      "Epoch 18/60\n",
      "7397/7397 [==============================] - 1s 69us/step - loss: 1653.7308 - mse: 1653.7300 - mae: 25.6308\n",
      "Epoch 19/60\n",
      "7397/7397 [==============================] - 1s 69us/step - loss: 1635.6474 - mse: 1635.6476 - mae: 25.4111\n",
      "Epoch 20/60\n",
      "7397/7397 [==============================] - 1s 69us/step - loss: 1615.5308 - mse: 1615.5310 - mae: 25.3038\n",
      "Epoch 21/60\n",
      "7397/7397 [==============================] - 1s 68us/step - loss: 1623.0641 - mse: 1623.0645 - mae: 25.2545\n",
      "Epoch 22/60\n",
      "7397/7397 [==============================] - 0s 68us/step - loss: 1628.0583 - mse: 1628.0588 - mae: 25.3623\n",
      "Epoch 23/60\n",
      "7397/7397 [==============================] - 0s 67us/step - loss: 1619.0042 - mse: 1619.0033 - mae: 25.3657\n",
      "Epoch 24/60\n",
      "7397/7397 [==============================] - 1s 68us/step - loss: 1619.0883 - mse: 1619.0879 - mae: 25.2903\n",
      "Epoch 25/60\n",
      "7397/7397 [==============================] - 1s 68us/step - loss: 1621.6799 - mse: 1621.6797 - mae: 25.3396\n",
      "Epoch 26/60\n",
      "7397/7397 [==============================] - 1s 68us/step - loss: 1605.5517 - mse: 1605.5513 - mae: 25.1049\n",
      "Epoch 27/60\n",
      "7397/7397 [==============================] - 1s 68us/step - loss: 1605.0422 - mse: 1605.0427 - mae: 25.1191\n",
      "Epoch 28/60\n",
      "7397/7397 [==============================] - 1s 68us/step - loss: 1610.9105 - mse: 1610.9106 - mae: 25.2086\n",
      "Epoch 29/60\n",
      "7397/7397 [==============================] - 0s 67us/step - loss: 1620.6170 - mse: 1620.6174 - mae: 25.1950\n",
      "Epoch 30/60\n",
      "7397/7397 [==============================] - 1s 69us/step - loss: 1616.7852 - mse: 1616.7852 - mae: 25.2574\n",
      "Epoch 31/60\n",
      "7397/7397 [==============================] - 1s 69us/step - loss: 1600.6087 - mse: 1600.6085 - mae: 25.0947\n",
      "Epoch 32/60\n",
      "7397/7397 [==============================] - 1s 68us/step - loss: 1613.6121 - mse: 1613.6121 - mae: 25.2652\n",
      "Epoch 33/60\n",
      "7397/7397 [==============================] - 1s 68us/step - loss: 1620.6474 - mse: 1620.6470 - mae: 25.2661\n",
      "Epoch 34/60\n",
      "7397/7397 [==============================] - 1s 69us/step - loss: 1605.9729 - mse: 1605.9730 - mae: 25.1281\n",
      "Epoch 35/60\n",
      "7397/7397 [==============================] - 1s 68us/step - loss: 1613.7709 - mse: 1613.7709 - mae: 25.1431\n",
      "Epoch 36/60\n",
      "7397/7397 [==============================] - 0s 68us/step - loss: 1614.8365 - mse: 1614.8365 - mae: 25.2611\n",
      "Epoch 37/60\n",
      "7397/7397 [==============================] - 0s 67us/step - loss: 1631.2943 - mse: 1631.2946 - mae: 25.4189\n",
      "Epoch 38/60\n",
      "7397/7397 [==============================] - 1s 69us/step - loss: 1600.5263 - mse: 1600.5259 - mae: 25.0509\n",
      "Epoch 39/60\n",
      "7397/7397 [==============================] - 1s 69us/step - loss: 1600.2494 - mse: 1600.2494 - mae: 25.0989\n",
      "Epoch 40/60\n",
      "7397/7397 [==============================] - 1s 70us/step - loss: 1590.2064 - mse: 1590.2061 - mae: 24.9384\n",
      "Epoch 41/60\n",
      "7397/7397 [==============================] - 1s 68us/step - loss: 1622.3658 - mse: 1622.3661 - mae: 25.3258\n",
      "Epoch 42/60\n",
      "7397/7397 [==============================] - 1s 68us/step - loss: 1609.6102 - mse: 1609.6101 - mae: 25.2155\n",
      "Epoch 43/60\n",
      "7397/7397 [==============================] - 0s 68us/step - loss: 1597.5093 - mse: 1597.5084 - mae: 25.0284\n",
      "Epoch 44/60\n",
      "7397/7397 [==============================] - 0s 68us/step - loss: 1604.2734 - mse: 1604.2738 - mae: 25.0318\n",
      "Epoch 45/60\n",
      "7397/7397 [==============================] - 0s 67us/step - loss: 1589.9477 - mse: 1589.9481 - mae: 24.9294\n",
      "Epoch 46/60\n",
      "7397/7397 [==============================] - 0s 68us/step - loss: 1591.0914 - mse: 1591.0916 - mae: 25.0432\n",
      "Epoch 47/60\n",
      "7397/7397 [==============================] - 0s 68us/step - loss: 1599.7151 - mse: 1599.7156 - mae: 25.0262\n",
      "Epoch 48/60\n",
      "7397/7397 [==============================] - 0s 67us/step - loss: 1587.8516 - mse: 1587.8517 - mae: 24.9040\n",
      "Epoch 49/60\n",
      "7397/7397 [==============================] - 0s 67us/step - loss: 1588.0555 - mse: 1588.0558 - mae: 25.0144\n",
      "Epoch 50/60\n",
      "7397/7397 [==============================] - 1s 68us/step - loss: 1610.7404 - mse: 1610.7407 - mae: 25.1475\n",
      "Epoch 51/60\n",
      "7397/7397 [==============================] - 1s 68us/step - loss: 1586.4012 - mse: 1586.4009 - mae: 25.1054\n",
      "Epoch 52/60\n",
      "7397/7397 [==============================] - 1s 68us/step - loss: 1594.3684 - mse: 1594.3688 - mae: 25.0438\n",
      "Epoch 53/60\n",
      "7397/7397 [==============================] - 1s 68us/step - loss: 1592.5287 - mse: 1592.5287 - mae: 25.0526\n",
      "Epoch 54/60\n",
      "7397/7397 [==============================] - 1s 68us/step - loss: 1582.9942 - mse: 1582.9943 - mae: 24.9366\n",
      "Epoch 55/60\n",
      "7397/7397 [==============================] - 1s 68us/step - loss: 1592.3732 - mse: 1592.3728 - mae: 25.0489\n",
      "Epoch 56/60\n",
      "7397/7397 [==============================] - 1s 69us/step - loss: 1584.0838 - mse: 1584.0839 - mae: 24.9908\n",
      "Epoch 57/60\n",
      "7397/7397 [==============================] - 1s 68us/step - loss: 1571.7822 - mse: 1571.7820 - mae: 24.8715\n",
      "Epoch 58/60\n",
      "7397/7397 [==============================] - 1s 68us/step - loss: 1577.1187 - mse: 1577.1188 - mae: 24.9363\n",
      "Epoch 59/60\n",
      "7397/7397 [==============================] - 1s 69us/step - loss: 1576.8826 - mse: 1576.8828 - mae: 24.8601\n",
      "Epoch 60/60\n",
      "7397/7397 [==============================] - 0s 67us/step - loss: 1577.3795 - mse: 1577.3795 - mae: 25.0281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=80)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "1850/1850 [==============================] - 1s 499us/step - loss: 6040.4671 - mse: 6040.4678 - mae: 62.3127\n",
      "Epoch 2/60\n",
      "1850/1850 [==============================] - 0s 54us/step - loss: 1027.0268 - mse: 1027.0271 - mae: 22.0015\n",
      "Epoch 3/60\n",
      "1850/1850 [==============================] - 0s 53us/step - loss: 1025.5563 - mse: 1025.5563 - mae: 22.0368\n",
      "Epoch 4/60\n",
      "1850/1850 [==============================] - 0s 53us/step - loss: 1021.9259 - mse: 1021.9260 - mae: 21.9105\n",
      "Epoch 5/60\n",
      "1850/1850 [==============================] - 0s 53us/step - loss: 1027.7995 - mse: 1027.7997 - mae: 21.9914\n",
      "Epoch 6/60\n",
      "1850/1850 [==============================] - 0s 53us/step - loss: 1020.3883 - mse: 1020.3885 - mae: 21.7392\n",
      "Epoch 7/60\n",
      "1850/1850 [==============================] - 0s 52us/step - loss: 1025.1183 - mse: 1025.1183 - mae: 21.8409\n",
      "Epoch 8/60\n",
      "1850/1850 [==============================] - 0s 54us/step - loss: 1018.4722 - mse: 1018.4723 - mae: 21.7745\n",
      "Epoch 9/60\n",
      "1850/1850 [==============================] - 0s 53us/step - loss: 1025.4974 - mse: 1025.4973 - mae: 21.6702\n",
      "Epoch 10/60\n",
      "1850/1850 [==============================] - 0s 53us/step - loss: 1015.9669 - mse: 1015.9670 - mae: 21.5292\n",
      "Epoch 11/60\n",
      "1850/1850 [==============================] - 0s 53us/step - loss: 1018.6522 - mse: 1018.6523 - mae: 21.6585\n",
      "Epoch 12/60\n",
      "1850/1850 [==============================] - 0s 52us/step - loss: 1019.7139 - mse: 1019.7139 - mae: 21.6451\n",
      "Epoch 13/60\n",
      "1850/1850 [==============================] - 0s 52us/step - loss: 1016.9645 - mse: 1016.9644 - mae: 21.6101\n",
      "Epoch 14/60\n",
      "1850/1850 [==============================] - 0s 53us/step - loss: 1021.2068 - mse: 1021.2068 - mae: 21.6848\n",
      "Epoch 15/60\n",
      "1850/1850 [==============================] - 0s 52us/step - loss: 1007.5976 - mse: 1007.5977 - mae: 21.5617\n",
      "Epoch 16/60\n",
      "1850/1850 [==============================] - 0s 53us/step - loss: 1019.7117 - mse: 1019.7117 - mae: 21.6109\n",
      "Epoch 17/60\n",
      "1850/1850 [==============================] - 0s 52us/step - loss: 1017.2800 - mse: 1017.2800 - mae: 21.6132\n",
      "Epoch 18/60\n",
      "1850/1850 [==============================] - 0s 53us/step - loss: 1022.8030 - mse: 1022.8030 - mae: 21.5560\n",
      "Epoch 19/60\n",
      "1850/1850 [==============================] - 0s 52us/step - loss: 1018.3166 - mse: 1018.3165 - mae: 21.5550\n",
      "Epoch 20/60\n",
      "1850/1850 [==============================] - 0s 52us/step - loss: 1016.3199 - mse: 1016.3200 - mae: 21.6284\n",
      "Epoch 21/60\n",
      "1850/1850 [==============================] - 0s 52us/step - loss: 1014.8305 - mse: 1014.8304 - mae: 21.5281\n",
      "Epoch 22/60\n",
      "1850/1850 [==============================] - 0s 53us/step - loss: 1014.8958 - mse: 1014.8958 - mae: 21.5096\n",
      "Epoch 23/60\n",
      "1850/1850 [==============================] - 0s 52us/step - loss: 1010.7740 - mse: 1010.7740 - mae: 21.4980\n",
      "Epoch 24/60\n",
      "1850/1850 [==============================] - 0s 52us/step - loss: 1011.3563 - mse: 1011.3563 - mae: 21.5652\n",
      "Epoch 25/60\n",
      "1850/1850 [==============================] - 0s 52us/step - loss: 1015.8617 - mse: 1015.8616 - mae: 21.5689\n",
      "Epoch 26/60\n",
      "1850/1850 [==============================] - 0s 52us/step - loss: 1014.5023 - mse: 1014.5024 - mae: 21.4672\n",
      "Epoch 27/60\n",
      "1850/1850 [==============================] - 0s 52us/step - loss: 1007.2997 - mse: 1007.2999 - mae: 21.5829\n",
      "Epoch 28/60\n",
      "1850/1850 [==============================] - 0s 53us/step - loss: 1012.4276 - mse: 1012.4276 - mae: 21.4811\n",
      "Epoch 29/60\n",
      "1850/1850 [==============================] - 0s 53us/step - loss: 1007.3652 - mse: 1007.3652 - mae: 21.4739\n",
      "Epoch 30/60\n",
      "1850/1850 [==============================] - 0s 53us/step - loss: 1015.0406 - mse: 1015.0403 - mae: 21.4954\n",
      "Epoch 31/60\n",
      "1850/1850 [==============================] - 0s 53us/step - loss: 1010.7981 - mse: 1010.7982 - mae: 21.5768\n",
      "Epoch 32/60\n",
      "1850/1850 [==============================] - 0s 52us/step - loss: 1014.3918 - mse: 1014.3918 - mae: 21.5049\n",
      "Epoch 33/60\n",
      "1850/1850 [==============================] - 0s 53us/step - loss: 1003.2773 - mse: 1003.2772 - mae: 21.4351\n",
      "Epoch 34/60\n",
      "1850/1850 [==============================] - 0s 52us/step - loss: 1005.8255 - mse: 1005.8251 - mae: 21.4812\n",
      "Epoch 35/60\n",
      "1850/1850 [==============================] - 0s 53us/step - loss: 1008.1426 - mse: 1008.1426 - mae: 21.5330\n",
      "Epoch 36/60\n",
      "1850/1850 [==============================] - 0s 52us/step - loss: 1007.7890 - mse: 1007.7890 - mae: 21.5875\n",
      "Epoch 37/60\n",
      "1850/1850 [==============================] - 0s 52us/step - loss: 1010.0191 - mse: 1010.0190 - mae: 21.4883\n",
      "Epoch 38/60\n",
      "1850/1850 [==============================] - 0s 53us/step - loss: 1004.5898 - mse: 1004.5898 - mae: 21.5633\n",
      "Epoch 39/60\n",
      "1850/1850 [==============================] - 0s 52us/step - loss: 1012.2191 - mse: 1012.2191 - mae: 21.5971\n",
      "Epoch 40/60\n",
      "1850/1850 [==============================] - 0s 52us/step - loss: 1009.8885 - mse: 1009.8885 - mae: 21.5433\n",
      "Epoch 41/60\n",
      "1850/1850 [==============================] - 0s 52us/step - loss: 1003.6198 - mse: 1003.6199 - mae: 21.4383\n",
      "Epoch 42/60\n",
      "1850/1850 [==============================] - 0s 52us/step - loss: 1004.6357 - mse: 1004.6357 - mae: 21.4656\n",
      "Epoch 43/60\n",
      "1850/1850 [==============================] - 0s 52us/step - loss: 1006.8881 - mse: 1006.8884 - mae: 21.4884\n",
      "Epoch 44/60\n",
      "1850/1850 [==============================] - 0s 53us/step - loss: 1006.8697 - mse: 1006.8699 - mae: 21.4977\n",
      "Epoch 45/60\n",
      "1850/1850 [==============================] - 0s 52us/step - loss: 1005.2077 - mse: 1005.2078 - mae: 21.4005\n",
      "Epoch 46/60\n",
      "1850/1850 [==============================] - 0s 53us/step - loss: 1002.8475 - mse: 1002.8474 - mae: 21.4773\n",
      "Epoch 47/60\n",
      "1850/1850 [==============================] - 0s 53us/step - loss: 1008.2062 - mse: 1008.2062 - mae: 21.4467\n",
      "Epoch 48/60\n",
      "1850/1850 [==============================] - 0s 53us/step - loss: 1010.0582 - mse: 1010.0583 - mae: 21.5793\n",
      "Epoch 49/60\n",
      "1850/1850 [==============================] - 0s 52us/step - loss: 1006.9810 - mse: 1006.9811 - mae: 21.3431\n",
      "Epoch 50/60\n",
      "1850/1850 [==============================] - 0s 53us/step - loss: 1007.0214 - mse: 1007.0213 - mae: 21.4281\n",
      "Epoch 51/60\n",
      "1850/1850 [==============================] - 0s 52us/step - loss: 1001.9405 - mse: 1001.9402 - mae: 21.3251\n",
      "Epoch 52/60\n",
      "1850/1850 [==============================] - 0s 53us/step - loss: 1004.4362 - mse: 1004.4362 - mae: 21.4428\n",
      "Epoch 53/60\n",
      "1850/1850 [==============================] - 0s 53us/step - loss: 1008.2624 - mse: 1008.2625 - mae: 21.5211\n",
      "Epoch 54/60\n",
      "1850/1850 [==============================] - 0s 52us/step - loss: 1006.6083 - mse: 1006.6083 - mae: 21.5204\n",
      "Epoch 55/60\n",
      "1850/1850 [==============================] - 0s 53us/step - loss: 1007.0231 - mse: 1007.0228 - mae: 21.3839\n",
      "Epoch 56/60\n",
      "1850/1850 [==============================] - 0s 53us/step - loss: 1002.2324 - mse: 1002.2322 - mae: 21.3813\n",
      "Epoch 57/60\n",
      "1850/1850 [==============================] - 0s 52us/step - loss: 1003.4071 - mse: 1003.4072 - mae: 21.5094\n",
      "Epoch 58/60\n",
      "1850/1850 [==============================] - 0s 53us/step - loss: 1005.3388 - mse: 1005.3389 - mae: 21.5961\n",
      "Epoch 59/60\n",
      "1850/1850 [==============================] - ETA: 0s - loss: 1065.5701 - mse: 1065.5701 - mae: 21.77 - 0s 53us/step - loss: 1005.7739 - mse: 1005.7739 - mae: 21.5474\n",
      "Epoch 60/60\n",
      "1850/1850 [==============================] - 0s 53us/step - loss: 1002.0225 - mse: 1002.0225 - mae: 21.3586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=80)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "3699/3699 [==============================] - 1s 277us/step - loss: 3489.7892 - mse: 3489.7886 - mae: 41.6962\n",
      "Epoch 2/60\n",
      "3699/3699 [==============================] - 0s 52us/step - loss: 1133.1562 - mse: 1133.1559 - mae: 22.7279\n",
      "Epoch 3/60\n",
      "3699/3699 [==============================] - 0s 52us/step - loss: 1134.7458 - mse: 1134.7455 - mae: 22.7698\n",
      "Epoch 4/60\n",
      "3699/3699 [==============================] - 0s 52us/step - loss: 1133.3131 - mse: 1133.3131 - mae: 22.8038\n",
      "Epoch 5/60\n",
      "3699/3699 [==============================] - 0s 53us/step - loss: 1134.0761 - mse: 1134.0759 - mae: 22.7729\n",
      "Epoch 6/60\n",
      "3699/3699 [==============================] - 0s 52us/step - loss: 1129.6909 - mse: 1129.6910 - mae: 22.5848\n",
      "Epoch 7/60\n",
      "3699/3699 [==============================] - 0s 54us/step - loss: 1132.0874 - mse: 1132.0872 - mae: 22.6635\n",
      "Epoch 8/60\n",
      "3699/3699 [==============================] - 0s 53us/step - loss: 1131.2233 - mse: 1131.2233 - mae: 22.6530\n",
      "Epoch 9/60\n",
      "3699/3699 [==============================] - 0s 54us/step - loss: 1131.9459 - mse: 1131.9460 - mae: 22.7535\n",
      "Epoch 10/60\n",
      "3699/3699 [==============================] - 0s 53us/step - loss: 1130.2808 - mse: 1130.2806 - mae: 22.6838\n",
      "Epoch 11/60\n",
      "3699/3699 [==============================] - 0s 53us/step - loss: 1130.2546 - mse: 1130.2544 - mae: 22.6534\n",
      "Epoch 12/60\n",
      "3699/3699 [==============================] - 0s 53us/step - loss: 1129.6781 - mse: 1129.6781 - mae: 22.6553\n",
      "Epoch 13/60\n",
      "3699/3699 [==============================] - 0s 53us/step - loss: 1131.5657 - mse: 1131.5656 - mae: 22.6439\n",
      "Epoch 14/60\n",
      "3699/3699 [==============================] - 0s 53us/step - loss: 1129.5508 - mse: 1129.5508 - mae: 22.7213\n",
      "Epoch 15/60\n",
      "3699/3699 [==============================] - 0s 54us/step - loss: 1126.6622 - mse: 1126.6622 - mae: 22.6966s - loss: 1005.7825 - mse: 1005.7824 - mae: 22.\n",
      "Epoch 16/60\n",
      "3699/3699 [==============================] - 0s 55us/step - loss: 1126.7937 - mse: 1126.7938 - mae: 22.6132\n",
      "Epoch 17/60\n",
      "3699/3699 [==============================] - 0s 53us/step - loss: 1127.7315 - mse: 1127.7316 - mae: 22.6286\n",
      "Epoch 18/60\n",
      "3699/3699 [==============================] - 0s 53us/step - loss: 1127.2201 - mse: 1127.2201 - mae: 22.6998\n",
      "Epoch 19/60\n",
      "3699/3699 [==============================] - 0s 53us/step - loss: 1125.5311 - mse: 1125.5311 - mae: 22.6429\n",
      "Epoch 20/60\n",
      "3699/3699 [==============================] - 0s 52us/step - loss: 1130.1849 - mse: 1130.1848 - mae: 22.6028\n",
      "Epoch 21/60\n",
      "3699/3699 [==============================] - 0s 53us/step - loss: 1125.7044 - mse: 1125.7042 - mae: 22.6212\n",
      "Epoch 22/60\n",
      "3699/3699 [==============================] - 0s 54us/step - loss: 1121.9995 - mse: 1121.9996 - mae: 22.5911\n",
      "Epoch 23/60\n",
      "3699/3699 [==============================] - 0s 54us/step - loss: 1123.0363 - mse: 1123.0363 - mae: 22.6959\n",
      "Epoch 24/60\n",
      "3699/3699 [==============================] - 0s 54us/step - loss: 1123.3549 - mse: 1123.3550 - mae: 22.5787\n",
      "Epoch 25/60\n",
      "3699/3699 [==============================] - 0s 53us/step - loss: 1126.1296 - mse: 1126.1300 - mae: 22.6253\n",
      "Epoch 26/60\n",
      "3699/3699 [==============================] - 0s 55us/step - loss: 1123.4387 - mse: 1123.4385 - mae: 22.6234\n",
      "Epoch 27/60\n",
      "3699/3699 [==============================] - 0s 52us/step - loss: 1125.3269 - mse: 1125.3268 - mae: 22.5320\n",
      "Epoch 28/60\n",
      "3699/3699 [==============================] - 0s 53us/step - loss: 1122.3156 - mse: 1122.3154 - mae: 22.5124\n",
      "Epoch 29/60\n",
      "3699/3699 [==============================] - 0s 53us/step - loss: 1123.2745 - mse: 1123.2747 - mae: 22.5448\n",
      "Epoch 30/60\n",
      "3699/3699 [==============================] - 0s 52us/step - loss: 1121.8524 - mse: 1121.8523 - mae: 22.6173\n",
      "Epoch 31/60\n",
      "3699/3699 [==============================] - 0s 52us/step - loss: 1122.8732 - mse: 1122.8732 - mae: 22.6061\n",
      "Epoch 32/60\n",
      "3699/3699 [==============================] - 0s 53us/step - loss: 1123.6322 - mse: 1123.6324 - mae: 22.6768\n",
      "Epoch 33/60\n",
      "3699/3699 [==============================] - 0s 53us/step - loss: 1124.3900 - mse: 1124.3899 - mae: 22.5637\n",
      "Epoch 34/60\n",
      "3699/3699 [==============================] - 0s 54us/step - loss: 1121.4157 - mse: 1121.4159 - mae: 22.5858\n",
      "Epoch 35/60\n",
      "3699/3699 [==============================] - 0s 52us/step - loss: 1126.1621 - mse: 1126.1620 - mae: 22.6047\n",
      "Epoch 36/60\n",
      "3699/3699 [==============================] - 0s 53us/step - loss: 1122.5060 - mse: 1122.5059 - mae: 22.5349\n",
      "Epoch 37/60\n",
      "3699/3699 [==============================] - 0s 52us/step - loss: 1125.3508 - mse: 1125.3510 - mae: 22.6572\n",
      "Epoch 38/60\n",
      "3699/3699 [==============================] - 0s 53us/step - loss: 1121.7570 - mse: 1121.7571 - mae: 22.4931\n",
      "Epoch 39/60\n",
      "3699/3699 [==============================] - ETA: 0s - loss: 1091.1205 - mse: 1091.1205 - mae: 22.48 - 0s 54us/step - loss: 1123.8034 - mse: 1123.8033 - mae: 22.6151\n",
      "Epoch 40/60\n",
      "3699/3699 [==============================] - 0s 53us/step - loss: 1125.4879 - mse: 1125.4882 - mae: 22.5832\n",
      "Epoch 41/60\n",
      "3699/3699 [==============================] - 0s 53us/step - loss: 1125.0935 - mse: 1125.0935 - mae: 22.5963\n",
      "Epoch 42/60\n",
      "3699/3699 [==============================] - 0s 53us/step - loss: 1121.6356 - mse: 1121.6359 - mae: 22.5202\n",
      "Epoch 43/60\n",
      "3699/3699 [==============================] - ETA: 0s - loss: 1157.6125 - mse: 1157.6125 - mae: 22.78 - 0s 53us/step - loss: 1119.9134 - mse: 1119.9136 - mae: 22.6145\n",
      "Epoch 44/60\n",
      "3699/3699 [==============================] - 0s 53us/step - loss: 1121.1391 - mse: 1121.1393 - mae: 22.5761\n",
      "Epoch 45/60\n",
      "3699/3699 [==============================] - 0s 54us/step - loss: 1125.6351 - mse: 1125.6351 - mae: 22.5851\n",
      "Epoch 46/60\n",
      "3699/3699 [==============================] - 0s 53us/step - loss: 1125.0698 - mse: 1125.0696 - mae: 22.5656\n",
      "Epoch 47/60\n",
      "3699/3699 [==============================] - 0s 53us/step - loss: 1123.3237 - mse: 1123.3239 - mae: 22.5234\n",
      "Epoch 48/60\n",
      "3699/3699 [==============================] - 0s 53us/step - loss: 1122.6676 - mse: 1122.6677 - mae: 22.5355\n",
      "Epoch 49/60\n",
      "3699/3699 [==============================] - 0s 53us/step - loss: 1118.8399 - mse: 1118.8398 - mae: 22.4683 0s - loss: 1027.6459 - mse: 1027.6459 - mae: 22.37 - ETA: 0s - loss: 1095.8666 - mse: 1095.8665 - mae: 22.50\n",
      "Epoch 50/60\n",
      "3699/3699 [==============================] - 0s 52us/step - loss: 1119.3719 - mse: 1119.3719 - mae: 22.5426\n",
      "Epoch 51/60\n",
      "3699/3699 [==============================] - 0s 54us/step - loss: 1122.9725 - mse: 1122.9725 - mae: 22.5723\n",
      "Epoch 52/60\n",
      "3699/3699 [==============================] - 0s 54us/step - loss: 1120.4864 - mse: 1120.4865 - mae: 22.5493\n",
      "Epoch 53/60\n",
      "3699/3699 [==============================] - 0s 53us/step - loss: 1125.4374 - mse: 1125.4375 - mae: 22.6811\n",
      "Epoch 54/60\n",
      "3699/3699 [==============================] - 0s 53us/step - loss: 1124.3413 - mse: 1124.3412 - mae: 22.5585\n",
      "Epoch 55/60\n",
      "3699/3699 [==============================] - 0s 53us/step - loss: 1122.6855 - mse: 1122.6855 - mae: 22.5735\n",
      "Epoch 56/60\n",
      "3699/3699 [==============================] - 0s 54us/step - loss: 1120.7101 - mse: 1120.7098 - mae: 22.5612\n",
      "Epoch 57/60\n",
      "3699/3699 [==============================] - 0s 53us/step - loss: 1121.4245 - mse: 1121.4243 - mae: 22.5778\n",
      "Epoch 58/60\n",
      "3699/3699 [==============================] - 0s 53us/step - loss: 1125.2549 - mse: 1125.2548 - mae: 22.5594\n",
      "Epoch 59/60\n",
      "3699/3699 [==============================] - 0s 53us/step - loss: 1122.5400 - mse: 1122.5399 - mae: 22.5840\n",
      "Epoch 60/60\n",
      "3699/3699 [==============================] - 0s 53us/step - loss: 1122.8011 - mse: 1122.8009 - mae: 22.4804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=80)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "5548/5548 [==============================] - 1s 196us/step - loss: 3412.9602 - mse: 3412.9585 - mae: 37.6363\n",
      "Epoch 2/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1713.7487 - mse: 1713.7484 - mae: 25.2225\n",
      "Epoch 3/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1711.4172 - mse: 1711.4175 - mae: 25.2526\n",
      "Epoch 4/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1706.2475 - mse: 1706.2474 - mae: 25.1687\n",
      "Epoch 5/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1696.1878 - mse: 1696.1871 - mae: 25.0444\n",
      "Epoch 6/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1693.0614 - mse: 1693.0615 - mae: 25.0977\n",
      "Epoch 7/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1689.9785 - mse: 1689.9784 - mae: 25.0831\n",
      "Epoch 8/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1688.3364 - mse: 1688.3359 - mae: 24.9951\n",
      "Epoch 9/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1690.2108 - mse: 1690.2109 - mae: 25.1318\n",
      "Epoch 10/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1687.6612 - mse: 1687.6604 - mae: 25.0605\n",
      "Epoch 11/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1684.9542 - mse: 1684.9539 - mae: 25.0464\n",
      "Epoch 12/60\n",
      "5548/5548 [==============================] - 0s 52us/step - loss: 1681.2434 - mse: 1681.2435 - mae: 25.0401\n",
      "Epoch 13/60\n",
      "5548/5548 [==============================] - 0s 52us/step - loss: 1685.7862 - mse: 1685.7860 - mae: 25.0371\n",
      "Epoch 14/60\n",
      "5548/5548 [==============================] - 0s 52us/step - loss: 1683.6847 - mse: 1683.6849 - mae: 25.0786\n",
      "Epoch 15/60\n",
      "5548/5548 [==============================] - 0s 52us/step - loss: 1678.6780 - mse: 1678.6782 - mae: 24.9603\n",
      "Epoch 16/60\n",
      "5548/5548 [==============================] - 0s 52us/step - loss: 1683.8216 - mse: 1683.8214 - mae: 24.9886\n",
      "Epoch 17/60\n",
      "5548/5548 [==============================] - 0s 52us/step - loss: 1677.6667 - mse: 1677.6667 - mae: 24.9663\n",
      "Epoch 18/60\n",
      "5548/5548 [==============================] - 0s 52us/step - loss: 1684.2960 - mse: 1684.2957 - mae: 24.9242\n",
      "Epoch 19/60\n",
      "5548/5548 [==============================] - 0s 52us/step - loss: 1680.6796 - mse: 1680.6797 - mae: 25.0330\n",
      "Epoch 20/60\n",
      "5548/5548 [==============================] - 0s 52us/step - loss: 1682.0246 - mse: 1682.0245 - mae: 25.0407\n",
      "Epoch 21/60\n",
      "5548/5548 [==============================] - 0s 52us/step - loss: 1677.8240 - mse: 1677.8242 - mae: 24.8691\n",
      "Epoch 22/60\n",
      "5548/5548 [==============================] - 0s 52us/step - loss: 1680.5288 - mse: 1680.5291 - mae: 25.1124\n",
      "Epoch 23/60\n",
      "5548/5548 [==============================] - 0s 52us/step - loss: 1677.4613 - mse: 1677.4613 - mae: 24.9064\n",
      "Epoch 24/60\n",
      "5548/5548 [==============================] - 0s 52us/step - loss: 1674.6403 - mse: 1674.6404 - mae: 25.0342\n",
      "Epoch 25/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1680.6190 - mse: 1680.6190 - mae: 24.9842\n",
      "Epoch 26/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1672.0648 - mse: 1672.0649 - mae: 24.9546\n",
      "Epoch 27/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1679.6526 - mse: 1679.6528 - mae: 24.9608\n",
      "Epoch 28/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1676.7421 - mse: 1676.7421 - mae: 24.9422\n",
      "Epoch 29/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1675.4792 - mse: 1675.4802 - mae: 24.9569\n",
      "Epoch 30/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1676.4024 - mse: 1676.4027 - mae: 24.9706\n",
      "Epoch 31/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1676.8831 - mse: 1676.8838 - mae: 25.0180\n",
      "Epoch 32/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1674.5516 - mse: 1674.5515 - mae: 24.8928\n",
      "Epoch 33/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1674.4459 - mse: 1674.4463 - mae: 25.0016\n",
      "Epoch 34/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1674.3321 - mse: 1674.3324 - mae: 24.9313\n",
      "Epoch 35/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1678.3507 - mse: 1678.3507 - mae: 24.9058\n",
      "Epoch 36/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1677.5122 - mse: 1677.5121 - mae: 24.9485\n",
      "Epoch 37/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1675.4956 - mse: 1675.4961 - mae: 24.9950\n",
      "Epoch 38/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1671.3355 - mse: 1671.3358 - mae: 24.9253\n",
      "Epoch 39/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1678.4758 - mse: 1678.4755 - mae: 24.9756\n",
      "Epoch 40/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1674.6428 - mse: 1674.6429 - mae: 25.0501\n",
      "Epoch 41/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1672.3271 - mse: 1672.3271 - mae: 24.9835\n",
      "Epoch 42/60\n",
      "5548/5548 [==============================] - 0s 52us/step - loss: 1673.8907 - mse: 1673.8910 - mae: 24.8940\n",
      "Epoch 43/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1675.1259 - mse: 1675.1256 - mae: 24.9500\n",
      "Epoch 44/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1673.7558 - mse: 1673.7561 - mae: 24.7922\n",
      "Epoch 45/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1672.9853 - mse: 1672.9852 - mae: 24.9665\n",
      "Epoch 46/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1668.8692 - mse: 1668.8699 - mae: 24.8578\n",
      "Epoch 47/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1669.8998 - mse: 1669.9000 - mae: 24.9403\n",
      "Epoch 48/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1669.1012 - mse: 1669.1011 - mae: 24.8287\n",
      "Epoch 49/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1664.7338 - mse: 1664.7341 - mae: 24.8701\n",
      "Epoch 50/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1665.0759 - mse: 1665.0763 - mae: 24.8688\n",
      "Epoch 51/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1670.4661 - mse: 1670.4656 - mae: 24.8796\n",
      "Epoch 52/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1667.9782 - mse: 1667.9785 - mae: 24.8696\n",
      "Epoch 53/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1669.9739 - mse: 1669.9736 - mae: 24.8964\n",
      "Epoch 54/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1668.0446 - mse: 1668.0443 - mae: 24.8636\n",
      "Epoch 55/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1666.1938 - mse: 1666.1936 - mae: 24.9130\n",
      "Epoch 56/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1666.9570 - mse: 1666.9569 - mae: 24.7941\n",
      "Epoch 57/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1662.7527 - mse: 1662.7531 - mae: 24.7645\n",
      "Epoch 58/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1665.9337 - mse: 1665.9335 - mae: 24.8635\n",
      "Epoch 59/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1665.1217 - mse: 1665.1215 - mae: 24.8121\n",
      "Epoch 60/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1662.5806 - mse: 1662.5808 - mae: 24.8417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=80)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "7397/7397 [==============================] - 1s 165us/step - loss: 2966.7174 - mse: 2966.7166 - mae: 35.1196\n",
      "Epoch 2/60\n",
      "7397/7397 [==============================] - 0s 52us/step - loss: 1658.1784 - mse: 1658.1779 - mae: 25.5874\n",
      "Epoch 3/60\n",
      "7397/7397 [==============================] - 0s 52us/step - loss: 1652.1322 - mse: 1652.1321 - mae: 25.5522\n",
      "Epoch 4/60\n",
      "7397/7397 [==============================] - 0s 52us/step - loss: 1643.5159 - mse: 1643.5153 - mae: 25.4865\n",
      "Epoch 5/60\n",
      "7397/7397 [==============================] - 0s 52us/step - loss: 1637.6348 - mse: 1637.6348 - mae: 25.4393\n",
      "Epoch 6/60\n",
      "7397/7397 [==============================] - 0s 53us/step - loss: 1630.5977 - mse: 1630.5983 - mae: 25.5035\n",
      "Epoch 7/60\n",
      "7397/7397 [==============================] - 0s 52us/step - loss: 1630.8207 - mse: 1630.8206 - mae: 25.4416\n",
      "Epoch 8/60\n",
      "7397/7397 [==============================] - 0s 52us/step - loss: 1626.4157 - mse: 1626.4155 - mae: 25.4201\n",
      "Epoch 9/60\n",
      "7397/7397 [==============================] - 0s 53us/step - loss: 1626.9614 - mse: 1626.9614 - mae: 25.4648\n",
      "Epoch 10/60\n",
      "7397/7397 [==============================] - 0s 53us/step - loss: 1630.0047 - mse: 1630.0051 - mae: 25.4664\n",
      "Epoch 11/60\n",
      "7397/7397 [==============================] - 0s 53us/step - loss: 1625.3930 - mse: 1625.3934 - mae: 25.4230\n",
      "Epoch 12/60\n",
      "7397/7397 [==============================] - 0s 53us/step - loss: 1623.0468 - mse: 1623.0474 - mae: 25.3612\n",
      "Epoch 13/60\n",
      "7397/7397 [==============================] - 0s 53us/step - loss: 1622.2845 - mse: 1622.2845 - mae: 25.3680\n",
      "Epoch 14/60\n",
      "7397/7397 [==============================] - 0s 52us/step - loss: 1624.6010 - mse: 1624.6013 - mae: 25.4327\n",
      "Epoch 15/60\n",
      "7397/7397 [==============================] - 0s 52us/step - loss: 1623.5205 - mse: 1623.5198 - mae: 25.2971\n",
      "Epoch 16/60\n",
      "7397/7397 [==============================] - 0s 53us/step - loss: 1618.2621 - mse: 1618.2621 - mae: 25.3023\n",
      "Epoch 17/60\n",
      "7397/7397 [==============================] - 0s 53us/step - loss: 1617.4448 - mse: 1617.4453 - mae: 25.3279\n",
      "Epoch 18/60\n",
      "7397/7397 [==============================] - 0s 52us/step - loss: 1617.9343 - mse: 1617.9348 - mae: 25.3587\n",
      "Epoch 19/60\n",
      "7397/7397 [==============================] - 0s 52us/step - loss: 1617.9133 - mse: 1617.9139 - mae: 25.3221\n",
      "Epoch 20/60\n",
      "7397/7397 [==============================] - 0s 52us/step - loss: 1616.2019 - mse: 1616.2018 - mae: 25.3301\n",
      "Epoch 21/60\n",
      "7397/7397 [==============================] - 0s 52us/step - loss: 1614.8979 - mse: 1614.8981 - mae: 25.2624\n",
      "Epoch 22/60\n",
      "7397/7397 [==============================] - 0s 52us/step - loss: 1618.9745 - mse: 1618.9747 - mae: 25.3549\n",
      "Epoch 23/60\n",
      "7397/7397 [==============================] - 0s 52us/step - loss: 1613.8934 - mse: 1613.8931 - mae: 25.2451\n",
      "Epoch 24/60\n",
      "7397/7397 [==============================] - 0s 52us/step - loss: 1612.6454 - mse: 1612.6455 - mae: 25.2869\n",
      "Epoch 25/60\n",
      "7397/7397 [==============================] - 0s 53us/step - loss: 1609.6272 - mse: 1609.6268 - mae: 25.2644\n",
      "Epoch 26/60\n",
      "7397/7397 [==============================] - 0s 53us/step - loss: 1612.6666 - mse: 1612.6663 - mae: 25.2850\n",
      "Epoch 27/60\n",
      "7397/7397 [==============================] - 0s 53us/step - loss: 1608.0190 - mse: 1608.0188 - mae: 25.1657\n",
      "Epoch 28/60\n",
      "7397/7397 [==============================] - 0s 52us/step - loss: 1608.4826 - mse: 1608.4827 - mae: 25.2755\n",
      "Epoch 29/60\n",
      "7397/7397 [==============================] - 0s 52us/step - loss: 1608.5636 - mse: 1608.5635 - mae: 25.1836\n",
      "Epoch 30/60\n",
      "7397/7397 [==============================] - 0s 52us/step - loss: 1606.8759 - mse: 1606.8765 - mae: 25.2065\n",
      "Epoch 31/60\n",
      "7397/7397 [==============================] - 0s 52us/step - loss: 1603.8790 - mse: 1603.8792 - mae: 25.1640\n",
      "Epoch 32/60\n",
      "7397/7397 [==============================] - 0s 53us/step - loss: 1606.0307 - mse: 1606.0305 - mae: 25.2186\n",
      "Epoch 33/60\n",
      "7397/7397 [==============================] - 0s 53us/step - loss: 1601.7550 - mse: 1601.7545 - mae: 25.2792\n",
      "Epoch 34/60\n",
      "7397/7397 [==============================] - 0s 53us/step - loss: 1600.6612 - mse: 1600.6614 - mae: 25.1909\n",
      "Epoch 35/60\n",
      "7397/7397 [==============================] - 0s 53us/step - loss: 1598.3329 - mse: 1598.3331 - mae: 25.1777\n",
      "Epoch 36/60\n",
      "7397/7397 [==============================] - 0s 53us/step - loss: 1601.7886 - mse: 1601.7888 - mae: 25.1275\n",
      "Epoch 37/60\n",
      "7397/7397 [==============================] - 0s 53us/step - loss: 1602.2173 - mse: 1602.2177 - mae: 25.0563\n",
      "Epoch 38/60\n",
      "7397/7397 [==============================] - 0s 53us/step - loss: 1600.7617 - mse: 1600.7612 - mae: 25.2119\n",
      "Epoch 39/60\n",
      "7397/7397 [==============================] - 0s 53us/step - loss: 1595.7502 - mse: 1595.7499 - mae: 25.0562\n",
      "Epoch 40/60\n",
      "7397/7397 [==============================] - 0s 53us/step - loss: 1599.6072 - mse: 1599.6077 - mae: 25.1359\n",
      "Epoch 41/60\n",
      "7397/7397 [==============================] - 0s 53us/step - loss: 1599.4297 - mse: 1599.4291 - mae: 25.1650\n",
      "Epoch 42/60\n",
      "7397/7397 [==============================] - 0s 52us/step - loss: 1599.3275 - mse: 1599.3267 - mae: 25.0686\n",
      "Epoch 43/60\n",
      "7397/7397 [==============================] - 0s 52us/step - loss: 1594.8754 - mse: 1594.8748 - mae: 25.0614\n",
      "Epoch 44/60\n",
      "7397/7397 [==============================] - 0s 52us/step - loss: 1596.9934 - mse: 1596.9938 - mae: 25.0717\n",
      "Epoch 45/60\n",
      "7397/7397 [==============================] - 0s 52us/step - loss: 1595.9559 - mse: 1595.9557 - mae: 25.0869\n",
      "Epoch 46/60\n",
      "7397/7397 [==============================] - 0s 53us/step - loss: 1601.7103 - mse: 1601.7107 - mae: 25.1600\n",
      "Epoch 47/60\n",
      "7397/7397 [==============================] - 0s 53us/step - loss: 1598.9905 - mse: 1598.9904 - mae: 25.0475\n",
      "Epoch 48/60\n",
      "7397/7397 [==============================] - 0s 52us/step - loss: 1594.6704 - mse: 1594.6705 - mae: 25.0834\n",
      "Epoch 49/60\n",
      "7397/7397 [==============================] - 0s 53us/step - loss: 1595.2449 - mse: 1595.2448 - mae: 25.1119\n",
      "Epoch 50/60\n",
      "7397/7397 [==============================] - 0s 53us/step - loss: 1592.8045 - mse: 1592.8047 - mae: 24.9909\n",
      "Epoch 51/60\n",
      "7397/7397 [==============================] - 0s 53us/step - loss: 1594.7841 - mse: 1594.7838 - mae: 25.0622\n",
      "Epoch 52/60\n",
      "7397/7397 [==============================] - 0s 53us/step - loss: 1590.0529 - mse: 1590.0526 - mae: 25.0030\n",
      "Epoch 53/60\n",
      "7397/7397 [==============================] - 0s 53us/step - loss: 1594.2186 - mse: 1594.2185 - mae: 25.0746\n",
      "Epoch 54/60\n",
      "7397/7397 [==============================] - 0s 53us/step - loss: 1591.5928 - mse: 1591.5928 - mae: 25.0531\n",
      "Epoch 55/60\n",
      "7397/7397 [==============================] - 0s 52us/step - loss: 1590.6369 - mse: 1590.6364 - mae: 25.0733\n",
      "Epoch 56/60\n",
      "7397/7397 [==============================] - 0s 53us/step - loss: 1593.1508 - mse: 1593.1505 - mae: 25.0390\n",
      "Epoch 57/60\n",
      "7397/7397 [==============================] - 0s 52us/step - loss: 1591.4660 - mse: 1591.4658 - mae: 25.0442\n",
      "Epoch 58/60\n",
      "7397/7397 [==============================] - 0s 52us/step - loss: 1593.5206 - mse: 1593.5212 - mae: 25.0933\n",
      "Epoch 59/60\n",
      "7397/7397 [==============================] - 0s 52us/step - loss: 1586.3768 - mse: 1586.3766 - mae: 24.9205\n",
      "Epoch 60/60\n",
      "7397/7397 [==============================] - 0s 53us/step - loss: 1585.8162 - mse: 1585.8158 - mae: 25.0115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=85)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "1850/1850 [==============================] - 0s 267us/step - loss: 11567.9850 - mse: 11567.9854 - mae: 102.6269\n",
      "Epoch 2/60\n",
      "1850/1850 [==============================] - 0s 43us/step - loss: 6017.9683 - mse: 6017.9678 - mae: 68.8164\n",
      "Epoch 3/60\n",
      "1850/1850 [==============================] - 0s 42us/step - loss: 1179.2123 - mse: 1179.2123 - mae: 23.5943\n",
      "Epoch 4/60\n",
      "1850/1850 [==============================] - 0s 42us/step - loss: 1020.8426 - mse: 1020.8427 - mae: 22.0081\n",
      "Epoch 5/60\n",
      "1850/1850 [==============================] - 0s 42us/step - loss: 1021.8407 - mse: 1021.8406 - mae: 22.0747\n",
      "Epoch 6/60\n",
      "1850/1850 [==============================] - 0s 42us/step - loss: 1019.4978 - mse: 1019.4979 - mae: 21.9938\n",
      "Epoch 7/60\n",
      "1850/1850 [==============================] - 0s 42us/step - loss: 1020.2453 - mse: 1020.2453 - mae: 22.0384\n",
      "Epoch 8/60\n",
      "1850/1850 [==============================] - 0s 42us/step - loss: 1021.6156 - mse: 1021.6156 - mae: 21.9586\n",
      "Epoch 9/60\n",
      "1850/1850 [==============================] - 0s 42us/step - loss: 1018.2162 - mse: 1018.2163 - mae: 21.8883\n",
      "Epoch 10/60\n",
      "1850/1850 [==============================] - 0s 42us/step - loss: 1016.8992 - mse: 1016.8992 - mae: 21.9530\n",
      "Epoch 11/60\n",
      "1850/1850 [==============================] - 0s 42us/step - loss: 1017.1666 - mse: 1017.1665 - mae: 21.8418\n",
      "Epoch 12/60\n",
      "1850/1850 [==============================] - 0s 42us/step - loss: 1016.3523 - mse: 1016.3524 - mae: 21.8569\n",
      "Epoch 13/60\n",
      "1850/1850 [==============================] - 0s 42us/step - loss: 1015.7043 - mse: 1015.7043 - mae: 21.9058\n",
      "Epoch 14/60\n",
      "1850/1850 [==============================] - 0s 43us/step - loss: 1015.8709 - mse: 1015.8708 - mae: 21.8855\n",
      "Epoch 15/60\n",
      "1850/1850 [==============================] - 0s 43us/step - loss: 1014.1907 - mse: 1014.1907 - mae: 21.8046\n",
      "Epoch 16/60\n",
      "1850/1850 [==============================] - 0s 42us/step - loss: 1012.5692 - mse: 1012.5692 - mae: 21.9293\n",
      "Epoch 17/60\n",
      "1850/1850 [==============================] - 0s 43us/step - loss: 1016.0616 - mse: 1016.0618 - mae: 21.7403\n",
      "Epoch 18/60\n",
      "1850/1850 [==============================] - 0s 42us/step - loss: 1014.2456 - mse: 1014.2456 - mae: 21.7467\n",
      "Epoch 19/60\n",
      "1850/1850 [==============================] - 0s 42us/step - loss: 1016.3275 - mse: 1016.3276 - mae: 21.8633\n",
      "Epoch 20/60\n",
      "1850/1850 [==============================] - 0s 42us/step - loss: 1013.3491 - mse: 1013.3491 - mae: 21.6981\n",
      "Epoch 21/60\n",
      "1850/1850 [==============================] - 0s 42us/step - loss: 1013.1381 - mse: 1013.1382 - mae: 21.6785\n",
      "Epoch 22/60\n",
      "1850/1850 [==============================] - 0s 42us/step - loss: 1012.0004 - mse: 1012.0004 - mae: 21.7429\n",
      "Epoch 23/60\n",
      "1850/1850 [==============================] - 0s 42us/step - loss: 1013.0284 - mse: 1013.0285 - mae: 21.7098\n",
      "Epoch 24/60\n",
      "1850/1850 [==============================] - 0s 42us/step - loss: 1013.3703 - mse: 1013.3701 - mae: 21.6346\n",
      "Epoch 25/60\n",
      "1850/1850 [==============================] - 0s 42us/step - loss: 1011.8332 - mse: 1011.8333 - mae: 21.7100\n",
      "Epoch 26/60\n",
      "1850/1850 [==============================] - 0s 42us/step - loss: 1012.2731 - mse: 1012.2730 - mae: 21.6469\n",
      "Epoch 27/60\n",
      "1850/1850 [==============================] - 0s 42us/step - loss: 1010.7712 - mse: 1010.7711 - mae: 21.6774\n",
      "Epoch 28/60\n",
      "1850/1850 [==============================] - 0s 42us/step - loss: 1010.3084 - mse: 1010.3083 - mae: 21.6261\n",
      "Epoch 29/60\n",
      "1850/1850 [==============================] - 0s 42us/step - loss: 1009.8558 - mse: 1009.8557 - mae: 21.7229\n",
      "Epoch 30/60\n",
      "1850/1850 [==============================] - 0s 42us/step - loss: 1011.2636 - mse: 1011.2636 - mae: 21.5802\n",
      "Epoch 31/60\n",
      "1850/1850 [==============================] - 0s 42us/step - loss: 1011.0717 - mse: 1011.0716 - mae: 21.6031\n",
      "Epoch 32/60\n",
      "1850/1850 [==============================] - 0s 42us/step - loss: 1009.4208 - mse: 1009.4207 - mae: 21.6358\n",
      "Epoch 33/60\n",
      "1850/1850 [==============================] - 0s 42us/step - loss: 1013.0144 - mse: 1013.0143 - mae: 21.6658\n",
      "Epoch 34/60\n",
      "1850/1850 [==============================] - 0s 42us/step - loss: 1010.4344 - mse: 1010.4343 - mae: 21.5907\n",
      "Epoch 35/60\n",
      "1850/1850 [==============================] - 0s 42us/step - loss: 1009.6072 - mse: 1009.6074 - mae: 21.5925\n",
      "Epoch 36/60\n",
      "1850/1850 [==============================] - 0s 42us/step - loss: 1008.7045 - mse: 1008.7047 - mae: 21.5791\n",
      "Epoch 37/60\n",
      "1850/1850 [==============================] - 0s 42us/step - loss: 1009.8437 - mse: 1009.8436 - mae: 21.6370\n",
      "Epoch 38/60\n",
      "1850/1850 [==============================] - 0s 42us/step - loss: 1008.2379 - mse: 1008.2378 - mae: 21.5419\n",
      "Epoch 39/60\n",
      "1850/1850 [==============================] - 0s 42us/step - loss: 1007.5677 - mse: 1007.5677 - mae: 21.5891\n",
      "Epoch 40/60\n",
      "1850/1850 [==============================] - 0s 42us/step - loss: 1008.9643 - mse: 1008.9642 - mae: 21.5120\n",
      "Epoch 41/60\n",
      "1850/1850 [==============================] - 0s 42us/step - loss: 1008.0132 - mse: 1008.0132 - mae: 21.5593\n",
      "Epoch 42/60\n",
      "1850/1850 [==============================] - 0s 42us/step - loss: 1008.0601 - mse: 1008.0600 - mae: 21.5582\n",
      "Epoch 43/60\n",
      "1850/1850 [==============================] - 0s 42us/step - loss: 1007.5841 - mse: 1007.5842 - mae: 21.5920\n",
      "Epoch 44/60\n",
      "1850/1850 [==============================] - 0s 42us/step - loss: 1010.4681 - mse: 1010.4681 - mae: 21.4564\n",
      "Epoch 45/60\n",
      "1850/1850 [==============================] - 0s 42us/step - loss: 1008.1187 - mse: 1008.1187 - mae: 21.5941\n",
      "Epoch 46/60\n",
      "1850/1850 [==============================] - 0s 42us/step - loss: 1008.6160 - mse: 1008.6158 - mae: 21.4701\n",
      "Epoch 47/60\n",
      "1850/1850 [==============================] - 0s 42us/step - loss: 1008.4778 - mse: 1008.4777 - mae: 21.6091\n",
      "Epoch 48/60\n",
      "1850/1850 [==============================] - 0s 42us/step - loss: 1009.2888 - mse: 1009.2888 - mae: 21.5815\n",
      "Epoch 49/60\n",
      "1850/1850 [==============================] - 0s 42us/step - loss: 1007.2318 - mse: 1007.2319 - mae: 21.4311\n",
      "Epoch 50/60\n",
      "1850/1850 [==============================] - 0s 42us/step - loss: 1008.1737 - mse: 1008.1734 - mae: 21.5342\n",
      "Epoch 51/60\n",
      "1850/1850 [==============================] - 0s 42us/step - loss: 1007.9347 - mse: 1007.9347 - mae: 21.5799\n",
      "Epoch 52/60\n",
      "1850/1850 [==============================] - 0s 42us/step - loss: 1007.0638 - mse: 1007.0637 - mae: 21.5201\n",
      "Epoch 53/60\n",
      "1850/1850 [==============================] - 0s 42us/step - loss: 1008.1514 - mse: 1008.1511 - mae: 21.4476\n",
      "Epoch 54/60\n",
      "1850/1850 [==============================] - 0s 42us/step - loss: 1009.4835 - mse: 1009.4836 - mae: 21.5607\n",
      "Epoch 55/60\n",
      "1850/1850 [==============================] - 0s 42us/step - loss: 1009.2828 - mse: 1009.2827 - mae: 21.4357\n",
      "Epoch 56/60\n",
      "1850/1850 [==============================] - 0s 42us/step - loss: 1010.4058 - mse: 1010.4058 - mae: 21.6289\n",
      "Epoch 57/60\n",
      "1850/1850 [==============================] - 0s 42us/step - loss: 1006.6657 - mse: 1006.6655 - mae: 21.5237\n",
      "Epoch 58/60\n",
      "1850/1850 [==============================] - 0s 42us/step - loss: 1007.2896 - mse: 1007.2897 - mae: 21.4888\n",
      "Epoch 59/60\n",
      "1850/1850 [==============================] - 0s 43us/step - loss: 1007.0905 - mse: 1007.0904 - mae: 21.4095\n",
      "Epoch 60/60\n",
      "1850/1850 [==============================] - 0s 43us/step - loss: 1008.5680 - mse: 1008.5680 - mae: 21.4757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=85)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "3699/3699 [==============================] - 1s 154us/step - loss: 8321.8010 - mse: 8321.8018 - mae: 80.8818\n",
      "Epoch 2/60\n",
      "3699/3699 [==============================] - 0s 41us/step - loss: 1154.1981 - mse: 1154.1982 - mae: 22.9416\n",
      "Epoch 3/60\n",
      "3699/3699 [==============================] - 0s 41us/step - loss: 1134.0917 - mse: 1134.0917 - mae: 22.7519\n",
      "Epoch 4/60\n",
      "3699/3699 [==============================] - 0s 41us/step - loss: 1133.8309 - mse: 1133.8308 - mae: 22.7693\n",
      "Epoch 5/60\n",
      "3699/3699 [==============================] - 0s 41us/step - loss: 1133.6752 - mse: 1133.6750 - mae: 22.8605\n",
      "Epoch 6/60\n",
      "3699/3699 [==============================] - 0s 41us/step - loss: 1131.6013 - mse: 1131.6011 - mae: 22.8497\n",
      "Epoch 7/60\n",
      "3699/3699 [==============================] - 0s 41us/step - loss: 1131.2953 - mse: 1131.2952 - mae: 22.7382\n",
      "Epoch 8/60\n",
      "3699/3699 [==============================] - 0s 41us/step - loss: 1131.2622 - mse: 1131.2623 - mae: 22.7472\n",
      "Epoch 9/60\n",
      "3699/3699 [==============================] - 0s 41us/step - loss: 1128.0827 - mse: 1128.0829 - mae: 22.6065\n",
      "Epoch 10/60\n",
      "3699/3699 [==============================] - 0s 42us/step - loss: 1128.6251 - mse: 1128.6250 - mae: 22.7132\n",
      "Epoch 11/60\n",
      "3699/3699 [==============================] - 0s 43us/step - loss: 1127.9875 - mse: 1127.9873 - mae: 22.8803\n",
      "Epoch 12/60\n",
      "3699/3699 [==============================] - 0s 43us/step - loss: 1128.1382 - mse: 1128.1381 - mae: 22.6439\n",
      "Epoch 13/60\n",
      "3699/3699 [==============================] - 0s 43us/step - loss: 1127.5251 - mse: 1127.5248 - mae: 22.7169\n",
      "Epoch 14/60\n",
      "3699/3699 [==============================] - 0s 43us/step - loss: 1127.3419 - mse: 1127.3419 - mae: 22.8132\n",
      "Epoch 15/60\n",
      "3699/3699 [==============================] - 0s 43us/step - loss: 1127.3876 - mse: 1127.3877 - mae: 22.6526\n",
      "Epoch 16/60\n",
      "3699/3699 [==============================] - 0s 43us/step - loss: 1127.7601 - mse: 1127.7599 - mae: 22.7132\n",
      "Epoch 17/60\n",
      "3699/3699 [==============================] - 0s 43us/step - loss: 1125.5355 - mse: 1125.5355 - mae: 22.6405\n",
      "Epoch 18/60\n",
      "3699/3699 [==============================] - 0s 43us/step - loss: 1125.3574 - mse: 1125.3574 - mae: 22.7074\n",
      "Epoch 19/60\n",
      "3699/3699 [==============================] - 0s 43us/step - loss: 1124.6151 - mse: 1124.6152 - mae: 22.7400\n",
      "Epoch 20/60\n",
      "3699/3699 [==============================] - 0s 43us/step - loss: 1124.1471 - mse: 1124.1473 - mae: 22.6633\n",
      "Epoch 21/60\n",
      "3699/3699 [==============================] - 0s 43us/step - loss: 1123.6927 - mse: 1123.6925 - mae: 22.7094\n",
      "Epoch 22/60\n",
      "3699/3699 [==============================] - 0s 42us/step - loss: 1122.8443 - mse: 1122.8444 - mae: 22.6725\n",
      "Epoch 23/60\n",
      "3699/3699 [==============================] - 0s 41us/step - loss: 1125.7318 - mse: 1125.7316 - mae: 22.6048\n",
      "Epoch 24/60\n",
      "3699/3699 [==============================] - 0s 41us/step - loss: 1123.5015 - mse: 1123.5016 - mae: 22.6936\n",
      "Epoch 25/60\n",
      "3699/3699 [==============================] - 0s 41us/step - loss: 1122.3989 - mse: 1122.3992 - mae: 22.6745\n",
      "Epoch 26/60\n",
      "3699/3699 [==============================] - 0s 41us/step - loss: 1124.1311 - mse: 1124.1311 - mae: 22.6813\n",
      "Epoch 27/60\n",
      "3699/3699 [==============================] - 0s 41us/step - loss: 1123.4027 - mse: 1123.4026 - mae: 22.5721\n",
      "Epoch 28/60\n",
      "3699/3699 [==============================] - 0s 41us/step - loss: 1122.8056 - mse: 1122.8058 - mae: 22.7040\n",
      "Epoch 29/60\n",
      "3699/3699 [==============================] - 0s 43us/step - loss: 1123.1416 - mse: 1123.1417 - mae: 22.5754\n",
      "Epoch 30/60\n",
      "3699/3699 [==============================] - 0s 43us/step - loss: 1123.5871 - mse: 1123.5872 - mae: 22.6706\n",
      "Epoch 31/60\n",
      "3699/3699 [==============================] - 0s 43us/step - loss: 1123.8571 - mse: 1123.8572 - mae: 22.7005\n",
      "Epoch 32/60\n",
      "3699/3699 [==============================] - 0s 43us/step - loss: 1122.0322 - mse: 1122.0322 - mae: 22.6110\n",
      "Epoch 33/60\n",
      "3699/3699 [==============================] - 0s 43us/step - loss: 1124.5979 - mse: 1124.5980 - mae: 22.7280\n",
      "Epoch 34/60\n",
      "3699/3699 [==============================] - 0s 43us/step - loss: 1120.4504 - mse: 1120.4506 - mae: 22.5437\n",
      "Epoch 35/60\n",
      "3699/3699 [==============================] - 0s 41us/step - loss: 1122.0501 - mse: 1122.0500 - mae: 22.6701\n",
      "Epoch 36/60\n",
      "3699/3699 [==============================] - 0s 41us/step - loss: 1121.4559 - mse: 1121.4558 - mae: 22.5854\n",
      "Epoch 37/60\n",
      "3699/3699 [==============================] - 0s 41us/step - loss: 1122.0122 - mse: 1122.0122 - mae: 22.6531\n",
      "Epoch 38/60\n",
      "3699/3699 [==============================] - 0s 41us/step - loss: 1121.4890 - mse: 1121.4889 - mae: 22.6311\n",
      "Epoch 39/60\n",
      "3699/3699 [==============================] - 0s 42us/step - loss: 1122.3607 - mse: 1122.3610 - mae: 22.6460\n",
      "Epoch 40/60\n",
      "3699/3699 [==============================] - 0s 41us/step - loss: 1122.8971 - mse: 1122.8970 - mae: 22.5357\n",
      "Epoch 41/60\n",
      "3699/3699 [==============================] - 0s 41us/step - loss: 1120.4037 - mse: 1120.4036 - mae: 22.7160\n",
      "Epoch 42/60\n",
      "3699/3699 [==============================] - 0s 41us/step - loss: 1121.5898 - mse: 1121.5896 - mae: 22.5867\n",
      "Epoch 43/60\n",
      "3699/3699 [==============================] - 0s 42us/step - loss: 1121.0638 - mse: 1121.0638 - mae: 22.5944\n",
      "Epoch 44/60\n",
      "3699/3699 [==============================] - 0s 43us/step - loss: 1121.1250 - mse: 1121.1249 - mae: 22.5809\n",
      "Epoch 45/60\n",
      "3699/3699 [==============================] - 0s 42us/step - loss: 1119.8613 - mse: 1119.8613 - mae: 22.6622\n",
      "Epoch 46/60\n",
      "3699/3699 [==============================] - 0s 41us/step - loss: 1121.6562 - mse: 1121.6562 - mae: 22.5359\n",
      "Epoch 47/60\n",
      "3699/3699 [==============================] - 0s 41us/step - loss: 1120.4222 - mse: 1120.4221 - mae: 22.5769\n",
      "Epoch 48/60\n",
      "3699/3699 [==============================] - 0s 41us/step - loss: 1119.4477 - mse: 1119.4479 - mae: 22.5541\n",
      "Epoch 49/60\n",
      "3699/3699 [==============================] - 0s 41us/step - loss: 1123.6931 - mse: 1123.6931 - mae: 22.6967\n",
      "Epoch 50/60\n",
      "3699/3699 [==============================] - 0s 41us/step - loss: 1119.1970 - mse: 1119.1970 - mae: 22.5817\n",
      "Epoch 51/60\n",
      "3699/3699 [==============================] - 0s 42us/step - loss: 1122.3885 - mse: 1122.3889 - mae: 22.5781\n",
      "Epoch 52/60\n",
      "3699/3699 [==============================] - 0s 43us/step - loss: 1119.5108 - mse: 1119.5107 - mae: 22.6766\n",
      "Epoch 53/60\n",
      "3699/3699 [==============================] - 0s 42us/step - loss: 1119.8745 - mse: 1119.8748 - mae: 22.5315\n",
      "Epoch 54/60\n",
      "3699/3699 [==============================] - 0s 41us/step - loss: 1119.9571 - mse: 1119.9570 - mae: 22.5778\n",
      "Epoch 55/60\n",
      "3699/3699 [==============================] - 0s 41us/step - loss: 1120.0562 - mse: 1120.0562 - mae: 22.6177\n",
      "Epoch 56/60\n",
      "3699/3699 [==============================] - 0s 41us/step - loss: 1119.3876 - mse: 1119.3876 - mae: 22.6672\n",
      "Epoch 57/60\n",
      "3699/3699 [==============================] - 0s 41us/step - loss: 1117.9970 - mse: 1117.9969 - mae: 22.5389\n",
      "Epoch 58/60\n",
      "3699/3699 [==============================] - 0s 41us/step - loss: 1119.7981 - mse: 1119.7982 - mae: 22.5223\n",
      "Epoch 59/60\n",
      "3699/3699 [==============================] - 0s 41us/step - loss: 1120.3186 - mse: 1120.3185 - mae: 22.6388\n",
      "Epoch 60/60\n",
      "3699/3699 [==============================] - 0s 43us/step - loss: 1120.2418 - mse: 1120.2417 - mae: 22.5487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=85)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "5548/5548 [==============================] - 1s 119us/step - loss: 6578.9506 - mse: 6578.9502 - mae: 62.4304\n",
      "Epoch 2/60\n",
      "5548/5548 [==============================] - 0s 42us/step - loss: 1711.9512 - mse: 1711.9508 - mae: 25.2606\n",
      "Epoch 3/60\n",
      "5548/5548 [==============================] - 0s 42us/step - loss: 1709.8650 - mse: 1709.8654 - mae: 25.2502\n",
      "Epoch 4/60\n",
      "5548/5548 [==============================] - 0s 42us/step - loss: 1708.6055 - mse: 1708.6055 - mae: 25.1653\n",
      "Epoch 5/60\n",
      "5548/5548 [==============================] - 0s 42us/step - loss: 1705.4240 - mse: 1705.4247 - mae: 25.1735\n",
      "Epoch 6/60\n",
      "5548/5548 [==============================] - 0s 42us/step - loss: 1705.3740 - mse: 1705.3740 - mae: 25.2408\n",
      "Epoch 7/60\n",
      "5548/5548 [==============================] - 0s 42us/step - loss: 1702.7967 - mse: 1702.7969 - mae: 25.1584\n",
      "Epoch 8/60\n",
      "5548/5548 [==============================] - 0s 42us/step - loss: 1700.5194 - mse: 1700.5194 - mae: 25.1637\n",
      "Epoch 9/60\n",
      "5548/5548 [==============================] - 0s 42us/step - loss: 1700.4101 - mse: 1700.4103 - mae: 25.1537\n",
      "Epoch 10/60\n",
      "5548/5548 [==============================] - 0s 42us/step - loss: 1697.9814 - mse: 1697.9816 - mae: 25.0954\n",
      "Epoch 11/60\n",
      "5548/5548 [==============================] - 0s 42us/step - loss: 1698.1007 - mse: 1698.1006 - mae: 25.1238\n",
      "Epoch 12/60\n",
      "5548/5548 [==============================] - 0s 42us/step - loss: 1696.3910 - mse: 1696.3907 - mae: 25.1662\n",
      "Epoch 13/60\n",
      "5548/5548 [==============================] - 0s 42us/step - loss: 1693.9732 - mse: 1693.9730 - mae: 25.0274\n",
      "Epoch 14/60\n",
      "5548/5548 [==============================] - 0s 42us/step - loss: 1693.9290 - mse: 1693.9286 - mae: 25.1460\n",
      "Epoch 15/60\n",
      "5548/5548 [==============================] - 0s 42us/step - loss: 1691.4430 - mse: 1691.4429 - mae: 25.0078\n",
      "Epoch 16/60\n",
      "5548/5548 [==============================] - 0s 42us/step - loss: 1693.1045 - mse: 1693.1045 - mae: 25.1483\n",
      "Epoch 17/60\n",
      "5548/5548 [==============================] - 0s 42us/step - loss: 1690.4527 - mse: 1690.4526 - mae: 25.1171\n",
      "Epoch 18/60\n",
      "5548/5548 [==============================] - 0s 42us/step - loss: 1690.7368 - mse: 1690.7368 - mae: 25.0808\n",
      "Epoch 19/60\n",
      "5548/5548 [==============================] - 0s 42us/step - loss: 1688.7968 - mse: 1688.7970 - mae: 25.0429\n",
      "Epoch 20/60\n",
      "5548/5548 [==============================] - 0s 42us/step - loss: 1686.2442 - mse: 1686.2439 - mae: 24.9700\n",
      "Epoch 21/60\n",
      "5548/5548 [==============================] - 0s 42us/step - loss: 1686.4457 - mse: 1686.4459 - mae: 25.0659\n",
      "Epoch 22/60\n",
      "5548/5548 [==============================] - 0s 42us/step - loss: 1685.7198 - mse: 1685.7195 - mae: 25.0328\n",
      "Epoch 23/60\n",
      "5548/5548 [==============================] - 0s 42us/step - loss: 1686.0110 - mse: 1686.0110 - mae: 25.0121\n",
      "Epoch 24/60\n",
      "5548/5548 [==============================] - 0s 52us/step - loss: 1686.2371 - mse: 1686.2379 - mae: 25.0202\n",
      "Epoch 25/60\n",
      "5548/5548 [==============================] - 0s 43us/step - loss: 1683.7679 - mse: 1683.7678 - mae: 24.9419\n",
      "Epoch 26/60\n",
      "5548/5548 [==============================] - 0s 42us/step - loss: 1683.2697 - mse: 1683.2698 - mae: 24.9371\n",
      "Epoch 27/60\n",
      "5548/5548 [==============================] - 0s 42us/step - loss: 1683.2574 - mse: 1683.2581 - mae: 25.0734\n",
      "Epoch 28/60\n",
      "5548/5548 [==============================] - 0s 42us/step - loss: 1681.6987 - mse: 1681.6989 - mae: 24.9994\n",
      "Epoch 29/60\n",
      "5548/5548 [==============================] - 0s 42us/step - loss: 1682.7609 - mse: 1682.7599 - mae: 25.0016\n",
      "Epoch 30/60\n",
      "5548/5548 [==============================] - 0s 42us/step - loss: 1680.6717 - mse: 1680.6713 - mae: 25.0276\n",
      "Epoch 31/60\n",
      "5548/5548 [==============================] - 0s 42us/step - loss: 1680.6897 - mse: 1680.6896 - mae: 25.0380\n",
      "Epoch 32/60\n",
      "5548/5548 [==============================] - 0s 42us/step - loss: 1680.3815 - mse: 1680.3816 - mae: 24.9422\n",
      "Epoch 33/60\n",
      "5548/5548 [==============================] - 0s 42us/step - loss: 1678.6740 - mse: 1678.6737 - mae: 25.0398\n",
      "Epoch 34/60\n",
      "5548/5548 [==============================] - 0s 42us/step - loss: 1679.2301 - mse: 1679.2299 - mae: 24.9791\n",
      "Epoch 35/60\n",
      "5548/5548 [==============================] - 0s 42us/step - loss: 1678.7499 - mse: 1678.7495 - mae: 24.9600\n",
      "Epoch 36/60\n",
      "5548/5548 [==============================] - 0s 42us/step - loss: 1678.1338 - mse: 1678.1338 - mae: 24.9473\n",
      "Epoch 37/60\n",
      "5548/5548 [==============================] - 0s 42us/step - loss: 1677.5956 - mse: 1677.5956 - mae: 24.9221\n",
      "Epoch 38/60\n",
      "5548/5548 [==============================] - 0s 42us/step - loss: 1676.5391 - mse: 1676.5386 - mae: 25.0133\n",
      "Epoch 39/60\n",
      "5548/5548 [==============================] - 0s 42us/step - loss: 1677.4421 - mse: 1677.4420 - mae: 24.9511\n",
      "Epoch 40/60\n",
      "5548/5548 [==============================] - 0s 42us/step - loss: 1676.4615 - mse: 1676.4615 - mae: 24.9759\n",
      "Epoch 41/60\n",
      "5548/5548 [==============================] - 0s 42us/step - loss: 1674.9544 - mse: 1674.9542 - mae: 24.8783\n",
      "Epoch 42/60\n",
      "5548/5548 [==============================] - 0s 42us/step - loss: 1676.8600 - mse: 1676.8600 - mae: 24.9658\n",
      "Epoch 43/60\n",
      "5548/5548 [==============================] - 0s 43us/step - loss: 1675.2442 - mse: 1675.2440 - mae: 24.9521\n",
      "Epoch 44/60\n",
      "5548/5548 [==============================] - 0s 42us/step - loss: 1675.4844 - mse: 1675.4845 - mae: 24.9604\n",
      "Epoch 45/60\n",
      "5548/5548 [==============================] - 0s 42us/step - loss: 1676.3324 - mse: 1676.3322 - mae: 25.0434\n",
      "Epoch 46/60\n",
      "5548/5548 [==============================] - 0s 42us/step - loss: 1675.3082 - mse: 1675.3080 - mae: 24.9047\n",
      "Epoch 47/60\n",
      "5548/5548 [==============================] - 0s 42us/step - loss: 1674.4715 - mse: 1674.4717 - mae: 24.9132\n",
      "Epoch 48/60\n",
      "5548/5548 [==============================] - 0s 42us/step - loss: 1674.9622 - mse: 1674.9626 - mae: 25.0216\n",
      "Epoch 49/60\n",
      "5548/5548 [==============================] - 0s 42us/step - loss: 1676.1449 - mse: 1676.1448 - mae: 24.9394\n",
      "Epoch 50/60\n",
      "5548/5548 [==============================] - 0s 42us/step - loss: 1674.2734 - mse: 1674.2734 - mae: 24.9455\n",
      "Epoch 51/60\n",
      "5548/5548 [==============================] - 0s 42us/step - loss: 1672.6158 - mse: 1672.6155 - mae: 24.7977\n",
      "Epoch 52/60\n",
      "5548/5548 [==============================] - 0s 42us/step - loss: 1673.0440 - mse: 1673.0439 - mae: 25.0142\n",
      "Epoch 53/60\n",
      "5548/5548 [==============================] - 0s 42us/step - loss: 1674.6560 - mse: 1674.6559 - mae: 24.9171\n",
      "Epoch 54/60\n",
      "5548/5548 [==============================] - 0s 42us/step - loss: 1672.4596 - mse: 1672.4585 - mae: 24.9048\n",
      "Epoch 55/60\n",
      "5548/5548 [==============================] - 0s 42us/step - loss: 1672.1801 - mse: 1672.1790 - mae: 24.9797\n",
      "Epoch 56/60\n",
      "5548/5548 [==============================] - 0s 42us/step - loss: 1674.7537 - mse: 1674.7538 - mae: 24.9388\n",
      "Epoch 57/60\n",
      "5548/5548 [==============================] - 0s 42us/step - loss: 1672.7340 - mse: 1672.7340 - mae: 24.9500\n",
      "Epoch 58/60\n",
      "5548/5548 [==============================] - 0s 42us/step - loss: 1672.4989 - mse: 1672.4985 - mae: 24.7456\n",
      "Epoch 59/60\n",
      "5548/5548 [==============================] - 0s 42us/step - loss: 1673.2843 - mse: 1673.2843 - mae: 25.0487\n",
      "Epoch 60/60\n",
      "5548/5548 [==============================] - 0s 42us/step - loss: 1671.3831 - mse: 1671.3831 - mae: 24.8730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=85)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "7397/7397 [==============================] - 1s 101us/step - loss: 5881.5869 - mse: 5881.5859 - mae: 57.6862\n",
      "Epoch 2/60\n",
      "7397/7397 [==============================] - 0s 42us/step - loss: 1660.7272 - mse: 1660.7272 - mae: 25.6478\n",
      "Epoch 3/60\n",
      "7397/7397 [==============================] - 0s 43us/step - loss: 1656.4817 - mse: 1656.4818 - mae: 25.5786\n",
      "Epoch 4/60\n",
      "7397/7397 [==============================] - 0s 43us/step - loss: 1652.1899 - mse: 1652.1898 - mae: 25.6282\n",
      "Epoch 5/60\n",
      "7397/7397 [==============================] - 0s 42us/step - loss: 1650.9548 - mse: 1650.9554 - mae: 25.5058\n",
      "Epoch 6/60\n",
      "7397/7397 [==============================] - 0s 42us/step - loss: 1648.0366 - mse: 1648.0366 - mae: 25.4652\n",
      "Epoch 7/60\n",
      "7397/7397 [==============================] - 0s 42us/step - loss: 1646.3461 - mse: 1646.3461 - mae: 25.4648\n",
      "Epoch 8/60\n",
      "7397/7397 [==============================] - 0s 43us/step - loss: 1644.7848 - mse: 1644.7838 - mae: 25.4988\n",
      "Epoch 9/60\n",
      "7397/7397 [==============================] - 0s 42us/step - loss: 1640.9239 - mse: 1640.9236 - mae: 25.3906\n",
      "Epoch 10/60\n",
      "7397/7397 [==============================] - 0s 42us/step - loss: 1640.0767 - mse: 1640.0768 - mae: 25.4836\n",
      "Epoch 11/60\n",
      "7397/7397 [==============================] - 0s 42us/step - loss: 1636.2600 - mse: 1636.2600 - mae: 25.4069\n",
      "Epoch 12/60\n",
      "7397/7397 [==============================] - 0s 42us/step - loss: 1635.9841 - mse: 1635.9838 - mae: 25.4052\n",
      "Epoch 13/60\n",
      "7397/7397 [==============================] - 0s 42us/step - loss: 1632.6097 - mse: 1632.6100 - mae: 25.3672\n",
      "Epoch 14/60\n",
      "7397/7397 [==============================] - 0s 43us/step - loss: 1632.1073 - mse: 1632.1069 - mae: 25.3888\n",
      "Epoch 15/60\n",
      "7397/7397 [==============================] - 0s 43us/step - loss: 1628.9213 - mse: 1628.9216 - mae: 25.3219\n",
      "Epoch 16/60\n",
      "7397/7397 [==============================] - 0s 43us/step - loss: 1629.7367 - mse: 1629.7362 - mae: 25.3935\n",
      "Epoch 17/60\n",
      "7397/7397 [==============================] - 0s 43us/step - loss: 1628.3774 - mse: 1628.3776 - mae: 25.3143\n",
      "Epoch 18/60\n",
      "7397/7397 [==============================] - 0s 43us/step - loss: 1627.2571 - mse: 1627.2571 - mae: 25.4141\n",
      "Epoch 19/60\n",
      "7397/7397 [==============================] - 0s 43us/step - loss: 1623.3583 - mse: 1623.3583 - mae: 25.3246\n",
      "Epoch 20/60\n",
      "7397/7397 [==============================] - 0s 43us/step - loss: 1624.3062 - mse: 1624.3062 - mae: 25.2457\n",
      "Epoch 21/60\n",
      "7397/7397 [==============================] - 0s 43us/step - loss: 1623.1854 - mse: 1623.1858 - mae: 25.3906\n",
      "Epoch 22/60\n",
      "7397/7397 [==============================] - 0s 43us/step - loss: 1622.2722 - mse: 1622.2725 - mae: 25.2582\n",
      "Epoch 23/60\n",
      "7397/7397 [==============================] - 0s 42us/step - loss: 1623.7969 - mse: 1623.7965 - mae: 25.3175\n",
      "Epoch 24/60\n",
      "7397/7397 [==============================] - 0s 42us/step - loss: 1621.7251 - mse: 1621.7252 - mae: 25.4153\n",
      "Epoch 25/60\n",
      "7397/7397 [==============================] - 0s 42us/step - loss: 1619.8842 - mse: 1619.8843 - mae: 25.2300\n",
      "Epoch 26/60\n",
      "7397/7397 [==============================] - 0s 42us/step - loss: 1620.8716 - mse: 1620.8715 - mae: 25.3296\n",
      "Epoch 27/60\n",
      "7397/7397 [==============================] - 0s 43us/step - loss: 1619.0226 - mse: 1619.0227 - mae: 25.3386\n",
      "Epoch 28/60\n",
      "7397/7397 [==============================] - 0s 43us/step - loss: 1618.8437 - mse: 1618.8440 - mae: 25.2898\n",
      "Epoch 29/60\n",
      "7397/7397 [==============================] - 0s 42us/step - loss: 1618.5689 - mse: 1618.5688 - mae: 25.3332\n",
      "Epoch 30/60\n",
      "7397/7397 [==============================] - 0s 43us/step - loss: 1618.7102 - mse: 1618.7097 - mae: 25.3076\n",
      "Epoch 31/60\n",
      "7397/7397 [==============================] - 0s 43us/step - loss: 1617.4304 - mse: 1617.4302 - mae: 25.3135\n",
      "Epoch 32/60\n",
      "7397/7397 [==============================] - 0s 43us/step - loss: 1617.2723 - mse: 1617.2725 - mae: 25.3341\n",
      "Epoch 33/60\n",
      "7397/7397 [==============================] - 0s 43us/step - loss: 1616.9821 - mse: 1616.9824 - mae: 25.2469\n",
      "Epoch 34/60\n",
      "7397/7397 [==============================] - 0s 43us/step - loss: 1616.0818 - mse: 1616.0815 - mae: 25.3117\n",
      "Epoch 35/60\n",
      "7397/7397 [==============================] - 0s 43us/step - loss: 1616.3666 - mse: 1616.3668 - mae: 25.3105\n",
      "Epoch 36/60\n",
      "7397/7397 [==============================] - 0s 43us/step - loss: 1616.4503 - mse: 1616.4510 - mae: 25.2924\n",
      "Epoch 37/60\n",
      "7397/7397 [==============================] - 0s 43us/step - loss: 1616.4313 - mse: 1616.4318 - mae: 25.2982\n",
      "Epoch 38/60\n",
      "7397/7397 [==============================] - 0s 43us/step - loss: 1617.2520 - mse: 1617.2518 - mae: 25.3495\n",
      "Epoch 39/60\n",
      "7397/7397 [==============================] - 0s 43us/step - loss: 1615.6740 - mse: 1615.6746 - mae: 25.3580\n",
      "Epoch 40/60\n",
      "7397/7397 [==============================] - 0s 43us/step - loss: 1615.1354 - mse: 1615.1357 - mae: 25.2805\n",
      "Epoch 41/60\n",
      "7397/7397 [==============================] - 0s 43us/step - loss: 1615.1218 - mse: 1615.1216 - mae: 25.2620\n",
      "Epoch 42/60\n",
      "7397/7397 [==============================] - 0s 43us/step - loss: 1615.9319 - mse: 1615.9320 - mae: 25.4322\n",
      "Epoch 43/60\n",
      "7397/7397 [==============================] - 0s 43us/step - loss: 1615.7165 - mse: 1615.7164 - mae: 25.2117\n",
      "Epoch 44/60\n",
      "7397/7397 [==============================] - 0s 43us/step - loss: 1614.7054 - mse: 1614.7052 - mae: 25.2805\n",
      "Epoch 45/60\n",
      "7397/7397 [==============================] - 0s 43us/step - loss: 1615.6087 - mse: 1615.6084 - mae: 25.3873\n",
      "Epoch 46/60\n",
      "7397/7397 [==============================] - 0s 43us/step - loss: 1615.2828 - mse: 1615.2820 - mae: 25.3239\n",
      "Epoch 47/60\n",
      "7397/7397 [==============================] - 0s 43us/step - loss: 1615.0526 - mse: 1615.0525 - mae: 25.2537\n",
      "Epoch 48/60\n",
      "7397/7397 [==============================] - 0s 43us/step - loss: 1615.1520 - mse: 1615.1522 - mae: 25.2929\n",
      "Epoch 49/60\n",
      "7397/7397 [==============================] - 0s 43us/step - loss: 1614.7318 - mse: 1614.7318 - mae: 25.3082\n",
      "Epoch 50/60\n",
      "7397/7397 [==============================] - 0s 43us/step - loss: 1616.7763 - mse: 1616.7769 - mae: 25.3502\n",
      "Epoch 51/60\n",
      "7397/7397 [==============================] - 0s 43us/step - loss: 1614.0162 - mse: 1614.0162 - mae: 25.2732\n",
      "Epoch 52/60\n",
      "7397/7397 [==============================] - 0s 43us/step - loss: 1613.9673 - mse: 1613.9673 - mae: 25.2515\n",
      "Epoch 53/60\n",
      "7397/7397 [==============================] - 0s 43us/step - loss: 1614.6298 - mse: 1614.6305 - mae: 25.2856\n",
      "Epoch 54/60\n",
      "7397/7397 [==============================] - 0s 43us/step - loss: 1614.9096 - mse: 1614.9098 - mae: 25.3679\n",
      "Epoch 55/60\n",
      "7397/7397 [==============================] - 0s 43us/step - loss: 1613.7138 - mse: 1613.7128 - mae: 25.3005\n",
      "Epoch 56/60\n",
      "7397/7397 [==============================] - 0s 43us/step - loss: 1612.8788 - mse: 1612.8790 - mae: 25.2462\n",
      "Epoch 57/60\n",
      "7397/7397 [==============================] - 0s 42us/step - loss: 1613.0873 - mse: 1613.0875 - mae: 25.4060\n",
      "Epoch 58/60\n",
      "7397/7397 [==============================] - 0s 42us/step - loss: 1614.0391 - mse: 1614.0388 - mae: 25.2852\n",
      "Epoch 59/60\n",
      "7397/7397 [==============================] - 0s 42us/step - loss: 1615.1820 - mse: 1615.1820 - mae: 25.2842\n",
      "Epoch 60/60\n",
      "7397/7397 [==============================] - 0s 42us/step - loss: 1613.4804 - mse: 1613.4806 - mae: 25.3914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=90)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "1850/1850 [==============================] - 1s 392us/step - loss: 9197.9253 - mse: 9197.9258 - mae: 88.4596\n",
      "Epoch 2/60\n",
      "1850/1850 [==============================] - 0s 48us/step - loss: 1160.2959 - mse: 1160.2959 - mae: 23.5744\n",
      "Epoch 3/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 1022.2068 - mse: 1022.2069 - mae: 21.9982\n",
      "Epoch 4/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 1019.5817 - mse: 1019.5815 - mae: 22.0201\n",
      "Epoch 5/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 1016.9332 - mse: 1016.9333 - mae: 21.8835\n",
      "Epoch 6/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 1018.6206 - mse: 1018.6206 - mae: 21.8793\n",
      "Epoch 7/60\n",
      "1850/1850 [==============================] - 0s 47us/step - loss: 1014.9089 - mse: 1014.9090 - mae: 21.8265\n",
      "Epoch 8/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 1014.5044 - mse: 1014.5043 - mae: 21.8084\n",
      "Epoch 9/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 1015.0180 - mse: 1015.0181 - mae: 21.6834\n",
      "Epoch 10/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 1018.6110 - mse: 1018.6110 - mae: 21.8148\n",
      "Epoch 11/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 1012.6356 - mse: 1012.6357 - mae: 21.7365\n",
      "Epoch 12/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 1013.5563 - mse: 1013.5563 - mae: 21.6526\n",
      "Epoch 13/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 1013.5531 - mse: 1013.5530 - mae: 21.7268\n",
      "Epoch 14/60\n",
      "1850/1850 [==============================] - 0s 47us/step - loss: 1012.0405 - mse: 1012.0405 - mae: 21.6015\n",
      "Epoch 15/60\n",
      "1850/1850 [==============================] - 0s 47us/step - loss: 1015.7109 - mse: 1015.7109 - mae: 21.7114\n",
      "Epoch 16/60\n",
      "1850/1850 [==============================] - 0s 47us/step - loss: 1010.6094 - mse: 1010.6093 - mae: 21.6781\n",
      "Epoch 17/60\n",
      "1850/1850 [==============================] - 0s 47us/step - loss: 1009.2859 - mse: 1009.2860 - mae: 21.5987\n",
      "Epoch 18/60\n",
      "1850/1850 [==============================] - 0s 47us/step - loss: 1014.1131 - mse: 1014.1131 - mae: 21.6199\n",
      "Epoch 19/60\n",
      "1850/1850 [==============================] - 0s 47us/step - loss: 1010.4722 - mse: 1010.4722 - mae: 21.5183\n",
      "Epoch 20/60\n",
      "1850/1850 [==============================] - 0s 47us/step - loss: 1009.7896 - mse: 1009.7895 - mae: 21.5911\n",
      "Epoch 21/60\n",
      "1850/1850 [==============================] - 0s 47us/step - loss: 1011.4224 - mse: 1011.4224 - mae: 21.5689\n",
      "Epoch 22/60\n",
      "1850/1850 [==============================] - 0s 47us/step - loss: 1012.5101 - mse: 1012.5102 - mae: 21.5703\n",
      "Epoch 23/60\n",
      "1850/1850 [==============================] - 0s 47us/step - loss: 1008.8685 - mse: 1008.8683 - mae: 21.5874\n",
      "Epoch 24/60\n",
      "1850/1850 [==============================] - 0s 47us/step - loss: 1007.0067 - mse: 1007.0066 - mae: 21.4369\n",
      "Epoch 25/60\n",
      "1850/1850 [==============================] - 0s 47us/step - loss: 1010.0849 - mse: 1010.0848 - mae: 21.4556\n",
      "Epoch 26/60\n",
      "1850/1850 [==============================] - 0s 47us/step - loss: 1008.3113 - mse: 1008.3113 - mae: 21.5012\n",
      "Epoch 27/60\n",
      "1850/1850 [==============================] - 0s 47us/step - loss: 1009.2295 - mse: 1009.2294 - mae: 21.5125\n",
      "Epoch 28/60\n",
      "1850/1850 [==============================] - 0s 47us/step - loss: 1005.8889 - mse: 1005.8888 - mae: 21.4621\n",
      "Epoch 29/60\n",
      "1850/1850 [==============================] - 0s 47us/step - loss: 1009.5787 - mse: 1009.5789 - mae: 21.5360\n",
      "Epoch 30/60\n",
      "1850/1850 [==============================] - 0s 47us/step - loss: 1008.4415 - mse: 1008.4415 - mae: 21.4339\n",
      "Epoch 31/60\n",
      "1850/1850 [==============================] - 0s 47us/step - loss: 1010.4008 - mse: 1010.4006 - mae: 21.5640\n",
      "Epoch 32/60\n",
      "1850/1850 [==============================] - 0s 47us/step - loss: 1007.5542 - mse: 1007.5543 - mae: 21.4380\n",
      "Epoch 33/60\n",
      "1850/1850 [==============================] - 0s 47us/step - loss: 1010.7157 - mse: 1010.7157 - mae: 21.4806\n",
      "Epoch 34/60\n",
      "1850/1850 [==============================] - 0s 47us/step - loss: 1005.5702 - mse: 1005.5701 - mae: 21.4706\n",
      "Epoch 35/60\n",
      "1850/1850 [==============================] - 0s 47us/step - loss: 1006.6617 - mse: 1006.6617 - mae: 21.4961\n",
      "Epoch 36/60\n",
      "1850/1850 [==============================] - 0s 47us/step - loss: 1007.1607 - mse: 1007.1607 - mae: 21.4649\n",
      "Epoch 37/60\n",
      "1850/1850 [==============================] - 0s 47us/step - loss: 1006.7605 - mse: 1006.7605 - mae: 21.4528\n",
      "Epoch 38/60\n",
      "1850/1850 [==============================] - 0s 47us/step - loss: 1004.9774 - mse: 1004.9774 - mae: 21.4363\n",
      "Epoch 39/60\n",
      "1850/1850 [==============================] - 0s 47us/step - loss: 1006.3590 - mse: 1006.3591 - mae: 21.4073\n",
      "Epoch 40/60\n",
      "1850/1850 [==============================] - 0s 47us/step - loss: 1007.4223 - mse: 1007.4222 - mae: 21.4546\n",
      "Epoch 41/60\n",
      "1850/1850 [==============================] - 0s 47us/step - loss: 1005.8689 - mse: 1005.8689 - mae: 21.4549\n",
      "Epoch 42/60\n",
      "1850/1850 [==============================] - 0s 47us/step - loss: 1008.2576 - mse: 1008.2576 - mae: 21.4605\n",
      "Epoch 43/60\n",
      "1850/1850 [==============================] - 0s 47us/step - loss: 1006.4387 - mse: 1006.4388 - mae: 21.3872\n",
      "Epoch 44/60\n",
      "1850/1850 [==============================] - 0s 47us/step - loss: 1005.9867 - mse: 1005.9867 - mae: 21.3631\n",
      "Epoch 45/60\n",
      "1850/1850 [==============================] - 0s 47us/step - loss: 1005.1647 - mse: 1005.1648 - mae: 21.5046\n",
      "Epoch 46/60\n",
      "1850/1850 [==============================] - 0s 47us/step - loss: 1004.3442 - mse: 1004.3441 - mae: 21.4706\n",
      "Epoch 47/60\n",
      "1850/1850 [==============================] - 0s 47us/step - loss: 1002.4895 - mse: 1002.4893 - mae: 21.4040\n",
      "Epoch 48/60\n",
      "1850/1850 [==============================] - 0s 47us/step - loss: 1003.9117 - mse: 1003.9117 - mae: 21.5697\n",
      "Epoch 49/60\n",
      "1850/1850 [==============================] - 0s 47us/step - loss: 1008.4582 - mse: 1008.4581 - mae: 21.4572\n",
      "Epoch 50/60\n",
      "1850/1850 [==============================] - 0s 47us/step - loss: 1001.8868 - mse: 1001.8867 - mae: 21.2949\n",
      "Epoch 51/60\n",
      "1850/1850 [==============================] - 0s 47us/step - loss: 1004.9571 - mse: 1004.9572 - mae: 21.4891\n",
      "Epoch 52/60\n",
      "1850/1850 [==============================] - 0s 47us/step - loss: 1002.0005 - mse: 1002.0005 - mae: 21.3954\n",
      "Epoch 53/60\n",
      "1850/1850 [==============================] - 0s 47us/step - loss: 1007.4226 - mse: 1007.4225 - mae: 21.4151\n",
      "Epoch 54/60\n",
      "1850/1850 [==============================] - 0s 47us/step - loss: 999.9476 - mse: 999.9476 - mae: 21.4899\n",
      "Epoch 55/60\n",
      "1850/1850 [==============================] - 0s 47us/step - loss: 1000.9653 - mse: 1000.9653 - mae: 21.3786\n",
      "Epoch 56/60\n",
      "1850/1850 [==============================] - 0s 47us/step - loss: 1003.9874 - mse: 1003.9874 - mae: 21.4577\n",
      "Epoch 57/60\n",
      "1850/1850 [==============================] - 0s 47us/step - loss: 1000.4126 - mse: 1000.4127 - mae: 21.3898\n",
      "Epoch 58/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 1003.1551 - mse: 1003.1550 - mae: 21.4780\n",
      "Epoch 59/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 1002.3713 - mse: 1002.3713 - mae: 21.4459\n",
      "Epoch 60/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 1003.4597 - mse: 1003.4597 - mae: 21.4061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=90)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "3699/3699 [==============================] - 1s 220us/step - loss: 5310.5416 - mse: 5310.5396 - mae: 57.0488\n",
      "Epoch 2/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1138.4233 - mse: 1138.4233 - mae: 22.8206\n",
      "Epoch 3/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1135.7454 - mse: 1135.7455 - mae: 22.7910\n",
      "Epoch 4/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1133.1077 - mse: 1133.1077 - mae: 22.7390\n",
      "Epoch 5/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1131.4899 - mse: 1131.4900 - mae: 22.7263\n",
      "Epoch 6/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1132.0412 - mse: 1132.0410 - mae: 22.7783\n",
      "Epoch 7/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1130.0760 - mse: 1130.0764 - mae: 22.6783\n",
      "Epoch 8/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1128.1045 - mse: 1128.1044 - mae: 22.6703\n",
      "Epoch 9/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1126.9058 - mse: 1126.9060 - mae: 22.6606\n",
      "Epoch 10/60\n",
      "3699/3699 [==============================] - 0s 46us/step - loss: 1127.5299 - mse: 1127.5300 - mae: 22.6915\n",
      "Epoch 11/60\n",
      "3699/3699 [==============================] - 0s 46us/step - loss: 1125.3904 - mse: 1125.3903 - mae: 22.6169\n",
      "Epoch 12/60\n",
      "3699/3699 [==============================] - 0s 46us/step - loss: 1125.2365 - mse: 1125.2367 - mae: 22.6665\n",
      "Epoch 13/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1123.9088 - mse: 1123.9089 - mae: 22.5997\n",
      "Epoch 14/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1124.1453 - mse: 1124.1453 - mae: 22.6097\n",
      "Epoch 15/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1122.9299 - mse: 1122.9297 - mae: 22.6219\n",
      "Epoch 16/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1124.1646 - mse: 1124.1643 - mae: 22.6657\n",
      "Epoch 17/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1123.7191 - mse: 1123.7192 - mae: 22.6455\n",
      "Epoch 18/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1123.4140 - mse: 1123.4138 - mae: 22.5944\n",
      "Epoch 19/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1122.2432 - mse: 1122.2433 - mae: 22.6357\n",
      "Epoch 20/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1122.4023 - mse: 1122.4025 - mae: 22.6007\n",
      "Epoch 21/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1122.4348 - mse: 1122.4343 - mae: 22.6529\n",
      "Epoch 22/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1122.2736 - mse: 1122.2734 - mae: 22.6034\n",
      "Epoch 23/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1121.8834 - mse: 1121.8833 - mae: 22.6244\n",
      "Epoch 24/60\n",
      "3699/3699 [==============================] - 0s 46us/step - loss: 1123.0022 - mse: 1123.0023 - mae: 22.6576\n",
      "Epoch 25/60\n",
      "3699/3699 [==============================] - 0s 46us/step - loss: 1122.5916 - mse: 1122.5918 - mae: 22.5904\n",
      "Epoch 26/60\n",
      "3699/3699 [==============================] - 0s 46us/step - loss: 1121.8060 - mse: 1121.8059 - mae: 22.5615\n",
      "Epoch 27/60\n",
      "3699/3699 [==============================] - 0s 46us/step - loss: 1119.9670 - mse: 1119.9672 - mae: 22.5790\n",
      "Epoch 28/60\n",
      "3699/3699 [==============================] - 0s 46us/step - loss: 1121.8830 - mse: 1121.8829 - mae: 22.5758\n",
      "Epoch 29/60\n",
      "3699/3699 [==============================] - 0s 46us/step - loss: 1120.0946 - mse: 1120.0947 - mae: 22.6042\n",
      "Epoch 30/60\n",
      "3699/3699 [==============================] - 0s 46us/step - loss: 1119.2765 - mse: 1119.2769 - mae: 22.5335\n",
      "Epoch 31/60\n",
      "3699/3699 [==============================] - 0s 46us/step - loss: 1118.7496 - mse: 1118.7491 - mae: 22.4990\n",
      "Epoch 32/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1118.3662 - mse: 1118.3667 - mae: 22.5831\n",
      "Epoch 33/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1120.3660 - mse: 1120.3660 - mae: 22.5267\n",
      "Epoch 34/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1120.1656 - mse: 1120.1659 - mae: 22.6595\n",
      "Epoch 35/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1118.9068 - mse: 1118.9071 - mae: 22.5091\n",
      "Epoch 36/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1119.9978 - mse: 1119.9982 - mae: 22.5445\n",
      "Epoch 37/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1118.2274 - mse: 1118.2271 - mae: 22.5906\n",
      "Epoch 38/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1118.9459 - mse: 1118.9458 - mae: 22.5382\n",
      "Epoch 39/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1117.9314 - mse: 1117.9314 - mae: 22.5585\n",
      "Epoch 40/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1118.4328 - mse: 1118.4326 - mae: 22.6012\n",
      "Epoch 41/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1117.4872 - mse: 1117.4872 - mae: 22.4045\n",
      "Epoch 42/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1118.8558 - mse: 1118.8560 - mae: 22.5459\n",
      "Epoch 43/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1118.4956 - mse: 1118.4957 - mae: 22.5018\n",
      "Epoch 44/60\n",
      "3699/3699 [==============================] - 0s 48us/step - loss: 1118.9728 - mse: 1118.9729 - mae: 22.5166\n",
      "Epoch 45/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1119.8898 - mse: 1119.8899 - mae: 22.5619\n",
      "Epoch 46/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1117.4935 - mse: 1117.4934 - mae: 22.5350\n",
      "Epoch 47/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1117.9774 - mse: 1117.9775 - mae: 22.5315\n",
      "Epoch 48/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1118.6379 - mse: 1118.6379 - mae: 22.4910\n",
      "Epoch 49/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1119.5241 - mse: 1119.5243 - mae: 22.5592\n",
      "Epoch 50/60\n",
      "3699/3699 [==============================] - 0s 46us/step - loss: 1118.3508 - mse: 1118.3506 - mae: 22.4550\n",
      "Epoch 51/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1118.1670 - mse: 1118.1670 - mae: 22.5371\n",
      "Epoch 52/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1118.4654 - mse: 1118.4655 - mae: 22.4402\n",
      "Epoch 53/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1119.8334 - mse: 1119.8335 - mae: 22.5870\n",
      "Epoch 54/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1116.3665 - mse: 1116.3666 - mae: 22.4523\n",
      "Epoch 55/60\n",
      "3699/3699 [==============================] - 0s 48us/step - loss: 1117.5360 - mse: 1117.5363 - mae: 22.5627\n",
      "Epoch 56/60\n",
      "3699/3699 [==============================] - 0s 48us/step - loss: 1119.1211 - mse: 1119.1212 - mae: 22.5196\n",
      "Epoch 57/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1118.7845 - mse: 1118.7843 - mae: 22.5234\n",
      "Epoch 58/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1121.6219 - mse: 1121.6218 - mae: 22.5843\n",
      "Epoch 59/60\n",
      "3699/3699 [==============================] - 0s 46us/step - loss: 1119.3006 - mse: 1119.3008 - mae: 22.5676\n",
      "Epoch 60/60\n",
      "3699/3699 [==============================] - 0s 46us/step - loss: 1120.4006 - mse: 1120.4009 - mae: 22.5252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=90)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "5548/5548 [==============================] - 1s 161us/step - loss: 4675.5983 - mse: 4675.5991 - mae: 47.7670\n",
      "Epoch 2/60\n",
      "5548/5548 [==============================] - 0s 46us/step - loss: 1708.3706 - mse: 1708.3704 - mae: 25.3181\n",
      "Epoch 3/60\n",
      "5548/5548 [==============================] - 0s 46us/step - loss: 1705.3288 - mse: 1705.3286 - mae: 25.1434\n",
      "Epoch 4/60\n",
      "5548/5548 [==============================] - 0s 46us/step - loss: 1702.5327 - mse: 1702.5328 - mae: 25.1496\n",
      "Epoch 5/60\n",
      "5548/5548 [==============================] - 0s 46us/step - loss: 1700.1236 - mse: 1700.1241 - mae: 25.1001\n",
      "Epoch 6/60\n",
      "5548/5548 [==============================] - 0s 46us/step - loss: 1694.0974 - mse: 1694.0973 - mae: 25.1189\n",
      "Epoch 7/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1693.9995 - mse: 1693.9993 - mae: 25.0273\n",
      "Epoch 8/60\n",
      "5548/5548 [==============================] - 0s 46us/step - loss: 1691.2817 - mse: 1691.2817 - mae: 25.1075\n",
      "Epoch 9/60\n",
      "5548/5548 [==============================] - 0s 46us/step - loss: 1686.2721 - mse: 1686.2723 - mae: 24.9593\n",
      "Epoch 10/60\n",
      "5548/5548 [==============================] - 0s 46us/step - loss: 1686.8794 - mse: 1686.8798 - mae: 25.0411\n",
      "Epoch 11/60\n",
      "5548/5548 [==============================] - 0s 46us/step - loss: 1682.3381 - mse: 1682.3384 - mae: 24.9990\n",
      "Epoch 12/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1685.1388 - mse: 1685.1384 - mae: 25.0977\n",
      "Epoch 13/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1681.6578 - mse: 1681.6578 - mae: 24.9861\n",
      "Epoch 14/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1680.1531 - mse: 1680.1528 - mae: 24.9470\n",
      "Epoch 15/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1677.3754 - mse: 1677.3755 - mae: 24.9800\n",
      "Epoch 16/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1681.4864 - mse: 1681.4860 - mae: 24.9906\n",
      "Epoch 17/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1676.8234 - mse: 1676.8234 - mae: 24.9265\n",
      "Epoch 18/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1676.7342 - mse: 1676.7340 - mae: 25.0324\n",
      "Epoch 19/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1676.0986 - mse: 1676.0975 - mae: 24.9392\n",
      "Epoch 20/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1676.8042 - mse: 1676.8046 - mae: 25.0290\n",
      "Epoch 21/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1675.5683 - mse: 1675.5680 - mae: 24.9624\n",
      "Epoch 22/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1673.3700 - mse: 1673.3702 - mae: 24.9756\n",
      "Epoch 23/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1673.4057 - mse: 1673.4054 - mae: 24.9638\n",
      "Epoch 24/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1676.2368 - mse: 1676.2368 - mae: 24.9269\n",
      "Epoch 25/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1674.1719 - mse: 1674.1721 - mae: 24.9313\n",
      "Epoch 26/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1675.5417 - mse: 1675.5415 - mae: 24.9407\n",
      "Epoch 27/60\n",
      "5548/5548 [==============================] - 0s 48us/step - loss: 1678.2406 - mse: 1678.2401 - mae: 24.9419\n",
      "Epoch 28/60\n",
      "5548/5548 [==============================] - 0s 48us/step - loss: 1674.0082 - mse: 1674.0081 - mae: 24.9362\n",
      "Epoch 29/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1671.6201 - mse: 1671.6199 - mae: 24.9574\n",
      "Epoch 30/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1673.2207 - mse: 1673.2202 - mae: 24.9542\n",
      "Epoch 31/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1671.6104 - mse: 1671.6107 - mae: 24.9338\n",
      "Epoch 32/60\n",
      "5548/5548 [==============================] - 0s 46us/step - loss: 1672.6943 - mse: 1672.6947 - mae: 24.9007\n",
      "Epoch 33/60\n",
      "5548/5548 [==============================] - 0s 46us/step - loss: 1669.4729 - mse: 1669.4728 - mae: 24.9587\n",
      "Epoch 34/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1673.2680 - mse: 1673.2684 - mae: 24.9157\n",
      "Epoch 35/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1671.2359 - mse: 1671.2367 - mae: 24.9024\n",
      "Epoch 36/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1673.9600 - mse: 1673.9602 - mae: 24.9218\n",
      "Epoch 37/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1670.9411 - mse: 1670.9413 - mae: 24.9016\n",
      "Epoch 38/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1672.1032 - mse: 1672.1029 - mae: 24.8959\n",
      "Epoch 39/60\n",
      "5548/5548 [==============================] - 0s 46us/step - loss: 1671.5807 - mse: 1671.5809 - mae: 24.9212\n",
      "Epoch 40/60\n",
      "5548/5548 [==============================] - 0s 46us/step - loss: 1672.2938 - mse: 1672.2936 - mae: 24.9265\n",
      "Epoch 41/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1671.3282 - mse: 1671.3280 - mae: 24.8701\n",
      "Epoch 42/60\n",
      "5548/5548 [==============================] - 0s 46us/step - loss: 1672.8913 - mse: 1672.8915 - mae: 24.9355\n",
      "Epoch 43/60\n",
      "5548/5548 [==============================] - 0s 46us/step - loss: 1668.9093 - mse: 1668.9093 - mae: 24.8711\n",
      "Epoch 44/60\n",
      "5548/5548 [==============================] - 0s 48us/step - loss: 1670.9679 - mse: 1670.9681 - mae: 24.9750\n",
      "Epoch 45/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1669.7690 - mse: 1669.7697 - mae: 24.8854\n",
      "Epoch 46/60\n",
      "5548/5548 [==============================] - 0s 48us/step - loss: 1673.0478 - mse: 1673.0477 - mae: 24.8734\n",
      "Epoch 47/60\n",
      "5548/5548 [==============================] - 0s 48us/step - loss: 1668.7530 - mse: 1668.7534 - mae: 24.9047\n",
      "Epoch 48/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1669.4144 - mse: 1669.4146 - mae: 24.8615\n",
      "Epoch 49/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1670.1442 - mse: 1670.1444 - mae: 24.9047\n",
      "Epoch 50/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1670.2573 - mse: 1670.2572 - mae: 24.9157\n",
      "Epoch 51/60\n",
      "5548/5548 [==============================] - 0s 48us/step - loss: 1671.1875 - mse: 1671.1871 - mae: 24.8970\n",
      "Epoch 52/60\n",
      "5548/5548 [==============================] - 0s 48us/step - loss: 1673.1738 - mse: 1673.1740 - mae: 24.8885\n",
      "Epoch 53/60\n",
      "5548/5548 [==============================] - 0s 48us/step - loss: 1668.8416 - mse: 1668.8419 - mae: 24.9308\n",
      "Epoch 54/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1671.0013 - mse: 1671.0015 - mae: 24.8676\n",
      "Epoch 55/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1669.6638 - mse: 1669.6633 - mae: 24.8841\n",
      "Epoch 56/60\n",
      "5548/5548 [==============================] - 0s 48us/step - loss: 1670.2460 - mse: 1670.2457 - mae: 24.8708\n",
      "Epoch 57/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1669.2925 - mse: 1669.2924 - mae: 24.8627\n",
      "Epoch 58/60\n",
      "5548/5548 [==============================] - 0s 48us/step - loss: 1669.5276 - mse: 1669.5281 - mae: 24.9499\n",
      "Epoch 59/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1670.1909 - mse: 1670.1910 - mae: 24.8806\n",
      "Epoch 60/60\n",
      "5548/5548 [==============================] - 0s 47us/step - loss: 1668.2749 - mse: 1668.2747 - mae: 24.8636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=90)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "7397/7397 [==============================] - 1s 132us/step - loss: 4024.5999 - mse: 4024.5977 - mae: 43.3114\n",
      "Epoch 2/60\n",
      "7397/7397 [==============================] - 0s 47us/step - loss: 1661.8181 - mse: 1661.8184 - mae: 25.6762\n",
      "Epoch 3/60\n",
      "7397/7397 [==============================] - 0s 46us/step - loss: 1654.1136 - mse: 1654.1133 - mae: 25.5593\n",
      "Epoch 4/60\n",
      "7397/7397 [==============================] - 0s 46us/step - loss: 1646.7160 - mse: 1646.7158 - mae: 25.5630\n",
      "Epoch 5/60\n",
      "7397/7397 [==============================] - 0s 46us/step - loss: 1639.8258 - mse: 1639.8254 - mae: 25.4433\n",
      "Epoch 6/60\n",
      "7397/7397 [==============================] - 0s 47us/step - loss: 1635.3253 - mse: 1635.3256 - mae: 25.4090\n",
      "Epoch 7/60\n",
      "7397/7397 [==============================] - 0s 48us/step - loss: 1633.5400 - mse: 1633.5406 - mae: 25.4029\n",
      "Epoch 8/60\n",
      "7397/7397 [==============================] - 0s 47us/step - loss: 1627.6511 - mse: 1627.6519 - mae: 25.3391\n",
      "Epoch 9/60\n",
      "7397/7397 [==============================] - 0s 47us/step - loss: 1624.8172 - mse: 1624.8168 - mae: 25.3526\n",
      "Epoch 10/60\n",
      "7397/7397 [==============================] - 0s 47us/step - loss: 1623.0454 - mse: 1623.0453 - mae: 25.3431\n",
      "Epoch 11/60\n",
      "7397/7397 [==============================] - 0s 47us/step - loss: 1620.4662 - mse: 1620.4667 - mae: 25.3420\n",
      "Epoch 12/60\n",
      "7397/7397 [==============================] - 0s 47us/step - loss: 1621.1645 - mse: 1621.1647 - mae: 25.3583\n",
      "Epoch 13/60\n",
      "7397/7397 [==============================] - 0s 47us/step - loss: 1619.7699 - mse: 1619.7699 - mae: 25.3058\n",
      "Epoch 14/60\n",
      "7397/7397 [==============================] - 0s 47us/step - loss: 1618.6325 - mse: 1618.6324 - mae: 25.3565\n",
      "Epoch 15/60\n",
      "7397/7397 [==============================] - 0s 47us/step - loss: 1618.7973 - mse: 1618.7976 - mae: 25.3823\n",
      "Epoch 16/60\n",
      "7397/7397 [==============================] - 0s 47us/step - loss: 1619.3269 - mse: 1619.3271 - mae: 25.3289\n",
      "Epoch 17/60\n",
      "7397/7397 [==============================] - 0s 47us/step - loss: 1620.2815 - mse: 1620.2815 - mae: 25.3185\n",
      "Epoch 18/60\n",
      "7397/7397 [==============================] - 0s 47us/step - loss: 1618.0614 - mse: 1618.0614 - mae: 25.3746\n",
      "Epoch 19/60\n",
      "7397/7397 [==============================] - 0s 47us/step - loss: 1618.4008 - mse: 1618.4011 - mae: 25.3547\n",
      "Epoch 20/60\n",
      "7397/7397 [==============================] - 0s 46us/step - loss: 1619.3146 - mse: 1619.3143 - mae: 25.3099\n",
      "Epoch 21/60\n",
      "7397/7397 [==============================] - 0s 47us/step - loss: 1616.3823 - mse: 1616.3829 - mae: 25.3559\n",
      "Epoch 22/60\n",
      "7397/7397 [==============================] - 0s 47us/step - loss: 1619.2105 - mse: 1619.2103 - mae: 25.3481\n",
      "Epoch 23/60\n",
      "7397/7397 [==============================] - 0s 47us/step - loss: 1619.1082 - mse: 1619.1078 - mae: 25.3848\n",
      "Epoch 24/60\n",
      "7397/7397 [==============================] - 0s 47us/step - loss: 1618.6274 - mse: 1618.6270 - mae: 25.3245\n",
      "Epoch 25/60\n",
      "7397/7397 [==============================] - 0s 47us/step - loss: 1616.3906 - mse: 1616.3900 - mae: 25.4061\n",
      "Epoch 26/60\n",
      "7397/7397 [==============================] - 0s 47us/step - loss: 1615.8909 - mse: 1615.8904 - mae: 25.3037\n",
      "Epoch 27/60\n",
      "7397/7397 [==============================] - 0s 46us/step - loss: 1618.5008 - mse: 1618.5007 - mae: 25.4008\n",
      "Epoch 28/60\n",
      "7397/7397 [==============================] - 0s 46us/step - loss: 1619.7445 - mse: 1619.7446 - mae: 25.3957\n",
      "Epoch 29/60\n",
      "7397/7397 [==============================] - 0s 46us/step - loss: 1614.8941 - mse: 1614.8931 - mae: 25.2272\n",
      "Epoch 30/60\n",
      "7397/7397 [==============================] - 0s 48us/step - loss: 1616.7466 - mse: 1616.7467 - mae: 25.3816\n",
      "Epoch 31/60\n",
      "7397/7397 [==============================] - 0s 47us/step - loss: 1618.7027 - mse: 1618.7030 - mae: 25.3214\n",
      "Epoch 32/60\n",
      "7397/7397 [==============================] - 0s 47us/step - loss: 1618.6546 - mse: 1618.6545 - mae: 25.3570\n",
      "Epoch 33/60\n",
      "7397/7397 [==============================] - 0s 46us/step - loss: 1616.9588 - mse: 1616.9597 - mae: 25.3437\n",
      "Epoch 34/60\n",
      "7397/7397 [==============================] - 0s 46us/step - loss: 1616.0258 - mse: 1616.0256 - mae: 25.3319\n",
      "Epoch 35/60\n",
      "7397/7397 [==============================] - 0s 46us/step - loss: 1619.0565 - mse: 1619.0563 - mae: 25.4537\n",
      "Epoch 36/60\n",
      "7397/7397 [==============================] - 0s 47us/step - loss: 1616.0063 - mse: 1616.0060 - mae: 25.3183\n",
      "Epoch 37/60\n",
      "7397/7397 [==============================] - 0s 46us/step - loss: 1615.8690 - mse: 1615.8691 - mae: 25.3581\n",
      "Epoch 38/60\n",
      "7397/7397 [==============================] - 0s 46us/step - loss: 1614.9359 - mse: 1614.9357 - mae: 25.3309\n",
      "Epoch 39/60\n",
      "7397/7397 [==============================] - 0s 47us/step - loss: 1616.4180 - mse: 1616.4178 - mae: 25.2917\n",
      "Epoch 40/60\n",
      "7397/7397 [==============================] - 0s 47us/step - loss: 1617.1255 - mse: 1617.1254 - mae: 25.3787\n",
      "Epoch 41/60\n",
      "7397/7397 [==============================] - 0s 46us/step - loss: 1616.3168 - mse: 1616.3169 - mae: 25.3529\n",
      "Epoch 42/60\n",
      "7397/7397 [==============================] - 0s 46us/step - loss: 1616.6318 - mse: 1616.6315 - mae: 25.3745\n",
      "Epoch 43/60\n",
      "7397/7397 [==============================] - 0s 46us/step - loss: 1615.5841 - mse: 1615.5844 - mae: 25.3141\n",
      "Epoch 44/60\n",
      "7397/7397 [==============================] - 0s 46us/step - loss: 1616.3538 - mse: 1616.3536 - mae: 25.3268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=40)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "1850/1850 [==============================] - 1s 562us/step - loss: 6578.9966 - mse: 6578.9971 - mae: 66.0474\n",
      "Epoch 2/60\n",
      "1850/1850 [==============================] - 0s 55us/step - loss: 1024.7927 - mse: 1024.7926 - mae: 22.0257\n",
      "Epoch 3/60\n",
      "1850/1850 [==============================] - 0s 53us/step - loss: 1022.3274 - mse: 1022.3274 - mae: 21.9873\n",
      "Epoch 4/60\n",
      "1850/1850 [==============================] - 0s 53us/step - loss: 1019.4307 - mse: 1019.4307 - mae: 21.8187\n",
      "Epoch 5/60\n",
      "1850/1850 [==============================] - 0s 53us/step - loss: 1018.5225 - mse: 1018.5223 - mae: 21.7852\n",
      "Epoch 6/60\n",
      "1850/1850 [==============================] - 0s 53us/step - loss: 1020.3535 - mse: 1020.3536 - mae: 21.7190\n",
      "Epoch 7/60\n",
      "1850/1850 [==============================] - 0s 53us/step - loss: 1024.8662 - mse: 1024.8662 - mae: 21.8356\n",
      "Epoch 8/60\n",
      "1850/1850 [==============================] - 0s 53us/step - loss: 1021.0540 - mse: 1021.0538 - mae: 21.8155\n",
      "Epoch 9/60\n",
      "1850/1850 [==============================] - 0s 53us/step - loss: 1020.1841 - mse: 1020.1842 - mae: 21.6817\n",
      "Epoch 10/60\n",
      "1850/1850 [==============================] - 0s 53us/step - loss: 1026.3670 - mse: 1026.3671 - mae: 21.8755\n",
      "Epoch 11/60\n",
      "1850/1850 [==============================] - 0s 53us/step - loss: 1017.0214 - mse: 1017.0214 - mae: 21.6297\n",
      "Epoch 12/60\n",
      "1850/1850 [==============================] - 0s 53us/step - loss: 1016.4058 - mse: 1016.4058 - mae: 21.7035\n",
      "Epoch 13/60\n",
      "1850/1850 [==============================] - 0s 53us/step - loss: 1015.2716 - mse: 1015.2715 - mae: 21.6627\n",
      "Epoch 14/60\n",
      "1850/1850 [==============================] - 0s 52us/step - loss: 1015.7848 - mse: 1015.7847 - mae: 21.5670\n",
      "Epoch 15/60\n",
      "1850/1850 [==============================] - 0s 52us/step - loss: 1013.9007 - mse: 1013.9009 - mae: 21.4800\n",
      "Epoch 16/60\n",
      "1850/1850 [==============================] - 0s 52us/step - loss: 1014.4375 - mse: 1014.4375 - mae: 21.6212\n",
      "Epoch 17/60\n",
      "1850/1850 [==============================] - 0s 52us/step - loss: 1017.3651 - mse: 1017.3650 - mae: 21.6925\n",
      "Epoch 18/60\n",
      "1850/1850 [==============================] - 0s 53us/step - loss: 1017.8182 - mse: 1017.8182 - mae: 21.5732\n",
      "Epoch 19/60\n",
      "1850/1850 [==============================] - 0s 53us/step - loss: 1018.6482 - mse: 1018.6482 - mae: 21.5728\n",
      "Epoch 20/60\n",
      "1850/1850 [==============================] - 0s 52us/step - loss: 1014.4371 - mse: 1014.4371 - mae: 21.5307\n",
      "Epoch 21/60\n",
      "1850/1850 [==============================] - 0s 52us/step - loss: 1008.3285 - mse: 1008.3286 - mae: 21.5670\n",
      "Epoch 22/60\n",
      "1850/1850 [==============================] - 0s 52us/step - loss: 1018.0538 - mse: 1018.0538 - mae: 21.6190\n",
      "Epoch 23/60\n",
      "1850/1850 [==============================] - 0s 52us/step - loss: 1016.8051 - mse: 1016.8051 - mae: 21.5450\n",
      "Epoch 24/60\n",
      "1850/1850 [==============================] - 0s 52us/step - loss: 1008.6178 - mse: 1008.6178 - mae: 21.5805\n",
      "Epoch 25/60\n",
      "1850/1850 [==============================] - 0s 52us/step - loss: 1012.1223 - mse: 1012.1222 - mae: 21.5322\n",
      "Epoch 26/60\n",
      "1850/1850 [==============================] - 0s 52us/step - loss: 1017.3969 - mse: 1017.3970 - mae: 21.5840\n",
      "Epoch 27/60\n",
      "1850/1850 [==============================] - 0s 52us/step - loss: 1015.1374 - mse: 1015.1374 - mae: 21.6348\n",
      "Epoch 28/60\n",
      "1850/1850 [==============================] - 0s 52us/step - loss: 1012.0309 - mse: 1012.0308 - mae: 21.5300\n",
      "Epoch 29/60\n",
      "1850/1850 [==============================] - 0s 52us/step - loss: 1011.5217 - mse: 1011.5217 - mae: 21.5255\n",
      "Epoch 30/60\n",
      "1850/1850 [==============================] - 0s 52us/step - loss: 1015.6898 - mse: 1015.6896 - mae: 21.6186\n",
      "Epoch 31/60\n",
      "1850/1850 [==============================] - 0s 53us/step - loss: 1010.4745 - mse: 1010.4744 - mae: 21.6261\n",
      "Epoch 32/60\n",
      "1850/1850 [==============================] - 0s 52us/step - loss: 1008.6512 - mse: 1008.6511 - mae: 21.5020\n",
      "Epoch 33/60\n",
      "1850/1850 [==============================] - 0s 54us/step - loss: 1004.7089 - mse: 1004.7087 - mae: 21.4147\n",
      "Epoch 34/60\n",
      "1850/1850 [==============================] - 0s 52us/step - loss: 1015.6738 - mse: 1015.6739 - mae: 21.5744\n",
      "Epoch 35/60\n",
      "1850/1850 [==============================] - 0s 52us/step - loss: 1010.8715 - mse: 1010.8717 - mae: 21.5979\n",
      "Epoch 36/60\n",
      "1850/1850 [==============================] - 0s 52us/step - loss: 1015.8825 - mse: 1015.8825 - mae: 21.5828\n",
      "Epoch 37/60\n",
      "1850/1850 [==============================] - 0s 54us/step - loss: 1007.8271 - mse: 1007.8273 - mae: 21.5116\n",
      "Epoch 38/60\n",
      "1850/1850 [==============================] - 0s 53us/step - loss: 1007.1618 - mse: 1007.1617 - mae: 21.4211\n",
      "Epoch 39/60\n",
      "1850/1850 [==============================] - 0s 53us/step - loss: 1012.8795 - mse: 1012.8796 - mae: 21.5337\n",
      "Epoch 40/60\n",
      "1850/1850 [==============================] - 0s 53us/step - loss: 1011.2549 - mse: 1011.2549 - mae: 21.5122\n",
      "Epoch 41/60\n",
      "1850/1850 [==============================] - 0s 53us/step - loss: 1013.7550 - mse: 1013.7550 - mae: 21.5467\n",
      "Epoch 42/60\n",
      "1850/1850 [==============================] - 0s 54us/step - loss: 1010.4900 - mse: 1010.4902 - mae: 21.5507\n",
      "Epoch 43/60\n",
      "1850/1850 [==============================] - 0s 53us/step - loss: 1016.2776 - mse: 1016.2776 - mae: 21.7026\n",
      "Epoch 44/60\n",
      "1850/1850 [==============================] - 0s 53us/step - loss: 1003.8596 - mse: 1003.8596 - mae: 21.4353\n",
      "Epoch 45/60\n",
      "1850/1850 [==============================] - 0s 52us/step - loss: 1003.0650 - mse: 1003.0651 - mae: 21.4982\n",
      "Epoch 46/60\n",
      "1850/1850 [==============================] - 0s 52us/step - loss: 1006.8575 - mse: 1006.8574 - mae: 21.5239\n",
      "Epoch 47/60\n",
      "1850/1850 [==============================] - 0s 52us/step - loss: 999.8112 - mse: 999.8113 - mae: 21.4944\n",
      "Epoch 48/60\n",
      "1850/1850 [==============================] - 0s 53us/step - loss: 1003.4065 - mse: 1003.4067 - mae: 21.4540\n",
      "Epoch 49/60\n",
      "1850/1850 [==============================] - 0s 53us/step - loss: 1010.1981 - mse: 1010.1980 - mae: 21.5530\n",
      "Epoch 50/60\n",
      "1850/1850 [==============================] - 0s 53us/step - loss: 1005.5171 - mse: 1005.5170 - mae: 21.5795\n",
      "Epoch 51/60\n",
      "1850/1850 [==============================] - 0s 53us/step - loss: 1007.5412 - mse: 1007.5413 - mae: 21.3866\n",
      "Epoch 52/60\n",
      "1850/1850 [==============================] - 0s 53us/step - loss: 1004.2585 - mse: 1004.2586 - mae: 21.4646\n",
      "Epoch 53/60\n",
      "1850/1850 [==============================] - 0s 53us/step - loss: 1003.1531 - mse: 1003.1531 - mae: 21.5158\n",
      "Epoch 54/60\n",
      "1850/1850 [==============================] - 0s 53us/step - loss: 1009.2424 - mse: 1009.2425 - mae: 21.4626\n",
      "Epoch 55/60\n",
      "1850/1850 [==============================] - 0s 53us/step - loss: 1003.0471 - mse: 1003.0471 - mae: 21.4987\n",
      "Epoch 56/60\n",
      "1850/1850 [==============================] - 0s 52us/step - loss: 1001.6126 - mse: 1001.6126 - mae: 21.5471\n",
      "Epoch 57/60\n",
      "1850/1850 [==============================] - 0s 52us/step - loss: 1006.8449 - mse: 1006.8448 - mae: 21.4622\n",
      "Epoch 58/60\n",
      "1850/1850 [==============================] - 0s 52us/step - loss: 1001.8024 - mse: 1001.8024 - mae: 21.4217\n",
      "Epoch 59/60\n",
      "1850/1850 [==============================] - 0s 52us/step - loss: 1004.8361 - mse: 1004.8361 - mae: 21.4719\n",
      "Epoch 60/60\n",
      "1850/1850 [==============================] - 0s 52us/step - loss: 1005.5729 - mse: 1005.5730 - mae: 21.5425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=40)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "3699/3699 [==============================] - 1s 309us/step - loss: 3901.5938 - mse: 3901.5938 - mae: 43.8044\n",
      "Epoch 2/60\n",
      "3699/3699 [==============================] - 0s 52us/step - loss: 1138.0737 - mse: 1138.0739 - mae: 22.7813\n",
      "Epoch 3/60\n",
      "3699/3699 [==============================] - 0s 54us/step - loss: 1138.7793 - mse: 1138.7793 - mae: 22.7850\n",
      "Epoch 4/60\n",
      "3699/3699 [==============================] - 0s 53us/step - loss: 1137.0495 - mse: 1137.0494 - mae: 22.7008\n",
      "Epoch 5/60\n",
      "3699/3699 [==============================] - 0s 53us/step - loss: 1139.8754 - mse: 1139.8754 - mae: 22.7581\n",
      "Epoch 6/60\n",
      "3699/3699 [==============================] - 0s 53us/step - loss: 1129.9181 - mse: 1129.9178 - mae: 22.6732\n",
      "Epoch 7/60\n",
      "3699/3699 [==============================] - 0s 53us/step - loss: 1132.6775 - mse: 1132.6775 - mae: 22.7169\n",
      "Epoch 8/60\n",
      "3699/3699 [==============================] - 0s 53us/step - loss: 1131.4222 - mse: 1131.4220 - mae: 22.6479\n",
      "Epoch 9/60\n",
      "3699/3699 [==============================] - 0s 54us/step - loss: 1128.4702 - mse: 1128.4700 - mae: 22.6788\n",
      "Epoch 10/60\n",
      "3699/3699 [==============================] - 0s 53us/step - loss: 1130.9406 - mse: 1130.9409 - mae: 22.6096\n",
      "Epoch 11/60\n",
      "3699/3699 [==============================] - 0s 54us/step - loss: 1132.9327 - mse: 1132.9329 - mae: 22.6948\n",
      "Epoch 12/60\n",
      "3699/3699 [==============================] - 0s 53us/step - loss: 1124.4659 - mse: 1124.4658 - mae: 22.6591\n",
      "Epoch 13/60\n",
      "3699/3699 [==============================] - 0s 53us/step - loss: 1128.6938 - mse: 1128.6938 - mae: 22.6473\n",
      "Epoch 14/60\n",
      "3699/3699 [==============================] - 0s 53us/step - loss: 1126.0308 - mse: 1126.0308 - mae: 22.6072\n",
      "Epoch 15/60\n",
      "3699/3699 [==============================] - 0s 55us/step - loss: 1128.2272 - mse: 1128.2274 - mae: 22.6224\n",
      "Epoch 16/60\n",
      "3699/3699 [==============================] - 0s 53us/step - loss: 1130.2761 - mse: 1130.2762 - mae: 22.6418\n",
      "Epoch 17/60\n",
      "3699/3699 [==============================] - 0s 52us/step - loss: 1127.3064 - mse: 1127.3064 - mae: 22.6762\n",
      "Epoch 18/60\n",
      "3699/3699 [==============================] - 0s 53us/step - loss: 1125.5587 - mse: 1125.5585 - mae: 22.5764\n",
      "Epoch 19/60\n",
      "3699/3699 [==============================] - 0s 53us/step - loss: 1128.6590 - mse: 1128.6587 - mae: 22.6801\n",
      "Epoch 20/60\n",
      "3699/3699 [==============================] - 0s 54us/step - loss: 1126.4858 - mse: 1126.4858 - mae: 22.6019\n",
      "Epoch 21/60\n",
      "3699/3699 [==============================] - 0s 55us/step - loss: 1128.6160 - mse: 1128.6161 - mae: 22.6502\n",
      "Epoch 22/60\n",
      "3699/3699 [==============================] - 0s 54us/step - loss: 1126.7457 - mse: 1126.7458 - mae: 22.6690\n",
      "Epoch 23/60\n",
      "3699/3699 [==============================] - 0s 53us/step - loss: 1125.2587 - mse: 1125.2585 - mae: 22.6535\n",
      "Epoch 24/60\n",
      "3699/3699 [==============================] - 0s 54us/step - loss: 1125.7731 - mse: 1125.7731 - mae: 22.5775\n",
      "Epoch 25/60\n",
      "3699/3699 [==============================] - 0s 54us/step - loss: 1121.9897 - mse: 1121.9896 - mae: 22.5104\n",
      "Epoch 26/60\n",
      "3699/3699 [==============================] - 0s 53us/step - loss: 1126.8468 - mse: 1126.8467 - mae: 22.6487\n",
      "Epoch 27/60\n",
      "3699/3699 [==============================] - 0s 53us/step - loss: 1130.7033 - mse: 1130.7034 - mae: 22.7275\n",
      "Epoch 28/60\n",
      "3699/3699 [==============================] - 0s 53us/step - loss: 1126.7495 - mse: 1126.7498 - mae: 22.5775\n",
      "Epoch 29/60\n",
      "3699/3699 [==============================] - 0s 54us/step - loss: 1127.4728 - mse: 1127.4727 - mae: 22.6609\n",
      "Epoch 30/60\n",
      "3699/3699 [==============================] - 0s 53us/step - loss: 1126.9826 - mse: 1126.9827 - mae: 22.5236\n",
      "Epoch 31/60\n",
      "3699/3699 [==============================] - 0s 53us/step - loss: 1124.3705 - mse: 1124.3706 - mae: 22.5727\n",
      "Epoch 32/60\n",
      "3699/3699 [==============================] - ETA: 0s - loss: 1181.8916 - mse: 1181.8917 - mae: 22.92 - 0s 53us/step - loss: 1126.7345 - mse: 1126.7344 - mae: 22.5732\n",
      "Epoch 33/60\n",
      "3699/3699 [==============================] - 0s 53us/step - loss: 1125.4200 - mse: 1125.4202 - mae: 22.6726\n",
      "Epoch 34/60\n",
      "3699/3699 [==============================] - 0s 52us/step - loss: 1122.0115 - mse: 1122.0116 - mae: 22.5669\n",
      "Epoch 35/60\n",
      "3699/3699 [==============================] - 0s 53us/step - loss: 1123.0539 - mse: 1123.0538 - mae: 22.6354\n",
      "Epoch 36/60\n",
      "3699/3699 [==============================] - 0s 53us/step - loss: 1124.6009 - mse: 1124.6007 - mae: 22.5521\n",
      "Epoch 37/60\n",
      "3699/3699 [==============================] - 0s 53us/step - loss: 1127.0443 - mse: 1127.0443 - mae: 22.5624\n",
      "Epoch 38/60\n",
      "3699/3699 [==============================] - 0s 53us/step - loss: 1122.9382 - mse: 1122.9384 - mae: 22.5741\n",
      "Epoch 39/60\n",
      "3699/3699 [==============================] - 0s 53us/step - loss: 1128.0766 - mse: 1128.0763 - mae: 22.6560\n",
      "Epoch 40/60\n",
      "3699/3699 [==============================] - 0s 54us/step - loss: 1121.6423 - mse: 1121.6423 - mae: 22.5799\n",
      "Epoch 41/60\n",
      "3699/3699 [==============================] - 0s 54us/step - loss: 1119.4563 - mse: 1119.4559 - mae: 22.4903\n",
      "Epoch 42/60\n",
      "3699/3699 [==============================] - 0s 53us/step - loss: 1123.7835 - mse: 1123.7837 - mae: 22.6270\n",
      "Epoch 43/60\n",
      "3699/3699 [==============================] - 0s 54us/step - loss: 1126.1919 - mse: 1126.1917 - mae: 22.5490 0s - loss: 1470.6803 - mse: 1470.6801 - mae: 2\n",
      "Epoch 44/60\n",
      "3699/3699 [==============================] - 0s 54us/step - loss: 1124.8324 - mse: 1124.8324 - mae: 22.5977\n",
      "Epoch 45/60\n",
      "3699/3699 [==============================] - 0s 53us/step - loss: 1121.3634 - mse: 1121.3634 - mae: 22.5481\n",
      "Epoch 46/60\n",
      "3699/3699 [==============================] - 0s 54us/step - loss: 1124.7092 - mse: 1124.7094 - mae: 22.6276\n",
      "Epoch 47/60\n",
      "3699/3699 [==============================] - 0s 53us/step - loss: 1123.8731 - mse: 1123.8730 - mae: 22.5336\n",
      "Epoch 48/60\n",
      "3699/3699 [==============================] - 0s 52us/step - loss: 1121.4742 - mse: 1121.4741 - mae: 22.5338\n",
      "Epoch 49/60\n",
      "3699/3699 [==============================] - 0s 52us/step - loss: 1124.5658 - mse: 1124.5658 - mae: 22.5292\n",
      "Epoch 50/60\n",
      "3699/3699 [==============================] - 0s 53us/step - loss: 1120.3409 - mse: 1120.3412 - mae: 22.4785\n",
      "Epoch 51/60\n",
      "3699/3699 [==============================] - 0s 52us/step - loss: 1118.4257 - mse: 1118.4258 - mae: 22.4813\n",
      "Epoch 52/60\n",
      "3699/3699 [==============================] - 0s 52us/step - loss: 1119.4647 - mse: 1119.4646 - mae: 22.5586\n",
      "Epoch 53/60\n",
      "3699/3699 [==============================] - 0s 53us/step - loss: 1123.9487 - mse: 1123.9486 - mae: 22.5784\n",
      "Epoch 54/60\n",
      "3699/3699 [==============================] - 0s 53us/step - loss: 1121.9830 - mse: 1121.9829 - mae: 22.4958\n",
      "Epoch 55/60\n",
      "3699/3699 [==============================] - 0s 54us/step - loss: 1122.4819 - mse: 1122.4819 - mae: 22.5627\n",
      "Epoch 56/60\n",
      "3699/3699 [==============================] - 0s 54us/step - loss: 1122.7227 - mse: 1122.7228 - mae: 22.6065\n",
      "Epoch 57/60\n",
      "3699/3699 [==============================] - 0s 54us/step - loss: 1123.6708 - mse: 1123.6708 - mae: 22.5402\n",
      "Epoch 58/60\n",
      "3699/3699 [==============================] - 0s 54us/step - loss: 1119.9710 - mse: 1119.9712 - mae: 22.4635\n",
      "Epoch 59/60\n",
      "3699/3699 [==============================] - 0s 53us/step - loss: 1122.2430 - mse: 1122.2429 - mae: 22.5884\n",
      "Epoch 60/60\n",
      "3699/3699 [==============================] - 0s 53us/step - loss: 1120.3198 - mse: 1120.3197 - mae: 22.5430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=40)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "5548/5548 [==============================] - 1s 224us/step - loss: 3962.1714 - mse: 3962.1709 - mae: 41.5247\n",
      "Epoch 2/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1717.1934 - mse: 1717.1937 - mae: 25.2393\n",
      "Epoch 3/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1708.4010 - mse: 1708.4010 - mae: 25.2463\n",
      "Epoch 4/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1706.4492 - mse: 1706.4493 - mae: 25.1905\n",
      "Epoch 5/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1703.1908 - mse: 1703.1909 - mae: 25.1370\n",
      "Epoch 6/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1697.5003 - mse: 1697.5001 - mae: 25.0364\n",
      "Epoch 7/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1698.0452 - mse: 1698.0458 - mae: 25.2418\n",
      "Epoch 8/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1692.4848 - mse: 1692.4850 - mae: 25.1184\n",
      "Epoch 9/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1691.8939 - mse: 1691.8945 - mae: 25.0819\n",
      "Epoch 10/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1690.4098 - mse: 1690.4092 - mae: 24.9749\n",
      "Epoch 11/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1687.4353 - mse: 1687.4354 - mae: 25.0178\n",
      "Epoch 12/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1684.9466 - mse: 1684.9470 - mae: 25.0179\n",
      "Epoch 13/60\n",
      "5548/5548 [==============================] - 0s 54us/step - loss: 1685.3255 - mse: 1685.3259 - mae: 25.0250\n",
      "Epoch 14/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1685.7273 - mse: 1685.7269 - mae: 25.0956\n",
      "Epoch 15/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1686.3003 - mse: 1686.3010 - mae: 25.0678\n",
      "Epoch 16/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1679.0077 - mse: 1679.0077 - mae: 25.0337\n",
      "Epoch 17/60\n",
      "5548/5548 [==============================] - 0s 52us/step - loss: 1678.2898 - mse: 1678.2904 - mae: 24.9945\n",
      "Epoch 18/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1686.5190 - mse: 1686.5193 - mae: 24.9995\n",
      "Epoch 19/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1679.1735 - mse: 1679.1736 - mae: 24.9085\n",
      "Epoch 20/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1684.5250 - mse: 1684.5254 - mae: 24.9944\n",
      "Epoch 21/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1684.1489 - mse: 1684.1489 - mae: 25.0291\n",
      "Epoch 22/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1675.1379 - mse: 1675.1379 - mae: 24.9948\n",
      "Epoch 23/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1679.4293 - mse: 1679.4296 - mae: 24.9584\n",
      "Epoch 24/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1679.4370 - mse: 1679.4373 - mae: 25.0118\n",
      "Epoch 25/60\n",
      "5548/5548 [==============================] - 0s 52us/step - loss: 1673.6482 - mse: 1673.6483 - mae: 25.0070\n",
      "Epoch 26/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1679.2502 - mse: 1679.2504 - mae: 24.9664\n",
      "Epoch 27/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1677.2246 - mse: 1677.2246 - mae: 24.9838\n",
      "Epoch 28/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1677.0772 - mse: 1677.0769 - mae: 24.9457\n",
      "Epoch 29/60\n",
      "5548/5548 [==============================] - 0s 52us/step - loss: 1675.8882 - mse: 1675.8881 - mae: 24.9317\n",
      "Epoch 30/60\n",
      "5548/5548 [==============================] - 0s 52us/step - loss: 1678.9638 - mse: 1678.9636 - mae: 25.0282\n",
      "Epoch 31/60\n",
      "5548/5548 [==============================] - 0s 52us/step - loss: 1677.1124 - mse: 1677.1121 - mae: 24.9980\n",
      "Epoch 32/60\n",
      "5548/5548 [==============================] - 0s 52us/step - loss: 1675.8481 - mse: 1675.8480 - mae: 24.9283\n",
      "Epoch 33/60\n",
      "5548/5548 [==============================] - 0s 52us/step - loss: 1678.2327 - mse: 1678.2327 - mae: 24.9975\n",
      "Epoch 34/60\n",
      "5548/5548 [==============================] - 0s 52us/step - loss: 1677.5588 - mse: 1677.5586 - mae: 24.8990\n",
      "Epoch 35/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1676.6058 - mse: 1676.6058 - mae: 24.9123\n",
      "Epoch 36/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1673.6293 - mse: 1673.6293 - mae: 24.9137\n",
      "Epoch 37/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1675.7821 - mse: 1675.7822 - mae: 24.9196\n",
      "Epoch 38/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1676.4517 - mse: 1676.4517 - mae: 24.9587\n",
      "Epoch 39/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1672.9591 - mse: 1672.9591 - mae: 24.9734\n",
      "Epoch 40/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1673.7583 - mse: 1673.7583 - mae: 24.8491\n",
      "Epoch 41/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1673.8335 - mse: 1673.8336 - mae: 24.9409\n",
      "Epoch 42/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1672.0354 - mse: 1672.0347 - mae: 24.9348\n",
      "Epoch 43/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1672.3351 - mse: 1672.3348 - mae: 24.8967\n",
      "Epoch 44/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1674.5383 - mse: 1674.5385 - mae: 24.8799\n",
      "Epoch 45/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1673.0769 - mse: 1673.0768 - mae: 24.9360\n",
      "Epoch 46/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1671.7725 - mse: 1671.7726 - mae: 24.8184\n",
      "Epoch 47/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1670.8335 - mse: 1670.8336 - mae: 24.8555\n",
      "Epoch 48/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1673.8168 - mse: 1673.8165 - mae: 24.9658\n",
      "Epoch 49/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1672.7376 - mse: 1672.7378 - mae: 24.9105\n",
      "Epoch 50/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1667.4964 - mse: 1667.4967 - mae: 24.9160\n",
      "Epoch 51/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1669.2382 - mse: 1669.2378 - mae: 24.8712\n",
      "Epoch 52/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1670.1326 - mse: 1670.1328 - mae: 24.8267\n",
      "Epoch 53/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1667.8269 - mse: 1667.8273 - mae: 24.8464\n",
      "Epoch 54/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1669.8218 - mse: 1669.8219 - mae: 24.9677\n",
      "Epoch 55/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1668.0850 - mse: 1668.0852 - mae: 24.8850\n",
      "Epoch 56/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1667.7447 - mse: 1667.7450 - mae: 24.9343\n",
      "Epoch 57/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1664.9181 - mse: 1664.9182 - mae: 24.8598\n",
      "Epoch 58/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1665.6944 - mse: 1665.6943 - mae: 24.8378\n",
      "Epoch 59/60\n",
      "5548/5548 [==============================] - 0s 52us/step - loss: 1665.2865 - mse: 1665.2867 - mae: 24.8696\n",
      "Epoch 60/60\n",
      "5548/5548 [==============================] - 0s 52us/step - loss: 1670.2951 - mse: 1670.2953 - mae: 24.8767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=40)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "7397/7397 [==============================] - 1s 191us/step - loss: 3300.2270 - mse: 3300.2258 - mae: 37.6871\n",
      "Epoch 2/60\n",
      "7397/7397 [==============================] - 0s 53us/step - loss: 1654.9439 - mse: 1654.9441 - mae: 25.5746\n",
      "Epoch 3/60\n",
      "7397/7397 [==============================] - 0s 53us/step - loss: 1649.5518 - mse: 1649.5516 - mae: 25.5564\n",
      "Epoch 4/60\n",
      "7397/7397 [==============================] - 0s 53us/step - loss: 1643.6902 - mse: 1643.6902 - mae: 25.4941\n",
      "Epoch 5/60\n",
      "7397/7397 [==============================] - 0s 53us/step - loss: 1639.7708 - mse: 1639.7711 - mae: 25.4351\n",
      "Epoch 6/60\n",
      "7397/7397 [==============================] - 0s 53us/step - loss: 1632.6832 - mse: 1632.6838 - mae: 25.4457\n",
      "Epoch 7/60\n",
      "7397/7397 [==============================] - 0s 53us/step - loss: 1634.7288 - mse: 1634.7284 - mae: 25.4245\n",
      "Epoch 8/60\n",
      "7397/7397 [==============================] - 0s 53us/step - loss: 1628.1342 - mse: 1628.1338 - mae: 25.4678\n",
      "Epoch 9/60\n",
      "7397/7397 [==============================] - 0s 53us/step - loss: 1626.7824 - mse: 1626.7827 - mae: 25.3929\n",
      "Epoch 10/60\n",
      "7397/7397 [==============================] - 0s 53us/step - loss: 1623.5226 - mse: 1623.5229 - mae: 25.3653\n",
      "Epoch 11/60\n",
      "7397/7397 [==============================] - 0s 53us/step - loss: 1625.8107 - mse: 1625.8109 - mae: 25.3892\n",
      "Epoch 12/60\n",
      "7397/7397 [==============================] - 0s 53us/step - loss: 1625.1575 - mse: 1625.1576 - mae: 25.4360\n",
      "Epoch 13/60\n",
      "7397/7397 [==============================] - 0s 53us/step - loss: 1622.8649 - mse: 1622.8652 - mae: 25.3382\n",
      "Epoch 14/60\n",
      "7397/7397 [==============================] - 0s 53us/step - loss: 1624.5283 - mse: 1624.5283 - mae: 25.4045\n",
      "Epoch 15/60\n",
      "7397/7397 [==============================] - 0s 53us/step - loss: 1618.9924 - mse: 1618.9921 - mae: 25.4167\n",
      "Epoch 16/60\n",
      "7397/7397 [==============================] - 0s 53us/step - loss: 1627.6095 - mse: 1627.6100 - mae: 25.4237\n",
      "Epoch 17/60\n",
      "7397/7397 [==============================] - 0s 54us/step - loss: 1625.6554 - mse: 1625.6559 - mae: 25.4226\n",
      "Epoch 18/60\n",
      "7397/7397 [==============================] - 0s 53us/step - loss: 1621.3361 - mse: 1621.3358 - mae: 25.4367\n",
      "Epoch 19/60\n",
      "7397/7397 [==============================] - 0s 54us/step - loss: 1621.2201 - mse: 1621.2203 - mae: 25.3347\n",
      "Epoch 20/60\n",
      "7397/7397 [==============================] - 0s 53us/step - loss: 1619.9315 - mse: 1619.9313 - mae: 25.4491\n",
      "Epoch 21/60\n",
      "7397/7397 [==============================] - 0s 54us/step - loss: 1623.0835 - mse: 1623.0834 - mae: 25.3641\n",
      "Epoch 22/60\n",
      "7397/7397 [==============================] - 0s 54us/step - loss: 1623.1038 - mse: 1623.1033 - mae: 25.3784\n",
      "Epoch 23/60\n",
      "7397/7397 [==============================] - 0s 54us/step - loss: 1619.6156 - mse: 1619.6152 - mae: 25.3501\n",
      "Epoch 24/60\n",
      "7397/7397 [==============================] - 0s 54us/step - loss: 1621.5249 - mse: 1621.5247 - mae: 25.4270\n",
      "Epoch 25/60\n",
      "7397/7397 [==============================] - 0s 54us/step - loss: 1624.4840 - mse: 1624.4844 - mae: 25.3503\n",
      "Epoch 26/60\n",
      "7397/7397 [==============================] - 0s 54us/step - loss: 1618.7060 - mse: 1618.7058 - mae: 25.3475\n",
      "Epoch 27/60\n",
      "7397/7397 [==============================] - 0s 54us/step - loss: 1614.5965 - mse: 1614.5966 - mae: 25.3279\n",
      "Epoch 28/60\n",
      "7397/7397 [==============================] - 0s 54us/step - loss: 1618.3101 - mse: 1618.3097 - mae: 25.3436\n",
      "Epoch 29/60\n",
      "7397/7397 [==============================] - 0s 56us/step - loss: 1617.9633 - mse: 1617.9634 - mae: 25.3467\n",
      "Epoch 30/60\n",
      "7397/7397 [==============================] - 0s 54us/step - loss: 1612.9612 - mse: 1612.9622 - mae: 25.3246\n",
      "Epoch 31/60\n",
      "7397/7397 [==============================] - 0s 53us/step - loss: 1613.5151 - mse: 1613.5153 - mae: 25.3260\n",
      "Epoch 32/60\n",
      "7397/7397 [==============================] - 0s 53us/step - loss: 1616.6860 - mse: 1616.6855 - mae: 25.3032\n",
      "Epoch 33/60\n",
      "7397/7397 [==============================] - 0s 54us/step - loss: 1612.5017 - mse: 1612.5011 - mae: 25.2793\n",
      "Epoch 34/60\n",
      "7397/7397 [==============================] - 0s 54us/step - loss: 1607.6501 - mse: 1607.6511 - mae: 25.1563\n",
      "Epoch 35/60\n",
      "7397/7397 [==============================] - 0s 54us/step - loss: 1610.3740 - mse: 1610.3739 - mae: 25.2837\n",
      "Epoch 36/60\n",
      "7397/7397 [==============================] - 0s 54us/step - loss: 1609.1904 - mse: 1609.1904 - mae: 25.2793\n",
      "Epoch 37/60\n",
      "7397/7397 [==============================] - 0s 54us/step - loss: 1605.5410 - mse: 1605.5410 - mae: 25.2741\n",
      "Epoch 38/60\n",
      "7397/7397 [==============================] - 0s 54us/step - loss: 1607.2789 - mse: 1607.2793 - mae: 25.2942\n",
      "Epoch 39/60\n",
      "7397/7397 [==============================] - 0s 53us/step - loss: 1606.9434 - mse: 1606.9436 - mae: 25.1924\n",
      "Epoch 40/60\n",
      "7397/7397 [==============================] - 0s 53us/step - loss: 1605.5223 - mse: 1605.5220 - mae: 25.2397\n",
      "Epoch 41/60\n",
      "7397/7397 [==============================] - 0s 53us/step - loss: 1609.1885 - mse: 1609.1888 - mae: 25.2914\n",
      "Epoch 42/60\n",
      "7397/7397 [==============================] - 0s 53us/step - loss: 1604.4332 - mse: 1604.4330 - mae: 25.2138\n",
      "Epoch 43/60\n",
      "7397/7397 [==============================] - 0s 54us/step - loss: 1607.9694 - mse: 1607.9696 - mae: 25.2653\n",
      "Epoch 44/60\n",
      "7397/7397 [==============================] - 0s 53us/step - loss: 1604.8947 - mse: 1604.8948 - mae: 25.1952\n",
      "Epoch 45/60\n",
      "7397/7397 [==============================] - 0s 54us/step - loss: 1602.3266 - mse: 1602.3270 - mae: 25.2360\n",
      "Epoch 46/60\n",
      "7397/7397 [==============================] - 0s 53us/step - loss: 1604.7419 - mse: 1604.7417 - mae: 25.1967\n",
      "Epoch 47/60\n",
      "7397/7397 [==============================] - 0s 53us/step - loss: 1603.9486 - mse: 1603.9486 - mae: 25.1704\n",
      "Epoch 48/60\n",
      "7397/7397 [==============================] - 0s 53us/step - loss: 1601.5794 - mse: 1601.5796 - mae: 25.2422\n",
      "Epoch 49/60\n",
      "7397/7397 [==============================] - 0s 53us/step - loss: 1600.3439 - mse: 1600.3435 - mae: 25.1115\n",
      "Epoch 50/60\n",
      "7397/7397 [==============================] - 0s 53us/step - loss: 1598.9888 - mse: 1598.9885 - mae: 25.1373\n",
      "Epoch 51/60\n",
      "7397/7397 [==============================] - 0s 53us/step - loss: 1599.4508 - mse: 1599.4507 - mae: 25.1223\n",
      "Epoch 52/60\n",
      "7397/7397 [==============================] - 0s 53us/step - loss: 1597.1102 - mse: 1597.1107 - mae: 25.1054\n",
      "Epoch 53/60\n",
      "7397/7397 [==============================] - 0s 53us/step - loss: 1596.0361 - mse: 1596.0356 - mae: 25.0699\n",
      "Epoch 54/60\n",
      "7397/7397 [==============================] - 0s 53us/step - loss: 1598.6914 - mse: 1598.6913 - mae: 25.1755\n",
      "Epoch 55/60\n",
      "7397/7397 [==============================] - 0s 53us/step - loss: 1600.3018 - mse: 1600.3015 - mae: 25.0866\n",
      "Epoch 56/60\n",
      "7397/7397 [==============================] - 0s 53us/step - loss: 1599.8412 - mse: 1599.8413 - mae: 25.0602\n",
      "Epoch 57/60\n",
      "7397/7397 [==============================] - 0s 53us/step - loss: 1594.6637 - mse: 1594.6635 - mae: 25.0566\n",
      "Epoch 58/60\n",
      "7397/7397 [==============================] - 0s 54us/step - loss: 1594.1786 - mse: 1594.1785 - mae: 25.0521\n",
      "Epoch 59/60\n",
      "7397/7397 [==============================] - 0s 54us/step - loss: 1593.8131 - mse: 1593.8129 - mae: 25.0368\n",
      "Epoch 60/60\n",
      "7397/7397 [==============================] - 0s 53us/step - loss: 1595.3868 - mse: 1595.3866 - mae: 25.0281\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Cannot clone object <keras.wrappers.scikit_learn.KerasRegressor object at 0x7f3d4241c850>, as the constructor either does not set or modifies parameter optimizer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-d04b0a426b6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mrnd_search_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python-cpu/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python-cpu/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0;31m# of the params are estimators as well.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m             self.best_estimator_ = clone(clone(base_estimator).set_params(\n\u001b[0;32m--> 762\u001b[0;31m                 **self.best_params_))\n\u001b[0m\u001b[1;32m    763\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python-cpu/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python-cpu/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     96\u001b[0m             raise RuntimeError('Cannot clone object %s, as the constructor '\n\u001b[1;32m     97\u001b[0m                                \u001b[0;34m'either does not set or modifies parameter %s'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m                                (estimator, name))\n\u001b[0m\u001b[1;32m     99\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Cannot clone object <keras.wrappers.scikit_learn.KerasRegressor object at 0x7f3d4241c850>, as the constructor either does not set or modifies parameter optimizer"
     ]
    }
   ],
   "source": [
    "regressor = KerasRegressor(build_fn = regressor_tunning)\n",
    "\n",
    "# Dictionary to include the parameters\n",
    "parameters = {'n_hidden': [1, 2, 3, 4, 6],\n",
    "              'n_neurons': np.arange(10,100, 5),\n",
    "              'bias_initializer':[initializers.Zeros(),\n",
    "                                 initializers.Ones()],\n",
    "              'kernel_initializer': ['glorot_uniform',\n",
    "                                     'he_normal',\n",
    "                                     'he_uniform'],\n",
    "              'optimizer': [keras.optimizers.RMSprop(), \n",
    "                            keras.optimizers.Adam(), \n",
    "                            keras.optimizers.Nadam(),\n",
    "                            keras.optimizers.Adamax()]\n",
    "               }\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits = 4)\n",
    "\n",
    "# add some early stopping\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='mse', patience = 15)\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(estimator = regressor,\n",
    "                                   param_distributions = parameters,\n",
    "                                   scoring = 'neg_mean_squared_error',\n",
    "                                   n_iter = 10,\n",
    "                                   n_jobs = -1,\n",
    "                                   cv = tscv)\n",
    "\n",
    "# checkpoints:\n",
    "# early_stopping_cb = keras.callbacks.EarlyStopping(patience = 10, restore_best_weights = True)\n",
    "# checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\")\n",
    "\n",
    "rnd_search_cv.fit(X_train, y_train, batch_size = 32, epochs = 60, callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the best parameters are:{'optimizer': <keras.optimizers.Nadam object at 0x7f3d74f75310>, 'n_neurons': 80, 'n_hidden': 2, 'kernel_initializer': 'he_normal', 'bias_initializer': <keras.initializers.Ones object at 0x7f3d4c4e8650>}\n",
      "the best score is:-2072.7588348385707\n"
     ]
    }
   ],
   "source": [
    "best_params_1 = rnd_search_cv.best_params_\n",
    "best_score_1 = rnd_search_cv.best_score_\n",
    "#results = rnd_search_cv.cv_results_\n",
    "\n",
    "print(\"the best parameters are:{}\".format(best_params_1))\n",
    "print(\"the best score is:{}\".format(best_score_1))\n",
    "#print(\"results:\".format(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
