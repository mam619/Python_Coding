{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Parameter Tuning\n",
    "    \n",
    "    Look for better optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\maria\\anaconda3\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from pandas) (1.18.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from python-dateutil>=2.6.1->pandas) (1.14.0)\n",
      "Requirement already satisfied: sklearn in c:\\users\\maria\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\maria\\anaconda3\\lib\\site-packages (from sklearn) (0.22.1)\n",
      "Requirement already satisfied: numpy>=1.11.0 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.18.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (0.14.1)\n",
      "Requirement already satisfied: scipy>=0.17.0 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.4.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install sklearn\n",
    "\n",
    "import pandas as pd;\n",
    "import numpy as np;\n",
    "import sklearn\n",
    "\n",
    "# parameters\n",
    "steps = 96\n",
    "n_hidden = 1\n",
    "units = 150\n",
    "batch_size = 96\n",
    "\n",
    "# months to evaluate model on\n",
    "date = 2018090000\n",
    "\n",
    "# for later use\n",
    "features_num = 15\n",
    "\n",
    "# lists to append results\n",
    "mae_gen = []\n",
    "mae_nor = []\n",
    "mae_spi = []\n",
    "rmse_gen = []\n",
    "rmse_nor = []\n",
    "rmse_spi = []\n",
    "y_pred_list = []\n",
    "time_count = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data; set X and y; fill nan values and split in test and training  data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "data = pd.read_csv('Data_set_1_smaller.csv', index_col = 0)\n",
    "\n",
    "# 2018 data\n",
    "data = data.loc[data.index > date, :]\n",
    "\n",
    "# reset index\n",
    "data.reset_index(inplace = True)\n",
    "data.drop('index', axis = 1, inplace = True)\n",
    "\n",
    "# fill nan values\n",
    "data.fillna(method = 'ffill', inplace = True)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# divide data into train and test \n",
    "data_train, data_test = train_test_split(\n",
    "         data, test_size = 0.15, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply feature scaling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# data scaling  (including offer (y))\n",
    "sc_X = MinMaxScaler()\n",
    "data_train = sc_X.fit_transform(data_train)\n",
    "data_test = sc_X.transform(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the Keras libraries and packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LeakyReLU\n",
    "from keras import initializers\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Need to process data with spike occurences the same way as features and offers:\n",
    "(Required to evaluate predictions in both normal regions and spike regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data for shaded area\n",
    "data = pd.read_csv('Spike_binary_1std.csv', index_col = 0)\n",
    "\n",
    "# set predictive window according with tuning best results\n",
    "data = data.loc[data.index > date, :]\n",
    "\n",
    "# make sure shaded area will correspond to values outputed by LSTM\n",
    "data.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# fill_nan is already made - so lets split data into test and train\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# divide data into train and test \n",
    "shade_train, shade_test = train_test_split(\n",
    "         data, test_size = 0.15, shuffle = False)\n",
    "\n",
    "# reset index of testing data\n",
    "shade_test.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# function to split data into correct shape for RNN\n",
    "def split_data(shade_test, steps):\n",
    "    y_spike_occ = list()\n",
    "    upper_lim = list()\n",
    "    lower_lim = list()\n",
    "    for i in range(steps, len(shade_test.index)):\n",
    "        y_spike_occ.append(shade_test['spike_occurance'][i])\n",
    "        upper_lim.append(shade_test['spike_upperlim'][i])\n",
    "        lower_lim.append(shade_test['spike_lowerlim'][i])\n",
    "    return np.array(y_spike_occ), np.array(upper_lim), np.array(lower_lim)\n",
    "\n",
    "# function to cut data set so it can be divisible by the batch_size\n",
    "def cut_data(data, batch_size):\n",
    "     # see if it is divisivel\n",
    "    condition = data.shape[0] % batch_size\n",
    "    if condition == 0:\n",
    "        return data\n",
    "    else:\n",
    "        return data[: -condition]\n",
    "\n",
    "# shape y_spike_occ for the right size to compare results in normal and spike regions\n",
    "y_spike_occ, spike_upperlim, spike_lowerlim = split_data(shade_test, steps)\n",
    "y_spike_occ = cut_data(y_spike_occ, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare of data according to LSTM needs,  create regressor & tune:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/180\n",
      "65/65 [==============================] - 32s 491ms/step - loss: 0.3554 - mse: 0.3554 - mae: 0.3783 - val_loss: 0.0508 - val_mse: 0.0508 - val_mae: 0.2232\n",
      "Epoch 2/180\n",
      "65/65 [==============================] - 31s 472ms/step - loss: 0.0693 - mse: 0.0693 - mae: 0.2092 - val_loss: 0.0322 - val_mse: 0.0322 - val_mae: 0.1763\n",
      "Epoch 3/180\n",
      "65/65 [==============================] - 32s 494ms/step - loss: 0.0240 - mse: 0.0240 - mae: 0.1226 - val_loss: 0.0118 - val_mse: 0.0118 - val_mae: 0.1032\n",
      "Epoch 4/180\n",
      "65/65 [==============================] - 32s 496ms/step - loss: 0.0085 - mse: 0.0085 - mae: 0.0721 - val_loss: 0.0043 - val_mse: 0.0043 - val_mae: 0.0618\n",
      "Epoch 5/180\n",
      "65/65 [==============================] - 32s 487ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0457 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0164\n",
      "Epoch 6/180\n",
      "65/65 [==============================] - 30s 464ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0326 - val_loss: 0.0015 - val_mse: 0.0015 - val_mae: 0.0216\n",
      "Epoch 7/180\n",
      "65/65 [==============================] - 27s 421ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0254 - val_loss: 0.0014 - val_mse: 0.0014 - val_mae: 0.0193\n",
      "Epoch 8/180\n",
      "65/65 [==============================] - 27s 418ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0217 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0169\n",
      "Epoch 9/180\n",
      "65/65 [==============================] - 27s 418ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0202 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0167\n",
      "Epoch 10/180\n",
      "65/65 [==============================] - 26s 403ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0194 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0164\n",
      "Epoch 11/180\n",
      "65/65 [==============================] - 28s 435ms/step - loss: 9.8874e-04 - mse: 9.8874e-04 - mae: 0.0189 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0161\n",
      "Epoch 12/180\n",
      "65/65 [==============================] - 28s 431ms/step - loss: 9.7189e-04 - mse: 9.7189e-04 - mae: 0.0186 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0164\n",
      "Epoch 13/180\n",
      "65/65 [==============================] - 27s 414ms/step - loss: 9.5189e-04 - mse: 9.5189e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0165\n",
      "Epoch 14/180\n",
      "65/65 [==============================] - 28s 434ms/step - loss: 9.3994e-04 - mse: 9.3994e-04 - mae: 0.0181 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0170\n",
      "Epoch 15/180\n",
      "65/65 [==============================] - 29s 444ms/step - loss: 9.3850e-04 - mse: 9.3850e-04 - mae: 0.0181 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0172\n",
      "Epoch 16/180\n",
      "65/65 [==============================] - 31s 474ms/step - loss: 9.2980e-04 - mse: 9.2980e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0175\n",
      "Epoch 17/180\n",
      "65/65 [==============================] - 28s 423ms/step - loss: 9.3199e-04 - mse: 9.3199e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0173\n",
      "Epoch 18/180\n",
      "65/65 [==============================] - 29s 444ms/step - loss: 9.2569e-04 - mse: 9.2569e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0176\n",
      "Epoch 19/180\n",
      "65/65 [==============================] - 29s 446ms/step - loss: 9.2017e-04 - mse: 9.2017e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0175\n",
      "Epoch 20/180\n",
      "65/65 [==============================] - 32s 498ms/step - loss: 9.1472e-04 - mse: 9.1472e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0179\n",
      "Epoch 21/180\n",
      "65/65 [==============================] - 32s 494ms/step - loss: 9.1602e-04 - mse: 9.1602e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0177\n",
      "Epoch 22/180\n",
      "65/65 [==============================] - 31s 481ms/step - loss: 9.1486e-04 - mse: 9.1486e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0180\n",
      "Epoch 23/180\n",
      "65/65 [==============================] - 31s 472ms/step - loss: 9.1125e-04 - mse: 9.1125e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0180\n",
      "Epoch 24/180\n",
      "65/65 [==============================] - 28s 424ms/step - loss: 9.1190e-04 - mse: 9.1190e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0180\n",
      "Epoch 25/180\n",
      "65/65 [==============================] - 33s 507ms/step - loss: 9.1361e-04 - mse: 9.1361e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0182\n",
      "Epoch 26/180\n",
      "65/65 [==============================] - 30s 456ms/step - loss: 9.1082e-04 - mse: 9.1082e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0184\n",
      "Epoch 27/180\n",
      "65/65 [==============================] - 29s 444ms/step - loss: 9.1173e-04 - mse: 9.1173e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 28/180\n",
      "65/65 [==============================] - 30s 463ms/step - loss: 9.1108e-04 - mse: 9.1108e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0184\n",
      "Epoch 29/180\n",
      "65/65 [==============================] - 35s 532ms/step - loss: 9.1013e-04 - mse: 9.1013e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 30/180\n",
      "65/65 [==============================] - 27s 423ms/step - loss: 9.0939e-04 - mse: 9.0939e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0184\n",
      "Epoch 31/180\n",
      "65/65 [==============================] - 29s 442ms/step - loss: 9.1033e-04 - mse: 9.1033e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 32/180\n",
      "65/65 [==============================] - 34s 524ms/step - loss: 9.1095e-04 - mse: 9.1095e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0188\n",
      "Epoch 33/180\n",
      "65/65 [==============================] - 36s 557ms/step - loss: 9.1097e-04 - mse: 9.1097e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0187\n",
      "Epoch 34/180\n",
      "65/65 [==============================] - 29s 443ms/step - loss: 9.1004e-04 - mse: 9.1004e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 35/180\n",
      "65/65 [==============================] - 30s 462ms/step - loss: 9.1008e-04 - mse: 9.1008e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 36/180\n",
      "65/65 [==============================] - 28s 426ms/step - loss: 9.0975e-04 - mse: 9.0975e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0187\n",
      "Epoch 37/180\n",
      "65/65 [==============================] - 35s 545ms/step - loss: 9.0844e-04 - mse: 9.0844e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 38/180\n",
      "65/65 [==============================] - 32s 494ms/step - loss: 9.0903e-04 - mse: 9.0903e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 39/180\n",
      "65/65 [==============================] - 32s 487ms/step - loss: 9.0950e-04 - mse: 9.0950e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 40/180\n",
      "65/65 [==============================] - 27s 418ms/step - loss: 9.0864e-04 - mse: 9.0864e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 41/180\n",
      "65/65 [==============================] - 27s 411ms/step - loss: 9.1002e-04 - mse: 9.1002e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0187\n",
      "Epoch 42/180\n",
      "65/65 [==============================] - 25s 383ms/step - loss: 9.0857e-04 - mse: 9.0857e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0187\n",
      "Epoch 43/180\n",
      "65/65 [==============================] - 25s 392ms/step - loss: 9.0714e-04 - mse: 9.0714e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 44/180\n",
      "65/65 [==============================] - 26s 393ms/step - loss: 9.0867e-04 - mse: 9.0867e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 45/180\n",
      "65/65 [==============================] - 27s 412ms/step - loss: 9.0939e-04 - mse: 9.0939e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 46/180\n",
      "65/65 [==============================] - 27s 411ms/step - loss: 9.0491e-04 - mse: 9.0491e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0183\n",
      "Epoch 47/180\n",
      "65/65 [==============================] - 27s 409ms/step - loss: 9.0681e-04 - mse: 9.0681e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 48/180\n",
      "65/65 [==============================] - 26s 394ms/step - loss: 9.1067e-04 - mse: 9.1067e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 49/180\n",
      "65/65 [==============================] - 26s 398ms/step - loss: 9.0873e-04 - mse: 9.0873e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 50/180\n",
      "65/65 [==============================] - 27s 415ms/step - loss: 9.0745e-04 - mse: 9.0745e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 51/180\n",
      "65/65 [==============================] - 26s 393ms/step - loss: 9.0430e-04 - mse: 9.0430e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0184\n",
      "Epoch 52/180\n",
      "65/65 [==============================] - 27s 409ms/step - loss: 9.0560e-04 - mse: 9.0560e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0183\n",
      "Epoch 53/180\n",
      "65/65 [==============================] - 26s 400ms/step - loss: 9.0807e-04 - mse: 9.0807e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 54/180\n",
      "65/65 [==============================] - 27s 408ms/step - loss: 9.0740e-04 - mse: 9.0740e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0184\n",
      "Epoch 55/180\n",
      "65/65 [==============================] - 25s 388ms/step - loss: 9.0949e-04 - mse: 9.0949e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 56/180\n",
      "65/65 [==============================] - 25s 384ms/step - loss: 9.0870e-04 - mse: 9.0870e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 57/180\n",
      "65/65 [==============================] - 26s 395ms/step - loss: 9.0769e-04 - mse: 9.0769e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0187\n",
      "Epoch 58/180\n",
      "65/65 [==============================] - 26s 398ms/step - loss: 9.0754e-04 - mse: 9.0754e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0183\n",
      "Epoch 59/180\n",
      "65/65 [==============================] - 27s 410ms/step - loss: 9.0661e-04 - mse: 9.0661e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0184\n",
      "Epoch 60/180\n",
      "65/65 [==============================] - 27s 410ms/step - loss: 9.0752e-04 - mse: 9.0752e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0182\n",
      "Epoch 61/180\n",
      "65/65 [==============================] - 28s 425ms/step - loss: 9.0620e-04 - mse: 9.0620e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 62/180\n",
      "65/65 [==============================] - 28s 426ms/step - loss: 9.0674e-04 - mse: 9.0674e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0184\n",
      "Epoch 63/180\n",
      "65/65 [==============================] - 28s 435ms/step - loss: 9.0525e-04 - mse: 9.0525e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0183\n",
      "Epoch 64/180\n",
      "65/65 [==============================] - 27s 421ms/step - loss: 9.0672e-04 - mse: 9.0672e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0187\n",
      "Epoch 65/180\n",
      "65/65 [==============================] - 29s 443ms/step - loss: 9.0494e-04 - mse: 9.0494e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0182\n",
      "Epoch 66/180\n",
      "65/65 [==============================] - 27s 420ms/step - loss: 9.0733e-04 - mse: 9.0733e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0183\n",
      "Epoch 67/180\n",
      "65/65 [==============================] - 29s 446ms/step - loss: 9.0167e-04 - mse: 9.0167e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0182\n",
      "Epoch 68/180\n",
      "65/65 [==============================] - 27s 415ms/step - loss: 9.0467e-04 - mse: 9.0467e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0180\n",
      "Epoch 69/180\n",
      "65/65 [==============================] - 31s 475ms/step - loss: 9.0103e-04 - mse: 9.0103e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0182\n",
      "Epoch 70/180\n",
      "65/65 [==============================] - 31s 480ms/step - loss: 9.0712e-04 - mse: 9.0712e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0182\n",
      "Epoch 71/180\n",
      "65/65 [==============================] - 30s 461ms/step - loss: 9.0529e-04 - mse: 9.0529e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0184\n",
      "Epoch 72/180\n",
      "65/65 [==============================] - 32s 488ms/step - loss: 9.0442e-04 - mse: 9.0442e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0182\n",
      "Epoch 73/180\n",
      "65/65 [==============================] - 35s 533ms/step - loss: 9.0170e-04 - mse: 9.0170e-04 - mae: 0.0175 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0182\n",
      "Epoch 74/180\n",
      "65/65 [==============================] - 31s 474ms/step - loss: 9.0116e-04 - mse: 9.0116e-04 - mae: 0.0175 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0181\n",
      "Epoch 75/180\n",
      "65/65 [==============================] - 31s 470ms/step - loss: 9.0503e-04 - mse: 9.0503e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0183\n",
      "Epoch 76/180\n",
      "65/65 [==============================] - 28s 434ms/step - loss: 9.0522e-04 - mse: 9.0522e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0179\n",
      "Epoch 77/180\n",
      "65/65 [==============================] - 28s 427ms/step - loss: 9.0145e-04 - mse: 9.0145e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0181\n",
      "Epoch 78/180\n",
      "65/65 [==============================] - 27s 420ms/step - loss: 9.0150e-04 - mse: 9.0150e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0180\n",
      "Epoch 79/180\n",
      "65/65 [==============================] - 30s 457ms/step - loss: 9.0190e-04 - mse: 9.0190e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0180\n",
      "Epoch 80/180\n",
      "65/65 [==============================] - 27s 415ms/step - loss: 9.0071e-04 - mse: 9.0071e-04 - mae: 0.0175 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0183\n",
      "Epoch 81/180\n",
      "65/65 [==============================] - 28s 428ms/step - loss: 9.0139e-04 - mse: 9.0139e-04 - mae: 0.0175 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0182\n",
      "Epoch 82/180\n",
      "65/65 [==============================] - 27s 420ms/step - loss: 9.0025e-04 - mse: 9.0025e-04 - mae: 0.0175 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0179\n",
      "Epoch 83/180\n",
      "65/65 [==============================] - 29s 448ms/step - loss: 9.0220e-04 - mse: 9.0220e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0179\n",
      "Epoch 84/180\n",
      "65/65 [==============================] - 29s 452ms/step - loss: 9.0250e-04 - mse: 9.0250e-04 - mae: 0.0175 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0182\n",
      "Epoch 85/180\n",
      "65/65 [==============================] - 29s 445ms/step - loss: 9.0020e-04 - mse: 9.0020e-04 - mae: 0.0174 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0177\n",
      "Epoch 86/180\n",
      "65/65 [==============================] - 29s 440ms/step - loss: 8.9898e-04 - mse: 8.9898e-04 - mae: 0.0175 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0177\n",
      "Epoch 87/180\n",
      "65/65 [==============================] - 33s 501ms/step - loss: 8.9690e-04 - mse: 8.9690e-04 - mae: 0.0175 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0178\n",
      "Epoch 88/180\n",
      "65/65 [==============================] - 28s 428ms/step - loss: 8.9533e-04 - mse: 8.9533e-04 - mae: 0.0175 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0177\n",
      "Epoch 89/180\n",
      "65/65 [==============================] - 29s 439ms/step - loss: 9.0420e-04 - mse: 9.0420e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0183\n",
      "Epoch 90/180\n",
      "65/65 [==============================] - 28s 428ms/step - loss: 9.0186e-04 - mse: 9.0186e-04 - mae: 0.0175 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0176\n",
      "Epoch 91/180\n",
      "65/65 [==============================] - 30s 458ms/step - loss: 9.0222e-04 - mse: 9.0222e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0183\n",
      "Epoch 92/180\n",
      "65/65 [==============================] - 28s 438ms/step - loss: 9.0166e-04 - mse: 9.0166e-04 - mae: 0.0175 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0175\n",
      "Epoch 93/180\n",
      "65/65 [==============================] - 30s 455ms/step - loss: 8.9917e-04 - mse: 8.9917e-04 - mae: 0.0175 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0175\n",
      "Epoch 94/180\n",
      "65/65 [==============================] - 31s 479ms/step - loss: 9.0161e-04 - mse: 9.0161e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/180\n",
      "65/65 [==============================] - 30s 462ms/step - loss: 8.9948e-04 - mse: 8.9948e-04 - mae: 0.0175 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0179\n",
      "Epoch 96/180\n",
      "65/65 [==============================] - 29s 449ms/step - loss: 8.9680e-04 - mse: 8.9680e-04 - mae: 0.0175 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0181\n",
      "Epoch 97/180\n",
      "65/65 [==============================] - 30s 458ms/step - loss: 8.9898e-04 - mse: 8.9898e-04 - mae: 0.0175 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0179\n",
      "Epoch 98/180\n",
      "65/65 [==============================] - 28s 427ms/step - loss: 8.9826e-04 - mse: 8.9826e-04 - mae: 0.0175 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0180\n",
      "Epoch 99/180\n",
      "65/65 [==============================] - 30s 460ms/step - loss: 8.9886e-04 - mse: 8.9886e-04 - mae: 0.0175 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0176\n",
      "Epoch 100/180\n",
      "65/65 [==============================] - 29s 453ms/step - loss: 9.0211e-04 - mse: 9.0211e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0183\n",
      "Epoch 101/180\n",
      "65/65 [==============================] - 29s 440ms/step - loss: 8.9899e-04 - mse: 8.9899e-04 - mae: 0.0175 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0179\n",
      "Epoch 102/180\n",
      "65/65 [==============================] - 26s 406ms/step - loss: 8.9863e-04 - mse: 8.9863e-04 - mae: 0.0175 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0178\n",
      "Epoch 103/180\n",
      "65/65 [==============================] - 25s 390ms/step - loss: 8.9508e-04 - mse: 8.9508e-04 - mae: 0.0174 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0178\n",
      "Epoch 104/180\n",
      "65/65 [==============================] - 26s 407ms/step - loss: 8.9890e-04 - mse: 8.9890e-04 - mae: 0.0175 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0176\n",
      "Epoch 105/180\n",
      "65/65 [==============================] - 25s 383ms/step - loss: 8.9709e-04 - mse: 8.9709e-04 - mae: 0.0174 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0177\n",
      "Epoch 106/180\n",
      "65/65 [==============================] - 27s 412ms/step - loss: 8.9169e-04 - mse: 8.9169e-04 - mae: 0.0174 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0177\n",
      "Epoch 107/180\n",
      "65/65 [==============================] - 26s 404ms/step - loss: 8.9499e-04 - mse: 8.9499e-04 - mae: 0.0174 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0177\n",
      "Epoch 108/180\n",
      "65/65 [==============================] - 27s 412ms/step - loss: 8.9309e-04 - mse: 8.9309e-04 - mae: 0.0174 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0175\n",
      "Epoch 109/180\n",
      "65/65 [==============================] - 26s 393ms/step - loss: 8.9427e-04 - mse: 8.9427e-04 - mae: 0.0174 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0178\n",
      "Epoch 110/180\n",
      "65/65 [==============================] - 25s 389ms/step - loss: 8.9249e-04 - mse: 8.9249e-04 - mae: 0.0174 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0170\n",
      "Epoch 111/180\n",
      "65/65 [==============================] - 26s 398ms/step - loss: 8.9815e-04 - mse: 8.9815e-04 - mae: 0.0175 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0174\n",
      "Epoch 112/180\n",
      "65/65 [==============================] - 25s 389ms/step - loss: 8.9817e-04 - mse: 8.9817e-04 - mae: 0.0175 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0178\n",
      "Epoch 113/180\n",
      "65/65 [==============================] - 29s 450ms/step - loss: 8.8995e-04 - mse: 8.8995e-04 - mae: 0.0174 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0176\n",
      "Epoch 114/180\n",
      "65/65 [==============================] - 29s 445ms/step - loss: 8.9381e-04 - mse: 8.9381e-04 - mae: 0.0174 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0177\n",
      "Epoch 115/180\n",
      "65/65 [==============================] - 27s 414ms/step - loss: 8.9965e-04 - mse: 8.9965e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0181\n",
      "Epoch 116/180\n",
      "65/65 [==============================] - 29s 445ms/step - loss: 9.0077e-04 - mse: 9.0077e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0182\n",
      "Epoch 117/180\n",
      "65/65 [==============================] - 30s 458ms/step - loss: 8.9490e-04 - mse: 8.9490e-04 - mae: 0.0175 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0178\n",
      "Epoch 118/180\n",
      "65/65 [==============================] - 30s 459ms/step - loss: 8.9504e-04 - mse: 8.9504e-04 - mae: 0.0175 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0175\n",
      "Epoch 119/180\n",
      "65/65 [==============================] - 31s 483ms/step - loss: 8.9772e-04 - mse: 8.9772e-04 - mae: 0.0175 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0178\n",
      "Epoch 120/180\n",
      "65/65 [==============================] - 33s 514ms/step - loss: 8.9543e-04 - mse: 8.9543e-04 - mae: 0.0175 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0177\n",
      "Epoch 121/180\n",
      "65/65 [==============================] - 43s 659ms/step - loss: 8.9667e-04 - mse: 8.9667e-04 - mae: 0.0175 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0178\n",
      "Epoch 122/180\n",
      "65/65 [==============================] - 50s 775ms/step - loss: 8.9459e-04 - mse: 8.9459e-04 - mae: 0.0174 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0175\n",
      "Epoch 123/180\n",
      "65/65 [==============================] - 43s 656ms/step - loss: 8.9562e-04 - mse: 8.9562e-04 - mae: 0.0175 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0177\n",
      "Epoch 124/180\n",
      "65/65 [==============================] - 40s 611ms/step - loss: 8.9434e-04 - mse: 8.9434e-04 - mae: 0.0174 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0178\n",
      "Epoch 125/180\n",
      "65/65 [==============================] - 36s 558ms/step - loss: 8.9284e-04 - mse: 8.9284e-04 - mae: 0.0174 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0177\n",
      "Epoch 126/180\n",
      "65/65 [==============================] - 38s 581ms/step - loss: 8.9256e-04 - mse: 8.9256e-04 - mae: 0.0174 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0177\n",
      "Epoch 127/180\n",
      "65/65 [==============================] - 39s 604ms/step - loss: 8.9202e-04 - mse: 8.9202e-04 - mae: 0.0173 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0178\n",
      "Epoch 128/180\n",
      "65/65 [==============================] - 37s 570ms/step - loss: 8.9052e-04 - mse: 8.9052e-04 - mae: 0.0174 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0173\n",
      "Epoch 129/180\n",
      "65/65 [==============================] - 38s 581ms/step - loss: 8.9198e-04 - mse: 8.9198e-04 - mae: 0.0174 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0174\n",
      "Epoch 130/180\n",
      "65/65 [==============================] - 38s 591ms/step - loss: 8.9172e-04 - mse: 8.9172e-04 - mae: 0.0174 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0176\n",
      "Epoch 131/180\n",
      "65/65 [==============================] - 39s 605ms/step - loss: 8.8623e-04 - mse: 8.8623e-04 - mae: 0.0173 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0174\n",
      "Epoch 132/180\n",
      "65/65 [==============================] - 41s 632ms/step - loss: 8.8574e-04 - mse: 8.8574e-04 - mae: 0.0172 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0172\n",
      "Epoch 133/180\n",
      "65/65 [==============================] - 42s 646ms/step - loss: 8.8918e-04 - mse: 8.8918e-04 - mae: 0.0174 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0176\n",
      "Epoch 134/180\n",
      "65/65 [==============================] - 40s 609ms/step - loss: 8.8842e-04 - mse: 8.8842e-04 - mae: 0.0173 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0175\n",
      "Epoch 135/180\n",
      "65/65 [==============================] - 41s 624ms/step - loss: 8.8377e-04 - mse: 8.8377e-04 - mae: 0.0173 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0176\n",
      "Epoch 136/180\n",
      "65/65 [==============================] - 39s 594ms/step - loss: 8.9008e-04 - mse: 8.9008e-04 - mae: 0.0173 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0175\n",
      "Epoch 137/180\n",
      "65/65 [==============================] - 37s 567ms/step - loss: 8.9736e-04 - mse: 8.9736e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0176\n",
      "Epoch 138/180\n",
      "65/65 [==============================] - 37s 576ms/step - loss: 8.8868e-04 - mse: 8.8868e-04 - mae: 0.0173 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0178\n",
      "Epoch 139/180\n",
      "65/65 [==============================] - 39s 592ms/step - loss: 8.8193e-04 - mse: 8.8193e-04 - mae: 0.0172 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0169\n",
      "Epoch 140/180\n",
      "65/65 [==============================] - 37s 570ms/step - loss: 8.8641e-04 - mse: 8.8641e-04 - mae: 0.0172 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0175\n",
      "Epoch 141/180\n",
      "65/65 [==============================] - 37s 568ms/step - loss: 8.8739e-04 - mse: 8.8739e-04 - mae: 0.0173 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0174\n",
      "Epoch 142/180\n",
      "65/65 [==============================] - 39s 596ms/step - loss: 8.8670e-04 - mse: 8.8670e-04 - mae: 0.0173 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0172\n",
      "Epoch 143/180\n",
      "65/65 [==============================] - 38s 581ms/step - loss: 8.8721e-04 - mse: 8.8721e-04 - mae: 0.0172 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0171\n",
      "Epoch 144/180\n",
      "65/65 [==============================] - 37s 565ms/step - loss: 8.8444e-04 - mse: 8.8444e-04 - mae: 0.0172 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0169\n",
      "Epoch 145/180\n",
      "65/65 [==============================] - 39s 603ms/step - loss: 8.8632e-04 - mse: 8.8632e-04 - mae: 0.0172 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0172\n",
      "Epoch 146/180\n",
      "65/65 [==============================] - 38s 580ms/step - loss: 8.8706e-04 - mse: 8.8706e-04 - mae: 0.0173 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0169\n",
      "Epoch 147/180\n",
      "65/65 [==============================] - 38s 583ms/step - loss: 8.8160e-04 - mse: 8.8160e-04 - mae: 0.0172 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0173\n",
      "Epoch 148/180\n",
      "65/65 [==============================] - 41s 628ms/step - loss: 8.8148e-04 - mse: 8.8148e-04 - mae: 0.0172 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0168\n",
      "Epoch 149/180\n",
      "65/65 [==============================] - 40s 612ms/step - loss: 8.7908e-04 - mse: 8.7908e-04 - mae: 0.0171 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0170\n",
      "Epoch 150/180\n",
      "65/65 [==============================] - 30s 464ms/step - loss: 8.7751e-04 - mse: 8.7751e-04 - mae: 0.0171 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0172\n",
      "Epoch 151/180\n",
      "65/65 [==============================] - 29s 451ms/step - loss: 8.8227e-04 - mse: 8.8227e-04 - mae: 0.0171 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0173\n",
      "Epoch 152/180\n",
      "65/65 [==============================] - 31s 480ms/step - loss: 8.8195e-04 - mse: 8.8195e-04 - mae: 0.0172 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0171\n",
      "Epoch 153/180\n",
      "65/65 [==============================] - 26s 407ms/step - loss: 8.8253e-04 - mse: 8.8253e-04 - mae: 0.0172 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0165\n",
      "Epoch 154/180\n",
      "65/65 [==============================] - 25s 388ms/step - loss: 8.8252e-04 - mse: 8.8252e-04 - mae: 0.0172 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0170\n",
      "Epoch 155/180\n",
      "65/65 [==============================] - 28s 427ms/step - loss: 8.8152e-04 - mse: 8.8152e-04 - mae: 0.0172 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0170\n",
      "Epoch 156/180\n",
      "65/65 [==============================] - 29s 440ms/step - loss: 8.8058e-04 - mse: 8.8058e-04 - mae: 0.0172 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0170\n",
      "Epoch 157/180\n",
      "65/65 [==============================] - 28s 433ms/step - loss: 8.8101e-04 - mse: 8.8101e-04 - mae: 0.0171 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0171\n",
      "Epoch 158/180\n",
      "65/65 [==============================] - 29s 452ms/step - loss: 8.7959e-04 - mse: 8.7959e-04 - mae: 0.0171 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0170\n",
      "Epoch 159/180\n",
      "65/65 [==============================] - 29s 449ms/step - loss: 8.7572e-04 - mse: 8.7572e-04 - mae: 0.0171 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0168\n",
      "Epoch 160/180\n",
      "65/65 [==============================] - 28s 426ms/step - loss: 8.7672e-04 - mse: 8.7672e-04 - mae: 0.0171 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0167\n",
      "Epoch 161/180\n",
      "65/65 [==============================] - 27s 408ms/step - loss: 8.7516e-04 - mse: 8.7516e-04 - mae: 0.0170 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0170\n",
      "Epoch 162/180\n",
      "65/65 [==============================] - 29s 448ms/step - loss: 8.8325e-04 - mse: 8.8325e-04 - mae: 0.0171 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0169\n",
      "Epoch 163/180\n",
      "65/65 [==============================] - 30s 465ms/step - loss: 8.8018e-04 - mse: 8.8018e-04 - mae: 0.0172 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0172\n",
      "Epoch 164/180\n",
      "65/65 [==============================] - 30s 465ms/step - loss: 8.7614e-04 - mse: 8.7614e-04 - mae: 0.0171 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0169\n",
      "Epoch 165/180\n",
      "65/65 [==============================] - 28s 432ms/step - loss: 8.7603e-04 - mse: 8.7603e-04 - mae: 0.0171 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0170\n",
      "Epoch 166/180\n",
      "65/65 [==============================] - 30s 464ms/step - loss: 8.7498e-04 - mse: 8.7498e-04 - mae: 0.0171 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0167\n",
      "Epoch 167/180\n",
      "65/65 [==============================] - 29s 453ms/step - loss: 8.7940e-04 - mse: 8.7940e-04 - mae: 0.0171 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0169\n",
      "Epoch 168/180\n",
      "65/65 [==============================] - 29s 449ms/step - loss: 8.7968e-04 - mse: 8.7968e-04 - mae: 0.0171 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0169\n",
      "Epoch 169/180\n",
      "65/65 [==============================] - 26s 404ms/step - loss: 8.7825e-04 - mse: 8.7825e-04 - mae: 0.0171 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0169\n",
      "Epoch 170/180\n",
      "65/65 [==============================] - 25s 383ms/step - loss: 8.7294e-04 - mse: 8.7294e-04 - mae: 0.0170 - val_loss: 9.9878e-04 - val_mse: 9.9878e-04 - val_mae: 0.0170\n",
      "Epoch 171/180\n",
      "65/65 [==============================] - 26s 403ms/step - loss: 8.7183e-04 - mse: 8.7183e-04 - mae: 0.0170 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0168\n",
      "Epoch 172/180\n",
      "65/65 [==============================] - 27s 413ms/step - loss: 8.7846e-04 - mse: 8.7846e-04 - mae: 0.0170 - val_loss: 9.9441e-04 - val_mse: 9.9441e-04 - val_mae: 0.0171\n",
      "Epoch 173/180\n",
      "65/65 [==============================] - 25s 390ms/step - loss: 8.7236e-04 - mse: 8.7236e-04 - mae: 0.0170 - val_loss: 9.9827e-04 - val_mse: 9.9827e-04 - val_mae: 0.0173\n",
      "Epoch 174/180\n",
      "65/65 [==============================] - 25s 392ms/step - loss: 8.7406e-04 - mse: 8.7406e-04 - mae: 0.0170 - val_loss: 9.9370e-04 - val_mse: 9.9370e-04 - val_mae: 0.0167\n",
      "Epoch 175/180\n",
      "65/65 [==============================] - 25s 388ms/step - loss: 8.7173e-04 - mse: 8.7173e-04 - mae: 0.0170 - val_loss: 9.9143e-04 - val_mse: 9.9143e-04 - val_mae: 0.0167\n",
      "Epoch 176/180\n",
      "65/65 [==============================] - 25s 380ms/step - loss: 8.7187e-04 - mse: 8.7187e-04 - mae: 0.0170 - val_loss: 9.9359e-04 - val_mse: 9.9359e-04 - val_mae: 0.0169\n",
      "Epoch 177/180\n",
      "65/65 [==============================] - 27s 412ms/step - loss: 8.6866e-04 - mse: 8.6866e-04 - mae: 0.0169 - val_loss: 9.9000e-04 - val_mse: 9.9000e-04 - val_mae: 0.0168\n",
      "Epoch 178/180\n",
      "65/65 [==============================] - 32s 490ms/step - loss: 8.6810e-04 - mse: 8.6810e-04 - mae: 0.0169 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0171\n",
      "Epoch 179/180\n",
      "65/65 [==============================] - 30s 462ms/step - loss: 8.6898e-04 - mse: 8.6898e-04 - mae: 0.0169 - val_loss: 9.9006e-04 - val_mse: 9.9006e-04 - val_mae: 0.0169\n",
      "Epoch 180/180\n",
      "65/65 [==============================] - 30s 457ms/step - loss: 8.7256e-04 - mse: 8.7256e-04 - mae: 0.0169 - val_loss: 9.9221e-04 - val_mse: 9.9221e-04 - val_mae: 0.0169\n",
      "Epoch 1/180\n",
      "65/65 [==============================] - 31s 482ms/step - loss: 0.2361 - mse: 0.2361 - mae: 0.3596 - val_loss: 0.0022 - val_mse: 0.0022 - val_mae: 0.0329\n",
      "Epoch 2/180\n",
      "65/65 [==============================] - 35s 542ms/step - loss: 0.0717 - mse: 0.0717 - mae: 0.2129 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0265\n",
      "Epoch 3/180\n",
      "65/65 [==============================] - 30s 465ms/step - loss: 0.0289 - mse: 0.0289 - mae: 0.1347 - val_loss: 0.0017 - val_mse: 0.0017 - val_mae: 0.0261\n",
      "Epoch 4/180\n",
      "65/65 [==============================] - 33s 505ms/step - loss: 0.0144 - mse: 0.0144 - mae: 0.0950 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0225\n",
      "Epoch 5/180\n",
      "65/65 [==============================] - 28s 426ms/step - loss: 0.0090 - mse: 0.0090 - mae: 0.0743 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0217\n",
      "Epoch 6/180\n",
      "65/65 [==============================] - 28s 437ms/step - loss: 0.0065 - mse: 0.0065 - mae: 0.0626 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0181\n",
      "Epoch 7/180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 34s 525ms/step - loss: 0.0048 - mse: 0.0048 - mae: 0.0536 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0176\n",
      "Epoch 8/180\n",
      "65/65 [==============================] - 32s 486ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0477 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0165\n",
      "Epoch 9/180\n",
      "65/65 [==============================] - 29s 453ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0428 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0245\n",
      "Epoch 10/180\n",
      "65/65 [==============================] - 29s 439ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0395 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0256\n",
      "Epoch 11/180\n",
      "65/65 [==============================] - 30s 462ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0359 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0228\n",
      "Epoch 12/180\n",
      "65/65 [==============================] - 34s 525ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0334 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0240\n",
      "Epoch 13/180\n",
      "65/65 [==============================] - 29s 449ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0312 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0228\n",
      "Epoch 14/180\n",
      "65/65 [==============================] - 32s 485ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0297 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0234\n",
      "Epoch 15/180\n",
      "65/65 [==============================] - 31s 482ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0280 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0225\n",
      "Epoch 16/180\n",
      "65/65 [==============================] - 30s 469ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0271 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0227\n",
      "Epoch 17/180\n",
      "65/65 [==============================] - 30s 465ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0265 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0211\n",
      "Epoch 18/180\n",
      "65/65 [==============================] - 30s 468ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0256 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0217\n",
      "Epoch 19/180\n",
      "65/65 [==============================] - 32s 487ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0250 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0224\n",
      "Epoch 20/180\n",
      "65/65 [==============================] - 32s 486ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0241 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0224\n",
      "Epoch 21/180\n",
      "65/65 [==============================] - 31s 480ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0234 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0222\n",
      "Epoch 22/180\n",
      "65/65 [==============================] - 31s 475ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0232 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0214\n",
      "Epoch 23/180\n",
      "65/65 [==============================] - 31s 483ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0229 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0217\n",
      "Epoch 24/180\n",
      "65/65 [==============================] - 31s 475ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0228 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0220\n",
      "Epoch 25/180\n",
      "65/65 [==============================] - 32s 492ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0223 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0203\n",
      "Epoch 26/180\n",
      "65/65 [==============================] - 31s 482ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0220 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0209\n",
      "Epoch 27/180\n",
      "65/65 [==============================] - 32s 495ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0214 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0221\n",
      "Epoch 28/180\n",
      "65/65 [==============================] - 31s 481ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0215 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0215\n",
      "Epoch 29/180\n",
      "65/65 [==============================] - 30s 466ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0217 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0207\n",
      "Epoch 30/180\n",
      "65/65 [==============================] - 31s 484ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0212 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0201\n",
      "Epoch 31/180\n",
      "65/65 [==============================] - 31s 477ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0213 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0209\n",
      "Epoch 32/180\n",
      "65/65 [==============================] - 30s 468ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0209 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0199\n",
      "Epoch 33/180\n",
      "65/65 [==============================] - 32s 498ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0208 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0199\n",
      "Epoch 34/180\n",
      "65/65 [==============================] - 30s 466ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0208 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0196\n",
      "Epoch 35/180\n",
      "65/65 [==============================] - 32s 490ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0210 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0194\n",
      "Epoch 36/180\n",
      "65/65 [==============================] - 32s 499ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0209 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0203\n",
      "Epoch 37/180\n",
      "65/65 [==============================] - 30s 460ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0205 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0193\n",
      "Epoch 38/180\n",
      "65/65 [==============================] - 28s 425ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0204 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0187\n",
      "Epoch 39/180\n",
      "65/65 [==============================] - 33s 503ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0202 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0194\n",
      "Epoch 40/180\n",
      "65/65 [==============================] - 30s 457ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0203 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0177\n",
      "Epoch 41/180\n",
      "65/65 [==============================] - 29s 446ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0204 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 42/180\n",
      "65/65 [==============================] - 31s 480ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0204 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 43/180\n",
      "65/65 [==============================] - 29s 447ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0202 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0180\n",
      "Epoch 44/180\n",
      "65/65 [==============================] - 28s 429ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0204 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 45/180\n",
      "65/65 [==============================] - 30s 455ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0200 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0172\n",
      "Epoch 46/180\n",
      "65/65 [==============================] - 28s 438ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0200 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 47/180\n",
      "65/65 [==============================] - 27s 422ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0201 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0170\n",
      "Epoch 48/180\n",
      "65/65 [==============================] - 30s 464ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0200 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0177\n",
      "Epoch 49/180\n",
      "65/65 [==============================] - 29s 451ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0197 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0182\n",
      "Epoch 50/180\n",
      "65/65 [==============================] - 30s 455ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0201 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0183\n",
      "Epoch 51/180\n",
      "65/65 [==============================] - 29s 453ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0198 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 52/180\n",
      "65/65 [==============================] - 31s 482ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0198 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 53/180\n",
      "65/65 [==============================] - 33s 504ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0195 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0189\n",
      "Epoch 54/180\n",
      "65/65 [==============================] - 29s 447ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0196 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0182\n",
      "Epoch 55/180\n",
      "65/65 [==============================] - 29s 441ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0197 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0189\n",
      "Epoch 56/180\n",
      "65/65 [==============================] - 27s 408ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0198 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0197\n",
      "Epoch 57/180\n",
      "65/65 [==============================] - 26s 393ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0194 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0204\n",
      "Epoch 58/180\n",
      "65/65 [==============================] - 26s 397ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0194 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0212\n",
      "Epoch 59/180\n",
      "65/65 [==============================] - 27s 414ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0191 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0208\n",
      "Epoch 60/180\n",
      "65/65 [==============================] - 26s 401ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0191 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0213\n",
      "Epoch 61/180\n",
      "65/65 [==============================] - 26s 402ms/step - loss: 9.9535e-04 - mse: 9.9535e-04 - mae: 0.0189 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0210\n",
      "Epoch 62/180\n",
      "65/65 [==============================] - 26s 398ms/step - loss: 9.9571e-04 - mse: 9.9571e-04 - mae: 0.0189 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0220\n",
      "Epoch 63/180\n",
      "65/65 [==============================] - 26s 407ms/step - loss: 9.9101e-04 - mse: 9.9101e-04 - mae: 0.0189 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0214\n",
      "Epoch 64/180\n",
      "65/65 [==============================] - 27s 408ms/step - loss: 9.8216e-04 - mse: 9.8216e-04 - mae: 0.0187 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0220\n",
      "Epoch 65/180\n",
      "65/65 [==============================] - 26s 408ms/step - loss: 9.8529e-04 - mse: 9.8529e-04 - mae: 0.0188 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0214\n",
      "Epoch 66/180\n",
      "65/65 [==============================] - 28s 429ms/step - loss: 9.7999e-04 - mse: 9.7999e-04 - mae: 0.0186 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0208\n",
      "Epoch 67/180\n",
      "65/65 [==============================] - 27s 409ms/step - loss: 9.7767e-04 - mse: 9.7767e-04 - mae: 0.0186 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0210\n",
      "Epoch 68/180\n",
      "65/65 [==============================] - 27s 419ms/step - loss: 9.7947e-04 - mse: 9.7947e-04 - mae: 0.0186 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0213\n",
      "Epoch 69/180\n",
      "65/65 [==============================] - 28s 428ms/step - loss: 9.7583e-04 - mse: 9.7583e-04 - mae: 0.0185 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0206\n",
      "Epoch 70/180\n",
      "65/65 [==============================] - 27s 410ms/step - loss: 9.6425e-04 - mse: 9.6425e-04 - mae: 0.0185 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0209\n",
      "Epoch 71/180\n",
      "65/65 [==============================] - 25s 390ms/step - loss: 9.6098e-04 - mse: 9.6098e-04 - mae: 0.0184 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0207\n",
      "Epoch 72/180\n",
      "65/65 [==============================] - 27s 411ms/step - loss: 9.6392e-04 - mse: 9.6392e-04 - mae: 0.0185 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0205\n",
      "Epoch 73/180\n",
      "65/65 [==============================] - 26s 395ms/step - loss: 9.6198e-04 - mse: 9.6198e-04 - mae: 0.0184 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0200\n",
      "Epoch 74/180\n",
      "65/65 [==============================] - 26s 393ms/step - loss: 9.6562e-04 - mse: 9.6562e-04 - mae: 0.0184 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0206\n",
      "Epoch 75/180\n",
      "65/65 [==============================] - 26s 392ms/step - loss: 9.6401e-04 - mse: 9.6401e-04 - mae: 0.0185 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0205\n",
      "Epoch 76/180\n",
      "65/65 [==============================] - 25s 391ms/step - loss: 9.6425e-04 - mse: 9.6425e-04 - mae: 0.0183 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0196\n",
      "Epoch 77/180\n",
      "65/65 [==============================] - 27s 409ms/step - loss: 9.5158e-04 - mse: 9.5158e-04 - mae: 0.0183 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0194\n",
      "Epoch 78/180\n",
      "65/65 [==============================] - 25s 392ms/step - loss: 9.4853e-04 - mse: 9.4853e-04 - mae: 0.0182 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0194\n",
      "Epoch 79/180\n",
      "65/65 [==============================] - 25s 390ms/step - loss: 9.5497e-04 - mse: 9.5497e-04 - mae: 0.0183 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0194\n",
      "Epoch 80/180\n",
      "65/65 [==============================] - 25s 392ms/step - loss: 9.4194e-04 - mse: 9.4194e-04 - mae: 0.0182 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0194\n",
      "Epoch 81/180\n",
      "65/65 [==============================] - 26s 401ms/step - loss: 9.4199e-04 - mse: 9.4199e-04 - mae: 0.0181 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0191\n",
      "Epoch 82/180\n",
      "65/65 [==============================] - 26s 399ms/step - loss: 9.3367e-04 - mse: 9.3367e-04 - mae: 0.0181 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0193\n",
      "Epoch 83/180\n",
      "65/65 [==============================] - 26s 407ms/step - loss: 9.3495e-04 - mse: 9.3495e-04 - mae: 0.0180 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0195\n",
      "Epoch 84/180\n",
      "65/65 [==============================] - 26s 396ms/step - loss: 9.3702e-04 - mse: 9.3702e-04 - mae: 0.0180 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0193\n",
      "Epoch 85/180\n",
      "65/65 [==============================] - 26s 401ms/step - loss: 9.3657e-04 - mse: 9.3657e-04 - mae: 0.0181 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0197\n",
      "Epoch 86/180\n",
      "65/65 [==============================] - 26s 407ms/step - loss: 9.3551e-04 - mse: 9.3551e-04 - mae: 0.0180 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0198\n",
      "Epoch 87/180\n",
      "65/65 [==============================] - 25s 390ms/step - loss: 9.3644e-04 - mse: 9.3644e-04 - mae: 0.0181 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0197\n",
      "Epoch 88/180\n",
      "65/65 [==============================] - 26s 407ms/step - loss: 9.2810e-04 - mse: 9.2810e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0194\n",
      "Epoch 89/180\n",
      "65/65 [==============================] - 27s 412ms/step - loss: 9.3419e-04 - mse: 9.3419e-04 - mae: 0.0180 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0194\n",
      "Epoch 90/180\n",
      "65/65 [==============================] - 26s 403ms/step - loss: 9.2378e-04 - mse: 9.2378e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0196\n",
      "Epoch 91/180\n",
      "65/65 [==============================] - 26s 400ms/step - loss: 9.3930e-04 - mse: 9.3930e-04 - mae: 0.0181 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0192\n",
      "Epoch 92/180\n",
      "65/65 [==============================] - 26s 393ms/step - loss: 9.3381e-04 - mse: 9.3381e-04 - mae: 0.0180 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0184\n",
      "Epoch 93/180\n",
      "65/65 [==============================] - 25s 390ms/step - loss: 9.3313e-04 - mse: 9.3313e-04 - mae: 0.0180 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 94/180\n",
      "65/65 [==============================] - 25s 391ms/step - loss: 9.2194e-04 - mse: 9.2194e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 95/180\n",
      "65/65 [==============================] - 27s 416ms/step - loss: 9.2820e-04 - mse: 9.2820e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0190\n",
      "Epoch 96/180\n",
      "65/65 [==============================] - 26s 394ms/step - loss: 9.2337e-04 - mse: 9.2337e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0187\n",
      "Epoch 97/180\n",
      "65/65 [==============================] - 26s 398ms/step - loss: 9.2417e-04 - mse: 9.2417e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 98/180\n",
      "65/65 [==============================] - 26s 396ms/step - loss: 9.2280e-04 - mse: 9.2280e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0188\n",
      "Epoch 99/180\n",
      "65/65 [==============================] - 25s 391ms/step - loss: 9.1795e-04 - mse: 9.1795e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 100/180\n",
      "65/65 [==============================] - 26s 401ms/step - loss: 9.1750e-04 - mse: 9.1750e-04 - mae: 0.0178 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0183\n",
      "Epoch 101/180\n",
      "65/65 [==============================] - 25s 391ms/step - loss: 9.2079e-04 - mse: 9.2079e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 102/180\n",
      "65/65 [==============================] - 25s 387ms/step - loss: 9.2315e-04 - mse: 9.2315e-04 - mae: 0.0179 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0188\n",
      "Epoch 103/180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 25s 390ms/step - loss: 9.2242e-04 - mse: 9.2242e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 104/180\n",
      "65/65 [==============================] - 26s 398ms/step - loss: 9.2078e-04 - mse: 9.2078e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 105/180\n",
      "65/65 [==============================] - 26s 393ms/step - loss: 9.1947e-04 - mse: 9.1947e-04 - mae: 0.0178 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0188\n",
      "Epoch 106/180\n",
      "65/65 [==============================] - 26s 393ms/step - loss: 9.1645e-04 - mse: 9.1645e-04 - mae: 0.0178 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0186\n",
      "Epoch 107/180\n",
      "65/65 [==============================] - 25s 388ms/step - loss: 9.1958e-04 - mse: 9.1958e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0187\n",
      "Epoch 108/180\n",
      "65/65 [==============================] - 25s 390ms/step - loss: 9.1868e-04 - mse: 9.1868e-04 - mae: 0.0179 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0189\n",
      "Epoch 109/180\n",
      "65/65 [==============================] - 26s 406ms/step - loss: 9.1968e-04 - mse: 9.1968e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0187\n",
      "Epoch 110/180\n",
      "65/65 [==============================] - 26s 402ms/step - loss: 9.1950e-04 - mse: 9.1950e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0189\n",
      "Epoch 111/180\n",
      "65/65 [==============================] - 28s 427ms/step - loss: 9.1606e-04 - mse: 9.1606e-04 - mae: 0.0178 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0188\n",
      "Epoch 112/180\n",
      "65/65 [==============================] - 27s 412ms/step - loss: 9.1653e-04 - mse: 9.1653e-04 - mae: 0.0178 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0189\n",
      "Epoch 113/180\n",
      "65/65 [==============================] - 26s 407ms/step - loss: 9.1791e-04 - mse: 9.1791e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 114/180\n",
      "65/65 [==============================] - 26s 397ms/step - loss: 9.1663e-04 - mse: 9.1663e-04 - mae: 0.0179 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0184\n",
      "Epoch 115/180\n",
      "65/65 [==============================] - 26s 394ms/step - loss: 9.1460e-04 - mse: 9.1460e-04 - mae: 0.0178 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0187\n",
      "Epoch 116/180\n",
      "65/65 [==============================] - 26s 395ms/step - loss: 9.1560e-04 - mse: 9.1560e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0187\n",
      "Epoch 117/180\n",
      "65/65 [==============================] - 27s 410ms/step - loss: 9.1522e-04 - mse: 9.1522e-04 - mae: 0.0179 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0186\n",
      "Epoch 118/180\n",
      "65/65 [==============================] - 28s 437ms/step - loss: 9.1684e-04 - mse: 9.1684e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 119/180\n",
      "65/65 [==============================] - 27s 419ms/step - loss: 9.1398e-04 - mse: 9.1398e-04 - mae: 0.0179 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0187\n",
      "Epoch 120/180\n",
      "65/65 [==============================] - 26s 405ms/step - loss: 9.1743e-04 - mse: 9.1743e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 121/180\n",
      "65/65 [==============================] - 26s 405ms/step - loss: 9.1567e-04 - mse: 9.1567e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 122/180\n",
      "65/65 [==============================] - 26s 404ms/step - loss: 9.1575e-04 - mse: 9.1575e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0188\n",
      "Epoch 123/180\n",
      "65/65 [==============================] - 26s 404ms/step - loss: 9.1304e-04 - mse: 9.1304e-04 - mae: 0.0177 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0189\n",
      "Epoch 124/180\n",
      "65/65 [==============================] - 25s 391ms/step - loss: 9.1230e-04 - mse: 9.1230e-04 - mae: 0.0178 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0183\n",
      "Epoch 125/180\n",
      "65/65 [==============================] - 26s 392ms/step - loss: 9.1657e-04 - mse: 9.1657e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0184\n",
      "Epoch 126/180\n",
      "65/65 [==============================] - 26s 399ms/step - loss: 9.1112e-04 - mse: 9.1112e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0188\n",
      "Epoch 127/180\n",
      "65/65 [==============================] - 27s 409ms/step - loss: 9.0982e-04 - mse: 9.0982e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 128/180\n",
      "65/65 [==============================] - 26s 403ms/step - loss: 9.1184e-04 - mse: 9.1184e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 129/180\n",
      "65/65 [==============================] - 26s 399ms/step - loss: 9.0987e-04 - mse: 9.0987e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0188\n",
      "Epoch 130/180\n",
      "65/65 [==============================] - 25s 391ms/step - loss: 9.0842e-04 - mse: 9.0842e-04 - mae: 0.0178 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0186\n",
      "Epoch 131/180\n",
      "65/65 [==============================] - 26s 400ms/step - loss: 9.0948e-04 - mse: 9.0948e-04 - mae: 0.0176 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0187\n",
      "Epoch 132/180\n",
      "65/65 [==============================] - 26s 400ms/step - loss: 9.0628e-04 - mse: 9.0628e-04 - mae: 0.0177 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0186\n",
      "Epoch 133/180\n",
      "65/65 [==============================] - 26s 406ms/step - loss: 9.0578e-04 - mse: 9.0578e-04 - mae: 0.0176 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0188\n",
      "Epoch 134/180\n",
      "65/65 [==============================] - 27s 415ms/step - loss: 9.0130e-04 - mse: 9.0130e-04 - mae: 0.0176 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0189\n",
      "Epoch 135/180\n",
      "65/65 [==============================] - 26s 400ms/step - loss: 8.9857e-04 - mse: 8.9857e-04 - mae: 0.0175 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0181\n",
      "Epoch 136/180\n",
      "65/65 [==============================] - 26s 406ms/step - loss: 9.0273e-04 - mse: 9.0273e-04 - mae: 0.0175 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0188\n",
      "Epoch 137/180\n",
      "65/65 [==============================] - 25s 389ms/step - loss: 9.0247e-04 - mse: 9.0247e-04 - mae: 0.0175 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0184\n",
      "Epoch 138/180\n",
      "65/65 [==============================] - 26s 402ms/step - loss: 8.9321e-04 - mse: 8.9321e-04 - mae: 0.0174 - val_loss: 9.9003e-04 - val_mse: 9.9003e-04 - val_mae: 0.0171\n",
      "Epoch 139/180\n",
      "65/65 [==============================] - 25s 389ms/step - loss: 8.9872e-04 - mse: 8.9872e-04 - mae: 0.0174 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0182\n",
      "Epoch 140/180\n",
      "65/65 [==============================] - 26s 404ms/step - loss: 9.0542e-04 - mse: 9.0542e-04 - mae: 0.0176 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0183\n",
      "Epoch 141/180\n",
      "65/65 [==============================] - 26s 398ms/step - loss: 9.0346e-04 - mse: 9.0346e-04 - mae: 0.0176 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0188\n",
      "Epoch 142/180\n",
      "65/65 [==============================] - 26s 394ms/step - loss: 9.0172e-04 - mse: 9.0172e-04 - mae: 0.0175 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0184\n",
      "Epoch 143/180\n",
      "65/65 [==============================] - 26s 394ms/step - loss: 9.1450e-04 - mse: 9.1450e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0183\n",
      "Epoch 144/180\n",
      "65/65 [==============================] - 26s 399ms/step - loss: 9.0098e-04 - mse: 9.0098e-04 - mae: 0.0176 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0185\n",
      "Epoch 145/180\n",
      "65/65 [==============================] - 27s 410ms/step - loss: 9.0258e-04 - mse: 9.0258e-04 - mae: 0.0176 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0184\n",
      "Epoch 146/180\n",
      "65/65 [==============================] - 26s 392ms/step - loss: 8.9549e-04 - mse: 8.9549e-04 - mae: 0.0174 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0184\n",
      "Epoch 147/180\n",
      "65/65 [==============================] - 25s 391ms/step - loss: 8.9352e-04 - mse: 8.9352e-04 - mae: 0.0174 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0186\n",
      "Epoch 148/180\n",
      "65/65 [==============================] - 25s 390ms/step - loss: 9.1856e-04 - mse: 9.1856e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 149/180\n",
      "65/65 [==============================] - 26s 403ms/step - loss: 9.0399e-04 - mse: 9.0399e-04 - mae: 0.0176 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0187\n",
      "Epoch 150/180\n",
      "65/65 [==============================] - 26s 406ms/step - loss: 9.0999e-04 - mse: 9.0999e-04 - mae: 0.0177 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0184\n",
      "Epoch 151/180\n",
      "65/65 [==============================] - 25s 389ms/step - loss: 8.9567e-04 - mse: 8.9567e-04 - mae: 0.0174 - val_loss: 9.6570e-04 - val_mse: 9.6570e-04 - val_mae: 0.0179\n",
      "Epoch 152/180\n",
      "65/65 [==============================] - 26s 405ms/step - loss: 9.0314e-04 - mse: 9.0314e-04 - mae: 0.0175 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0184\n",
      "Epoch 153/180\n",
      "65/65 [==============================] - 25s 389ms/step - loss: 8.8970e-04 - mse: 8.8970e-04 - mae: 0.0174 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0184\n",
      "Epoch 154/180\n",
      "65/65 [==============================] - 26s 405ms/step - loss: 9.0134e-04 - mse: 9.0134e-04 - mae: 0.0176 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0190\n",
      "Epoch 155/180\n",
      "65/65 [==============================] - 25s 388ms/step - loss: 8.9822e-04 - mse: 8.9822e-04 - mae: 0.0174 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0176\n",
      "Epoch 156/180\n",
      "65/65 [==============================] - 26s 400ms/step - loss: 9.0226e-04 - mse: 9.0226e-04 - mae: 0.0175 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0181\n",
      "Epoch 157/180\n",
      "65/65 [==============================] - 27s 410ms/step - loss: 8.9940e-04 - mse: 8.9940e-04 - mae: 0.0174 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0186\n",
      "Epoch 158/180\n",
      "65/65 [==============================] - 25s 392ms/step - loss: 9.0812e-04 - mse: 9.0812e-04 - mae: 0.0177 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0191\n",
      "Epoch 159/180\n",
      "65/65 [==============================] - 26s 405ms/step - loss: 9.0609e-04 - mse: 9.0609e-04 - mae: 0.0177 - val_loss: 9.7456e-04 - val_mse: 9.7456e-04 - val_mae: 0.0186\n",
      "Epoch 160/180\n",
      "65/65 [==============================] - 25s 386ms/step - loss: 8.9572e-04 - mse: 8.9572e-04 - mae: 0.0173 - val_loss: 9.6799e-04 - val_mse: 9.6799e-04 - val_mae: 0.0197\n",
      "Epoch 161/180\n",
      "65/65 [==============================] - 25s 390ms/step - loss: 9.0146e-04 - mse: 9.0146e-04 - mae: 0.0176 - val_loss: 9.7566e-04 - val_mse: 9.7566e-04 - val_mae: 0.0182\n",
      "Epoch 162/180\n",
      "65/65 [==============================] - 26s 397ms/step - loss: 9.1306e-04 - mse: 9.1306e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0190\n",
      "Epoch 163/180\n",
      "65/65 [==============================] - 26s 400ms/step - loss: 9.0422e-04 - mse: 9.0422e-04 - mae: 0.0176 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0186\n",
      "Epoch 164/180\n",
      "65/65 [==============================] - 25s 391ms/step - loss: 8.9465e-04 - mse: 8.9465e-04 - mae: 0.0175 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0190\n",
      "Epoch 165/180\n",
      "65/65 [==============================] - 25s 390ms/step - loss: 8.9369e-04 - mse: 8.9369e-04 - mae: 0.0174 - val_loss: 9.9054e-04 - val_mse: 9.9054e-04 - val_mae: 0.0181\n",
      "Epoch 166/180\n",
      "65/65 [==============================] - 25s 390ms/step - loss: 8.9178e-04 - mse: 8.9178e-04 - mae: 0.0173 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0182\n",
      "Epoch 167/180\n",
      "65/65 [==============================] - 25s 392ms/step - loss: 8.8938e-04 - mse: 8.8938e-04 - mae: 0.0173 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0188\n",
      "Epoch 168/180\n",
      "65/65 [==============================] - 26s 406ms/step - loss: 8.8978e-04 - mse: 8.8978e-04 - mae: 0.0174 - val_loss: 9.8877e-04 - val_mse: 9.8877e-04 - val_mae: 0.0180\n",
      "Epoch 169/180\n",
      "65/65 [==============================] - 25s 388ms/step - loss: 8.9059e-04 - mse: 8.9059e-04 - mae: 0.0174 - val_loss: 9.4429e-04 - val_mse: 9.4429e-04 - val_mae: 0.0182\n",
      "Epoch 170/180\n",
      "65/65 [==============================] - 26s 398ms/step - loss: 8.8794e-04 - mse: 8.8794e-04 - mae: 0.0173 - val_loss: 9.1870e-04 - val_mse: 9.1870e-04 - val_mae: 0.0183\n",
      "Epoch 171/180\n",
      "65/65 [==============================] - 27s 417ms/step - loss: 8.9044e-04 - mse: 8.9044e-04 - mae: 0.0173 - val_loss: 9.1673e-04 - val_mse: 9.1673e-04 - val_mae: 0.0177\n",
      "Epoch 172/180\n",
      "65/65 [==============================] - 31s 473ms/step - loss: 8.8783e-04 - mse: 8.8783e-04 - mae: 0.0172 - val_loss: 9.4155e-04 - val_mse: 9.4155e-04 - val_mae: 0.0179\n",
      "Epoch 173/180\n",
      "65/65 [==============================] - 30s 463ms/step - loss: 8.9117e-04 - mse: 8.9117e-04 - mae: 0.0174 - val_loss: 9.4656e-04 - val_mse: 9.4656e-04 - val_mae: 0.0170\n",
      "Epoch 174/180\n",
      "65/65 [==============================] - 31s 472ms/step - loss: 8.8829e-04 - mse: 8.8829e-04 - mae: 0.0172 - val_loss: 9.6795e-04 - val_mse: 9.6795e-04 - val_mae: 0.0188\n",
      "Epoch 175/180\n",
      "65/65 [==============================] - 30s 457ms/step - loss: 8.8787e-04 - mse: 8.8787e-04 - mae: 0.0174 - val_loss: 9.4774e-04 - val_mse: 9.4774e-04 - val_mae: 0.0177\n",
      "Epoch 176/180\n",
      "65/65 [==============================] - 28s 437ms/step - loss: 8.8767e-04 - mse: 8.8767e-04 - mae: 0.0173 - val_loss: 9.2735e-04 - val_mse: 9.2735e-04 - val_mae: 0.0180\n",
      "Epoch 177/180\n",
      "65/65 [==============================] - 29s 452ms/step - loss: 8.9741e-04 - mse: 8.9741e-04 - mae: 0.0174 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0189\n",
      "Epoch 178/180\n",
      "65/65 [==============================] - 32s 491ms/step - loss: 9.1567e-04 - mse: 9.1567e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0193\n",
      "Epoch 179/180\n",
      "65/65 [==============================] - 33s 504ms/step - loss: 9.0651e-04 - mse: 9.0651e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0187\n",
      "Epoch 180/180\n",
      "65/65 [==============================] - 34s 526ms/step - loss: 9.0012e-04 - mse: 9.0012e-04 - mae: 0.0175 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0188\n",
      "Epoch 1/180\n",
      "65/65 [==============================] - 34s 516ms/step - loss: 0.1748 - mse: 0.1748 - mae: 0.3209 - val_loss: 0.0467 - val_mse: 0.0467 - val_mae: 0.2093\n",
      "Epoch 2/180\n",
      "65/65 [==============================] - 33s 504ms/step - loss: 0.0392 - mse: 0.0392 - mae: 0.1551 - val_loss: 0.0021 - val_mse: 0.0021 - val_mae: 0.0314\n",
      "Epoch 3/180\n",
      "65/65 [==============================] - 34s 517ms/step - loss: 0.0162 - mse: 0.0162 - mae: 0.1001 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0198\n",
      "Epoch 4/180\n",
      "65/65 [==============================] - 33s 509ms/step - loss: 0.0089 - mse: 0.0089 - mae: 0.0741 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0184\n",
      "Epoch 5/180\n",
      "65/65 [==============================] - 32s 500ms/step - loss: 0.0056 - mse: 0.0056 - mae: 0.0576 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0176\n",
      "Epoch 6/180\n",
      "65/65 [==============================] - 33s 509ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0484 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0178\n",
      "Epoch 7/180\n",
      "65/65 [==============================] - 35s 537ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0412 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0189\n",
      "Epoch 8/180\n",
      "65/65 [==============================] - 34s 516ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0363 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0161\n",
      "Epoch 9/180\n",
      "65/65 [==============================] - 32s 496ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0332 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0219\n",
      "Epoch 10/180\n",
      "65/65 [==============================] - 32s 494ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0302 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0197\n",
      "Epoch 11/180\n",
      "65/65 [==============================] - 36s 554ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0280 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0198\n",
      "Epoch 12/180\n",
      "65/65 [==============================] - 33s 512ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0263 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0201\n",
      "Epoch 13/180\n",
      "65/65 [==============================] - 32s 498ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0247 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0200\n",
      "Epoch 14/180\n",
      "65/65 [==============================] - 34s 525ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0241 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0187\n",
      "Epoch 15/180\n",
      "65/65 [==============================] - 33s 511ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0232 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/180\n",
      "65/65 [==============================] - 34s 519ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0223 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0196\n",
      "Epoch 17/180\n",
      "65/65 [==============================] - 34s 519ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0217 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0189\n",
      "Epoch 18/180\n",
      "65/65 [==============================] - 40s 608ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0216 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0180\n",
      "Epoch 19/180\n",
      "65/65 [==============================] - 35s 541ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0210 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0183\n",
      "Epoch 20/180\n",
      "65/65 [==============================] - 37s 574ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0209 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 21/180\n",
      "65/65 [==============================] - 34s 530ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0202 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0183\n",
      "Epoch 22/180\n",
      "65/65 [==============================] - 31s 480ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0200 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0182\n",
      "Epoch 23/180\n",
      "65/65 [==============================] - 31s 479ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0200 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0183\n",
      "Epoch 24/180\n",
      "65/65 [==============================] - 33s 512ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0197 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0181\n",
      "Epoch 25/180\n",
      "65/65 [==============================] - 32s 487ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0197 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0182\n",
      "Epoch 26/180\n",
      "65/65 [==============================] - 31s 471ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0195 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0177\n",
      "Epoch 27/180\n",
      "65/65 [==============================] - 31s 483ms/step - loss: 9.9673e-04 - mse: 9.9673e-04 - mae: 0.0192 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 28/180\n",
      "65/65 [==============================] - 36s 557ms/step - loss: 9.9657e-04 - mse: 9.9657e-04 - mae: 0.0191 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0182\n",
      "Epoch 29/180\n",
      "65/65 [==============================] - 32s 499ms/step - loss: 9.9910e-04 - mse: 9.9910e-04 - mae: 0.0192 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0177\n",
      "Epoch 30/180\n",
      "65/65 [==============================] - 33s 510ms/step - loss: 9.9297e-04 - mse: 9.9297e-04 - mae: 0.0191 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0177\n",
      "Epoch 31/180\n",
      "65/65 [==============================] - 30s 469ms/step - loss: 9.7149e-04 - mse: 9.7149e-04 - mae: 0.0188 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0176\n",
      "Epoch 32/180\n",
      "65/65 [==============================] - 31s 475ms/step - loss: 9.7111e-04 - mse: 9.7111e-04 - mae: 0.0185 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0177\n",
      "Epoch 33/180\n",
      "65/65 [==============================] - 33s 508ms/step - loss: 9.7557e-04 - mse: 9.7557e-04 - mae: 0.0187 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0179\n",
      "Epoch 34/180\n",
      "65/65 [==============================] - 32s 494ms/step - loss: 9.7585e-04 - mse: 9.7585e-04 - mae: 0.0188 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0176\n",
      "Epoch 35/180\n",
      "65/65 [==============================] - 32s 490ms/step - loss: 9.7313e-04 - mse: 9.7313e-04 - mae: 0.0187 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0174\n",
      "Epoch 36/180\n",
      "65/65 [==============================] - 32s 492ms/step - loss: 9.6592e-04 - mse: 9.6592e-04 - mae: 0.0185 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0175\n",
      "Epoch 37/180\n",
      "65/65 [==============================] - 30s 469ms/step - loss: 9.7398e-04 - mse: 9.7398e-04 - mae: 0.0186 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0171\n",
      "Epoch 38/180\n",
      "65/65 [==============================] - 31s 475ms/step - loss: 9.6517e-04 - mse: 9.6517e-04 - mae: 0.0184 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0171\n",
      "Epoch 39/180\n",
      "65/65 [==============================] - 33s 510ms/step - loss: 9.5591e-04 - mse: 9.5591e-04 - mae: 0.0185 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0175\n",
      "Epoch 40/180\n",
      "65/65 [==============================] - 30s 460ms/step - loss: 9.6284e-04 - mse: 9.6284e-04 - mae: 0.0184 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0171\n",
      "Epoch 41/180\n",
      "65/65 [==============================] - 32s 485ms/step - loss: 9.5154e-04 - mse: 9.5154e-04 - mae: 0.0183 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0170\n",
      "Epoch 42/180\n",
      "65/65 [==============================] - 29s 452ms/step - loss: 9.5474e-04 - mse: 9.5474e-04 - mae: 0.0184 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0172\n",
      "Epoch 43/180\n",
      "65/65 [==============================] - 32s 492ms/step - loss: 9.5071e-04 - mse: 9.5071e-04 - mae: 0.0182 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0172\n",
      "Epoch 44/180\n",
      "65/65 [==============================] - 31s 473ms/step - loss: 9.4321e-04 - mse: 9.4321e-04 - mae: 0.0182 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0170\n",
      "Epoch 45/180\n",
      "65/65 [==============================] - 30s 464ms/step - loss: 9.3059e-04 - mse: 9.3059e-04 - mae: 0.0180 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0173\n",
      "Epoch 46/180\n",
      "65/65 [==============================] - 33s 501ms/step - loss: 9.4223e-04 - mse: 9.4223e-04 - mae: 0.0181 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0171\n",
      "Epoch 47/180\n",
      "65/65 [==============================] - 34s 527ms/step - loss: 9.3461e-04 - mse: 9.3461e-04 - mae: 0.0181 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0170\n",
      "Epoch 48/180\n",
      "65/65 [==============================] - 31s 475ms/step - loss: 9.4132e-04 - mse: 9.4132e-04 - mae: 0.0182 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0174\n",
      "Epoch 49/180\n",
      "65/65 [==============================] - 30s 465ms/step - loss: 9.3708e-04 - mse: 9.3708e-04 - mae: 0.0181 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0169\n",
      "Epoch 50/180\n",
      "65/65 [==============================] - 34s 522ms/step - loss: 9.3546e-04 - mse: 9.3546e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0171\n",
      "Epoch 51/180\n",
      "65/65 [==============================] - 31s 481ms/step - loss: 9.3368e-04 - mse: 9.3368e-04 - mae: 0.0180 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0171\n",
      "Epoch 52/180\n",
      "65/65 [==============================] - 33s 504ms/step - loss: 9.3598e-04 - mse: 9.3598e-04 - mae: 0.0180 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0169\n",
      "Epoch 53/180\n",
      "65/65 [==============================] - 34s 516ms/step - loss: 9.2966e-04 - mse: 9.2966e-04 - mae: 0.0180 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0173\n",
      "Epoch 54/180\n",
      "65/65 [==============================] - 35s 543ms/step - loss: 9.3071e-04 - mse: 9.3071e-04 - mae: 0.0180 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0169\n",
      "Epoch 55/180\n",
      "65/65 [==============================] - 36s 547ms/step - loss: 9.2653e-04 - mse: 9.2653e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0169\n",
      "Epoch 56/180\n",
      "65/65 [==============================] - 35s 540ms/step - loss: 9.2439e-04 - mse: 9.2439e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0172\n",
      "Epoch 57/180\n",
      "65/65 [==============================] - 34s 523ms/step - loss: 9.2605e-04 - mse: 9.2605e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0168\n",
      "Epoch 58/180\n",
      "65/65 [==============================] - 34s 518ms/step - loss: 9.2015e-04 - mse: 9.2015e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0169\n",
      "Epoch 59/180\n",
      "65/65 [==============================] - 30s 469ms/step - loss: 9.2882e-04 - mse: 9.2882e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0169\n",
      "Epoch 60/180\n",
      "65/65 [==============================] - 32s 497ms/step - loss: 9.2804e-04 - mse: 9.2804e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0171\n",
      "Epoch 61/180\n",
      "65/65 [==============================] - 31s 469ms/step - loss: 9.2375e-04 - mse: 9.2375e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0167\n",
      "Epoch 62/180\n",
      "65/65 [==============================] - 32s 497ms/step - loss: 9.2663e-04 - mse: 9.2663e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0167\n",
      "Epoch 63/180\n",
      "65/65 [==============================] - 34s 519ms/step - loss: 9.1746e-04 - mse: 9.1746e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0168\n",
      "Epoch 64/180\n",
      "65/65 [==============================] - 33s 515ms/step - loss: 9.2093e-04 - mse: 9.2093e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0170\n",
      "Epoch 65/180\n",
      "65/65 [==============================] - 36s 555ms/step - loss: 9.1805e-04 - mse: 9.1805e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0165\n",
      "Epoch 66/180\n",
      "65/65 [==============================] - 36s 559ms/step - loss: 9.1297e-04 - mse: 9.1297e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0170\n",
      "Epoch 67/180\n",
      "65/65 [==============================] - 32s 490ms/step - loss: 9.0675e-04 - mse: 9.0675e-04 - mae: 0.0176 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0173\n",
      "Epoch 68/180\n",
      "65/65 [==============================] - 36s 558ms/step - loss: 9.1268e-04 - mse: 9.1268e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0169\n",
      "Epoch 69/180\n",
      "65/65 [==============================] - 32s 500ms/step - loss: 9.0950e-04 - mse: 9.0950e-04 - mae: 0.0175 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0171\n",
      "Epoch 70/180\n",
      "65/65 [==============================] - 31s 483ms/step - loss: 9.0892e-04 - mse: 9.0892e-04 - mae: 0.0176 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0172\n",
      "Epoch 71/180\n",
      "65/65 [==============================] - 30s 457ms/step - loss: 9.0510e-04 - mse: 9.0510e-04 - mae: 0.0175 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0169\n",
      "Epoch 72/180\n",
      "65/65 [==============================] - 30s 455ms/step - loss: 9.1497e-04 - mse: 9.1497e-04 - mae: 0.0177 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0171\n",
      "Epoch 73/180\n",
      "65/65 [==============================] - 28s 431ms/step - loss: 9.0396e-04 - mse: 9.0396e-04 - mae: 0.0175 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0170\n",
      "Epoch 74/180\n",
      "65/65 [==============================] - 28s 437ms/step - loss: 9.0546e-04 - mse: 9.0546e-04 - mae: 0.0175 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0168\n",
      "Epoch 75/180\n",
      "65/65 [==============================] - 28s 432ms/step - loss: 9.0004e-04 - mse: 9.0004e-04 - mae: 0.0176 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0172\n",
      "Epoch 76/180\n",
      "65/65 [==============================] - 29s 453ms/step - loss: 8.9774e-04 - mse: 8.9774e-04 - mae: 0.0174 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0171\n",
      "Epoch 77/180\n",
      "65/65 [==============================] - 28s 438ms/step - loss: 9.0028e-04 - mse: 9.0028e-04 - mae: 0.0174 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0166\n",
      "Epoch 78/180\n",
      "65/65 [==============================] - 28s 438ms/step - loss: 9.0685e-04 - mse: 9.0685e-04 - mae: 0.0175 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0174\n",
      "Epoch 79/180\n",
      "65/65 [==============================] - 28s 432ms/step - loss: 9.0009e-04 - mse: 9.0009e-04 - mae: 0.0174 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0171\n",
      "Epoch 80/180\n",
      "65/65 [==============================] - 30s 455ms/step - loss: 8.9487e-04 - mse: 8.9487e-04 - mae: 0.0174 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0171\n",
      "Epoch 81/180\n",
      "65/65 [==============================] - 28s 435ms/step - loss: 9.0191e-04 - mse: 9.0191e-04 - mae: 0.0174 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0169\n",
      "Epoch 82/180\n",
      "65/65 [==============================] - 28s 436ms/step - loss: 8.9719e-04 - mse: 8.9719e-04 - mae: 0.0173 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0172\n",
      "Epoch 83/180\n",
      "65/65 [==============================] - 28s 431ms/step - loss: 8.9928e-04 - mse: 8.9928e-04 - mae: 0.0173 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0170\n",
      "Epoch 84/180\n",
      "65/65 [==============================] - 29s 447ms/step - loss: 8.8917e-04 - mse: 8.8917e-04 - mae: 0.0172 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0171\n",
      "Epoch 85/180\n",
      "65/65 [==============================] - 28s 438ms/step - loss: 8.9334e-04 - mse: 8.9334e-04 - mae: 0.0173 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0173\n",
      "Epoch 86/180\n",
      "65/65 [==============================] - 28s 437ms/step - loss: 9.1081e-04 - mse: 9.1081e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0174\n",
      "Epoch 87/180\n",
      "65/65 [==============================] - 28s 431ms/step - loss: 8.9519e-04 - mse: 8.9519e-04 - mae: 0.0174 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0171\n",
      "Epoch 88/180\n",
      "65/65 [==============================] - 29s 441ms/step - loss: 8.8947e-04 - mse: 8.8947e-04 - mae: 0.0173 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0172\n",
      "Epoch 89/180\n",
      "65/65 [==============================] - 28s 435ms/step - loss: 8.8093e-04 - mse: 8.8093e-04 - mae: 0.0171 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0164\n",
      "Epoch 90/180\n",
      "65/65 [==============================] - 30s 455ms/step - loss: 8.9583e-04 - mse: 8.9583e-04 - mae: 0.0175 - val_loss: 9.6073e-04 - val_mse: 9.6073e-04 - val_mae: 0.0163\n",
      "Epoch 91/180\n",
      "65/65 [==============================] - 27s 421ms/step - loss: 8.9993e-04 - mse: 8.9993e-04 - mae: 0.0173 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0174\n",
      "Epoch 92/180\n",
      "65/65 [==============================] - 27s 413ms/step - loss: 8.8950e-04 - mse: 8.8950e-04 - mae: 0.0173 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0181\n",
      "Epoch 93/180\n",
      "65/65 [==============================] - 26s 406ms/step - loss: 8.9374e-04 - mse: 8.9374e-04 - mae: 0.0173 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0174\n",
      "Epoch 94/180\n",
      "65/65 [==============================] - 26s 400ms/step - loss: 8.8945e-04 - mse: 8.8945e-04 - mae: 0.0172 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0170\n",
      "Epoch 95/180\n",
      "65/65 [==============================] - 25s 391ms/step - loss: 8.8631e-04 - mse: 8.8631e-04 - mae: 0.0172 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0166\n",
      "Epoch 96/180\n",
      "65/65 [==============================] - 26s 393ms/step - loss: 8.8927e-04 - mse: 8.8927e-04 - mae: 0.0173 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0174\n",
      "Epoch 97/180\n",
      "65/65 [==============================] - 27s 415ms/step - loss: 8.8412e-04 - mse: 8.8412e-04 - mae: 0.0172 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0169\n",
      "Epoch 98/180\n",
      "65/65 [==============================] - 26s 396ms/step - loss: 8.8923e-04 - mse: 8.8923e-04 - mae: 0.0172 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0170\n",
      "Epoch 99/180\n",
      "65/65 [==============================] - 26s 402ms/step - loss: 8.8802e-04 - mse: 8.8802e-04 - mae: 0.0173 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0171\n",
      "Epoch 100/180\n",
      "65/65 [==============================] - 26s 395ms/step - loss: 8.8290e-04 - mse: 8.8290e-04 - mae: 0.0172 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0169\n",
      "Epoch 101/180\n",
      "65/65 [==============================] - 25s 392ms/step - loss: 8.7908e-04 - mse: 8.7908e-04 - mae: 0.0171 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0170\n",
      "Epoch 102/180\n",
      "65/65 [==============================] - 27s 411ms/step - loss: 8.8454e-04 - mse: 8.8454e-04 - mae: 0.0172 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0168\n",
      "Epoch 103/180\n",
      "65/65 [==============================] - 25s 380ms/step - loss: 8.8408e-04 - mse: 8.8408e-04 - mae: 0.0171 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0168\n",
      "Epoch 104/180\n",
      "65/65 [==============================] - 25s 387ms/step - loss: 8.9199e-04 - mse: 8.9199e-04 - mae: 0.0173 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0167\n",
      "Epoch 105/180\n",
      "65/65 [==============================] - 25s 389ms/step - loss: 8.7460e-04 - mse: 8.7460e-04 - mae: 0.0170 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0170\n",
      "Epoch 106/180\n",
      "65/65 [==============================] - 26s 395ms/step - loss: 8.8070e-04 - mse: 8.8070e-04 - mae: 0.0171 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0172\n",
      "Epoch 107/180\n",
      "65/65 [==============================] - 25s 389ms/step - loss: 8.8388e-04 - mse: 8.8388e-04 - mae: 0.0172 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0165\n",
      "Epoch 108/180\n",
      "65/65 [==============================] - 25s 389ms/step - loss: 8.8406e-04 - mse: 8.8406e-04 - mae: 0.0172 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0165\n",
      "Epoch 109/180\n",
      "65/65 [==============================] - 25s 392ms/step - loss: 8.7559e-04 - mse: 8.7559e-04 - mae: 0.0170 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110/180\n",
      "65/65 [==============================] - 25s 380ms/step - loss: 8.7974e-04 - mse: 8.7974e-04 - mae: 0.0172 - val_loss: 9.6970e-04 - val_mse: 9.6970e-04 - val_mae: 0.0168\n",
      "Epoch 111/180\n",
      "65/65 [==============================] - 27s 413ms/step - loss: 8.6853e-04 - mse: 8.6853e-04 - mae: 0.0169 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0167\n",
      "Epoch 112/180\n",
      "65/65 [==============================] - 25s 392ms/step - loss: 8.7389e-04 - mse: 8.7389e-04 - mae: 0.0170 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0164\n",
      "Epoch 113/180\n",
      "65/65 [==============================] - 26s 403ms/step - loss: 8.6806e-04 - mse: 8.6806e-04 - mae: 0.0169 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0162\n",
      "Epoch 114/180\n",
      "65/65 [==============================] - 26s 408ms/step - loss: 8.9395e-04 - mse: 8.9395e-04 - mae: 0.0173 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0168\n",
      "Epoch 115/180\n",
      "65/65 [==============================] - 25s 389ms/step - loss: 8.8432e-04 - mse: 8.8432e-04 - mae: 0.0173 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0169\n",
      "Epoch 116/180\n",
      "65/65 [==============================] - 26s 403ms/step - loss: 8.6850e-04 - mse: 8.6850e-04 - mae: 0.0169 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0161\n",
      "Epoch 117/180\n",
      "65/65 [==============================] - 25s 382ms/step - loss: 8.6521e-04 - mse: 8.6521e-04 - mae: 0.0169 - val_loss: 9.8990e-04 - val_mse: 9.8990e-04 - val_mae: 0.0163\n",
      "Epoch 118/180\n",
      "65/65 [==============================] - 25s 380ms/step - loss: 8.9233e-04 - mse: 8.9233e-04 - mae: 0.0174 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0178\n",
      "Epoch 119/180\n",
      "65/65 [==============================] - 25s 385ms/step - loss: 8.7455e-04 - mse: 8.7455e-04 - mae: 0.0170 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0161\n",
      "Epoch 120/180\n",
      "65/65 [==============================] - 26s 407ms/step - loss: 8.7543e-04 - mse: 8.7543e-04 - mae: 0.0170 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0160\n",
      "Epoch 121/180\n",
      "65/65 [==============================] - 25s 383ms/step - loss: 8.6968e-04 - mse: 8.6968e-04 - mae: 0.0170 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0166\n",
      "Epoch 122/180\n",
      "65/65 [==============================] - 25s 382ms/step - loss: 8.7091e-04 - mse: 8.7091e-04 - mae: 0.0170 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0172\n",
      "Epoch 123/180\n",
      "65/65 [==============================] - 25s 384ms/step - loss: 8.7505e-04 - mse: 8.7505e-04 - mae: 0.0170 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0168\n",
      "Epoch 124/180\n",
      "65/65 [==============================] - 25s 382ms/step - loss: 8.9981e-04 - mse: 8.9981e-04 - mae: 0.0175 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0184\n",
      "Epoch 125/180\n",
      "65/65 [==============================] - 26s 404ms/step - loss: 8.9518e-04 - mse: 8.9518e-04 - mae: 0.0174 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0171\n",
      "Epoch 126/180\n",
      "65/65 [==============================] - 25s 390ms/step - loss: 8.8460e-04 - mse: 8.8460e-04 - mae: 0.0172 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0166\n",
      "Epoch 127/180\n",
      "65/65 [==============================] - 28s 429ms/step - loss: 8.7972e-04 - mse: 8.7972e-04 - mae: 0.0171 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0166\n",
      "Epoch 128/180\n",
      "65/65 [==============================] - 34s 529ms/step - loss: 9.0373e-04 - mse: 9.0373e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 129/180\n",
      "65/65 [==============================] - 30s 459ms/step - loss: 8.8637e-04 - mse: 8.8637e-04 - mae: 0.0173 - val_loss: 9.9640e-04 - val_mse: 9.9640e-04 - val_mae: 0.0166\n",
      "Epoch 130/180\n",
      "65/65 [==============================] - 26s 403ms/step - loss: 8.7274e-04 - mse: 8.7274e-04 - mae: 0.0169 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0162\n",
      "Epoch 131/180\n",
      "65/65 [==============================] - 27s 411ms/step - loss: 8.7740e-04 - mse: 8.7740e-04 - mae: 0.0171 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0171\n",
      "Epoch 132/180\n",
      "65/65 [==============================] - 26s 394ms/step - loss: 8.8366e-04 - mse: 8.8366e-04 - mae: 0.0172 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0163\n",
      "Epoch 133/180\n",
      "65/65 [==============================] - 26s 404ms/step - loss: 8.8473e-04 - mse: 8.8473e-04 - mae: 0.0172 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0168\n",
      "Epoch 134/180\n",
      "65/65 [==============================] - 27s 409ms/step - loss: 8.8552e-04 - mse: 8.8552e-04 - mae: 0.0173 - val_loss: 9.5650e-04 - val_mse: 9.5650e-04 - val_mae: 0.0164\n",
      "Epoch 135/180\n",
      "65/65 [==============================] - 26s 403ms/step - loss: 8.8764e-04 - mse: 8.8764e-04 - mae: 0.0173 - val_loss: 9.7258e-04 - val_mse: 9.7258e-04 - val_mae: 0.0170\n",
      "Epoch 136/180\n",
      "65/65 [==============================] - 27s 418ms/step - loss: 8.6555e-04 - mse: 8.6555e-04 - mae: 0.0169 - val_loss: 9.6296e-04 - val_mse: 9.6296e-04 - val_mae: 0.0162\n",
      "Epoch 137/180\n",
      "65/65 [==============================] - 28s 437ms/step - loss: 8.7191e-04 - mse: 8.7191e-04 - mae: 0.0169 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0165\n",
      "Epoch 138/180\n",
      "65/65 [==============================] - 27s 421ms/step - loss: 8.8638e-04 - mse: 8.8638e-04 - mae: 0.0172 - val_loss: 9.8497e-04 - val_mse: 9.8497e-04 - val_mae: 0.0173\n",
      "Epoch 139/180\n",
      "65/65 [==============================] - 25s 389ms/step - loss: 9.0501e-04 - mse: 9.0501e-04 - mae: 0.0177 - val_loss: 9.8422e-04 - val_mse: 9.8422e-04 - val_mae: 0.0185\n",
      "Epoch 140/180\n",
      "65/65 [==============================] - 25s 378ms/step - loss: 8.9257e-04 - mse: 8.9257e-04 - mae: 0.0173 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0170\n",
      "Epoch 141/180\n",
      "65/65 [==============================] - 25s 386ms/step - loss: 8.9270e-04 - mse: 8.9270e-04 - mae: 0.0174 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0171\n",
      "Epoch 142/180\n",
      "65/65 [==============================] - 26s 396ms/step - loss: 8.8831e-04 - mse: 8.8831e-04 - mae: 0.0173 - val_loss: 9.9357e-04 - val_mse: 9.9357e-04 - val_mae: 0.0165\n",
      "Epoch 143/180\n",
      "65/65 [==============================] - 26s 400ms/step - loss: 9.0781e-04 - mse: 9.0781e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0191\n",
      "Epoch 144/180\n",
      "65/65 [==============================] - 25s 379ms/step - loss: 9.1135e-04 - mse: 9.1135e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0188\n",
      "Epoch 145/180\n",
      "65/65 [==============================] - 25s 384ms/step - loss: 9.1061e-04 - mse: 9.1061e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0189\n",
      "Epoch 146/180\n",
      "65/65 [==============================] - 25s 392ms/step - loss: 9.0814e-04 - mse: 9.0814e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0188\n",
      "Epoch 147/180\n",
      "65/65 [==============================] - 26s 400ms/step - loss: 9.0936e-04 - mse: 9.0936e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 148/180\n",
      "65/65 [==============================] - 25s 380ms/step - loss: 9.0453e-04 - mse: 9.0453e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0188\n",
      "Epoch 149/180\n",
      "65/65 [==============================] - 25s 383ms/step - loss: 9.0007e-04 - mse: 9.0007e-04 - mae: 0.0176 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0188\n",
      "Epoch 150/180\n",
      "65/65 [==============================] - 25s 381ms/step - loss: 8.8860e-04 - mse: 8.8860e-04 - mae: 0.0173 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0178\n",
      "Epoch 151/180\n",
      "65/65 [==============================] - 25s 380ms/step - loss: 8.7585e-04 - mse: 8.7585e-04 - mae: 0.0170 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0171\n",
      "Epoch 152/180\n",
      "65/65 [==============================] - 26s 401ms/step - loss: 8.7402e-04 - mse: 8.7402e-04 - mae: 0.0171 - val_loss: 9.9617e-04 - val_mse: 9.9617e-04 - val_mae: 0.0180\n",
      "Epoch 153/180\n",
      "65/65 [==============================] - 25s 378ms/step - loss: 8.7330e-04 - mse: 8.7330e-04 - mae: 0.0169 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0171\n",
      "Epoch 154/180\n",
      "65/65 [==============================] - 25s 386ms/step - loss: 8.8162e-04 - mse: 8.8162e-04 - mae: 0.0172 - val_loss: 9.7563e-04 - val_mse: 9.7563e-04 - val_mae: 0.0177\n",
      "Epoch 155/180\n",
      "65/65 [==============================] - 26s 398ms/step - loss: 8.7177e-04 - mse: 8.7177e-04 - mae: 0.0170 - val_loss: 9.8911e-04 - val_mse: 9.8911e-04 - val_mae: 0.0167\n",
      "Epoch 156/180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 26s 400ms/step - loss: 8.7230e-04 - mse: 8.7230e-04 - mae: 0.0170 - val_loss: 9.6010e-04 - val_mse: 9.6010e-04 - val_mae: 0.0171\n",
      "Epoch 157/180\n",
      "65/65 [==============================] - 28s 425ms/step - loss: 8.6911e-04 - mse: 8.6911e-04 - mae: 0.0169 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0168\n",
      "Epoch 158/180\n",
      "65/65 [==============================] - 27s 409ms/step - loss: 8.8003e-04 - mse: 8.8003e-04 - mae: 0.0172 - val_loss: 9.8200e-04 - val_mse: 9.8200e-04 - val_mae: 0.0163\n",
      "Epoch 159/180\n",
      "65/65 [==============================] - 27s 409ms/step - loss: 8.6949e-04 - mse: 8.6949e-04 - mae: 0.0170 - val_loss: 9.5106e-04 - val_mse: 9.5106e-04 - val_mae: 0.0180\n",
      "Epoch 160/180\n",
      "65/65 [==============================] - 25s 390ms/step - loss: 8.7504e-04 - mse: 8.7504e-04 - mae: 0.0170 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0175\n",
      "Epoch 161/180\n",
      "65/65 [==============================] - 26s 400ms/step - loss: 9.0415e-04 - mse: 9.0415e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0187\n",
      "Epoch 162/180\n",
      "65/65 [==============================] - 25s 386ms/step - loss: 8.9002e-04 - mse: 8.9002e-04 - mae: 0.0174 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0176\n",
      "Epoch 163/180\n",
      "65/65 [==============================] - 25s 385ms/step - loss: 8.8702e-04 - mse: 8.8702e-04 - mae: 0.0173 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0183\n",
      "Epoch 164/180\n",
      "65/65 [==============================] - 25s 388ms/step - loss: 8.8586e-04 - mse: 8.8586e-04 - mae: 0.0172 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0180\n",
      "Epoch 165/180\n",
      "65/65 [==============================] - 25s 390ms/step - loss: 9.0410e-04 - mse: 9.0410e-04 - mae: 0.0175 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0191\n",
      "Epoch 166/180\n",
      "65/65 [==============================] - 26s 405ms/step - loss: 8.9141e-04 - mse: 8.9141e-04 - mae: 0.0174 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0174\n",
      "Epoch 167/180\n",
      "65/65 [==============================] - 25s 381ms/step - loss: 8.9231e-04 - mse: 8.9231e-04 - mae: 0.0175 - val_loss: 9.7791e-04 - val_mse: 9.7791e-04 - val_mae: 0.0182\n",
      "Epoch 168/180\n",
      "65/65 [==============================] - 25s 383ms/step - loss: 8.9215e-04 - mse: 8.9215e-04 - mae: 0.0174 - val_loss: 9.8714e-04 - val_mse: 9.8714e-04 - val_mae: 0.0173\n",
      "Epoch 169/180\n",
      "65/65 [==============================] - 25s 389ms/step - loss: 8.7728e-04 - mse: 8.7728e-04 - mae: 0.0171 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0171\n",
      "Epoch 170/180\n",
      "65/65 [==============================] - 27s 418ms/step - loss: 8.9453e-04 - mse: 8.9453e-04 - mae: 0.0175 - val_loss: 9.2468e-04 - val_mse: 9.2468e-04 - val_mae: 0.0173\n",
      "Epoch 171/180\n",
      "65/65 [==============================] - 25s 383ms/step - loss: 8.6103e-04 - mse: 8.6103e-04 - mae: 0.0168 - val_loss: 9.8537e-04 - val_mse: 9.8537e-04 - val_mae: 0.0167\n",
      "Epoch 172/180\n",
      "65/65 [==============================] - 25s 382ms/step - loss: 8.7443e-04 - mse: 8.7443e-04 - mae: 0.0171 - val_loss: 9.6802e-04 - val_mse: 9.6802e-04 - val_mae: 0.0169\n",
      "Epoch 173/180\n",
      "65/65 [==============================] - 25s 388ms/step - loss: 8.6686e-04 - mse: 8.6686e-04 - mae: 0.0169 - val_loss: 9.9641e-04 - val_mse: 9.9641e-04 - val_mae: 0.0169\n",
      "Epoch 174/180\n",
      "65/65 [==============================] - 25s 382ms/step - loss: 8.7280e-04 - mse: 8.7280e-04 - mae: 0.0170 - val_loss: 9.6779e-04 - val_mse: 9.6779e-04 - val_mae: 0.0173\n",
      "Epoch 175/180\n",
      "65/65 [==============================] - 26s 402ms/step - loss: 8.6718e-04 - mse: 8.6718e-04 - mae: 0.0169 - val_loss: 9.4248e-04 - val_mse: 9.4248e-04 - val_mae: 0.0168\n",
      "Epoch 176/180\n",
      "65/65 [==============================] - 25s 378ms/step - loss: 8.6851e-04 - mse: 8.6851e-04 - mae: 0.0169 - val_loss: 9.8705e-04 - val_mse: 9.8705e-04 - val_mae: 0.0166\n",
      "Epoch 177/180\n",
      "65/65 [==============================] - 25s 388ms/step - loss: 8.8057e-04 - mse: 8.8057e-04 - mae: 0.0173 - val_loss: 9.3179e-04 - val_mse: 9.3179e-04 - val_mae: 0.0168\n",
      "Epoch 178/180\n",
      "65/65 [==============================] - 25s 378ms/step - loss: 8.5803e-04 - mse: 8.5803e-04 - mae: 0.0168 - val_loss: 9.5088e-04 - val_mse: 9.5088e-04 - val_mae: 0.0165\n",
      "Epoch 179/180\n",
      "65/65 [==============================] - 25s 384ms/step - loss: 9.1014e-04 - mse: 9.1014e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0192\n",
      "Epoch 180/180\n",
      "65/65 [==============================] - 26s 402ms/step - loss: 9.1195e-04 - mse: 9.1195e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0190\n",
      "Epoch 1/180\n",
      "65/65 [==============================] - 28s 431ms/step - loss: 0.1733 - mse: 0.1733 - mae: 0.3282 - val_loss: 0.0018 - val_mse: 0.0018 - val_mae: 0.0281\n",
      "Epoch 2/180\n",
      "65/65 [==============================] - 28s 431ms/step - loss: 0.0925 - mse: 0.0925 - mae: 0.2407 - val_loss: 0.0014 - val_mse: 0.0014 - val_mae: 0.0232\n",
      "Epoch 3/180\n",
      "65/65 [==============================] - 26s 405ms/step - loss: 0.0584 - mse: 0.0584 - mae: 0.1921 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0213\n",
      "Epoch 4/180\n",
      "65/65 [==============================] - 28s 426ms/step - loss: 0.0373 - mse: 0.0373 - mae: 0.1541 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0240\n",
      "Epoch 5/180\n",
      "65/65 [==============================] - 26s 407ms/step - loss: 0.0244 - mse: 0.0244 - mae: 0.1241 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0241\n",
      "Epoch 6/180\n",
      "65/65 [==============================] - 27s 411ms/step - loss: 0.0179 - mse: 0.0179 - mae: 0.1065 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0194\n",
      "Epoch 7/180\n",
      "65/65 [==============================] - 27s 422ms/step - loss: 0.0135 - mse: 0.0135 - mae: 0.0924 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0217\n",
      "Epoch 8/180\n",
      "65/65 [==============================] - 31s 483ms/step - loss: 0.0106 - mse: 0.0106 - mae: 0.0811 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0227\n",
      "Epoch 9/180\n",
      "65/65 [==============================] - 27s 414ms/step - loss: 0.0089 - mse: 0.0089 - mae: 0.0740 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0216\n",
      "Epoch 10/180\n",
      "65/65 [==============================] - 26s 407ms/step - loss: 0.0074 - mse: 0.0074 - mae: 0.0680 - val_loss: 0.0015 - val_mse: 0.0015 - val_mae: 0.0306\n",
      "Epoch 11/180\n",
      "65/65 [==============================] - 26s 405ms/step - loss: 0.0062 - mse: 0.0062 - mae: 0.0610 - val_loss: 0.0019 - val_mse: 0.0019 - val_mae: 0.0350\n",
      "Epoch 12/180\n",
      "65/65 [==============================] - 27s 419ms/step - loss: 0.0053 - mse: 0.0053 - mae: 0.0563 - val_loss: 0.0014 - val_mse: 0.0014 - val_mae: 0.0255\n",
      "Epoch 13/180\n",
      "65/65 [==============================] - 27s 418ms/step - loss: 0.0045 - mse: 0.0045 - mae: 0.0513 - val_loss: 0.0015 - val_mse: 0.0015 - val_mae: 0.0299\n",
      "Epoch 14/180\n",
      "65/65 [==============================] - 27s 422ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0492 - val_loss: 0.0015 - val_mse: 0.0015 - val_mae: 0.0292\n",
      "Epoch 15/180\n",
      "65/65 [==============================] - 27s 409ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0460 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0266\n",
      "Epoch 16/180\n",
      "65/65 [==============================] - 27s 414ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0438 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0240\n",
      "Epoch 17/180\n",
      "65/65 [==============================] - 28s 437ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0412 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0249\n",
      "Epoch 18/180\n",
      "65/65 [==============================] - 27s 408ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0393 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0252\n",
      "Epoch 19/180\n",
      "65/65 [==============================] - 27s 413ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0374 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0214\n",
      "Epoch 20/180\n",
      "65/65 [==============================] - 27s 410ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0360 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0219\n",
      "Epoch 21/180\n",
      "65/65 [==============================] - 28s 432ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0346 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0216\n",
      "Epoch 22/180\n",
      "65/65 [==============================] - 27s 408ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0328 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0212\n",
      "Epoch 23/180\n",
      "65/65 [==============================] - 28s 438ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0320 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0201\n",
      "Epoch 24/180\n",
      "65/65 [==============================] - 29s 441ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0311 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0210\n",
      "Epoch 25/180\n",
      "65/65 [==============================] - 27s 418ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0298 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0196\n",
      "Epoch 26/180\n",
      "65/65 [==============================] - 27s 414ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0294 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0202\n",
      "Epoch 27/180\n",
      "65/65 [==============================] - 27s 415ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0283 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0217\n",
      "Epoch 28/180\n",
      "65/65 [==============================] - 35s 533ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0274 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0194\n",
      "Epoch 29/180\n",
      "65/65 [==============================] - 33s 510ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0265 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0204\n",
      "Epoch 30/180\n",
      "65/65 [==============================] - 36s 549ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0261 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 31/180\n",
      "65/65 [==============================] - 32s 497ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0253 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0205\n",
      "Epoch 32/180\n",
      "65/65 [==============================] - 38s 591ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0244 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0201\n",
      "Epoch 33/180\n",
      "65/65 [==============================] - 37s 562ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0240 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0187\n",
      "Epoch 34/180\n",
      "65/65 [==============================] - 34s 516ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0238 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0192\n",
      "Epoch 35/180\n",
      "65/65 [==============================] - 35s 537ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0236 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0199\n",
      "Epoch 36/180\n",
      "65/65 [==============================] - 38s 583ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0232 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0208\n",
      "Epoch 37/180\n",
      "65/65 [==============================] - 32s 495ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0229 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0218\n",
      "Epoch 38/180\n",
      "65/65 [==============================] - 30s 463ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0225 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0201\n",
      "Epoch 39/180\n",
      "65/65 [==============================] - 34s 520ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0220 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0208\n",
      "Epoch 40/180\n",
      "65/65 [==============================] - 37s 567ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0221 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0224\n",
      "Epoch 41/180\n",
      "65/65 [==============================] - 37s 575ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0218 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0217\n",
      "Epoch 42/180\n",
      "65/65 [==============================] - 36s 559ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0211 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0209\n",
      "Epoch 43/180\n",
      "65/65 [==============================] - 35s 534ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0212 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0221\n",
      "Epoch 44/180\n",
      "65/65 [==============================] - 32s 500ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0209 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0208\n",
      "Epoch 45/180\n",
      "65/65 [==============================] - 32s 485ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0208 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0215\n",
      "Epoch 46/180\n",
      "65/65 [==============================] - 36s 549ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0208 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0216\n",
      "Epoch 47/180\n",
      "65/65 [==============================] - 34s 524ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0203 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0206\n",
      "Epoch 48/180\n",
      "65/65 [==============================] - 32s 492ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0203 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0205\n",
      "Epoch 49/180\n",
      "65/65 [==============================] - 32s 499ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0204 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0217\n",
      "Epoch 50/180\n",
      "65/65 [==============================] - 32s 499ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0201 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0212\n",
      "Epoch 51/180\n",
      "65/65 [==============================] - 31s 477ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0200 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0215\n",
      "Epoch 52/180\n",
      "65/65 [==============================] - 36s 551ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0199 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0214\n",
      "Epoch 53/180\n",
      "65/65 [==============================] - 36s 550ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0196 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0215\n",
      "Epoch 54/180\n",
      "65/65 [==============================] - 36s 551ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0195 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0217\n",
      "Epoch 55/180\n",
      "65/65 [==============================] - 32s 499ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0195 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0212\n",
      "Epoch 56/180\n",
      "65/65 [==============================] - 32s 487ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0194 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0211\n",
      "Epoch 57/180\n",
      "65/65 [==============================] - 32s 500ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0193 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0211\n",
      "Epoch 58/180\n",
      "65/65 [==============================] - 31s 480ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0193 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0212\n",
      "Epoch 59/180\n",
      "65/65 [==============================] - 33s 510ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0193 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0212\n",
      "Epoch 60/180\n",
      "65/65 [==============================] - 32s 492ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0191 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0208\n",
      "Epoch 61/180\n",
      "65/65 [==============================] - 31s 485ms/step - loss: 9.8718e-04 - mse: 9.8718e-04 - mae: 0.0188 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0214\n",
      "Epoch 62/180\n",
      "65/65 [==============================] - 31s 481ms/step - loss: 9.9586e-04 - mse: 9.9586e-04 - mae: 0.0190 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0210\n",
      "Epoch 63/180\n",
      "65/65 [==============================] - 31s 475ms/step - loss: 9.9509e-04 - mse: 9.9509e-04 - mae: 0.0190 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0202\n",
      "Epoch 64/180\n",
      "65/65 [==============================] - 35s 536ms/step - loss: 9.8706e-04 - mse: 9.8706e-04 - mae: 0.0188 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0211\n",
      "Epoch 65/180\n",
      "65/65 [==============================] - 36s 557ms/step - loss: 9.7747e-04 - mse: 9.7747e-04 - mae: 0.0188 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0198\n",
      "Epoch 66/180\n",
      "65/65 [==============================] - 31s 472ms/step - loss: 9.8427e-04 - mse: 9.8427e-04 - mae: 0.0187 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0206\n",
      "Epoch 67/180\n",
      "65/65 [==============================] - 33s 509ms/step - loss: 9.8267e-04 - mse: 9.8267e-04 - mae: 0.0188 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0205\n",
      "Epoch 68/180\n",
      "65/65 [==============================] - 32s 498ms/step - loss: 9.7034e-04 - mse: 9.7034e-04 - mae: 0.0185 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0205\n",
      "Epoch 69/180\n",
      "65/65 [==============================] - 37s 567ms/step - loss: 9.7608e-04 - mse: 9.7608e-04 - mae: 0.0186 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0208\n",
      "Epoch 70/180\n",
      "65/65 [==============================] - 56s 858ms/step - loss: 9.6663e-04 - mse: 9.6663e-04 - mae: 0.0185 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0197\n",
      "Epoch 71/180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 42s 650ms/step - loss: 9.6583e-04 - mse: 9.6583e-04 - mae: 0.0183 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0208\n",
      "Epoch 72/180\n",
      "65/65 [==============================] - 40s 610ms/step - loss: 9.7034e-04 - mse: 9.7034e-04 - mae: 0.0186 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0200\n",
      "Epoch 73/180\n",
      "65/65 [==============================] - 45s 692ms/step - loss: 9.6204e-04 - mse: 9.6204e-04 - mae: 0.0184 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0201\n",
      "Epoch 74/180\n",
      "65/65 [==============================] - 40s 622ms/step - loss: 9.6342e-04 - mse: 9.6342e-04 - mae: 0.0184 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0204\n",
      "Epoch 75/180\n",
      "65/65 [==============================] - 38s 592ms/step - loss: 9.4926e-04 - mse: 9.4926e-04 - mae: 0.0183 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0204\n",
      "Epoch 76/180\n",
      "65/65 [==============================] - 38s 591ms/step - loss: 9.6299e-04 - mse: 9.6299e-04 - mae: 0.0184 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0204\n",
      "Epoch 77/180\n",
      "65/65 [==============================] - 42s 649ms/step - loss: 9.5291e-04 - mse: 9.5291e-04 - mae: 0.0181 - val_loss: 9.8913e-04 - val_mse: 9.8913e-04 - val_mae: 0.0194\n",
      "Epoch 78/180\n",
      "65/65 [==============================] - 34s 528ms/step - loss: 9.5003e-04 - mse: 9.5003e-04 - mae: 0.0182 - val_loss: 9.8980e-04 - val_mse: 9.8980e-04 - val_mae: 0.0191\n",
      "Epoch 79/180\n",
      "65/65 [==============================] - 34s 527ms/step - loss: 9.4959e-04 - mse: 9.4959e-04 - mae: 0.0181 - val_loss: 9.8826e-04 - val_mse: 9.8826e-04 - val_mae: 0.0186\n",
      "Epoch 80/180\n",
      "65/65 [==============================] - 35s 546ms/step - loss: 9.2915e-04 - mse: 9.2915e-04 - mae: 0.0179 - val_loss: 9.7779e-04 - val_mse: 9.7779e-04 - val_mae: 0.0191\n",
      "Epoch 81/180\n",
      "65/65 [==============================] - 36s 549ms/step - loss: 9.3891e-04 - mse: 9.3891e-04 - mae: 0.0181 - val_loss: 9.7567e-04 - val_mse: 9.7567e-04 - val_mae: 0.0187\n",
      "Epoch 82/180\n",
      "65/65 [==============================] - 34s 519ms/step - loss: 9.3509e-04 - mse: 9.3509e-04 - mae: 0.0180 - val_loss: 9.7289e-04 - val_mse: 9.7289e-04 - val_mae: 0.0190\n",
      "Epoch 83/180\n",
      "65/65 [==============================] - 35s 535ms/step - loss: 9.3832e-04 - mse: 9.3832e-04 - mae: 0.0179 - val_loss: 9.3728e-04 - val_mse: 9.3728e-04 - val_mae: 0.0170\n",
      "Epoch 84/180\n",
      "65/65 [==============================] - 32s 487ms/step - loss: 9.5495e-04 - mse: 9.5495e-04 - mae: 0.0183 - val_loss: 9.6282e-04 - val_mse: 9.6282e-04 - val_mae: 0.0197\n",
      "Epoch 85/180\n",
      "65/65 [==============================] - 41s 626ms/step - loss: 9.3585e-04 - mse: 9.3585e-04 - mae: 0.0180 - val_loss: 9.4987e-04 - val_mse: 9.4987e-04 - val_mae: 0.0197\n",
      "Epoch 86/180\n",
      "65/65 [==============================] - 35s 534ms/step - loss: 9.3120e-04 - mse: 9.3120e-04 - mae: 0.0179 - val_loss: 9.2457e-04 - val_mse: 9.2457e-04 - val_mae: 0.0192\n",
      "Epoch 87/180\n",
      "65/65 [==============================] - 34s 525ms/step - loss: 9.3925e-04 - mse: 9.3925e-04 - mae: 0.0180 - val_loss: 9.1107e-04 - val_mse: 9.1107e-04 - val_mae: 0.0181\n",
      "Epoch 88/180\n",
      "65/65 [==============================] - 32s 493ms/step - loss: 9.2782e-04 - mse: 9.2782e-04 - mae: 0.0178 - val_loss: 9.0643e-04 - val_mse: 9.0643e-04 - val_mae: 0.0181\n",
      "Epoch 89/180\n",
      "65/65 [==============================] - 36s 549ms/step - loss: 9.2502e-04 - mse: 9.2502e-04 - mae: 0.0177 - val_loss: 8.9734e-04 - val_mse: 8.9734e-04 - val_mae: 0.0184\n",
      "Epoch 90/180\n",
      "65/65 [==============================] - 33s 513ms/step - loss: 9.1750e-04 - mse: 9.1750e-04 - mae: 0.0177 - val_loss: 9.1775e-04 - val_mse: 9.1775e-04 - val_mae: 0.0177\n",
      "Epoch 91/180\n",
      "65/65 [==============================] - 32s 490ms/step - loss: 9.0581e-04 - mse: 9.0581e-04 - mae: 0.0175 - val_loss: 8.9778e-04 - val_mse: 8.9778e-04 - val_mae: 0.0175\n",
      "Epoch 92/180\n",
      "65/65 [==============================] - 36s 561ms/step - loss: 9.0609e-04 - mse: 9.0609e-04 - mae: 0.0175 - val_loss: 9.0330e-04 - val_mse: 9.0330e-04 - val_mae: 0.0177\n",
      "Epoch 93/180\n",
      "65/65 [==============================] - 36s 548ms/step - loss: 9.0317e-04 - mse: 9.0317e-04 - mae: 0.0175 - val_loss: 8.9204e-04 - val_mse: 8.9204e-04 - val_mae: 0.0179\n",
      "Epoch 94/180\n",
      "65/65 [==============================] - 31s 481ms/step - loss: 9.0427e-04 - mse: 9.0427e-04 - mae: 0.0176 - val_loss: 8.7007e-04 - val_mse: 8.7007e-04 - val_mae: 0.0183\n",
      "Epoch 95/180\n",
      "65/65 [==============================] - 31s 480ms/step - loss: 8.9051e-04 - mse: 8.9051e-04 - mae: 0.0173 - val_loss: 8.8221e-04 - val_mse: 8.8221e-04 - val_mae: 0.0178\n",
      "Epoch 96/180\n",
      "65/65 [==============================] - 33s 511ms/step - loss: 8.8910e-04 - mse: 8.8910e-04 - mae: 0.0174 - val_loss: 9.0741e-04 - val_mse: 9.0741e-04 - val_mae: 0.0176\n",
      "Epoch 97/180\n",
      "65/65 [==============================] - 38s 587ms/step - loss: 8.9388e-04 - mse: 8.9388e-04 - mae: 0.0173 - val_loss: 8.8117e-04 - val_mse: 8.8117e-04 - val_mae: 0.0181\n",
      "Epoch 98/180\n",
      "65/65 [==============================] - 30s 469ms/step - loss: 8.7886e-04 - mse: 8.7886e-04 - mae: 0.0171 - val_loss: 8.8291e-04 - val_mse: 8.8291e-04 - val_mae: 0.0169\n",
      "Epoch 99/180\n",
      "65/65 [==============================] - 32s 494ms/step - loss: 8.8427e-04 - mse: 8.8427e-04 - mae: 0.0172 - val_loss: 8.7539e-04 - val_mse: 8.7539e-04 - val_mae: 0.0169\n",
      "Epoch 100/180\n",
      "65/65 [==============================] - 36s 554ms/step - loss: 8.8529e-04 - mse: 8.8529e-04 - mae: 0.0172 - val_loss: 8.8698e-04 - val_mse: 8.8698e-04 - val_mae: 0.0176\n",
      "Epoch 101/180\n",
      "65/65 [==============================] - 31s 478ms/step - loss: 8.7799e-04 - mse: 8.7799e-04 - mae: 0.0172 - val_loss: 8.7088e-04 - val_mse: 8.7088e-04 - val_mae: 0.0167\n",
      "Epoch 102/180\n",
      "65/65 [==============================] - 31s 479ms/step - loss: 8.8224e-04 - mse: 8.8224e-04 - mae: 0.0172 - val_loss: 8.7497e-04 - val_mse: 8.7497e-04 - val_mae: 0.0183\n",
      "Epoch 103/180\n",
      "65/65 [==============================] - 34s 523ms/step - loss: 8.7598e-04 - mse: 8.7598e-04 - mae: 0.0170 - val_loss: 8.7672e-04 - val_mse: 8.7672e-04 - val_mae: 0.0162\n",
      "Epoch 104/180\n",
      "65/65 [==============================] - 40s 609ms/step - loss: 8.7306e-04 - mse: 8.7306e-04 - mae: 0.0170 - val_loss: 8.4824e-04 - val_mse: 8.4824e-04 - val_mae: 0.0167\n",
      "Epoch 105/180\n",
      "65/65 [==============================] - 38s 592ms/step - loss: 8.6797e-04 - mse: 8.6797e-04 - mae: 0.0169 - val_loss: 8.8933e-04 - val_mse: 8.8933e-04 - val_mae: 0.0157\n",
      "Epoch 106/180\n",
      "65/65 [==============================] - 33s 507ms/step - loss: 8.7827e-04 - mse: 8.7827e-04 - mae: 0.0172 - val_loss: 8.5493e-04 - val_mse: 8.5493e-04 - val_mae: 0.0173\n",
      "Epoch 107/180\n",
      "65/65 [==============================] - 37s 569ms/step - loss: 8.7568e-04 - mse: 8.7568e-04 - mae: 0.0170 - val_loss: 8.6372e-04 - val_mse: 8.6372e-04 - val_mae: 0.0190\n",
      "Epoch 108/180\n",
      "65/65 [==============================] - 34s 525ms/step - loss: 8.6649e-04 - mse: 8.6649e-04 - mae: 0.0169 - val_loss: 8.3511e-04 - val_mse: 8.3511e-04 - val_mae: 0.0175\n",
      "Epoch 109/180\n",
      "65/65 [==============================] - 37s 572ms/step - loss: 8.6384e-04 - mse: 8.6384e-04 - mae: 0.0169 - val_loss: 8.6438e-04 - val_mse: 8.6438e-04 - val_mae: 0.0192\n",
      "Epoch 110/180\n",
      "65/65 [==============================] - 36s 558ms/step - loss: 8.6065e-04 - mse: 8.6065e-04 - mae: 0.0167 - val_loss: 8.4952e-04 - val_mse: 8.4952e-04 - val_mae: 0.0184\n",
      "Epoch 111/180\n",
      "65/65 [==============================] - 34s 530ms/step - loss: 8.5524e-04 - mse: 8.5524e-04 - mae: 0.0167 - val_loss: 8.2708e-04 - val_mse: 8.2708e-04 - val_mae: 0.0180\n",
      "Epoch 112/180\n",
      "65/65 [==============================] - 33s 503ms/step - loss: 8.5508e-04 - mse: 8.5508e-04 - mae: 0.0166 - val_loss: 8.1784e-04 - val_mse: 8.1784e-04 - val_mae: 0.0174\n",
      "Epoch 113/180\n",
      "65/65 [==============================] - 31s 482ms/step - loss: 8.5045e-04 - mse: 8.5045e-04 - mae: 0.0166 - val_loss: 8.0983e-04 - val_mse: 8.0983e-04 - val_mae: 0.0167\n",
      "Epoch 114/180\n",
      "65/65 [==============================] - 33s 510ms/step - loss: 8.5600e-04 - mse: 8.5600e-04 - mae: 0.0168 - val_loss: 8.3241e-04 - val_mse: 8.3241e-04 - val_mae: 0.0176\n",
      "Epoch 115/180\n",
      "65/65 [==============================] - 35s 541ms/step - loss: 8.5218e-04 - mse: 8.5218e-04 - mae: 0.0166 - val_loss: 8.5204e-04 - val_mse: 8.5204e-04 - val_mae: 0.0189\n",
      "Epoch 116/180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 37s 565ms/step - loss: 8.4998e-04 - mse: 8.4998e-04 - mae: 0.0165 - val_loss: 8.4250e-04 - val_mse: 8.4250e-04 - val_mae: 0.0187\n",
      "Epoch 117/180\n",
      "65/65 [==============================] - 38s 586ms/step - loss: 8.4909e-04 - mse: 8.4909e-04 - mae: 0.0165 - val_loss: 8.2757e-04 - val_mse: 8.2757e-04 - val_mae: 0.0183\n",
      "Epoch 118/180\n",
      "65/65 [==============================] - 35s 540ms/step - loss: 8.4294e-04 - mse: 8.4294e-04 - mae: 0.0164 - val_loss: 7.9463e-04 - val_mse: 7.9463e-04 - val_mae: 0.0168\n",
      "Epoch 119/180\n",
      "65/65 [==============================] - 35s 531ms/step - loss: 8.4077e-04 - mse: 8.4077e-04 - mae: 0.0164 - val_loss: 8.2681e-04 - val_mse: 8.2681e-04 - val_mae: 0.0182\n",
      "Epoch 120/180\n",
      "65/65 [==============================] - 37s 568ms/step - loss: 8.3370e-04 - mse: 8.3370e-04 - mae: 0.0164 - val_loss: 8.2829e-04 - val_mse: 8.2829e-04 - val_mae: 0.0183\n",
      "Epoch 121/180\n",
      "65/65 [==============================] - 36s 557ms/step - loss: 8.3463e-04 - mse: 8.3463e-04 - mae: 0.0163 - val_loss: 7.7042e-04 - val_mse: 7.7042e-04 - val_mae: 0.0161\n",
      "Epoch 122/180\n",
      "65/65 [==============================] - 37s 562ms/step - loss: 8.3346e-04 - mse: 8.3346e-04 - mae: 0.0163 - val_loss: 7.9558e-04 - val_mse: 7.9558e-04 - val_mae: 0.0168\n",
      "Epoch 123/180\n",
      "65/65 [==============================] - 31s 476ms/step - loss: 8.2968e-04 - mse: 8.2968e-04 - mae: 0.0162 - val_loss: 7.8432e-04 - val_mse: 7.8432e-04 - val_mae: 0.0171\n",
      "Epoch 124/180\n",
      "65/65 [==============================] - 34s 522ms/step - loss: 8.3950e-04 - mse: 8.3950e-04 - mae: 0.0164 - val_loss: 8.4607e-04 - val_mse: 8.4607e-04 - val_mae: 0.0188\n",
      "Epoch 125/180\n",
      "65/65 [==============================] - 32s 488ms/step - loss: 8.3588e-04 - mse: 8.3588e-04 - mae: 0.0164 - val_loss: 8.0464e-04 - val_mse: 8.0464e-04 - val_mae: 0.0179\n",
      "Epoch 126/180\n",
      "65/65 [==============================] - 32s 494ms/step - loss: 8.2602e-04 - mse: 8.2602e-04 - mae: 0.0161 - val_loss: 8.1725e-04 - val_mse: 8.1725e-04 - val_mae: 0.0179\n",
      "Epoch 127/180\n",
      "65/65 [==============================] - 33s 502ms/step - loss: 8.1854e-04 - mse: 8.1854e-04 - mae: 0.0161 - val_loss: 8.2785e-04 - val_mse: 8.2785e-04 - val_mae: 0.0191\n",
      "Epoch 128/180\n",
      "65/65 [==============================] - 32s 488ms/step - loss: 8.0967e-04 - mse: 8.0967e-04 - mae: 0.0161 - val_loss: 7.9613e-04 - val_mse: 7.9613e-04 - val_mae: 0.0170\n",
      "Epoch 129/180\n",
      "65/65 [==============================] - 35s 537ms/step - loss: 8.1885e-04 - mse: 8.1885e-04 - mae: 0.0160 - val_loss: 8.4072e-04 - val_mse: 8.4072e-04 - val_mae: 0.0191\n",
      "Epoch 130/180\n",
      "65/65 [==============================] - 33s 511ms/step - loss: 8.1888e-04 - mse: 8.1888e-04 - mae: 0.0160 - val_loss: 7.9727e-04 - val_mse: 7.9727e-04 - val_mae: 0.0173\n",
      "Epoch 131/180\n",
      "65/65 [==============================] - 29s 446ms/step - loss: 8.4013e-04 - mse: 8.4013e-04 - mae: 0.0164 - val_loss: 7.7646e-04 - val_mse: 7.7646e-04 - val_mae: 0.0168\n",
      "Epoch 132/180\n",
      "65/65 [==============================] - 28s 437ms/step - loss: 8.2613e-04 - mse: 8.2613e-04 - mae: 0.0162 - val_loss: 8.3763e-04 - val_mse: 8.3763e-04 - val_mae: 0.0184\n",
      "Epoch 133/180\n",
      "65/65 [==============================] - 28s 434ms/step - loss: 8.1325e-04 - mse: 8.1325e-04 - mae: 0.0159 - val_loss: 7.9647e-04 - val_mse: 7.9647e-04 - val_mae: 0.0176\n",
      "Epoch 134/180\n",
      "65/65 [==============================] - 28s 428ms/step - loss: 8.0781e-04 - mse: 8.0781e-04 - mae: 0.0159 - val_loss: 7.8214e-04 - val_mse: 7.8214e-04 - val_mae: 0.0163\n",
      "Epoch 135/180\n",
      "65/65 [==============================] - 28s 437ms/step - loss: 8.2420e-04 - mse: 8.2420e-04 - mae: 0.0161 - val_loss: 9.6598e-04 - val_mse: 9.6598e-04 - val_mae: 0.0217\n",
      "Epoch 136/180\n",
      "65/65 [==============================] - 30s 461ms/step - loss: 8.1267e-04 - mse: 8.1267e-04 - mae: 0.0160 - val_loss: 8.4815e-04 - val_mse: 8.4815e-04 - val_mae: 0.0194\n",
      "Epoch 137/180\n",
      "65/65 [==============================] - 32s 493ms/step - loss: 8.1232e-04 - mse: 8.1232e-04 - mae: 0.0160 - val_loss: 7.9464e-04 - val_mse: 7.9464e-04 - val_mae: 0.0177\n",
      "Epoch 138/180\n",
      "65/65 [==============================] - 33s 510ms/step - loss: 8.0860e-04 - mse: 8.0860e-04 - mae: 0.0161 - val_loss: 7.9881e-04 - val_mse: 7.9881e-04 - val_mae: 0.0176\n",
      "Epoch 139/180\n",
      "65/65 [==============================] - 39s 606ms/step - loss: 7.9858e-04 - mse: 7.9858e-04 - mae: 0.0158 - val_loss: 7.8769e-04 - val_mse: 7.8769e-04 - val_mae: 0.0173\n",
      "Epoch 140/180\n",
      "65/65 [==============================] - 34s 525ms/step - loss: 7.9702e-04 - mse: 7.9702e-04 - mae: 0.0157 - val_loss: 8.0073e-04 - val_mse: 8.0073e-04 - val_mae: 0.0169\n",
      "Epoch 141/180\n",
      "65/65 [==============================] - 35s 545ms/step - loss: 8.0937e-04 - mse: 8.0937e-04 - mae: 0.0160 - val_loss: 8.0614e-04 - val_mse: 8.0614e-04 - val_mae: 0.0178\n",
      "Epoch 142/180\n",
      "65/65 [==============================] - 42s 639ms/step - loss: 8.0407e-04 - mse: 8.0407e-04 - mae: 0.0157 - val_loss: 8.0733e-04 - val_mse: 8.0733e-04 - val_mae: 0.0180\n",
      "Epoch 143/180\n",
      "65/65 [==============================] - 49s 760ms/step - loss: 7.8278e-04 - mse: 7.8278e-04 - mae: 0.0156 - val_loss: 7.8957e-04 - val_mse: 7.8957e-04 - val_mae: 0.0162\n",
      "Epoch 144/180\n",
      "65/65 [==============================] - 45s 687ms/step - loss: 7.8904e-04 - mse: 7.8904e-04 - mae: 0.0156 - val_loss: 7.8020e-04 - val_mse: 7.8020e-04 - val_mae: 0.0164\n",
      "Epoch 145/180\n",
      "65/65 [==============================] - 49s 756ms/step - loss: 7.8891e-04 - mse: 7.8891e-04 - mae: 0.0157 - val_loss: 8.3600e-04 - val_mse: 8.3600e-04 - val_mae: 0.0184\n",
      "Epoch 146/180\n",
      "65/65 [==============================] - 53s 819ms/step - loss: 7.8675e-04 - mse: 7.8675e-04 - mae: 0.0158 - val_loss: 8.7909e-04 - val_mse: 8.7909e-04 - val_mae: 0.0189\n",
      "Epoch 147/180\n",
      "65/65 [==============================] - 50s 775ms/step - loss: 7.9220e-04 - mse: 7.9220e-04 - mae: 0.0155 - val_loss: 7.9913e-04 - val_mse: 7.9913e-04 - val_mae: 0.0166\n",
      "Epoch 148/180\n",
      "65/65 [==============================] - 39s 600ms/step - loss: 7.9998e-04 - mse: 7.9998e-04 - mae: 0.0156 - val_loss: 8.3131e-04 - val_mse: 8.3131e-04 - val_mae: 0.0178\n",
      "Epoch 149/180\n",
      "65/65 [==============================] - 44s 670ms/step - loss: 7.9537e-04 - mse: 7.9537e-04 - mae: 0.0156 - val_loss: 8.2268e-04 - val_mse: 8.2268e-04 - val_mae: 0.0188\n",
      "Epoch 150/180\n",
      "65/65 [==============================] - 55s 845ms/step - loss: 7.8486e-04 - mse: 7.8486e-04 - mae: 0.0157 - val_loss: 8.6582e-04 - val_mse: 8.6582e-04 - val_mae: 0.0191\n",
      "Epoch 151/180\n",
      "65/65 [==============================] - 37s 575ms/step - loss: 7.7305e-04 - mse: 7.7305e-04 - mae: 0.0153 - val_loss: 8.3416e-04 - val_mse: 8.3416e-04 - val_mae: 0.0185\n",
      "Epoch 152/180\n",
      "65/65 [==============================] - 52s 805ms/step - loss: 7.8784e-04 - mse: 7.8784e-04 - mae: 0.0155 - val_loss: 9.0185e-04 - val_mse: 9.0185e-04 - val_mae: 0.0199\n",
      "Epoch 153/180\n",
      "65/65 [==============================] - 42s 643ms/step - loss: 7.6698e-04 - mse: 7.6698e-04 - mae: 0.0153 - val_loss: 8.3339e-04 - val_mse: 8.3339e-04 - val_mae: 0.0179\n",
      "Epoch 154/180\n",
      "65/65 [==============================] - 53s 819ms/step - loss: 7.8136e-04 - mse: 7.8136e-04 - mae: 0.0153 - val_loss: 7.9193e-04 - val_mse: 7.9193e-04 - val_mae: 0.0168\n",
      "Epoch 155/180\n",
      "65/65 [==============================] - 48s 740ms/step - loss: 7.8667e-04 - mse: 7.8667e-04 - mae: 0.0157 - val_loss: 8.2949e-04 - val_mse: 8.2949e-04 - val_mae: 0.0179\n",
      "Epoch 156/180\n",
      "65/65 [==============================] - 37s 567ms/step - loss: 7.7457e-04 - mse: 7.7457e-04 - mae: 0.0154 - val_loss: 8.4723e-04 - val_mse: 8.4723e-04 - val_mae: 0.0178\n",
      "Epoch 157/180\n",
      "65/65 [==============================] - 45s 694ms/step - loss: 7.7680e-04 - mse: 7.7680e-04 - mae: 0.0155 - val_loss: 7.9604e-04 - val_mse: 7.9604e-04 - val_mae: 0.0177\n",
      "Epoch 158/180\n",
      "65/65 [==============================] - 38s 585ms/step - loss: 7.8617e-04 - mse: 7.8617e-04 - mae: 0.0157 - val_loss: 8.3973e-04 - val_mse: 8.3973e-04 - val_mae: 0.0181\n",
      "Epoch 159/180\n",
      "65/65 [==============================] - 36s 553ms/step - loss: 7.6099e-04 - mse: 7.6099e-04 - mae: 0.0154 - val_loss: 7.5263e-04 - val_mse: 7.5263e-04 - val_mae: 0.0162\n",
      "Epoch 160/180\n",
      "65/65 [==============================] - 38s 589ms/step - loss: 7.7976e-04 - mse: 7.7976e-04 - mae: 0.0155 - val_loss: 7.8738e-04 - val_mse: 7.8738e-04 - val_mae: 0.0169\n",
      "Epoch 161/180\n",
      "65/65 [==============================] - 37s 568ms/step - loss: 7.6738e-04 - mse: 7.6738e-04 - mae: 0.0154 - val_loss: 8.5029e-04 - val_mse: 8.5029e-04 - val_mae: 0.0186\n",
      "Epoch 162/180\n",
      "65/65 [==============================] - 35s 543ms/step - loss: 7.7973e-04 - mse: 7.7973e-04 - mae: 0.0158 - val_loss: 8.0622e-04 - val_mse: 8.0622e-04 - val_mae: 0.0161\n",
      "Epoch 163/180\n",
      "65/65 [==============================] - 36s 548ms/step - loss: 7.7628e-04 - mse: 7.7628e-04 - mae: 0.0155 - val_loss: 8.3325e-04 - val_mse: 8.3325e-04 - val_mae: 0.0176\n",
      "Epoch 164/180\n",
      "65/65 [==============================] - 36s 547ms/step - loss: 7.7457e-04 - mse: 7.7457e-04 - mae: 0.0156 - val_loss: 8.1468e-04 - val_mse: 8.1468e-04 - val_mae: 0.0178\n",
      "Epoch 165/180\n",
      "65/65 [==============================] - 35s 543ms/step - loss: 7.5379e-04 - mse: 7.5379e-04 - mae: 0.0152 - val_loss: 8.6447e-04 - val_mse: 8.6447e-04 - val_mae: 0.0183\n",
      "Epoch 166/180\n",
      "65/65 [==============================] - 36s 554ms/step - loss: 7.5191e-04 - mse: 7.5191e-04 - mae: 0.0152 - val_loss: 8.3389e-04 - val_mse: 8.3389e-04 - val_mae: 0.0176\n",
      "Epoch 167/180\n",
      "65/65 [==============================] - 36s 561ms/step - loss: 7.9947e-04 - mse: 7.9947e-04 - mae: 0.0159 - val_loss: 7.9959e-04 - val_mse: 7.9959e-04 - val_mae: 0.0169\n",
      "Epoch 168/180\n",
      "65/65 [==============================] - 40s 622ms/step - loss: 7.5937e-04 - mse: 7.5937e-04 - mae: 0.0154 - val_loss: 8.3824e-04 - val_mse: 8.3824e-04 - val_mae: 0.0187\n",
      "Epoch 169/180\n",
      "65/65 [==============================] - 37s 574ms/step - loss: 7.7366e-04 - mse: 7.7366e-04 - mae: 0.0155 - val_loss: 8.6296e-04 - val_mse: 8.6296e-04 - val_mae: 0.0184\n",
      "Epoch 170/180\n",
      "65/65 [==============================] - 29s 450ms/step - loss: 7.3364e-04 - mse: 7.3364e-04 - mae: 0.0149 - val_loss: 8.1917e-04 - val_mse: 8.1917e-04 - val_mae: 0.0167\n",
      "Epoch 171/180\n",
      "65/65 [==============================] - 40s 618ms/step - loss: 7.6956e-04 - mse: 7.6956e-04 - mae: 0.0155 - val_loss: 8.7834e-04 - val_mse: 8.7834e-04 - val_mae: 0.0183\n",
      "Epoch 172/180\n",
      "65/65 [==============================] - 45s 687ms/step - loss: 7.3410e-04 - mse: 7.3410e-04 - mae: 0.0149 - val_loss: 8.5639e-04 - val_mse: 8.5639e-04 - val_mae: 0.0168\n",
      "Epoch 173/180\n",
      "65/65 [==============================] - 37s 572ms/step - loss: 7.6872e-04 - mse: 7.6872e-04 - mae: 0.0156 - val_loss: 8.4948e-04 - val_mse: 8.4948e-04 - val_mae: 0.0174\n",
      "Epoch 174/180\n",
      "65/65 [==============================] - 45s 697ms/step - loss: 7.6356e-04 - mse: 7.6356e-04 - mae: 0.0153 - val_loss: 8.8978e-04 - val_mse: 8.8978e-04 - val_mae: 0.0190\n",
      "Epoch 175/180\n",
      "65/65 [==============================] - 45s 690ms/step - loss: 7.8143e-04 - mse: 7.8143e-04 - mae: 0.0155 - val_loss: 8.2191e-04 - val_mse: 8.2191e-04 - val_mae: 0.0170\n",
      "Epoch 176/180\n",
      "65/65 [==============================] - 48s 745ms/step - loss: 7.6494e-04 - mse: 7.6494e-04 - mae: 0.0153 - val_loss: 8.4365e-04 - val_mse: 8.4365e-04 - val_mae: 0.0171\n",
      "Epoch 177/180\n",
      "65/65 [==============================] - 39s 605ms/step - loss: 7.5991e-04 - mse: 7.5991e-04 - mae: 0.0153 - val_loss: 9.0031e-04 - val_mse: 9.0031e-04 - val_mae: 0.0191\n",
      "Epoch 178/180\n",
      "65/65 [==============================] - 43s 654ms/step - loss: 7.3465e-04 - mse: 7.3465e-04 - mae: 0.0151 - val_loss: 8.3590e-04 - val_mse: 8.3590e-04 - val_mae: 0.0164\n",
      "Epoch 179/180\n",
      "65/65 [==============================] - 42s 646ms/step - loss: 7.4549e-04 - mse: 7.4549e-04 - mae: 0.0154 - val_loss: 8.4217e-04 - val_mse: 8.4217e-04 - val_mae: 0.0170\n",
      "Epoch 180/180\n",
      "65/65 [==============================] - 40s 623ms/step - loss: 7.5056e-04 - mse: 7.5056e-04 - mae: 0.0152 - val_loss: 8.4823e-04 - val_mse: 8.4823e-04 - val_mae: 0.0172\n"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "optimizers = [optimizers.RMSprop(), \n",
    "              optimizers.Adam(), \n",
    "              optimizers.Nadam(),\n",
    "              optimizers.Adamax()]\n",
    "\n",
    "\n",
    "# function to split data into correct shape for RNN\n",
    "def split_data(X, y, steps):\n",
    "    X_, y_ = list(), list()\n",
    "    for i in range(steps, len(y)):\n",
    "        X_.append(X[i - steps : i, :])\n",
    "        y_.append(y[i]) \n",
    "    return np.array(X_), np.array(y_)\n",
    "\n",
    "# function to cut data set so it can be divisible by the batch_size\n",
    "def cut_data(data, batch_size):\n",
    "     # see if it is divisivel\n",
    "    condition = data.shape[0] % batch_size\n",
    "    if condition == 0:\n",
    "        return data\n",
    "    else:\n",
    "        return data[: -condition]\n",
    "\n",
    "# divide features and labels\n",
    "X_train = data_train[:, 0:15] \n",
    "y_train = data_train[:, -1]\n",
    "X_test = data_test[:, 0:15] \n",
    "y_test = data_test[:, -1] \n",
    "\n",
    "# divide data into train and test \n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "         X_train, y_train, test_size = 0.15, shuffle=False)\n",
    "\n",
    "# put data into correct shape\n",
    "X_train, y_train = split_data(X_train, y_train, steps)\n",
    "X_test, y_test = split_data(X_test, y_test, steps)\n",
    "X_val, y_val = split_data(X_val, y_val, steps)\n",
    "\n",
    "X_train = cut_data(X_train, batch_size)\n",
    "y_train = cut_data(y_train, batch_size)\n",
    "X_test = cut_data(X_test, batch_size)\n",
    "y_test = cut_data(y_test, batch_size)\n",
    "X_val = cut_data(X_val, batch_size)\n",
    "y_val = cut_data(y_val, batch_size)\n",
    "\n",
    "# inverse of test set should not be inside the loop \n",
    "y_test = (y_test * sc_X.data_range_[15]) + (sc_X.data_min_[15])\n",
    "\n",
    "# smal adjustment\n",
    "y_test = pd.Series(y_test)\n",
    "y_test.replace(0, 0.0001,inplace = True)\n",
    "\n",
    "for i in optimizers:  \n",
    "    # design the LSTM\n",
    "    def regressor_tunning(kernel_initializer = 'he_normal',\n",
    "                      bias_initializer = initializers.Ones()):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        if n_hidden == 0:\n",
    "            model.add(LSTM(units = units,                    \n",
    "                           batch_input_shape = (batch_size, steps, features_num), \n",
    "                           stateful = True,\n",
    "                           kernel_initializer = kernel_initializer,\n",
    "                           bias_initializer = bias_initializer))\n",
    "            model.add(LeakyReLU(alpha = 0.2))\n",
    "            model.add(Dropout(0.2))\n",
    "        else:\n",
    "            model.add(LSTM(units = units,                    \n",
    "                           batch_input_shape = (batch_size, steps, features_num), \n",
    "                           stateful = True,\n",
    "                           return_sequences = True,\n",
    "                           kernel_initializer = kernel_initializer,\n",
    "                           bias_initializer = bias_initializer))\n",
    "            model.add(LeakyReLU(alpha = 0.2))\n",
    "            model.add(Dropout(0.2))\n",
    "            model.add(LSTM(units = units, \n",
    "                           batch_input_shape = (batch_size, steps, features_num), \n",
    "                           stateful = True,\n",
    "                           kernel_initializer = kernel_initializer,\n",
    "                           bias_initializer = bias_initializer))\n",
    "            model.add(LeakyReLU(alpha = 0.2))\n",
    "            model.add(Dropout(0.2))\n",
    "        model.add(Dense(1, activation='linear'))\n",
    "        optimizer = i\n",
    "        model.compile(loss = 'mse', metrics = ['mse', 'mae'], optimizer = optimizer)\n",
    "        return model\n",
    "\n",
    "    model = regressor_tunning()\n",
    "\n",
    "    # fitting the LSTM to the training set\n",
    "    history = model.fit(X_train,\n",
    "                        y_train, \n",
    "                        batch_size = batch_size, \n",
    "                        epochs = 100,\n",
    "                        shuffle = False, \n",
    "                        validation_data = (X_val, y_val))\n",
    "    \n",
    "    model.reset_states()\n",
    "    \n",
    "    # make new predicitons with test set\n",
    "    y_pred = model.predict(X_test, batch_size = batch_size)\n",
    "    \n",
    "    # prices col = 15\n",
    "    y_pred = (y_pred * sc_X.data_range_[15]) + (sc_X.data_min_[15])\n",
    "\n",
    "    y_pred_list.append(y_pred)\n",
    "    \n",
    "    from sklearn.metrics import mean_squared_error as mse\n",
    "    from sklearn.metrics import mean_absolute_error as mae\n",
    "\n",
    "    rmse_error = mse(y_test, y_pred, squared = False)\n",
    "    mae_error = mae(y_test, y_pred)\n",
    "    \n",
    "    rmse_gen.append(rmse_error)\n",
    "    mae_gen.append(mae_error)\n",
    "    \n",
    "    # =============================================================================\n",
    "    # Metrics evaluation on spike regions\n",
    "    # =============================================================================\n",
    "\n",
    "    # select y_pred and y_test only for regions with spikes\n",
    "    y_test_spike = (y_test.T * y_spike_occ).T\n",
    "    y_pred_spike = (y_pred.T * y_spike_occ).T\n",
    "    y_test_spike = y_test_spike[y_test_spike != 0]\n",
    "    y_pred_spike = y_pred_spike[y_pred_spike != 0]\n",
    "    \n",
    "    # calculate metric\n",
    "    rmse_spike = mse(y_test_spike, y_pred_spike, squared = False)\n",
    "    mae_spike = mae(y_test_spike, y_pred_spike)\n",
    "    \n",
    "    rmse_spi.append(rmse_spike)\n",
    "    mae_spi.append(mae_spike)\n",
    "    \n",
    "    # =============================================================================\n",
    "    # Metric evaluation on normal regions\n",
    "    # =============================================================================\n",
    "    \n",
    "    # inverse y_spike_occ so the only normal occurences are chosen\n",
    "    y_normal_occ = (y_spike_occ - 1) * (-1)\n",
    "    \n",
    "    # sanity check\n",
    "    y_normal_occ.sum() + y_spike_occ.sum() # gives the correct total \n",
    "    \n",
    "    # select y_pred and y_test only for normal regions\n",
    "    y_test_normal = (y_test.T * y_normal_occ).T\n",
    "    y_pred_normal = (y_pred.T * y_normal_occ).T\n",
    "    y_test_normal = y_test_normal[y_test_normal != 0.00]\n",
    "    y_pred_normal = y_pred_normal[y_pred_normal != 0.00]\n",
    "    \n",
    "    # calculate metric\n",
    "    rmse_normal = mse(y_test_normal, y_pred_normal, squared = False)\n",
    "    mae_normal = mae(y_test_normal, y_pred_normal)\n",
    "    \n",
    "    rmse_nor.append(rmse_normal)\n",
    "    mae_nor.append(mae_normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({'optimizers':optimizers,\n",
    "                        \n",
    "                        'rmse_general': rmse_gen, \n",
    "                 \n",
    "                        'mae_general': mae_gen,\n",
    "                        \n",
    "                        'rmse_spike': rmse_spi,\n",
    "                 \n",
    "                        'mae_spike': mae_spi,\n",
    "                        \n",
    "                        'rmse_normal': rmse_nor,\n",
    "                    \n",
    "                        'mae_normal': mae_nor})\n",
    "\n",
    "results.to_csv('Results_LSTM_3_optimizer.csv')\n",
    "\n",
    "y_pred = pd.DataFrame({'optimizers':optimizers,\n",
    "                       'Predicitons': y_pred_list})\n",
    "\n",
    "y_pred.to_csv('Pedictions_LSTM_3_optimizers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_c59273b4_d123_11ea_904d_7cb27da2bf47row0_col0 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_c59273b4_d123_11ea_904d_7cb27da2bf47row0_col4 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_c59273b4_d123_11ea_904d_7cb27da2bf47row3_col1 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_c59273b4_d123_11ea_904d_7cb27da2bf47row3_col2 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_c59273b4_d123_11ea_904d_7cb27da2bf47row3_col3 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_c59273b4_d123_11ea_904d_7cb27da2bf47row3_col5 {\n",
       "            background-color:  yellow;\n",
       "        }</style><table id=\"T_c59273b4_d123_11ea_904d_7cb27da2bf47\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >rmse_general</th>        <th class=\"col_heading level0 col1\" >mae_general</th>        <th class=\"col_heading level0 col2\" >rmse_spike</th>        <th class=\"col_heading level0 col3\" >mae_spike</th>        <th class=\"col_heading level0 col4\" >rmse_normal</th>        <th class=\"col_heading level0 col5\" >mae_normal</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_c59273b4_d123_11ea_904d_7cb27da2bf47level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_c59273b4_d123_11ea_904d_7cb27da2bf47row0_col0\" class=\"data row0 col0\" >32.536261</td>\n",
       "                        <td id=\"T_c59273b4_d123_11ea_904d_7cb27da2bf47row0_col1\" class=\"data row0 col1\" >20.998041</td>\n",
       "                        <td id=\"T_c59273b4_d123_11ea_904d_7cb27da2bf47row0_col2\" class=\"data row0 col2\" >29.362422</td>\n",
       "                        <td id=\"T_c59273b4_d123_11ea_904d_7cb27da2bf47row0_col3\" class=\"data row0 col3\" >20.628882</td>\n",
       "                        <td id=\"T_c59273b4_d123_11ea_904d_7cb27da2bf47row0_col4\" class=\"data row0 col4\" >32.981703</td>\n",
       "                        <td id=\"T_c59273b4_d123_11ea_904d_7cb27da2bf47row0_col5\" class=\"data row0 col5\" >21.052881</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c59273b4_d123_11ea_904d_7cb27da2bf47level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_c59273b4_d123_11ea_904d_7cb27da2bf47row1_col0\" class=\"data row1 col0\" >33.268096</td>\n",
       "                        <td id=\"T_c59273b4_d123_11ea_904d_7cb27da2bf47row1_col1\" class=\"data row1 col1\" >23.631728</td>\n",
       "                        <td id=\"T_c59273b4_d123_11ea_904d_7cb27da2bf47row1_col2\" class=\"data row1 col2\" >30.429167</td>\n",
       "                        <td id=\"T_c59273b4_d123_11ea_904d_7cb27da2bf47row1_col3\" class=\"data row1 col3\" >23.274971</td>\n",
       "                        <td id=\"T_c59273b4_d123_11ea_904d_7cb27da2bf47row1_col4\" class=\"data row1 col4\" >33.669416</td>\n",
       "                        <td id=\"T_c59273b4_d123_11ea_904d_7cb27da2bf47row1_col5\" class=\"data row1 col5\" >23.684726</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c59273b4_d123_11ea_904d_7cb27da2bf47level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_c59273b4_d123_11ea_904d_7cb27da2bf47row2_col0\" class=\"data row2 col0\" >33.545703</td>\n",
       "                        <td id=\"T_c59273b4_d123_11ea_904d_7cb27da2bf47row2_col1\" class=\"data row2 col1\" >23.893952</td>\n",
       "                        <td id=\"T_c59273b4_d123_11ea_904d_7cb27da2bf47row2_col2\" class=\"data row2 col2\" >30.897532</td>\n",
       "                        <td id=\"T_c59273b4_d123_11ea_904d_7cb27da2bf47row2_col3\" class=\"data row2 col3\" >23.795983</td>\n",
       "                        <td id=\"T_c59273b4_d123_11ea_904d_7cb27da2bf47row2_col4\" class=\"data row2 col4\" >33.921468</td>\n",
       "                        <td id=\"T_c59273b4_d123_11ea_904d_7cb27da2bf47row2_col5\" class=\"data row2 col5\" >23.908506</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c59273b4_d123_11ea_904d_7cb27da2bf47level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_c59273b4_d123_11ea_904d_7cb27da2bf47row3_col0\" class=\"data row3 col0\" >33.508238</td>\n",
       "                        <td id=\"T_c59273b4_d123_11ea_904d_7cb27da2bf47row3_col1\" class=\"data row3 col1\" >20.099735</td>\n",
       "                        <td id=\"T_c59273b4_d123_11ea_904d_7cb27da2bf47row3_col2\" class=\"data row3 col2\" >27.877429</td>\n",
       "                        <td id=\"T_c59273b4_d123_11ea_904d_7cb27da2bf47row3_col3\" class=\"data row3 col3\" >16.356400</td>\n",
       "                        <td id=\"T_c59273b4_d123_11ea_904d_7cb27da2bf47row3_col4\" class=\"data row3 col4\" >34.265872</td>\n",
       "                        <td id=\"T_c59273b4_d123_11ea_904d_7cb27da2bf47row3_col5\" class=\"data row3 col5\" >20.655824</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x21a889f74c8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({'rmse_general': rmse_gen, \n",
    "                 \n",
    "                        'mae_general': mae_gen,\n",
    "                        \n",
    "                        'rmse_spike': rmse_spi,\n",
    "                 \n",
    "                        'mae_spike': mae_spi,\n",
    "                        \n",
    "                        'rmse_normal': rmse_nor,\n",
    "                    \n",
    "                        'mae_normal': mae_nor})\n",
    "\n",
    "def highlight_min(s):\n",
    "    '''\n",
    "    highlight the maximum in a Series yellow.\n",
    "    '''\n",
    "    is_max = s == s.min()\n",
    "    return ['background-color: yellow' if v else '' for v in is_max]\n",
    "\n",
    "results.style.apply(highlight_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
