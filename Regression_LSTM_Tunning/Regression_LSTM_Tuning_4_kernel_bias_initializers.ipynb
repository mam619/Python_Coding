{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Parameter Tuning\n",
    "    \n",
    "    Look for the best kernel initializer and bias initializer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages (1.1.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages (from pandas) (2020.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages (from pandas) (1.18.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.14.0)\n",
      "Requirement already satisfied: sklearn in /home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages (from sklearn) (0.23.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages (from scikit-learn->sklearn) (0.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.18.1)\n",
      "Requirement already satisfied: matplotlib in /home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages (3.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.15 in /home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages (from matplotlib) (1.18.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages (from matplotlib) (7.0.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages (from python-dateutil>=2.1->matplotlib) (1.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install sklearn\n",
    "!pip install matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd;\n",
    "import numpy as np;\n",
    "import sklearn\n",
    "\n",
    "# parameters\n",
    "steps = 96\n",
    "n_hidden = 1\n",
    "units = 150\n",
    "batch_size = 96\n",
    "features_num = 15\n",
    "\n",
    "# months to evaluate model on\n",
    "date = 2018090000\n",
    "\n",
    "# lists to append results\n",
    "mae_gen = []\n",
    "mae_nor = []\n",
    "mae_spi = []\n",
    "rmse_gen = []\n",
    "rmse_nor = []\n",
    "rmse_spi = []\n",
    "y_pred_list = []\n",
    "time_count = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data; set X and y; fill nan values and split in test and training  data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "data = pd.read_csv('Data_set_1_smaller.csv', index_col = 0)\n",
    "\n",
    "# data\n",
    "data = data.loc[data.index > date, :]\n",
    "\n",
    "# reset index\n",
    "data.reset_index(inplace = True)\n",
    "data.drop('index', axis = 1, inplace = True)\n",
    "\n",
    "# fill nan values\n",
    "data.fillna(method = 'ffill', inplace = True)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# divide data into train and test \n",
    "data_train, data_test = train_test_split(\n",
    "         data, test_size = 0.15, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply feature scaling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# data scaling  (including offer (y))\n",
    "sc_X = MinMaxScaler()\n",
    "data_train = sc_X.fit_transform(data_train)\n",
    "data_test = sc_X.transform(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the Keras libraries and packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LeakyReLU\n",
    "from keras import initializers\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Need to process data with spike occurences the same way as features and offers:\n",
    "(Required to evaluate predictions in both normal regions and spike regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data for shaded area\n",
    "data = pd.read_csv('Spike_binary_1std.csv', index_col = 0)\n",
    "\n",
    "# set predictive window according with tuning best results\n",
    "data = data.loc[data.index > date, :]\n",
    "\n",
    "# make sure shaded area will correspond to values outputed by LSTM\n",
    "data.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# fill_nan is already made - so lets split data into test and train\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# divide data into train and test \n",
    "shade_train, shade_test = train_test_split(\n",
    "         data, test_size = 0.15, shuffle = False)\n",
    "\n",
    "# reset index of testing data\n",
    "shade_test.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# function to split data into correct shape for RNN\n",
    "def split_data(shade_test, steps):\n",
    "    y_spike_occ = list()\n",
    "    upper_lim = list()\n",
    "    lower_lim = list()\n",
    "    for i in range(steps, len(shade_test.index)):\n",
    "        y_spike_occ.append(shade_test['spike_occurance'][i])\n",
    "        upper_lim.append(shade_test['spike_upperlim'][i])\n",
    "        lower_lim.append(shade_test['spike_lowerlim'][i])\n",
    "    return np.array(y_spike_occ), np.array(upper_lim), np.array(lower_lim)\n",
    "\n",
    "# function to cut data set so it can be divisible by the batch_size\n",
    "def cut_data(data, batch_size):\n",
    "     # see if it is divisivel\n",
    "    condition = data.shape[0] % batch_size\n",
    "    if condition == 0:\n",
    "        return data\n",
    "    else:\n",
    "        return data[: -condition]\n",
    "\n",
    "# shape y_spike_occ for the right size to compare results in normal and spike regions\n",
    "y_spike_occ, spike_upperlim, spike_lowerlim = split_data(shade_test, steps)\n",
    "y_spike_occ = cut_data(y_spike_occ, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create regressor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4128 samples, validate on 576 samples\n",
      "Epoch 1/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0052 - mse: 0.0052 - mae: 0.0529 - val_loss: 4.8689e-04 - val_mse: 4.8689e-04 - val_mae: 0.0160\n",
      "Epoch 2/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0356 - val_loss: 4.8927e-04 - val_mse: 4.8927e-04 - val_mae: 0.0158\n",
      "Epoch 3/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0309 - val_loss: 4.7381e-04 - val_mse: 4.7381e-04 - val_mae: 0.0149\n",
      "Epoch 4/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0271 - val_loss: 4.6644e-04 - val_mse: 4.6644e-04 - val_mae: 0.0136\n",
      "Epoch 5/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0250 - val_loss: 4.8970e-04 - val_mse: 4.8970e-04 - val_mae: 0.0134\n",
      "Epoch 6/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0238 - val_loss: 5.9866e-04 - val_mse: 5.9866e-04 - val_mae: 0.0153\n",
      "Epoch 7/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0225 - val_loss: 4.8278e-04 - val_mse: 4.8278e-04 - val_mae: 0.0136\n",
      "Epoch 8/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0220 - val_loss: 5.5270e-04 - val_mse: 5.5270e-04 - val_mae: 0.0145\n",
      "Epoch 9/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0218 - val_loss: 5.2749e-04 - val_mse: 5.2749e-04 - val_mae: 0.0140\n",
      "Epoch 10/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0209 - val_loss: 4.9233e-04 - val_mse: 4.9233e-04 - val_mae: 0.0131\n",
      "Epoch 11/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0207 - val_loss: 4.7902e-04 - val_mse: 4.7902e-04 - val_mae: 0.0129\n",
      "Epoch 12/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0204 - val_loss: 4.7090e-04 - val_mse: 4.7090e-04 - val_mae: 0.0128\n",
      "Epoch 13/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0200 - val_loss: 4.7336e-04 - val_mse: 4.7336e-04 - val_mae: 0.0131\n",
      "Epoch 14/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0198 - val_loss: 4.8446e-04 - val_mse: 4.8446e-04 - val_mae: 0.0129\n",
      "Epoch 15/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0198 - val_loss: 4.6559e-04 - val_mse: 4.6559e-04 - val_mae: 0.0126\n",
      "Epoch 16/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0195 - val_loss: 4.5554e-04 - val_mse: 4.5554e-04 - val_mae: 0.0125\n",
      "Epoch 17/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0193 - val_loss: 4.9012e-04 - val_mse: 4.9012e-04 - val_mae: 0.0130\n",
      "Epoch 18/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0191 - val_loss: 4.5797e-04 - val_mse: 4.5797e-04 - val_mae: 0.0125\n",
      "Epoch 19/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0190 - val_loss: 4.7781e-04 - val_mse: 4.7781e-04 - val_mae: 0.0127\n",
      "Epoch 20/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0189 - val_loss: 4.6617e-04 - val_mse: 4.6617e-04 - val_mae: 0.0124\n",
      "Epoch 21/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0188 - val_loss: 4.7016e-04 - val_mse: 4.7016e-04 - val_mae: 0.0126\n",
      "Epoch 22/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0190 - val_loss: 4.4795e-04 - val_mse: 4.4795e-04 - val_mae: 0.0124\n",
      "Epoch 23/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0186 - val_loss: 4.5034e-04 - val_mse: 4.5034e-04 - val_mae: 0.0124\n",
      "Epoch 24/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0186 - val_loss: 4.7410e-04 - val_mse: 4.7410e-04 - val_mae: 0.0127\n",
      "Epoch 25/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0184 - val_loss: 4.5363e-04 - val_mse: 4.5363e-04 - val_mae: 0.0126\n",
      "Epoch 26/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0184 - val_loss: 4.6396e-04 - val_mse: 4.6396e-04 - val_mae: 0.0125\n",
      "Epoch 27/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0181 - val_loss: 4.6242e-04 - val_mse: 4.6242e-04 - val_mae: 0.0126\n",
      "Epoch 28/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0183 - val_loss: 4.7418e-04 - val_mse: 4.7418e-04 - val_mae: 0.0126\n",
      "Epoch 29/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0181 - val_loss: 4.8499e-04 - val_mse: 4.8499e-04 - val_mae: 0.0128\n",
      "Epoch 30/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0181 - val_loss: 4.6943e-04 - val_mse: 4.6943e-04 - val_mae: 0.0127\n",
      "Epoch 31/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0181 - val_loss: 4.7158e-04 - val_mse: 4.7158e-04 - val_mae: 0.0128\n",
      "Epoch 32/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0180 - val_loss: 4.9451e-04 - val_mse: 4.9451e-04 - val_mae: 0.0131\n",
      "Epoch 33/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0178 - val_loss: 4.6856e-04 - val_mse: 4.6856e-04 - val_mae: 0.0126\n",
      "Epoch 34/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0178 - val_loss: 4.7793e-04 - val_mse: 4.7793e-04 - val_mae: 0.0128\n",
      "Epoch 35/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0177 - val_loss: 4.8455e-04 - val_mse: 4.8455e-04 - val_mae: 0.0129\n",
      "Epoch 36/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0177 - val_loss: 4.6616e-04 - val_mse: 4.6616e-04 - val_mae: 0.0128\n",
      "Epoch 37/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0178 - val_loss: 4.7521e-04 - val_mse: 4.7521e-04 - val_mae: 0.0128\n",
      "Epoch 38/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0176 - val_loss: 4.7309e-04 - val_mse: 4.7309e-04 - val_mae: 0.0128\n",
      "Epoch 39/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0178 - val_loss: 4.6160e-04 - val_mse: 4.6160e-04 - val_mae: 0.0128\n",
      "Epoch 40/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0178 - val_loss: 4.6563e-04 - val_mse: 4.6563e-04 - val_mae: 0.0126\n",
      "Epoch 41/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0179 - val_loss: 4.8979e-04 - val_mse: 4.8979e-04 - val_mae: 0.0131\n",
      "Epoch 42/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0176 - val_loss: 4.7683e-04 - val_mse: 4.7683e-04 - val_mae: 0.0129\n",
      "Epoch 43/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0176 - val_loss: 4.7817e-04 - val_mse: 4.7817e-04 - val_mae: 0.0129\n",
      "Epoch 44/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0176 - val_loss: 4.7361e-04 - val_mse: 4.7361e-04 - val_mae: 0.0130\n",
      "Epoch 45/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0175 - val_loss: 4.7267e-04 - val_mse: 4.7267e-04 - val_mae: 0.0129\n",
      "Epoch 46/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0175 - val_loss: 4.8097e-04 - val_mse: 4.8097e-04 - val_mae: 0.0130\n",
      "Epoch 47/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0174 - val_loss: 4.6600e-04 - val_mse: 4.6600e-04 - val_mae: 0.0127\n",
      "Epoch 48/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0174 - val_loss: 4.7120e-04 - val_mse: 4.7120e-04 - val_mae: 0.0128\n",
      "Epoch 49/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0173 - val_loss: 4.8194e-04 - val_mse: 4.8194e-04 - val_mae: 0.0129\n",
      "Epoch 50/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0174 - val_loss: 5.0311e-04 - val_mse: 5.0311e-04 - val_mae: 0.0132\n",
      "Epoch 51/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0174 - val_loss: 4.8145e-04 - val_mse: 4.8145e-04 - val_mae: 0.0130\n",
      "Epoch 52/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0174 - val_loss: 4.8323e-04 - val_mse: 4.8323e-04 - val_mae: 0.0128\n",
      "Epoch 53/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0174 - val_loss: 5.0598e-04 - val_mse: 5.0598e-04 - val_mae: 0.0132\n",
      "Epoch 54/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0173 - val_loss: 4.8004e-04 - val_mse: 4.8004e-04 - val_mae: 0.0130\n",
      "Epoch 55/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0174 - val_loss: 5.0503e-04 - val_mse: 5.0503e-04 - val_mae: 0.0132\n",
      "Epoch 56/100\n",
      "4128/4128 [==============================] - 14s 4ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0174 - val_loss: 5.0781e-04 - val_mse: 5.0781e-04 - val_mae: 0.0134\n",
      "Epoch 57/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0173 - val_loss: 4.7040e-04 - val_mse: 4.7040e-04 - val_mae: 0.0130\n",
      "Epoch 58/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0173 - val_loss: 4.8833e-04 - val_mse: 4.8833e-04 - val_mae: 0.0132\n",
      "Epoch 59/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0171 - val_loss: 4.9618e-04 - val_mse: 4.9618e-04 - val_mae: 0.0130\n",
      "Epoch 60/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0173 - val_loss: 5.0183e-04 - val_mse: 5.0183e-04 - val_mae: 0.0136\n",
      "Epoch 61/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0174 - val_loss: 5.2266e-04 - val_mse: 5.2266e-04 - val_mae: 0.0138\n",
      "Epoch 62/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0172 - val_loss: 4.9784e-04 - val_mse: 4.9784e-04 - val_mae: 0.0131\n",
      "Epoch 63/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0170 - val_loss: 4.9195e-04 - val_mse: 4.9195e-04 - val_mae: 0.0134\n",
      "Epoch 64/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0173 - val_loss: 5.0958e-04 - val_mse: 5.0958e-04 - val_mae: 0.0134\n",
      "Epoch 65/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0172 - val_loss: 4.9997e-04 - val_mse: 4.9997e-04 - val_mae: 0.0131\n",
      "Epoch 66/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 9.9976e-04 - mse: 9.9976e-04 - mae: 0.0170 - val_loss: 5.1489e-04 - val_mse: 5.1489e-04 - val_mae: 0.0137\n",
      "Epoch 67/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 9.9323e-04 - mse: 9.9323e-04 - mae: 0.0170 - val_loss: 4.9388e-04 - val_mse: 4.9388e-04 - val_mae: 0.0134\n",
      "Epoch 68/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0170 - val_loss: 5.1147e-04 - val_mse: 5.1147e-04 - val_mae: 0.0137\n",
      "Epoch 69/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0172 - val_loss: 4.8597e-04 - val_mse: 4.8597e-04 - val_mae: 0.0132\n",
      "Epoch 70/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 9.9444e-04 - mse: 9.9444e-04 - mae: 0.0170 - val_loss: 5.0614e-04 - val_mse: 5.0614e-04 - val_mae: 0.0136\n",
      "Epoch 71/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 9.9633e-04 - mse: 9.9633e-04 - mae: 0.0170 - val_loss: 5.1068e-04 - val_mse: 5.1068e-04 - val_mae: 0.0138\n",
      "Epoch 72/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 9.9799e-04 - mse: 9.9799e-04 - mae: 0.0169 - val_loss: 5.2199e-04 - val_mse: 5.2199e-04 - val_mae: 0.0138\n",
      "Epoch 73/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 9.9423e-04 - mse: 9.9423e-04 - mae: 0.0168 - val_loss: 5.1281e-04 - val_mse: 5.1281e-04 - val_mae: 0.0137\n",
      "Epoch 74/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 9.9851e-04 - mse: 9.9851e-04 - mae: 0.0169 - val_loss: 5.0730e-04 - val_mse: 5.0730e-04 - val_mae: 0.0134\n",
      "Epoch 75/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 9.7402e-04 - mse: 9.7402e-04 - mae: 0.0167 - val_loss: 5.2165e-04 - val_mse: 5.2165e-04 - val_mae: 0.0139\n",
      "Epoch 76/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 9.8353e-04 - mse: 9.8353e-04 - mae: 0.0168 - val_loss: 5.1282e-04 - val_mse: 5.1282e-04 - val_mae: 0.0136\n",
      "Epoch 77/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0170 - val_loss: 4.9244e-04 - val_mse: 4.9244e-04 - val_mae: 0.0131\n",
      "Epoch 78/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 9.8125e-04 - mse: 9.8125e-04 - mae: 0.0168 - val_loss: 4.9746e-04 - val_mse: 4.9746e-04 - val_mae: 0.0140\n",
      "Epoch 79/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 9.7578e-04 - mse: 9.7578e-04 - mae: 0.0168 - val_loss: 5.1424e-04 - val_mse: 5.1424e-04 - val_mae: 0.0139\n",
      "Epoch 80/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 9.7345e-04 - mse: 9.7345e-04 - mae: 0.0167 - val_loss: 5.0427e-04 - val_mse: 5.0427e-04 - val_mae: 0.0136\n",
      "Epoch 81/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 9.7192e-04 - mse: 9.7192e-04 - mae: 0.0168 - val_loss: 4.8029e-04 - val_mse: 4.8029e-04 - val_mae: 0.0134\n",
      "Epoch 82/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 9.7777e-04 - mse: 9.7777e-04 - mae: 0.0168 - val_loss: 4.7968e-04 - val_mse: 4.7968e-04 - val_mae: 0.0137\n",
      "Epoch 83/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 9.8001e-04 - mse: 9.8001e-04 - mae: 0.0168 - val_loss: 5.1761e-04 - val_mse: 5.1761e-04 - val_mae: 0.0137\n",
      "Epoch 84/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 9.8563e-04 - mse: 9.8563e-04 - mae: 0.0168 - val_loss: 4.9845e-04 - val_mse: 4.9845e-04 - val_mae: 0.0133\n",
      "Epoch 85/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 9.8698e-04 - mse: 9.8698e-04 - mae: 0.0169 - val_loss: 4.9975e-04 - val_mse: 4.9975e-04 - val_mae: 0.0135\n",
      "Epoch 86/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 9.9172e-04 - mse: 9.9172e-04 - mae: 0.0168 - val_loss: 4.7640e-04 - val_mse: 4.7640e-04 - val_mae: 0.0133\n",
      "Epoch 87/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 9.8750e-04 - mse: 9.8750e-04 - mae: 0.0166 - val_loss: 4.9817e-04 - val_mse: 4.9817e-04 - val_mae: 0.0135\n",
      "Epoch 88/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 9.8369e-04 - mse: 9.8369e-04 - mae: 0.0167 - val_loss: 4.8622e-04 - val_mse: 4.8622e-04 - val_mae: 0.0140\n",
      "Epoch 89/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 9.8611e-04 - mse: 9.8611e-04 - mae: 0.0167 - val_loss: 4.8453e-04 - val_mse: 4.8453e-04 - val_mae: 0.0134\n",
      "Epoch 90/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 9.8103e-04 - mse: 9.8103e-04 - mae: 0.0165 - val_loss: 5.1346e-04 - val_mse: 5.1346e-04 - val_mae: 0.0138\n",
      "Epoch 91/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 9.6402e-04 - mse: 9.6402e-04 - mae: 0.0166 - val_loss: 5.0333e-04 - val_mse: 5.0333e-04 - val_mae: 0.0140\n",
      "Epoch 92/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 9.7433e-04 - mse: 9.7433e-04 - mae: 0.0167 - val_loss: 5.0057e-04 - val_mse: 5.0057e-04 - val_mae: 0.0138\n",
      "Epoch 93/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 9.7628e-04 - mse: 9.7628e-04 - mae: 0.0168 - val_loss: 4.9426e-04 - val_mse: 4.9426e-04 - val_mae: 0.0132\n",
      "Epoch 94/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 9.6597e-04 - mse: 9.6597e-04 - mae: 0.0166 - val_loss: 5.2395e-04 - val_mse: 5.2395e-04 - val_mae: 0.0140\n",
      "Epoch 95/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 9.7073e-04 - mse: 9.7073e-04 - mae: 0.0165 - val_loss: 4.8342e-04 - val_mse: 4.8342e-04 - val_mae: 0.0135\n",
      "Epoch 96/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 9.5641e-04 - mse: 9.5641e-04 - mae: 0.0165 - val_loss: 5.0396e-04 - val_mse: 5.0396e-04 - val_mae: 0.0141\n",
      "Epoch 97/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 9.5868e-04 - mse: 9.5868e-04 - mae: 0.0165 - val_loss: 4.9669e-04 - val_mse: 4.9669e-04 - val_mae: 0.0136\n",
      "Epoch 98/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 9.8094e-04 - mse: 9.8094e-04 - mae: 0.0166 - val_loss: 4.9124e-04 - val_mse: 4.9124e-04 - val_mae: 0.0134\n",
      "Epoch 99/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 9.6098e-04 - mse: 9.6098e-04 - mae: 0.0164 - val_loss: 5.0032e-04 - val_mse: 5.0032e-04 - val_mae: 0.0144\n",
      "Epoch 100/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 9.7671e-04 - mse: 9.7671e-04 - mae: 0.0165 - val_loss: 4.8847e-04 - val_mse: 4.8847e-04 - val_mae: 0.0138\n",
      "Train on 4128 samples, validate on 576 samples\n",
      "Epoch 1/100\n",
      "4128/4128 [==============================] - 17s 4ms/step - loss: 0.0327 - mse: 0.0327 - mae: 0.1433 - val_loss: 0.0026 - val_mse: 0.0026 - val_mae: 0.0390\n",
      "Epoch 2/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0232 - mse: 0.0232 - mae: 0.1200 - val_loss: 0.0021 - val_mse: 0.0021 - val_mae: 0.0337\n",
      "Epoch 3/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0177 - mse: 0.0177 - mae: 0.1051 - val_loss: 0.0016 - val_mse: 0.0016 - val_mae: 0.0311\n",
      "Epoch 4/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0140 - mse: 0.0140 - mae: 0.0922 - val_loss: 0.0015 - val_mse: 0.0015 - val_mae: 0.0293\n",
      "Epoch 5/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0112 - mse: 0.0112 - mae: 0.0828 - val_loss: 0.0015 - val_mse: 0.0015 - val_mae: 0.0291\n",
      "Epoch 6/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0091 - mse: 0.0091 - mae: 0.0746 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0254\n",
      "Epoch 7/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0076 - mse: 0.0076 - mae: 0.0680 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0247\n",
      "Epoch 8/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0066 - mse: 0.0066 - mae: 0.0624 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0251\n",
      "Epoch 9/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0055 - mse: 0.0055 - mae: 0.0568 - val_loss: 9.0141e-04 - val_mse: 9.0141e-04 - val_mae: 0.0214\n",
      "Epoch 10/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0050 - mse: 0.0050 - mae: 0.0538 - val_loss: 7.9873e-04 - val_mse: 7.9873e-04 - val_mae: 0.0195\n",
      "Epoch 11/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0503 - val_loss: 6.2842e-04 - val_mse: 6.2842e-04 - val_mae: 0.0187\n",
      "Epoch 12/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0478 - val_loss: 6.6992e-04 - val_mse: 6.6992e-04 - val_mae: 0.0176\n",
      "Epoch 13/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0447 - val_loss: 6.7640e-04 - val_mse: 6.7640e-04 - val_mae: 0.0178\n",
      "Epoch 14/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0432 - val_loss: 5.7029e-04 - val_mse: 5.7029e-04 - val_mae: 0.0161\n",
      "Epoch 15/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0398 - val_loss: 6.0752e-04 - val_mse: 6.0752e-04 - val_mae: 0.0160\n",
      "Epoch 16/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0388 - val_loss: 6.2283e-04 - val_mse: 6.2283e-04 - val_mae: 0.0162\n",
      "Epoch 17/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0375 - val_loss: 5.4219e-04 - val_mse: 5.4219e-04 - val_mae: 0.0148\n",
      "Epoch 18/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0356 - val_loss: 5.5667e-04 - val_mse: 5.5667e-04 - val_mae: 0.0149\n",
      "Epoch 19/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0347 - val_loss: 5.1830e-04 - val_mse: 5.1830e-04 - val_mae: 0.0147\n",
      "Epoch 20/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0328 - val_loss: 5.6434e-04 - val_mse: 5.6434e-04 - val_mae: 0.0150\n",
      "Epoch 21/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0319 - val_loss: 7.1263e-04 - val_mse: 7.1263e-04 - val_mae: 0.0176\n",
      "Epoch 22/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0311 - val_loss: 6.5028e-04 - val_mse: 6.5028e-04 - val_mae: 0.0163\n",
      "Epoch 23/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0306 - val_loss: 5.2136e-04 - val_mse: 5.2136e-04 - val_mae: 0.0142\n",
      "Epoch 24/100\n",
      "4128/4128 [==============================] - 17s 4ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0285 - val_loss: 5.1153e-04 - val_mse: 5.1153e-04 - val_mae: 0.0158\n",
      "Epoch 25/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0285 - val_loss: 5.7726e-04 - val_mse: 5.7726e-04 - val_mae: 0.0148\n",
      "Epoch 26/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0279 - val_loss: 5.1178e-04 - val_mse: 5.1178e-04 - val_mae: 0.0140\n",
      "Epoch 27/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0272 - val_loss: 5.2655e-04 - val_mse: 5.2655e-04 - val_mae: 0.0141\n",
      "Epoch 28/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0264 - val_loss: 5.0765e-04 - val_mse: 5.0765e-04 - val_mae: 0.0149\n",
      "Epoch 29/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0264 - val_loss: 5.0352e-04 - val_mse: 5.0352e-04 - val_mae: 0.0136\n",
      "Epoch 30/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0252 - val_loss: 5.4506e-04 - val_mse: 5.4506e-04 - val_mae: 0.0142\n",
      "Epoch 31/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0249 - val_loss: 5.1638e-04 - val_mse: 5.1638e-04 - val_mae: 0.0137\n",
      "Epoch 32/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0249 - val_loss: 4.9165e-04 - val_mse: 4.9165e-04 - val_mae: 0.0134\n",
      "Epoch 33/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0241 - val_loss: 4.8096e-04 - val_mse: 4.8096e-04 - val_mae: 0.0134\n",
      "Epoch 34/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0235 - val_loss: 5.1138e-04 - val_mse: 5.1138e-04 - val_mae: 0.0135\n",
      "Epoch 35/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0234 - val_loss: 5.7885e-04 - val_mse: 5.7885e-04 - val_mae: 0.0146\n",
      "Epoch 36/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0222 - val_loss: 5.4307e-04 - val_mse: 5.4307e-04 - val_mae: 0.0140\n",
      "Epoch 37/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0229 - val_loss: 5.1492e-04 - val_mse: 5.1492e-04 - val_mae: 0.0133\n",
      "Epoch 38/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0221 - val_loss: 5.0537e-04 - val_mse: 5.0537e-04 - val_mae: 0.0133\n",
      "Epoch 39/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0217 - val_loss: 4.6310e-04 - val_mse: 4.6310e-04 - val_mae: 0.0134\n",
      "Epoch 40/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0215 - val_loss: 5.1534e-04 - val_mse: 5.1534e-04 - val_mae: 0.0133\n",
      "Epoch 41/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0215 - val_loss: 4.9533e-04 - val_mse: 4.9533e-04 - val_mae: 0.0131\n",
      "Epoch 42/100\n",
      "4128/4128 [==============================] - 17s 4ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0214 - val_loss: 5.4962e-04 - val_mse: 5.4962e-04 - val_mae: 0.0140\n",
      "Epoch 43/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0209 - val_loss: 4.8887e-04 - val_mse: 4.8887e-04 - val_mae: 0.0130\n",
      "Epoch 44/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0206 - val_loss: 4.8738e-04 - val_mse: 4.8738e-04 - val_mae: 0.0131\n",
      "Epoch 45/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0207 - val_loss: 5.1465e-04 - val_mse: 5.1465e-04 - val_mae: 0.0133\n",
      "Epoch 46/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0202 - val_loss: 4.7267e-04 - val_mse: 4.7267e-04 - val_mae: 0.0132\n",
      "Epoch 47/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0199 - val_loss: 5.2511e-04 - val_mse: 5.2511e-04 - val_mae: 0.0135\n",
      "Epoch 48/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0202 - val_loss: 4.8087e-04 - val_mse: 4.8087e-04 - val_mae: 0.0130\n",
      "Epoch 49/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0199 - val_loss: 5.2952e-04 - val_mse: 5.2952e-04 - val_mae: 0.0136\n",
      "Epoch 50/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0195 - val_loss: 4.7935e-04 - val_mse: 4.7935e-04 - val_mae: 0.0130\n",
      "Epoch 51/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0197 - val_loss: 4.5120e-04 - val_mse: 4.5120e-04 - val_mae: 0.0128\n",
      "Epoch 52/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0194 - val_loss: 4.7302e-04 - val_mse: 4.7302e-04 - val_mae: 0.0129\n",
      "Epoch 53/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0191 - val_loss: 4.8857e-04 - val_mse: 4.8857e-04 - val_mae: 0.0131\n",
      "Epoch 54/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0190 - val_loss: 4.8635e-04 - val_mse: 4.8635e-04 - val_mae: 0.0131\n",
      "Epoch 55/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0194 - val_loss: 4.9471e-04 - val_mse: 4.9471e-04 - val_mae: 0.0130\n",
      "Epoch 56/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0189 - val_loss: 5.0902e-04 - val_mse: 5.0902e-04 - val_mae: 0.0134\n",
      "Epoch 57/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0188 - val_loss: 4.9341e-04 - val_mse: 4.9341e-04 - val_mae: 0.0132\n",
      "Epoch 58/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0187 - val_loss: 4.7491e-04 - val_mse: 4.7491e-04 - val_mae: 0.0129\n",
      "Epoch 59/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0188 - val_loss: 4.6901e-04 - val_mse: 4.6901e-04 - val_mae: 0.0129\n",
      "Epoch 60/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0186 - val_loss: 4.7941e-04 - val_mse: 4.7941e-04 - val_mae: 0.0127\n",
      "Epoch 61/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0183 - val_loss: 4.9159e-04 - val_mse: 4.9159e-04 - val_mae: 0.0130\n",
      "Epoch 62/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0184 - val_loss: 5.1219e-04 - val_mse: 5.1219e-04 - val_mae: 0.0132\n",
      "Epoch 63/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0183 - val_loss: 5.0773e-04 - val_mse: 5.0773e-04 - val_mae: 0.0133\n",
      "Epoch 64/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0184 - val_loss: 4.6526e-04 - val_mse: 4.6526e-04 - val_mae: 0.0126\n",
      "Epoch 65/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0183 - val_loss: 4.8472e-04 - val_mse: 4.8472e-04 - val_mae: 0.0129\n",
      "Epoch 66/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0183 - val_loss: 4.6192e-04 - val_mse: 4.6192e-04 - val_mae: 0.0126\n",
      "Epoch 67/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0181 - val_loss: 4.6593e-04 - val_mse: 4.6593e-04 - val_mae: 0.0128\n",
      "Epoch 68/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0180 - val_loss: 4.9228e-04 - val_mse: 4.9228e-04 - val_mae: 0.0129\n",
      "Epoch 69/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0180 - val_loss: 4.7233e-04 - val_mse: 4.7233e-04 - val_mae: 0.0127\n",
      "Epoch 70/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0179 - val_loss: 4.6188e-04 - val_mse: 4.6188e-04 - val_mae: 0.0127\n",
      "Epoch 71/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0179 - val_loss: 4.7354e-04 - val_mse: 4.7354e-04 - val_mae: 0.0127\n",
      "Epoch 72/100\n",
      "4128/4128 [==============================] - 17s 4ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0178 - val_loss: 5.1453e-04 - val_mse: 5.1453e-04 - val_mae: 0.0133\n",
      "Epoch 73/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0179 - val_loss: 5.0078e-04 - val_mse: 5.0078e-04 - val_mae: 0.0129\n",
      "Epoch 74/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0176 - val_loss: 4.7192e-04 - val_mse: 4.7192e-04 - val_mae: 0.0128\n",
      "Epoch 75/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0178 - val_loss: 4.6219e-04 - val_mse: 4.6219e-04 - val_mae: 0.0127\n",
      "Epoch 76/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0177 - val_loss: 4.7941e-04 - val_mse: 4.7941e-04 - val_mae: 0.0128\n",
      "Epoch 77/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0177 - val_loss: 4.7436e-04 - val_mse: 4.7436e-04 - val_mae: 0.0126\n",
      "Epoch 78/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0173 - val_loss: 4.8777e-04 - val_mse: 4.8777e-04 - val_mae: 0.0128\n",
      "Epoch 79/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0173 - val_loss: 4.9358e-04 - val_mse: 4.9358e-04 - val_mae: 0.0130\n",
      "Epoch 80/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0177 - val_loss: 4.8248e-04 - val_mse: 4.8248e-04 - val_mae: 0.0128\n",
      "Epoch 81/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0174 - val_loss: 4.6716e-04 - val_mse: 4.6716e-04 - val_mae: 0.0127\n",
      "Epoch 82/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0172 - val_loss: 4.9098e-04 - val_mse: 4.9098e-04 - val_mae: 0.0128\n",
      "Epoch 83/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0173 - val_loss: 4.6523e-04 - val_mse: 4.6523e-04 - val_mae: 0.0128\n",
      "Epoch 84/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0173 - val_loss: 4.8485e-04 - val_mse: 4.8485e-04 - val_mae: 0.0129\n",
      "Epoch 85/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 9.9904e-04 - mse: 9.9904e-04 - mae: 0.0172 - val_loss: 4.7000e-04 - val_mse: 4.7000e-04 - val_mae: 0.0127\n",
      "Epoch 86/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 9.9425e-04 - mse: 9.9425e-04 - mae: 0.0172 - val_loss: 4.8155e-04 - val_mse: 4.8155e-04 - val_mae: 0.0129\n",
      "Epoch 87/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0172 - val_loss: 4.6799e-04 - val_mse: 4.6799e-04 - val_mae: 0.0126\n",
      "Epoch 88/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0172 - val_loss: 4.7826e-04 - val_mse: 4.7826e-04 - val_mae: 0.0128\n",
      "Epoch 89/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 9.7599e-04 - mse: 9.7600e-04 - mae: 0.0169 - val_loss: 4.7494e-04 - val_mse: 4.7494e-04 - val_mae: 0.0129\n",
      "Epoch 90/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 9.8607e-04 - mse: 9.8607e-04 - mae: 0.0170 - val_loss: 4.6857e-04 - val_mse: 4.6857e-04 - val_mae: 0.0127\n",
      "Epoch 91/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 9.7107e-04 - mse: 9.7107e-04 - mae: 0.0169 - val_loss: 4.7395e-04 - val_mse: 4.7395e-04 - val_mae: 0.0128\n",
      "Epoch 92/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 9.7003e-04 - mse: 9.7003e-04 - mae: 0.0169 - val_loss: 4.6740e-04 - val_mse: 4.6740e-04 - val_mae: 0.0128\n",
      "Epoch 93/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0171 - val_loss: 4.8566e-04 - val_mse: 4.8566e-04 - val_mae: 0.0128\n",
      "Epoch 94/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 9.9080e-04 - mse: 9.9080e-04 - mae: 0.0171 - val_loss: 4.9046e-04 - val_mse: 4.9046e-04 - val_mae: 0.0129\n",
      "Epoch 95/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 9.8253e-04 - mse: 9.8253e-04 - mae: 0.0169 - val_loss: 4.6975e-04 - val_mse: 4.6975e-04 - val_mae: 0.0127\n",
      "Epoch 96/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 9.7655e-04 - mse: 9.7655e-04 - mae: 0.0168 - val_loss: 4.8682e-04 - val_mse: 4.8682e-04 - val_mae: 0.0128\n",
      "Epoch 97/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 9.6652e-04 - mse: 9.6652e-04 - mae: 0.0167 - val_loss: 4.6607e-04 - val_mse: 4.6607e-04 - val_mae: 0.0129\n",
      "Epoch 98/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 9.8658e-04 - mse: 9.8658e-04 - mae: 0.0169 - val_loss: 4.7692e-04 - val_mse: 4.7692e-04 - val_mae: 0.0127\n",
      "Epoch 99/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 9.7237e-04 - mse: 9.7237e-04 - mae: 0.0168 - val_loss: 4.8002e-04 - val_mse: 4.8002e-04 - val_mae: 0.0130\n",
      "Epoch 100/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 9.8275e-04 - mse: 9.8275e-04 - mae: 0.0166 - val_loss: 4.8997e-04 - val_mse: 4.8997e-04 - val_mae: 0.0129\n",
      "Train on 4128 samples, validate on 576 samples\n",
      "Epoch 1/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0285 - mse: 0.0285 - mae: 0.1334 - val_loss: 0.0110 - val_mse: 0.0110 - val_mae: 0.0963\n",
      "Epoch 2/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0225 - mse: 0.0225 - mae: 0.1191 - val_loss: 0.0047 - val_mse: 0.0047 - val_mae: 0.0592\n",
      "Epoch 3/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0178 - mse: 0.0178 - mae: 0.1059 - val_loss: 0.0021 - val_mse: 0.0021 - val_mae: 0.0351\n",
      "Epoch 4/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0142 - mse: 0.0142 - mae: 0.0943 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0258\n",
      "Epoch 5/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0120 - mse: 0.0120 - mae: 0.0859 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0245\n",
      "Epoch 6/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0092 - mse: 0.0092 - mae: 0.0753 - val_loss: 0.0015 - val_mse: 0.0015 - val_mae: 0.0280\n",
      "Epoch 7/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0079 - mse: 0.0079 - mae: 0.0687 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0258\n",
      "Epoch 8/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0066 - mse: 0.0066 - mae: 0.0625 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0234\n",
      "Epoch 9/100\n",
      "4128/4128 [==============================] - 14s 3ms/step - loss: 0.0056 - mse: 0.0056 - mae: 0.0575 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0236\n",
      "Epoch 10/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0050 - mse: 0.0050 - mae: 0.0537 - val_loss: 7.6855e-04 - val_mse: 7.6855e-04 - val_mae: 0.0198\n",
      "Epoch 11/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0496 - val_loss: 6.5106e-04 - val_mse: 6.5106e-04 - val_mae: 0.0183\n",
      "Epoch 12/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0480 - val_loss: 9.9958e-04 - val_mse: 9.9958e-04 - val_mae: 0.0227\n",
      "Epoch 13/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0453 - val_loss: 7.1909e-04 - val_mse: 7.1909e-04 - val_mae: 0.0181\n",
      "Epoch 14/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0446 - val_loss: 6.8305e-04 - val_mse: 6.8305e-04 - val_mae: 0.0177\n",
      "Epoch 15/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0412 - val_loss: 6.7327e-04 - val_mse: 6.7327e-04 - val_mae: 0.0178\n",
      "Epoch 16/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0408 - val_loss: 5.7489e-04 - val_mse: 5.7489e-04 - val_mae: 0.0158\n",
      "Epoch 17/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0397 - val_loss: 6.0654e-04 - val_mse: 6.0654e-04 - val_mae: 0.0163\n",
      "Epoch 18/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0381 - val_loss: 5.5102e-04 - val_mse: 5.5102e-04 - val_mae: 0.0152\n",
      "Epoch 19/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0362 - val_loss: 5.5128e-04 - val_mse: 5.5128e-04 - val_mae: 0.0151\n",
      "Epoch 20/100\n",
      "4128/4128 [==============================] - 14s 3ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0351 - val_loss: 5.4380e-04 - val_mse: 5.4380e-04 - val_mae: 0.0148\n",
      "Epoch 21/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0341 - val_loss: 7.2758e-04 - val_mse: 7.2758e-04 - val_mae: 0.0178\n",
      "Epoch 22/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0326 - val_loss: 4.7116e-04 - val_mse: 4.7116e-04 - val_mae: 0.0140\n",
      "Epoch 23/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0320 - val_loss: 5.0333e-04 - val_mse: 5.0333e-04 - val_mae: 0.0144\n",
      "Epoch 24/100\n",
      "4128/4128 [==============================] - 14s 4ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0317 - val_loss: 6.5861e-04 - val_mse: 6.5861e-04 - val_mae: 0.0163\n",
      "Epoch 25/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0306 - val_loss: 4.9467e-04 - val_mse: 4.9467e-04 - val_mae: 0.0143\n",
      "Epoch 26/100\n",
      "4128/4128 [==============================] - 14s 3ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0294 - val_loss: 4.9760e-04 - val_mse: 4.9760e-04 - val_mae: 0.0140\n",
      "Epoch 27/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0292 - val_loss: 6.3520e-04 - val_mse: 6.3520e-04 - val_mae: 0.0157\n",
      "Epoch 28/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0285 - val_loss: 5.1094e-04 - val_mse: 5.1094e-04 - val_mae: 0.0135\n",
      "Epoch 29/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0277 - val_loss: 4.9638e-04 - val_mse: 4.9638e-04 - val_mae: 0.0135\n",
      "Epoch 30/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0270 - val_loss: 5.1422e-04 - val_mse: 5.1422e-04 - val_mae: 0.0136\n",
      "Epoch 31/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0269 - val_loss: 4.5464e-04 - val_mse: 4.5464e-04 - val_mae: 0.0132\n",
      "Epoch 32/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0263 - val_loss: 4.6911e-04 - val_mse: 4.6911e-04 - val_mae: 0.0131\n",
      "Epoch 33/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0256 - val_loss: 5.0849e-04 - val_mse: 5.0849e-04 - val_mae: 0.0133\n",
      "Epoch 34/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0256 - val_loss: 4.7620e-04 - val_mse: 4.7620e-04 - val_mae: 0.0135\n",
      "Epoch 35/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0253 - val_loss: 4.3463e-04 - val_mse: 4.3463e-04 - val_mae: 0.0134\n",
      "Epoch 36/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0247 - val_loss: 4.8683e-04 - val_mse: 4.8683e-04 - val_mae: 0.0131\n",
      "Epoch 37/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0242 - val_loss: 4.8233e-04 - val_mse: 4.8233e-04 - val_mae: 0.0129\n",
      "Epoch 38/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0241 - val_loss: 4.6241e-04 - val_mse: 4.6241e-04 - val_mae: 0.0126\n",
      "Epoch 39/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0238 - val_loss: 4.5032e-04 - val_mse: 4.5032e-04 - val_mae: 0.0125\n",
      "Epoch 40/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0236 - val_loss: 5.0377e-04 - val_mse: 5.0377e-04 - val_mae: 0.0130\n",
      "Epoch 41/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0227 - val_loss: 4.5530e-04 - val_mse: 4.5530e-04 - val_mae: 0.0125\n",
      "Epoch 42/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0227 - val_loss: 4.6550e-04 - val_mse: 4.6550e-04 - val_mae: 0.0127\n",
      "Epoch 43/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0229 - val_loss: 5.1684e-04 - val_mse: 5.1684e-04 - val_mae: 0.0132\n",
      "Epoch 44/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0224 - val_loss: 4.6420e-04 - val_mse: 4.6420e-04 - val_mae: 0.0124\n",
      "Epoch 45/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0220 - val_loss: 4.8759e-04 - val_mse: 4.8759e-04 - val_mae: 0.0128\n",
      "Epoch 46/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0220 - val_loss: 4.9797e-04 - val_mse: 4.9797e-04 - val_mae: 0.0129\n",
      "Epoch 47/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0217 - val_loss: 4.7777e-04 - val_mse: 4.7777e-04 - val_mae: 0.0126\n",
      "Epoch 48/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0212 - val_loss: 4.7808e-04 - val_mse: 4.7808e-04 - val_mae: 0.0128\n",
      "Epoch 49/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0215 - val_loss: 4.5594e-04 - val_mse: 4.5594e-04 - val_mae: 0.0124\n",
      "Epoch 50/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0209 - val_loss: 4.6583e-04 - val_mse: 4.6583e-04 - val_mae: 0.0125\n",
      "Epoch 51/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0208 - val_loss: 4.8790e-04 - val_mse: 4.8790e-04 - val_mae: 0.0127\n",
      "Epoch 52/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0204 - val_loss: 4.7261e-04 - val_mse: 4.7261e-04 - val_mae: 0.0127\n",
      "Epoch 53/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0207 - val_loss: 4.8102e-04 - val_mse: 4.8102e-04 - val_mae: 0.0125\n",
      "Epoch 54/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0204 - val_loss: 5.0746e-04 - val_mse: 5.0746e-04 - val_mae: 0.0130\n",
      "Epoch 55/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0202 - val_loss: 4.5988e-04 - val_mse: 4.5988e-04 - val_mae: 0.0124\n",
      "Epoch 56/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0202 - val_loss: 4.8710e-04 - val_mse: 4.8710e-04 - val_mae: 0.0127\n",
      "Epoch 57/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0203 - val_loss: 4.5800e-04 - val_mse: 4.5800e-04 - val_mae: 0.0122\n",
      "Epoch 58/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0199 - val_loss: 4.6432e-04 - val_mse: 4.6432e-04 - val_mae: 0.0123\n",
      "Epoch 59/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0198 - val_loss: 4.7369e-04 - val_mse: 4.7369e-04 - val_mae: 0.0124\n",
      "Epoch 60/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0197 - val_loss: 4.7477e-04 - val_mse: 4.7477e-04 - val_mae: 0.0124\n",
      "Epoch 61/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0195 - val_loss: 4.6940e-04 - val_mse: 4.6940e-04 - val_mae: 0.0123\n",
      "Epoch 62/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0194 - val_loss: 4.8466e-04 - val_mse: 4.8466e-04 - val_mae: 0.0126\n",
      "Epoch 63/100\n",
      "4128/4128 [==============================] - 17s 4ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0196 - val_loss: 4.7255e-04 - val_mse: 4.7255e-04 - val_mae: 0.0124\n",
      "Epoch 64/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0193 - val_loss: 4.9468e-04 - val_mse: 4.9468e-04 - val_mae: 0.0127\n",
      "Epoch 65/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0188 - val_loss: 4.7433e-04 - val_mse: 4.7433e-04 - val_mae: 0.0125\n",
      "Epoch 66/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0191 - val_loss: 4.6283e-04 - val_mse: 4.6283e-04 - val_mae: 0.0123\n",
      "Epoch 67/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0190 - val_loss: 4.5061e-04 - val_mse: 4.5061e-04 - val_mae: 0.0121\n",
      "Epoch 68/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0190 - val_loss: 4.8477e-04 - val_mse: 4.8477e-04 - val_mae: 0.0127\n",
      "Epoch 69/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0186 - val_loss: 4.6469e-04 - val_mse: 4.6469e-04 - val_mae: 0.0123\n",
      "Epoch 70/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0187 - val_loss: 4.9271e-04 - val_mse: 4.9271e-04 - val_mae: 0.0127\n",
      "Epoch 71/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0189 - val_loss: 4.7418e-04 - val_mse: 4.7418e-04 - val_mae: 0.0125\n",
      "Epoch 72/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0189 - val_loss: 4.6877e-04 - val_mse: 4.6877e-04 - val_mae: 0.0124\n",
      "Epoch 73/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0187 - val_loss: 4.9501e-04 - val_mse: 4.9501e-04 - val_mae: 0.0128\n",
      "Epoch 74/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0186 - val_loss: 4.9640e-04 - val_mse: 4.9640e-04 - val_mae: 0.0128\n",
      "Epoch 75/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0184 - val_loss: 4.8265e-04 - val_mse: 4.8265e-04 - val_mae: 0.0126\n",
      "Epoch 76/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0183 - val_loss: 4.6961e-04 - val_mse: 4.6961e-04 - val_mae: 0.0124\n",
      "Epoch 77/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0183 - val_loss: 4.8740e-04 - val_mse: 4.8740e-04 - val_mae: 0.0128\n",
      "Epoch 78/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0182 - val_loss: 4.6175e-04 - val_mse: 4.6175e-04 - val_mae: 0.0123\n",
      "Epoch 79/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0185 - val_loss: 4.5469e-04 - val_mse: 4.5469e-04 - val_mae: 0.0123\n",
      "Epoch 80/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0182 - val_loss: 4.7814e-04 - val_mse: 4.7814e-04 - val_mae: 0.0125\n",
      "Epoch 81/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0180 - val_loss: 4.4308e-04 - val_mse: 4.4308e-04 - val_mae: 0.0121\n",
      "Epoch 82/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0181 - val_loss: 4.6999e-04 - val_mse: 4.6999e-04 - val_mae: 0.0125\n",
      "Epoch 83/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0180 - val_loss: 4.6531e-04 - val_mse: 4.6531e-04 - val_mae: 0.0125\n",
      "Epoch 84/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0179 - val_loss: 4.6031e-04 - val_mse: 4.6031e-04 - val_mae: 0.0123\n",
      "Epoch 85/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0180 - val_loss: 4.7239e-04 - val_mse: 4.7239e-04 - val_mae: 0.0125\n",
      "Epoch 86/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0180 - val_loss: 4.6825e-04 - val_mse: 4.6825e-04 - val_mae: 0.0124\n",
      "Epoch 87/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0178 - val_loss: 4.7146e-04 - val_mse: 4.7146e-04 - val_mae: 0.0125\n",
      "Epoch 88/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0179 - val_loss: 4.5646e-04 - val_mse: 4.5646e-04 - val_mae: 0.0123\n",
      "Epoch 89/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0177 - val_loss: 4.8105e-04 - val_mse: 4.8105e-04 - val_mae: 0.0127\n",
      "Epoch 90/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0177 - val_loss: 4.8195e-04 - val_mse: 4.8195e-04 - val_mae: 0.0126\n",
      "Epoch 91/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0177 - val_loss: 4.5051e-04 - val_mse: 4.5051e-04 - val_mae: 0.0123\n",
      "Epoch 92/100\n",
      "4128/4128 [==============================] - 14s 3ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0177 - val_loss: 4.7383e-04 - val_mse: 4.7383e-04 - val_mae: 0.0127\n",
      "Epoch 93/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0175 - val_loss: 4.7423e-04 - val_mse: 4.7423e-04 - val_mae: 0.0126\n",
      "Epoch 94/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0178 - val_loss: 4.6815e-04 - val_mse: 4.6815e-04 - val_mae: 0.0125\n",
      "Epoch 95/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0175 - val_loss: 4.8436e-04 - val_mse: 4.8436e-04 - val_mae: 0.0127\n",
      "Epoch 96/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0173 - val_loss: 4.7170e-04 - val_mse: 4.7170e-04 - val_mae: 0.0127\n",
      "Epoch 97/100\n",
      "4128/4128 [==============================] - 14s 3ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0173 - val_loss: 4.6753e-04 - val_mse: 4.6753e-04 - val_mae: 0.0125\n",
      "Epoch 98/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0176 - val_loss: 4.5773e-04 - val_mse: 4.5773e-04 - val_mae: 0.0124\n",
      "Epoch 99/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0175 - val_loss: 4.8891e-04 - val_mse: 4.8891e-04 - val_mae: 0.0130\n",
      "Epoch 100/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0173 - val_loss: 4.6738e-04 - val_mse: 4.6738e-04 - val_mae: 0.0127\n",
      "Train on 4128 samples, validate on 576 samples\n",
      "Epoch 1/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.2475 - mse: 0.2475 - mae: 0.3947 - val_loss: 8.7416e-04 - val_mse: 8.7416e-04 - val_mae: 0.0243\n",
      "Epoch 2/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.1994 - mse: 0.1994 - mae: 0.3549 - val_loss: 0.0049 - val_mse: 0.0049 - val_mae: 0.0652\n",
      "Epoch 3/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.1652 - mse: 0.1652 - mae: 0.3248 - val_loss: 0.0017 - val_mse: 0.0017 - val_mae: 0.0339\n",
      "Epoch 4/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.1410 - mse: 0.1410 - mae: 0.2999 - val_loss: 0.0085 - val_mse: 0.0085 - val_mae: 0.0885\n",
      "Epoch 5/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.1211 - mse: 0.1211 - mae: 0.2770 - val_loss: 7.1522e-04 - val_mse: 7.1522e-04 - val_mae: 0.0177\n",
      "Epoch 6/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.1005 - mse: 0.1005 - mae: 0.2544 - val_loss: 0.0037 - val_mse: 0.0037 - val_mae: 0.0575\n",
      "Epoch 7/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0890 - mse: 0.0890 - mae: 0.2394 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0290\n",
      "Epoch 8/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0795 - mse: 0.0795 - mae: 0.2253 - val_loss: 6.8498e-04 - val_mse: 6.8498e-04 - val_mae: 0.0166\n",
      "Epoch 9/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0689 - mse: 0.0689 - mae: 0.2092 - val_loss: 0.0029 - val_mse: 0.0029 - val_mae: 0.0486\n",
      "Epoch 10/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0618 - mse: 0.0618 - mae: 0.1993 - val_loss: 0.0102 - val_mse: 0.0102 - val_mae: 0.0984\n",
      "Epoch 11/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0547 - mse: 0.0547 - mae: 0.1851 - val_loss: 0.0042 - val_mse: 0.0042 - val_mae: 0.0608\n",
      "Epoch 12/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0501 - mse: 0.0501 - mae: 0.1776 - val_loss: 5.5573e-04 - val_mse: 5.5573e-04 - val_mae: 0.0174\n",
      "Epoch 13/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0450 - mse: 0.0450 - mae: 0.1673 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0301\n",
      "Epoch 14/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0415 - mse: 0.0415 - mae: 0.1617 - val_loss: 5.3891e-04 - val_mse: 5.3891e-04 - val_mae: 0.0166\n",
      "Epoch 15/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0384 - mse: 0.0384 - mae: 0.1560 - val_loss: 0.0048 - val_mse: 0.0048 - val_mae: 0.0668\n",
      "Epoch 16/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0340 - mse: 0.0340 - mae: 0.1468 - val_loss: 5.2486e-04 - val_mse: 5.2486e-04 - val_mae: 0.0153\n",
      "Epoch 17/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0312 - mse: 0.0312 - mae: 0.1406 - val_loss: 5.1566e-04 - val_mse: 5.1566e-04 - val_mae: 0.0156\n",
      "Epoch 18/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0289 - mse: 0.0289 - mae: 0.1347 - val_loss: 5.1074e-04 - val_mse: 5.1074e-04 - val_mae: 0.0153\n",
      "Epoch 19/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0264 - mse: 0.0264 - mae: 0.1288 - val_loss: 6.8712e-04 - val_mse: 6.8712e-04 - val_mae: 0.0218\n",
      "Epoch 20/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0244 - mse: 0.0244 - mae: 0.1247 - val_loss: 7.3819e-04 - val_mse: 7.3819e-04 - val_mae: 0.0230\n",
      "Epoch 21/100\n",
      "4128/4128 [==============================] - 14s 3ms/step - loss: 0.0228 - mse: 0.0228 - mae: 0.1194 - val_loss: 0.0014 - val_mse: 0.0014 - val_mae: 0.0289\n",
      "Epoch 22/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0201 - mse: 0.0201 - mae: 0.1122 - val_loss: 6.0611e-04 - val_mse: 6.0611e-04 - val_mae: 0.0199\n",
      "Epoch 23/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0190 - mse: 0.0190 - mae: 0.1085 - val_loss: 6.1267e-04 - val_mse: 6.1267e-04 - val_mae: 0.0200\n",
      "Epoch 24/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0175 - mse: 0.0175 - mae: 0.1044 - val_loss: 9.8831e-04 - val_mse: 9.8831e-04 - val_mae: 0.0223\n",
      "Epoch 25/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0153 - mse: 0.0153 - mae: 0.0973 - val_loss: 8.8733e-04 - val_mse: 8.8733e-04 - val_mae: 0.0202\n",
      "Epoch 26/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0146 - mse: 0.0146 - mae: 0.0957 - val_loss: 5.0155e-04 - val_mse: 5.0155e-04 - val_mae: 0.0153\n",
      "Epoch 27/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0132 - mse: 0.0132 - mae: 0.0906 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0569\n",
      "Epoch 28/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0130 - mse: 0.0130 - mae: 0.0895 - val_loss: 5.0782e-04 - val_mse: 5.0782e-04 - val_mae: 0.0141\n",
      "Epoch 29/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0116 - mse: 0.0116 - mae: 0.0849 - val_loss: 6.1519e-04 - val_mse: 6.1519e-04 - val_mae: 0.0144\n",
      "Epoch 30/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0106 - mse: 0.0106 - mae: 0.0805 - val_loss: 5.6086e-04 - val_mse: 5.6086e-04 - val_mae: 0.0182\n",
      "Epoch 31/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0102 - mse: 0.0102 - mae: 0.0784 - val_loss: 5.2466e-04 - val_mse: 5.2466e-04 - val_mae: 0.0165\n",
      "Epoch 32/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0098 - mse: 0.0098 - mae: 0.0776 - val_loss: 6.0710e-04 - val_mse: 6.0710e-04 - val_mae: 0.0197\n",
      "Epoch 33/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0085 - mse: 0.0085 - mae: 0.0721 - val_loss: 5.7269e-04 - val_mse: 5.7269e-04 - val_mae: 0.0141\n",
      "Epoch 34/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0082 - mse: 0.0082 - mae: 0.0708 - val_loss: 8.9815e-04 - val_mse: 8.9815e-04 - val_mae: 0.0269\n",
      "Epoch 35/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0079 - mse: 0.0079 - mae: 0.0696 - val_loss: 5.1138e-04 - val_mse: 5.1138e-04 - val_mae: 0.0149\n",
      "Epoch 36/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0069 - mse: 0.0069 - mae: 0.0642 - val_loss: 0.0021 - val_mse: 0.0021 - val_mae: 0.0398\n",
      "Epoch 37/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0068 - mse: 0.0068 - mae: 0.0634 - val_loss: 8.0287e-04 - val_mse: 8.0287e-04 - val_mae: 0.0252\n",
      "Epoch 38/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0061 - mse: 0.0061 - mae: 0.0599 - val_loss: 6.7533e-04 - val_mse: 6.7533e-04 - val_mae: 0.0225\n",
      "Epoch 39/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0057 - mse: 0.0057 - mae: 0.0584 - val_loss: 7.5045e-04 - val_mse: 7.5045e-04 - val_mae: 0.0242\n",
      "Epoch 40/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0054 - mse: 0.0054 - mae: 0.0563 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0238\n",
      "Epoch 41/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0050 - mse: 0.0050 - mae: 0.0535 - val_loss: 4.8160e-04 - val_mse: 4.8160e-04 - val_mae: 0.0135\n",
      "Epoch 42/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0048 - mse: 0.0048 - mae: 0.0529 - val_loss: 5.5872e-04 - val_mse: 5.5872e-04 - val_mae: 0.0189\n",
      "Epoch 43/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0044 - mse: 0.0044 - mae: 0.0503 - val_loss: 4.8572e-04 - val_mse: 4.8572e-04 - val_mae: 0.0151\n",
      "Epoch 44/100\n",
      "4128/4128 [==============================] - 14s 3ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0472 - val_loss: 5.2375e-04 - val_mse: 5.2375e-04 - val_mae: 0.0127\n",
      "Epoch 45/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0466 - val_loss: 4.7512e-04 - val_mse: 4.7512e-04 - val_mae: 0.0148\n",
      "Epoch 46/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0451 - val_loss: 4.9055e-04 - val_mse: 4.9055e-04 - val_mae: 0.0153\n",
      "Epoch 47/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0431 - val_loss: 4.8273e-04 - val_mse: 4.8273e-04 - val_mae: 0.0145\n",
      "Epoch 48/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0421 - val_loss: 4.7101e-04 - val_mse: 4.7101e-04 - val_mae: 0.0134\n",
      "Epoch 49/100\n",
      "4128/4128 [==============================] - 14s 4ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0397 - val_loss: 4.6999e-04 - val_mse: 4.6999e-04 - val_mae: 0.0139\n",
      "Epoch 50/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0383 - val_loss: 4.6854e-04 - val_mse: 4.6854e-04 - val_mae: 0.0145\n",
      "Epoch 51/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0379 - val_loss: 4.8921e-04 - val_mse: 4.8921e-04 - val_mae: 0.0126\n",
      "Epoch 52/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0363 - val_loss: 5.7807e-04 - val_mse: 5.7807e-04 - val_mae: 0.0134\n",
      "Epoch 53/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0356 - val_loss: 4.7555e-04 - val_mse: 4.7555e-04 - val_mae: 0.0134\n",
      "Epoch 54/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0339 - val_loss: 4.7827e-04 - val_mse: 4.7827e-04 - val_mae: 0.0154\n",
      "Epoch 55/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0328 - val_loss: 5.6652e-04 - val_mse: 5.6652e-04 - val_mae: 0.0132\n",
      "Epoch 56/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0322 - val_loss: 4.9117e-04 - val_mse: 4.9117e-04 - val_mae: 0.0125\n",
      "Epoch 57/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0305 - val_loss: 6.1867e-04 - val_mse: 6.1867e-04 - val_mae: 0.0144\n",
      "Epoch 58/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0302 - val_loss: 4.6527e-04 - val_mse: 4.6527e-04 - val_mae: 0.0139\n",
      "Epoch 59/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0289 - val_loss: 4.5722e-04 - val_mse: 4.5722e-04 - val_mae: 0.0136\n",
      "Epoch 60/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0281 - val_loss: 5.7150e-04 - val_mse: 5.7150e-04 - val_mae: 0.0135\n",
      "Epoch 61/100\n",
      "4128/4128 [==============================] - 14s 3ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0278 - val_loss: 5.2261e-04 - val_mse: 5.2261e-04 - val_mae: 0.0127\n",
      "Epoch 62/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0271 - val_loss: 6.3138e-04 - val_mse: 6.3138e-04 - val_mae: 0.0148\n",
      "Epoch 63/100\n",
      "4128/4128 [==============================] - 14s 3ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0262 - val_loss: 5.8461e-04 - val_mse: 5.8461e-04 - val_mae: 0.0139\n",
      "Epoch 64/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0253 - val_loss: 4.6572e-04 - val_mse: 4.6572e-04 - val_mae: 0.0125\n",
      "Epoch 65/100\n",
      "4128/4128 [==============================] - 14s 3ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0248 - val_loss: 5.4520e-04 - val_mse: 5.4520e-04 - val_mae: 0.0131\n",
      "Epoch 66/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0243 - val_loss: 5.5869e-04 - val_mse: 5.5869e-04 - val_mae: 0.0133\n",
      "Epoch 67/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0238 - val_loss: 6.0268e-04 - val_mse: 6.0268e-04 - val_mae: 0.0145\n",
      "Epoch 68/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0230 - val_loss: 5.7007e-04 - val_mse: 5.7007e-04 - val_mae: 0.0137\n",
      "Epoch 69/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0229 - val_loss: 5.2737e-04 - val_mse: 5.2737e-04 - val_mae: 0.0128\n",
      "Epoch 70/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0222 - val_loss: 5.2804e-04 - val_mse: 5.2804e-04 - val_mae: 0.0128\n",
      "Epoch 71/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0218 - val_loss: 4.7622e-04 - val_mse: 4.7622e-04 - val_mae: 0.0122\n",
      "Epoch 72/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0216 - val_loss: 4.9212e-04 - val_mse: 4.9212e-04 - val_mae: 0.0122\n",
      "Epoch 73/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0217 - val_loss: 5.7070e-04 - val_mse: 5.7070e-04 - val_mae: 0.0137\n",
      "Epoch 74/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0211 - val_loss: 5.1762e-04 - val_mse: 5.1762e-04 - val_mae: 0.0126\n",
      "Epoch 75/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0212 - val_loss: 4.9943e-04 - val_mse: 4.9943e-04 - val_mae: 0.0123\n",
      "Epoch 76/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0208 - val_loss: 5.3979e-04 - val_mse: 5.3979e-04 - val_mae: 0.0130\n",
      "Epoch 77/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0205 - val_loss: 5.2605e-04 - val_mse: 5.2605e-04 - val_mae: 0.0127\n",
      "Epoch 78/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0206 - val_loss: 5.0403e-04 - val_mse: 5.0403e-04 - val_mae: 0.0123\n",
      "Epoch 79/100\n",
      "4128/4128 [==============================] - 14s 3ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0203 - val_loss: 5.0502e-04 - val_mse: 5.0502e-04 - val_mae: 0.0124\n",
      "Epoch 80/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0200 - val_loss: 5.1267e-04 - val_mse: 5.1267e-04 - val_mae: 0.0125\n",
      "Epoch 81/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0200 - val_loss: 5.1579e-04 - val_mse: 5.1579e-04 - val_mae: 0.0126\n",
      "Epoch 82/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0196 - val_loss: 5.0261e-04 - val_mse: 5.0261e-04 - val_mae: 0.0124\n",
      "Epoch 83/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0197 - val_loss: 4.9088e-04 - val_mse: 4.9088e-04 - val_mae: 0.0122\n",
      "Epoch 84/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0193 - val_loss: 4.6819e-04 - val_mse: 4.6819e-04 - val_mae: 0.0121\n",
      "Epoch 85/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0194 - val_loss: 4.7651e-04 - val_mse: 4.7651e-04 - val_mae: 0.0122\n",
      "Epoch 86/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0194 - val_loss: 5.0249e-04 - val_mse: 5.0249e-04 - val_mae: 0.0124\n",
      "Epoch 87/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0191 - val_loss: 4.7233e-04 - val_mse: 4.7233e-04 - val_mae: 0.0122\n",
      "Epoch 88/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0191 - val_loss: 4.8666e-04 - val_mse: 4.8666e-04 - val_mae: 0.0122\n",
      "Epoch 89/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0191 - val_loss: 4.7077e-04 - val_mse: 4.7077e-04 - val_mae: 0.0120\n",
      "Epoch 90/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0189 - val_loss: 4.9635e-04 - val_mse: 4.9635e-04 - val_mae: 0.0123\n",
      "Epoch 91/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0187 - val_loss: 4.6773e-04 - val_mse: 4.6773e-04 - val_mae: 0.0121\n",
      "Epoch 92/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0187 - val_loss: 4.7864e-04 - val_mse: 4.7864e-04 - val_mae: 0.0121\n",
      "Epoch 93/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0187 - val_loss: 4.6503e-04 - val_mse: 4.6503e-04 - val_mae: 0.0121\n",
      "Epoch 94/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0188 - val_loss: 4.8349e-04 - val_mse: 4.8349e-04 - val_mae: 0.0122\n",
      "Epoch 95/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0186 - val_loss: 4.7219e-04 - val_mse: 4.7219e-04 - val_mae: 0.0122\n",
      "Epoch 96/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0187 - val_loss: 4.7165e-04 - val_mse: 4.7165e-04 - val_mae: 0.0121\n",
      "Epoch 97/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0187 - val_loss: 4.8074e-04 - val_mse: 4.8074e-04 - val_mae: 0.0122\n",
      "Epoch 98/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0186 - val_loss: 4.6842e-04 - val_mse: 4.6842e-04 - val_mae: 0.0121\n",
      "Epoch 99/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0185 - val_loss: 4.6185e-04 - val_mse: 4.6185e-04 - val_mae: 0.0121\n",
      "Epoch 100/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0185 - val_loss: 4.6191e-04 - val_mse: 4.6191e-04 - val_mae: 0.0121\n",
      "Train on 4128 samples, validate on 576 samples\n",
      "Epoch 1/100\n",
      "4128/4128 [==============================] - 17s 4ms/step - loss: 0.1977 - mse: 0.1977 - mae: 0.3542 - val_loss: 0.0067 - val_mse: 0.0067 - val_mae: 0.0646\n",
      "Epoch 2/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.1592 - mse: 0.1592 - mae: 0.3189 - val_loss: 0.0038 - val_mse: 0.0038 - val_mae: 0.0447\n",
      "Epoch 3/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.1398 - mse: 0.1398 - mae: 0.2990 - val_loss: 0.0057 - val_mse: 0.0057 - val_mae: 0.0607\n",
      "Epoch 4/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.1165 - mse: 0.1165 - mae: 0.2734 - val_loss: 0.0057 - val_mse: 0.0057 - val_mae: 0.0618\n",
      "Epoch 5/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0996 - mse: 0.0996 - mae: 0.2524 - val_loss: 0.0029 - val_mse: 0.0029 - val_mae: 0.0396\n",
      "Epoch 6/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0877 - mse: 0.0877 - mae: 0.2369 - val_loss: 0.0025 - val_mse: 0.0025 - val_mae: 0.0373\n",
      "Epoch 7/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0692 - mse: 0.0692 - mae: 0.2099 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0479\n",
      "Epoch 8/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0608 - mse: 0.0608 - mae: 0.1970 - val_loss: 0.0020 - val_mse: 0.0020 - val_mae: 0.0335\n",
      "Epoch 9/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0558 - mse: 0.0558 - mae: 0.1868 - val_loss: 0.0018 - val_mse: 0.0018 - val_mae: 0.0312\n",
      "Epoch 10/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0469 - mse: 0.0469 - mae: 0.1742 - val_loss: 0.0023 - val_mse: 0.0023 - val_mae: 0.0365\n",
      "Epoch 11/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0435 - mse: 0.0435 - mae: 0.1677 - val_loss: 0.0021 - val_mse: 0.0021 - val_mae: 0.0350\n",
      "Epoch 12/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0369 - mse: 0.0369 - mae: 0.1523 - val_loss: 0.0031 - val_mse: 0.0031 - val_mae: 0.0463\n",
      "Epoch 13/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0352 - mse: 0.0352 - mae: 0.1483 - val_loss: 0.0017 - val_mse: 0.0017 - val_mae: 0.0317\n",
      "Epoch 14/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0303 - mse: 0.0303 - mae: 0.1382 - val_loss: 0.0019 - val_mse: 0.0019 - val_mae: 0.0356\n",
      "Epoch 15/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0275 - mse: 0.0275 - mae: 0.1311 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0267\n",
      "Epoch 16/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0251 - mse: 0.0251 - mae: 0.1260 - val_loss: 0.0014 - val_mse: 0.0014 - val_mae: 0.0277\n",
      "Epoch 17/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0233 - mse: 0.0233 - mae: 0.1206 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0254\n",
      "Epoch 18/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0202 - mse: 0.0202 - mae: 0.1122 - val_loss: 0.0015 - val_mse: 0.0015 - val_mae: 0.0319\n",
      "Epoch 19/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0186 - mse: 0.0186 - mae: 0.1077 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0275\n",
      "Epoch 20/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0174 - mse: 0.0174 - mae: 0.1038 - val_loss: 0.0014 - val_mse: 0.0014 - val_mae: 0.0323\n",
      "Epoch 21/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0159 - mse: 0.0159 - mae: 0.0999 - val_loss: 9.8132e-04 - val_mse: 9.8132e-04 - val_mae: 0.0244\n",
      "Epoch 22/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0141 - mse: 0.0141 - mae: 0.0936 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0237\n",
      "Epoch 23/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0132 - mse: 0.0132 - mae: 0.0897 - val_loss: 9.6313e-04 - val_mse: 9.6313e-04 - val_mae: 0.0229\n",
      "Epoch 24/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0119 - mse: 0.0119 - mae: 0.0859 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0296\n",
      "Epoch 25/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0110 - mse: 0.0110 - mae: 0.0822 - val_loss: 8.1683e-04 - val_mse: 8.1683e-04 - val_mae: 0.0227\n",
      "Epoch 26/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0101 - mse: 0.0101 - mae: 0.0783 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0260\n",
      "Epoch 27/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0092 - mse: 0.0092 - mae: 0.0750 - val_loss: 7.5253e-04 - val_mse: 7.5253e-04 - val_mae: 0.0203\n",
      "Epoch 28/100\n",
      "4128/4128 [==============================] - 14s 3ms/step - loss: 0.0083 - mse: 0.0083 - mae: 0.0709 - val_loss: 7.3654e-04 - val_mse: 7.3654e-04 - val_mae: 0.0186\n",
      "Epoch 29/100\n",
      "4128/4128 [==============================] - 14s 3ms/step - loss: 0.0076 - mse: 0.0076 - mae: 0.0678 - val_loss: 6.5373e-04 - val_mse: 6.5373e-04 - val_mae: 0.0184\n",
      "Epoch 30/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0071 - mse: 0.0071 - mae: 0.0661 - val_loss: 7.5866e-04 - val_mse: 7.5866e-04 - val_mae: 0.0210\n",
      "Epoch 31/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0064 - mse: 0.0064 - mae: 0.0621 - val_loss: 6.5095e-04 - val_mse: 6.5095e-04 - val_mae: 0.0191\n",
      "Epoch 32/100\n",
      "4128/4128 [==============================] - 14s 4ms/step - loss: 0.0062 - mse: 0.0062 - mae: 0.0613 - val_loss: 7.0535e-04 - val_mse: 7.0535e-04 - val_mae: 0.0194\n",
      "Epoch 33/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0056 - mse: 0.0056 - mae: 0.0579 - val_loss: 6.2632e-04 - val_mse: 6.2632e-04 - val_mae: 0.0167\n",
      "Epoch 34/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0052 - mse: 0.0052 - mae: 0.0548 - val_loss: 6.6070e-04 - val_mse: 6.6070e-04 - val_mae: 0.0202\n",
      "Epoch 35/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0049 - mse: 0.0049 - mae: 0.0530 - val_loss: 5.9654e-04 - val_mse: 5.9654e-04 - val_mae: 0.0159\n",
      "Epoch 36/100\n",
      "4128/4128 [==============================] - 14s 4ms/step - loss: 0.0045 - mse: 0.0045 - mae: 0.0508 - val_loss: 5.9014e-04 - val_mse: 5.9014e-04 - val_mae: 0.0178\n",
      "Epoch 37/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0494 - val_loss: 5.3276e-04 - val_mse: 5.3276e-04 - val_mae: 0.0152\n",
      "Epoch 38/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0453 - val_loss: 5.7586e-04 - val_mse: 5.7586e-04 - val_mae: 0.0173\n",
      "Epoch 39/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0451 - val_loss: 5.8534e-04 - val_mse: 5.8534e-04 - val_mae: 0.0177\n",
      "Epoch 40/100\n",
      "4128/4128 [==============================] - 14s 3ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0428 - val_loss: 5.7957e-04 - val_mse: 5.7957e-04 - val_mae: 0.0170\n",
      "Epoch 41/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0416 - val_loss: 5.7358e-04 - val_mse: 5.7358e-04 - val_mae: 0.0172\n",
      "Epoch 42/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0396 - val_loss: 5.2962e-04 - val_mse: 5.2962e-04 - val_mae: 0.0166\n",
      "Epoch 43/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0379 - val_loss: 5.4320e-04 - val_mse: 5.4320e-04 - val_mae: 0.0152\n",
      "Epoch 44/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0370 - val_loss: 5.5320e-04 - val_mse: 5.5320e-04 - val_mae: 0.0151\n",
      "Epoch 45/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0352 - val_loss: 5.5882e-04 - val_mse: 5.5882e-04 - val_mae: 0.0146\n",
      "Epoch 46/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0351 - val_loss: 5.1916e-04 - val_mse: 5.1916e-04 - val_mae: 0.0147\n",
      "Epoch 47/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0337 - val_loss: 5.4517e-04 - val_mse: 5.4517e-04 - val_mae: 0.0165\n",
      "Epoch 48/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0320 - val_loss: 5.3075e-04 - val_mse: 5.3075e-04 - val_mae: 0.0157\n",
      "Epoch 49/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0309 - val_loss: 6.4814e-04 - val_mse: 6.4814e-04 - val_mae: 0.0163\n",
      "Epoch 50/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0304 - val_loss: 5.4773e-04 - val_mse: 5.4773e-04 - val_mae: 0.0155\n",
      "Epoch 51/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0289 - val_loss: 5.0829e-04 - val_mse: 5.0829e-04 - val_mae: 0.0155\n",
      "Epoch 52/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0286 - val_loss: 4.9181e-04 - val_mse: 4.9181e-04 - val_mae: 0.0143\n",
      "Epoch 53/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0277 - val_loss: 5.3807e-04 - val_mse: 5.3807e-04 - val_mae: 0.0147\n",
      "Epoch 54/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0267 - val_loss: 5.4467e-04 - val_mse: 5.4467e-04 - val_mae: 0.0150\n",
      "Epoch 55/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0263 - val_loss: 5.1739e-04 - val_mse: 5.1739e-04 - val_mae: 0.0142\n",
      "Epoch 56/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0258 - val_loss: 5.0891e-04 - val_mse: 5.0891e-04 - val_mae: 0.0141\n",
      "Epoch 57/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0251 - val_loss: 5.5748e-04 - val_mse: 5.5748e-04 - val_mae: 0.0144\n",
      "Epoch 58/100\n",
      "4128/4128 [==============================] - 14s 3ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0247 - val_loss: 5.1187e-04 - val_mse: 5.1187e-04 - val_mae: 0.0139\n",
      "Epoch 59/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0239 - val_loss: 4.9846e-04 - val_mse: 4.9846e-04 - val_mae: 0.0140\n",
      "Epoch 60/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0232 - val_loss: 5.2770e-04 - val_mse: 5.2770e-04 - val_mae: 0.0141\n",
      "Epoch 61/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0231 - val_loss: 5.5974e-04 - val_mse: 5.5974e-04 - val_mae: 0.0146\n",
      "Epoch 62/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0224 - val_loss: 5.1892e-04 - val_mse: 5.1892e-04 - val_mae: 0.0140\n",
      "Epoch 63/100\n",
      "4128/4128 [==============================] - 14s 3ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0223 - val_loss: 5.1096e-04 - val_mse: 5.1096e-04 - val_mae: 0.0138\n",
      "Epoch 64/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0219 - val_loss: 5.1432e-04 - val_mse: 5.1432e-04 - val_mae: 0.0137\n",
      "Epoch 65/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0214 - val_loss: 5.1429e-04 - val_mse: 5.1429e-04 - val_mae: 0.0135\n",
      "Epoch 66/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0212 - val_loss: 5.1450e-04 - val_mse: 5.1450e-04 - val_mae: 0.0136\n",
      "Epoch 67/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0205 - val_loss: 5.5502e-04 - val_mse: 5.5502e-04 - val_mae: 0.0142\n",
      "Epoch 68/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0206 - val_loss: 4.9939e-04 - val_mse: 4.9939e-04 - val_mae: 0.0135\n",
      "Epoch 69/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0204 - val_loss: 4.8770e-04 - val_mse: 4.8770e-04 - val_mae: 0.0133\n",
      "Epoch 70/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0201 - val_loss: 5.0039e-04 - val_mse: 5.0039e-04 - val_mae: 0.0133\n",
      "Epoch 71/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0202 - val_loss: 5.2483e-04 - val_mse: 5.2483e-04 - val_mae: 0.0136\n",
      "Epoch 72/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0201 - val_loss: 5.2663e-04 - val_mse: 5.2663e-04 - val_mae: 0.0137\n",
      "Epoch 73/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0195 - val_loss: 5.0869e-04 - val_mse: 5.0869e-04 - val_mae: 0.0136\n",
      "Epoch 74/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0199 - val_loss: 5.3266e-04 - val_mse: 5.3266e-04 - val_mae: 0.0137\n",
      "Epoch 75/100\n",
      "4128/4128 [==============================] - 14s 3ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0194 - val_loss: 4.9005e-04 - val_mse: 4.9005e-04 - val_mae: 0.0133\n",
      "Epoch 76/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0193 - val_loss: 4.8901e-04 - val_mse: 4.8901e-04 - val_mae: 0.0131\n",
      "Epoch 77/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0192 - val_loss: 4.9598e-04 - val_mse: 4.9598e-04 - val_mae: 0.0132\n",
      "Epoch 78/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0194 - val_loss: 5.1491e-04 - val_mse: 5.1491e-04 - val_mae: 0.0134\n",
      "Epoch 79/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0191 - val_loss: 5.0887e-04 - val_mse: 5.0887e-04 - val_mae: 0.0133\n",
      "Epoch 80/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0189 - val_loss: 5.1859e-04 - val_mse: 5.1859e-04 - val_mae: 0.0134\n",
      "Epoch 81/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0190 - val_loss: 4.7961e-04 - val_mse: 4.7961e-04 - val_mae: 0.0129\n",
      "Epoch 82/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0186 - val_loss: 5.0372e-04 - val_mse: 5.0372e-04 - val_mae: 0.0132\n",
      "Epoch 83/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0187 - val_loss: 5.1014e-04 - val_mse: 5.1014e-04 - val_mae: 0.0134\n",
      "Epoch 84/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0186 - val_loss: 5.1242e-04 - val_mse: 5.1242e-04 - val_mae: 0.0134\n",
      "Epoch 85/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0184 - val_loss: 5.0988e-04 - val_mse: 5.0988e-04 - val_mae: 0.0133\n",
      "Epoch 86/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0184 - val_loss: 4.9098e-04 - val_mse: 4.9098e-04 - val_mae: 0.0130\n",
      "Epoch 87/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0185 - val_loss: 4.8865e-04 - val_mse: 4.8865e-04 - val_mae: 0.0130\n",
      "Epoch 88/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0186 - val_loss: 5.0568e-04 - val_mse: 5.0568e-04 - val_mae: 0.0132\n",
      "Epoch 89/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0181 - val_loss: 5.0363e-04 - val_mse: 5.0363e-04 - val_mae: 0.0133\n",
      "Epoch 90/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0181 - val_loss: 5.0039e-04 - val_mse: 5.0039e-04 - val_mae: 0.0131\n",
      "Epoch 91/100\n",
      "4128/4128 [==============================] - 14s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0182 - val_loss: 5.2188e-04 - val_mse: 5.2188e-04 - val_mae: 0.0136\n",
      "Epoch 92/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0180 - val_loss: 5.5691e-04 - val_mse: 5.5691e-04 - val_mae: 0.0143\n",
      "Epoch 93/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0182 - val_loss: 4.9382e-04 - val_mse: 4.9382e-04 - val_mae: 0.0133\n",
      "Epoch 94/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0179 - val_loss: 5.0606e-04 - val_mse: 5.0606e-04 - val_mae: 0.0134\n",
      "Epoch 95/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0178 - val_loss: 5.0338e-04 - val_mse: 5.0338e-04 - val_mae: 0.0132\n",
      "Epoch 96/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0178 - val_loss: 4.8791e-04 - val_mse: 4.8791e-04 - val_mae: 0.0130\n",
      "Epoch 97/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0180 - val_loss: 4.9129e-04 - val_mse: 4.9129e-04 - val_mae: 0.0130\n",
      "Epoch 98/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0178 - val_loss: 5.2377e-04 - val_mse: 5.2377e-04 - val_mae: 0.0136\n",
      "Epoch 99/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0179 - val_loss: 5.0780e-04 - val_mse: 5.0780e-04 - val_mae: 0.0134\n",
      "Epoch 100/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0176 - val_loss: 4.7703e-04 - val_mse: 4.7703e-04 - val_mae: 0.0131\n",
      "Train on 4128 samples, validate on 576 samples\n",
      "Epoch 1/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.2088 - mse: 0.2088 - mae: 0.3643 - val_loss: 0.0312 - val_mse: 0.0312 - val_mae: 0.1535\n",
      "Epoch 2/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.1824 - mse: 0.1824 - mae: 0.3420 - val_loss: 0.0231 - val_mse: 0.0231 - val_mae: 0.1359\n",
      "Epoch 3/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.1526 - mse: 0.1526 - mae: 0.3097 - val_loss: 0.0165 - val_mse: 0.0165 - val_mae: 0.1101\n",
      "Epoch 4/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.1362 - mse: 0.1362 - mae: 0.2917 - val_loss: 0.0082 - val_mse: 0.0082 - val_mae: 0.0747\n",
      "Epoch 5/100\n",
      "4128/4128 [==============================] - 14s 3ms/step - loss: 0.1188 - mse: 0.1188 - mae: 0.2746 - val_loss: 0.0072 - val_mse: 0.0072 - val_mae: 0.0685\n",
      "Epoch 6/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.1047 - mse: 0.1047 - mae: 0.2576 - val_loss: 0.0150 - val_mse: 0.0150 - val_mae: 0.1108\n",
      "Epoch 7/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0920 - mse: 0.0920 - mae: 0.2410 - val_loss: 0.0025 - val_mse: 0.0025 - val_mae: 0.0403\n",
      "Epoch 8/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0793 - mse: 0.0793 - mae: 0.2228 - val_loss: 0.0047 - val_mse: 0.0047 - val_mae: 0.0577\n",
      "Epoch 9/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0711 - mse: 0.0711 - mae: 0.2116 - val_loss: 0.0018 - val_mse: 0.0018 - val_mae: 0.0328\n",
      "Epoch 10/100\n",
      "4128/4128 [==============================] - 14s 3ms/step - loss: 0.0641 - mse: 0.0641 - mae: 0.1991 - val_loss: 0.0019 - val_mse: 0.0019 - val_mae: 0.0347\n",
      "Epoch 11/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0552 - mse: 0.0552 - mae: 0.1853 - val_loss: 0.0017 - val_mse: 0.0017 - val_mae: 0.0331\n",
      "Epoch 12/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0510 - mse: 0.0510 - mae: 0.1793 - val_loss: 0.0021 - val_mse: 0.0021 - val_mae: 0.0366\n",
      "Epoch 13/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0436 - mse: 0.0436 - mae: 0.1654 - val_loss: 0.0019 - val_mse: 0.0019 - val_mae: 0.0341\n",
      "Epoch 14/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0408 - mse: 0.0408 - mae: 0.1601 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0265\n",
      "Epoch 15/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0364 - mse: 0.0364 - mae: 0.1515 - val_loss: 0.0050 - val_mse: 0.0050 - val_mae: 0.0611\n",
      "Epoch 16/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0344 - mse: 0.0344 - mae: 0.1468 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0264\n",
      "Epoch 17/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0323 - mse: 0.0323 - mae: 0.1423 - val_loss: 0.0027 - val_mse: 0.0027 - val_mae: 0.0445\n",
      "Epoch 18/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0297 - mse: 0.0297 - mae: 0.1372 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0267\n",
      "Epoch 19/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0259 - mse: 0.0259 - mae: 0.1280 - val_loss: 0.0024 - val_mse: 0.0024 - val_mae: 0.0405\n",
      "Epoch 20/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0239 - mse: 0.0239 - mae: 0.1225 - val_loss: 7.9159e-04 - val_mse: 7.9159e-04 - val_mae: 0.0197\n",
      "Epoch 21/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0226 - mse: 0.0226 - mae: 0.1191 - val_loss: 8.5604e-04 - val_mse: 8.5604e-04 - val_mae: 0.0206\n",
      "Epoch 22/100\n",
      "4128/4128 [==============================] - 14s 3ms/step - loss: 0.0202 - mse: 0.0202 - mae: 0.1129 - val_loss: 8.4462e-04 - val_mse: 8.4462e-04 - val_mae: 0.0210\n",
      "Epoch 23/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0196 - mse: 0.0196 - mae: 0.1108 - val_loss: 0.0016 - val_mse: 0.0016 - val_mae: 0.0315\n",
      "Epoch 24/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0186 - mse: 0.0186 - mae: 0.1079 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0303\n",
      "Epoch 25/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0158 - mse: 0.0158 - mae: 0.0996 - val_loss: 8.6153e-04 - val_mse: 8.6153e-04 - val_mae: 0.0235\n",
      "Epoch 26/100\n",
      "4128/4128 [==============================] - 14s 3ms/step - loss: 0.0146 - mse: 0.0146 - mae: 0.0952 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0269\n",
      "Epoch 27/100\n",
      "4128/4128 [==============================] - 14s 3ms/step - loss: 0.0138 - mse: 0.0138 - mae: 0.0924 - val_loss: 8.8666e-04 - val_mse: 8.8666e-04 - val_mae: 0.0238\n",
      "Epoch 28/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0129 - mse: 0.0129 - mae: 0.0905 - val_loss: 8.4877e-04 - val_mse: 8.4877e-04 - val_mae: 0.0205\n",
      "Epoch 29/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0122 - mse: 0.0122 - mae: 0.0875 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0302\n",
      "Epoch 30/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0111 - mse: 0.0111 - mae: 0.0826 - val_loss: 6.6880e-04 - val_mse: 6.6880e-04 - val_mae: 0.0174\n",
      "Epoch 31/100\n",
      "4128/4128 [==============================] - 14s 3ms/step - loss: 0.0100 - mse: 0.0100 - mae: 0.0781 - val_loss: 6.1026e-04 - val_mse: 6.1026e-04 - val_mae: 0.0168\n",
      "Epoch 32/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0094 - mse: 0.0094 - mae: 0.0759 - val_loss: 9.4255e-04 - val_mse: 9.4255e-04 - val_mae: 0.0222\n",
      "Epoch 33/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0089 - mse: 0.0089 - mae: 0.0732 - val_loss: 6.3256e-04 - val_mse: 6.3256e-04 - val_mae: 0.0167\n",
      "Epoch 34/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0083 - mse: 0.0083 - mae: 0.0706 - val_loss: 6.8317e-04 - val_mse: 6.8317e-04 - val_mae: 0.0175\n",
      "Epoch 35/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0073 - mse: 0.0073 - mae: 0.0662 - val_loss: 5.9609e-04 - val_mse: 5.9609e-04 - val_mae: 0.0191\n",
      "Epoch 36/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0071 - mse: 0.0071 - mae: 0.0653 - val_loss: 5.8163e-04 - val_mse: 5.8163e-04 - val_mae: 0.0154\n",
      "Epoch 37/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0065 - mse: 0.0065 - mae: 0.0625 - val_loss: 0.0015 - val_mse: 0.0015 - val_mae: 0.0307\n",
      "Epoch 38/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0596 - val_loss: 5.3564e-04 - val_mse: 5.3564e-04 - val_mae: 0.0168\n",
      "Epoch 39/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0056 - mse: 0.0056 - mae: 0.0577 - val_loss: 5.4160e-04 - val_mse: 5.4160e-04 - val_mae: 0.0148\n",
      "Epoch 40/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0054 - mse: 0.0054 - mae: 0.0566 - val_loss: 5.5743e-04 - val_mse: 5.5743e-04 - val_mae: 0.0150\n",
      "Epoch 41/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0049 - mse: 0.0049 - mae: 0.0530 - val_loss: 5.4566e-04 - val_mse: 5.4566e-04 - val_mae: 0.0148\n",
      "Epoch 42/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0045 - mse: 0.0045 - mae: 0.0504 - val_loss: 5.1584e-04 - val_mse: 5.1584e-04 - val_mae: 0.0161\n",
      "Epoch 43/100\n",
      "4128/4128 [==============================] - 14s 3ms/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0492 - val_loss: 5.6188e-04 - val_mse: 5.6188e-04 - val_mae: 0.0148\n",
      "Epoch 44/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0475 - val_loss: 5.1014e-04 - val_mse: 5.1014e-04 - val_mae: 0.0167\n",
      "Epoch 45/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0462 - val_loss: 5.0243e-04 - val_mse: 5.0243e-04 - val_mae: 0.0142\n",
      "Epoch 46/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0436 - val_loss: 6.3095e-04 - val_mse: 6.3095e-04 - val_mae: 0.0157\n",
      "Epoch 47/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0420 - val_loss: 8.2591e-04 - val_mse: 8.2591e-04 - val_mae: 0.0201\n",
      "Epoch 48/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0401 - val_loss: 5.4075e-04 - val_mse: 5.4075e-04 - val_mae: 0.0144\n",
      "Epoch 49/100\n",
      "4128/4128 [==============================] - 14s 3ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0391 - val_loss: 5.0067e-04 - val_mse: 5.0067e-04 - val_mae: 0.0135\n",
      "Epoch 50/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0378 - val_loss: 4.7790e-04 - val_mse: 4.7790e-04 - val_mae: 0.0141\n",
      "Epoch 51/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0359 - val_loss: 6.1108e-04 - val_mse: 6.1108e-04 - val_mae: 0.0152\n",
      "Epoch 52/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0348 - val_loss: 5.1514e-04 - val_mse: 5.1514e-04 - val_mae: 0.0137\n",
      "Epoch 53/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0332 - val_loss: 5.0982e-04 - val_mse: 5.0982e-04 - val_mae: 0.0135\n",
      "Epoch 54/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0325 - val_loss: 4.6305e-04 - val_mse: 4.6305e-04 - val_mae: 0.0129\n",
      "Epoch 55/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0314 - val_loss: 7.7126e-04 - val_mse: 7.7126e-04 - val_mae: 0.0189\n",
      "Epoch 56/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0304 - val_loss: 4.7219e-04 - val_mse: 4.7219e-04 - val_mae: 0.0131\n",
      "Epoch 57/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0294 - val_loss: 4.8619e-04 - val_mse: 4.8619e-04 - val_mae: 0.0132\n",
      "Epoch 58/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0288 - val_loss: 4.5956e-04 - val_mse: 4.5956e-04 - val_mae: 0.0131\n",
      "Epoch 59/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0279 - val_loss: 5.4885e-04 - val_mse: 5.4885e-04 - val_mae: 0.0139\n",
      "Epoch 60/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0268 - val_loss: 6.1781e-04 - val_mse: 6.1781e-04 - val_mae: 0.0154\n",
      "Epoch 61/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0258 - val_loss: 7.2036e-04 - val_mse: 7.2036e-04 - val_mae: 0.0177\n",
      "Epoch 62/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0259 - val_loss: 6.5989e-04 - val_mse: 6.5989e-04 - val_mae: 0.0164\n",
      "Epoch 63/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0249 - val_loss: 6.1324e-04 - val_mse: 6.1324e-04 - val_mae: 0.0153\n",
      "Epoch 64/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0241 - val_loss: 5.7438e-04 - val_mse: 5.7438e-04 - val_mae: 0.0145\n",
      "Epoch 65/100\n",
      "4128/4128 [==============================] - 14s 3ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0237 - val_loss: 6.2153e-04 - val_mse: 6.2153e-04 - val_mae: 0.0155\n",
      "Epoch 66/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0230 - val_loss: 5.7869e-04 - val_mse: 5.7869e-04 - val_mae: 0.0146\n",
      "Epoch 67/100\n",
      "4128/4128 [==============================] - 14s 3ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0227 - val_loss: 5.9051e-04 - val_mse: 5.9051e-04 - val_mae: 0.0149\n",
      "Epoch 68/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0221 - val_loss: 5.6069e-04 - val_mse: 5.6069e-04 - val_mae: 0.0143\n",
      "Epoch 69/100\n",
      "4128/4128 [==============================] - 14s 3ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0221 - val_loss: 5.6395e-04 - val_mse: 5.6395e-04 - val_mae: 0.0143\n",
      "Epoch 70/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0219 - val_loss: 5.5591e-04 - val_mse: 5.5591e-04 - val_mae: 0.0142\n",
      "Epoch 71/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0216 - val_loss: 5.3945e-04 - val_mse: 5.3945e-04 - val_mae: 0.0139\n",
      "Epoch 72/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0212 - val_loss: 5.9738e-04 - val_mse: 5.9738e-04 - val_mae: 0.0149\n",
      "Epoch 73/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0212 - val_loss: 5.5477e-04 - val_mse: 5.5477e-04 - val_mae: 0.0141\n",
      "Epoch 74/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0208 - val_loss: 5.5770e-04 - val_mse: 5.5770e-04 - val_mae: 0.0142\n",
      "Epoch 75/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0203 - val_loss: 6.8887e-04 - val_mse: 6.8887e-04 - val_mae: 0.0170\n",
      "Epoch 76/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0204 - val_loss: 5.8765e-04 - val_mse: 5.8765e-04 - val_mae: 0.0149\n",
      "Epoch 77/100\n",
      "4128/4128 [==============================] - 14s 3ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0200 - val_loss: 5.9073e-04 - val_mse: 5.9073e-04 - val_mae: 0.0149\n",
      "Epoch 78/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0201 - val_loss: 5.6139e-04 - val_mse: 5.6139e-04 - val_mae: 0.0144\n",
      "Epoch 79/100\n",
      "4128/4128 [==============================] - 14s 3ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0199 - val_loss: 5.8386e-04 - val_mse: 5.8386e-04 - val_mae: 0.0148\n",
      "Epoch 80/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0196 - val_loss: 5.7641e-04 - val_mse: 5.7641e-04 - val_mae: 0.0145\n",
      "Epoch 81/100\n",
      "4128/4128 [==============================] - 14s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0194 - val_loss: 5.6796e-04 - val_mse: 5.6796e-04 - val_mae: 0.0144\n",
      "Epoch 82/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0195 - val_loss: 5.6997e-04 - val_mse: 5.6997e-04 - val_mae: 0.0144\n",
      "Epoch 83/100\n",
      "4128/4128 [==============================] - 14s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0192 - val_loss: 5.7846e-04 - val_mse: 5.7846e-04 - val_mae: 0.0146\n",
      "Epoch 84/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0190 - val_loss: 5.8023e-04 - val_mse: 5.8023e-04 - val_mae: 0.0146\n",
      "Epoch 85/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0193 - val_loss: 5.2265e-04 - val_mse: 5.2265e-04 - val_mae: 0.0135\n",
      "Epoch 86/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0191 - val_loss: 5.5197e-04 - val_mse: 5.5197e-04 - val_mae: 0.0140\n",
      "Epoch 87/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0189 - val_loss: 6.3449e-04 - val_mse: 6.3449e-04 - val_mae: 0.0157\n",
      "Epoch 88/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0189 - val_loss: 6.3884e-04 - val_mse: 6.3884e-04 - val_mae: 0.0158\n",
      "Epoch 89/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0187 - val_loss: 6.0651e-04 - val_mse: 6.0651e-04 - val_mae: 0.0151\n",
      "Epoch 90/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0188 - val_loss: 5.7450e-04 - val_mse: 5.7450e-04 - val_mae: 0.0144\n",
      "Epoch 91/100\n",
      "4128/4128 [==============================] - 16s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0185 - val_loss: 5.0983e-04 - val_mse: 5.0983e-04 - val_mae: 0.0132\n",
      "Epoch 92/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0186 - val_loss: 5.7869e-04 - val_mse: 5.7869e-04 - val_mae: 0.0144\n",
      "Epoch 93/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0186 - val_loss: 5.9189e-04 - val_mse: 5.9189e-04 - val_mae: 0.0147\n",
      "Epoch 94/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0182 - val_loss: 5.7790e-04 - val_mse: 5.7790e-04 - val_mae: 0.0144\n",
      "Epoch 95/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0184 - val_loss: 5.9426e-04 - val_mse: 5.9426e-04 - val_mae: 0.0148\n",
      "Epoch 96/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0183 - val_loss: 5.5953e-04 - val_mse: 5.5953e-04 - val_mae: 0.0141\n",
      "Epoch 97/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0184 - val_loss: 5.9352e-04 - val_mse: 5.9352e-04 - val_mae: 0.0149\n",
      "Epoch 98/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0183 - val_loss: 5.8138e-04 - val_mse: 5.8138e-04 - val_mae: 0.0146\n",
      "Epoch 99/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0181 - val_loss: 5.6736e-04 - val_mse: 5.6736e-04 - val_mae: 0.0143\n",
      "Epoch 100/100\n",
      "4128/4128 [==============================] - 15s 4ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0179 - val_loss: 6.3699e-04 - val_mse: 6.3699e-04 - val_mae: 0.0159\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "# Dictionary to include the parameters\n",
    "parameters = {'bias_initializer':[initializers.Zeros(),\n",
    "                                 initializers.Ones()],\n",
    "              'kernel_initializer': ['glorot_uniform',\n",
    "                                     'he_normal',\n",
    "                                     'he_uniform']\n",
    "               }\n",
    "\n",
    "all_param = ParameterGrid(parameters)\n",
    "\n",
    "# function to split data into correct shape for RNN\n",
    "def split_data(X, y, steps):\n",
    "    X_, y_ = list(), list()\n",
    "    for i in range(steps, len(y)):\n",
    "        X_.append(X[i - steps : i, :])\n",
    "        y_.append(y[i]) \n",
    "    return np.array(X_), np.array(y_)\n",
    "\n",
    "# function to cut data set so it can be divisible by the batch_size\n",
    "def cut_data(data, batch_size):\n",
    "     # see if it is divisivel\n",
    "    condition = data.shape[0] % batch_size\n",
    "    if condition == 0:\n",
    "        return data\n",
    "    else:\n",
    "        return data[: -condition]\n",
    "\n",
    "# divide features and labels\n",
    "X_train = data_train[:, 0:15] \n",
    "y_train = data_train[:, -1]\n",
    "X_test = data_test[:, 0:15] \n",
    "y_test = data_test[:, -1] \n",
    "\n",
    "# divide data into train and test \n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "         X_train, y_train, test_size = 0.15, shuffle=False)\n",
    "\n",
    "# put data into correct shape\n",
    "X_train, y_train = split_data(X_train, y_train, steps)\n",
    "X_test, y_test = split_data(X_test, y_test, steps)\n",
    "X_val, y_val = split_data(X_val, y_val, steps)\n",
    "\n",
    "X_train = cut_data(X_train, batch_size)\n",
    "y_train = cut_data(y_train, batch_size)\n",
    "X_test = cut_data(X_test, batch_size)\n",
    "y_test = cut_data(y_test, batch_size)\n",
    "X_val = cut_data(X_val, batch_size)\n",
    "y_val = cut_data(y_val, batch_size)\n",
    "\n",
    "# inverse of test set should not be inside the loop \n",
    "y_test = (y_test * sc_X.data_range_[15]) + (sc_X.data_min_[15])\n",
    "\n",
    "# smal adjustment\n",
    "y_test = pd.Series(y_test)\n",
    "y_test.replace(0, 0.0001,inplace = True)\n",
    "\n",
    "for i in range(len(all_param)):\n",
    "    \n",
    "    bias_initializer = all_param[i]['bias_initializer']\n",
    "    kernel_initializer = all_param[i]['kernel_initializer']\n",
    "\n",
    "    # design the LSTM\n",
    "    def regressor_tunning(bias_initializer, kernel_initializer):\n",
    "        model = Sequential()\n",
    "        if n_hidden == 1:\n",
    "            model.add(LSTM(units = units,                    \n",
    "                           batch_input_shape = (batch_size, steps, features_num), \n",
    "                           stateful = True,\n",
    "                           kernel_initializer = kernel_initializer,\n",
    "                           bias_initializer = bias_initializer))\n",
    "            model.add(LeakyReLU(alpha = 0.2))\n",
    "            model.add(Dropout(0.2))\n",
    "        else:\n",
    "            model.add(LSTM(units = units,                    \n",
    "                           batch_input_shape = (batch_size, steps, features_num), \n",
    "                           stateful = True,\n",
    "                           return_sequences = True,\n",
    "                           kernel_initializer = kernel_initializer,\n",
    "                           bias_initializer = bias_initializer))\n",
    "            model.add(LeakyReLU(alpha = 0.2))\n",
    "            model.add(Dropout(0.2))\n",
    "            model.add(LSTM(units = units, \n",
    "                           batch_input_shape = (batch_size, steps, features_num), \n",
    "                           stateful = True,\n",
    "                           kernel_initializer = kernel_initializer,\n",
    "                           bias_initializer = bias_initializer))\n",
    "            model.add(LeakyReLU(alpha = 0.2))\n",
    "            model.add(Dropout(0.2))\n",
    "        model.add(Dense(1, activation='linear'))\n",
    "        optimizer = optimizers.RMSprop(lr = 0.0001)\n",
    "        model.compile(loss = 'mse', metrics = ['mse', 'mae'], optimizer = optimizer)\n",
    "        return model\n",
    "\n",
    "    model = regressor_tunning(bias_initializer, kernel_initializer)\n",
    "\n",
    "    # fitting the LSTM to the training set\n",
    "    history = model.fit(X_train,\n",
    "                        y_train, \n",
    "                        batch_size = batch_size, \n",
    "                        epochs = 100,\n",
    "                        shuffle = False, \n",
    "                        validation_data = (X_val, y_val))\n",
    "    \n",
    "    model.reset_states()\n",
    "    \n",
    "    # make new predicitons with test set\n",
    "    y_pred = model.predict(X_test, batch_size = batch_size)\n",
    "    \n",
    "    # prices col = 15\n",
    "    y_pred = (y_pred * sc_X.data_range_[15]) + (sc_X.data_min_[15])\n",
    "\n",
    "    y_pred_list.append(y_pred)\n",
    "    \n",
    "    from sklearn.metrics import mean_squared_error as mse\n",
    "    from sklearn.metrics import mean_absolute_error as mae\n",
    "\n",
    "    rmse_error = mse(y_test, y_pred, squared = False)\n",
    "    mae_error = mae(y_test, y_pred)\n",
    "    \n",
    "    rmse_gen.append(rmse_error)\n",
    "    mae_gen.append(mae_error)\n",
    "    \n",
    "    # =============================================================================\n",
    "    # Metrics evaluation on spike regions\n",
    "    # =============================================================================\n",
    "\n",
    "    # select y_pred and y_test only for regions with spikes\n",
    "    y_test_spike = (y_test.T * y_spike_occ).T\n",
    "    y_pred_spike = (y_pred.T * y_spike_occ).T\n",
    "    y_test_spike = y_test_spike[y_test_spike != 0]\n",
    "    y_pred_spike = y_pred_spike[y_pred_spike != 0]\n",
    "    \n",
    "    # calculate metric\n",
    "    rmse_spike = mse(y_test_spike, y_pred_spike, squared = False)\n",
    "    mae_spike = mae(y_test_spike, y_pred_spike)\n",
    "    \n",
    "    rmse_spi.append(rmse_spike)\n",
    "    mae_spi.append(mae_spike)\n",
    "    \n",
    "    # =============================================================================\n",
    "    # Metric evaluation on normal regions\n",
    "    # =============================================================================\n",
    "    \n",
    "    # inverse y_spike_occ so the only normal occurences are chosen\n",
    "    y_normal_occ = (y_spike_occ - 1) * (-1)\n",
    "    \n",
    "    # sanity check\n",
    "    y_normal_occ.sum() + y_spike_occ.sum() # gives the correct total \n",
    "    \n",
    "    # select y_pred and y_test only for normal regions\n",
    "    y_test_normal = (y_test.T * y_normal_occ).T\n",
    "    y_pred_normal = (y_pred.T * y_normal_occ).T\n",
    "    y_test_normal = y_test_normal[y_test_normal != 0.00]\n",
    "    y_pred_normal = y_pred_normal[y_pred_normal != 0.00]\n",
    "    \n",
    "    # calculate metric\n",
    "    rmse_normal = mse(y_test_normal, y_pred_normal, squared = False)\n",
    "    mae_normal = mae(y_test_normal, y_pred_normal)\n",
    "    \n",
    "    rmse_nor.append(rmse_normal)\n",
    "    mae_nor.append(mae_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_param</th>\n",
       "      <th>rmse_general</th>\n",
       "      <th>mae_general</th>\n",
       "      <th>rmse_spike</th>\n",
       "      <th>mae_spike</th>\n",
       "      <th>rmse_normal</th>\n",
       "      <th>mae_normal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'bias_initializer': &lt;keras.initializers.Zeros...</td>\n",
       "      <td>32.203745</td>\n",
       "      <td>20.668285</td>\n",
       "      <td>72.321964</td>\n",
       "      <td>56.492732</td>\n",
       "      <td>19.687037</td>\n",
       "      <td>15.119536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'bias_initializer': &lt;keras.initializers.Zeros...</td>\n",
       "      <td>31.601369</td>\n",
       "      <td>18.372158</td>\n",
       "      <td>75.824887</td>\n",
       "      <td>58.992808</td>\n",
       "      <td>16.211523</td>\n",
       "      <td>12.080539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'bias_initializer': &lt;keras.initializers.Zeros...</td>\n",
       "      <td>30.521818</td>\n",
       "      <td>17.630540</td>\n",
       "      <td>74.687986</td>\n",
       "      <td>60.108848</td>\n",
       "      <td>14.555576</td>\n",
       "      <td>11.051194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'bias_initializer': &lt;keras.initializers.Ones ...</td>\n",
       "      <td>31.300486</td>\n",
       "      <td>17.441123</td>\n",
       "      <td>77.499574</td>\n",
       "      <td>60.942363</td>\n",
       "      <td>14.183986</td>\n",
       "      <td>10.703336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'bias_initializer': &lt;keras.initializers.Ones ...</td>\n",
       "      <td>30.791579</td>\n",
       "      <td>17.137586</td>\n",
       "      <td>75.959740</td>\n",
       "      <td>59.099031</td>\n",
       "      <td>14.187750</td>\n",
       "      <td>10.638295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'bias_initializer': &lt;keras.initializers.Ones ...</td>\n",
       "      <td>33.939001</td>\n",
       "      <td>19.463654</td>\n",
       "      <td>82.762000</td>\n",
       "      <td>64.854810</td>\n",
       "      <td>16.412069</td>\n",
       "      <td>12.433144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           all_param  rmse_general  \\\n",
       "0  {'bias_initializer': <keras.initializers.Zeros...     32.203745   \n",
       "1  {'bias_initializer': <keras.initializers.Zeros...     31.601369   \n",
       "2  {'bias_initializer': <keras.initializers.Zeros...     30.521818   \n",
       "3  {'bias_initializer': <keras.initializers.Ones ...     31.300486   \n",
       "4  {'bias_initializer': <keras.initializers.Ones ...     30.791579   \n",
       "5  {'bias_initializer': <keras.initializers.Ones ...     33.939001   \n",
       "\n",
       "   mae_general  rmse_spike  mae_spike  rmse_normal  mae_normal  \n",
       "0    20.668285   72.321964  56.492732    19.687037   15.119536  \n",
       "1    18.372158   75.824887  58.992808    16.211523   12.080539  \n",
       "2    17.630540   74.687986  60.108848    14.555576   11.051194  \n",
       "3    17.441123   77.499574  60.942363    14.183986   10.703336  \n",
       "4    17.137586   75.959740  59.099031    14.187750   10.638295  \n",
       "5    19.463654   82.762000  64.854810    16.412069   12.433144  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({'all_param':all_param,\n",
    "                        \n",
    "                        'rmse_general': rmse_gen, \n",
    "                 \n",
    "                        'mae_general': mae_gen,\n",
    "                        \n",
    "                        'rmse_spike': rmse_spi,\n",
    "                 \n",
    "                        'mae_spike': mae_spi,\n",
    "                        \n",
    "                        'rmse_normal': rmse_nor,\n",
    "                    \n",
    "                        'mae_normal': mae_nor})\n",
    "\n",
    "results.to_csv('Results_LSTM_5_kernel_bias.csv')\n",
    "\n",
    "y_pred = pd.DataFrame({'all_param': all_param,\n",
    "                       'Predicitons': y_pred_list})\n",
    "\n",
    "y_pred.to_csv('Pedictions_LSTM_4_kernel_bias.csv')\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_b6f1829e_d961_11ea_8ab3_e15df2ad3e50row0_col2,#T_b6f1829e_d961_11ea_8ab3_e15df2ad3e50row0_col3,#T_b6f1829e_d961_11ea_8ab3_e15df2ad3e50row2_col0,#T_b6f1829e_d961_11ea_8ab3_e15df2ad3e50row3_col4,#T_b6f1829e_d961_11ea_8ab3_e15df2ad3e50row4_col1,#T_b6f1829e_d961_11ea_8ab3_e15df2ad3e50row4_col5{\n",
       "            background-color:  yellow;\n",
       "        }</style><table id=\"T_b6f1829e_d961_11ea_8ab3_e15df2ad3e50\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >rmse_general</th>        <th class=\"col_heading level0 col1\" >mae_general</th>        <th class=\"col_heading level0 col2\" >rmse_spike</th>        <th class=\"col_heading level0 col3\" >mae_spike</th>        <th class=\"col_heading level0 col4\" >rmse_normal</th>        <th class=\"col_heading level0 col5\" >mae_normal</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_b6f1829e_d961_11ea_8ab3_e15df2ad3e50level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_b6f1829e_d961_11ea_8ab3_e15df2ad3e50row0_col0\" class=\"data row0 col0\" >32.203745</td>\n",
       "                        <td id=\"T_b6f1829e_d961_11ea_8ab3_e15df2ad3e50row0_col1\" class=\"data row0 col1\" >20.668285</td>\n",
       "                        <td id=\"T_b6f1829e_d961_11ea_8ab3_e15df2ad3e50row0_col2\" class=\"data row0 col2\" >72.321964</td>\n",
       "                        <td id=\"T_b6f1829e_d961_11ea_8ab3_e15df2ad3e50row0_col3\" class=\"data row0 col3\" >56.492732</td>\n",
       "                        <td id=\"T_b6f1829e_d961_11ea_8ab3_e15df2ad3e50row0_col4\" class=\"data row0 col4\" >19.687037</td>\n",
       "                        <td id=\"T_b6f1829e_d961_11ea_8ab3_e15df2ad3e50row0_col5\" class=\"data row0 col5\" >15.119536</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b6f1829e_d961_11ea_8ab3_e15df2ad3e50level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_b6f1829e_d961_11ea_8ab3_e15df2ad3e50row1_col0\" class=\"data row1 col0\" >31.601369</td>\n",
       "                        <td id=\"T_b6f1829e_d961_11ea_8ab3_e15df2ad3e50row1_col1\" class=\"data row1 col1\" >18.372158</td>\n",
       "                        <td id=\"T_b6f1829e_d961_11ea_8ab3_e15df2ad3e50row1_col2\" class=\"data row1 col2\" >75.824887</td>\n",
       "                        <td id=\"T_b6f1829e_d961_11ea_8ab3_e15df2ad3e50row1_col3\" class=\"data row1 col3\" >58.992808</td>\n",
       "                        <td id=\"T_b6f1829e_d961_11ea_8ab3_e15df2ad3e50row1_col4\" class=\"data row1 col4\" >16.211523</td>\n",
       "                        <td id=\"T_b6f1829e_d961_11ea_8ab3_e15df2ad3e50row1_col5\" class=\"data row1 col5\" >12.080539</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b6f1829e_d961_11ea_8ab3_e15df2ad3e50level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_b6f1829e_d961_11ea_8ab3_e15df2ad3e50row2_col0\" class=\"data row2 col0\" >30.521818</td>\n",
       "                        <td id=\"T_b6f1829e_d961_11ea_8ab3_e15df2ad3e50row2_col1\" class=\"data row2 col1\" >17.630540</td>\n",
       "                        <td id=\"T_b6f1829e_d961_11ea_8ab3_e15df2ad3e50row2_col2\" class=\"data row2 col2\" >74.687986</td>\n",
       "                        <td id=\"T_b6f1829e_d961_11ea_8ab3_e15df2ad3e50row2_col3\" class=\"data row2 col3\" >60.108848</td>\n",
       "                        <td id=\"T_b6f1829e_d961_11ea_8ab3_e15df2ad3e50row2_col4\" class=\"data row2 col4\" >14.555576</td>\n",
       "                        <td id=\"T_b6f1829e_d961_11ea_8ab3_e15df2ad3e50row2_col5\" class=\"data row2 col5\" >11.051194</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b6f1829e_d961_11ea_8ab3_e15df2ad3e50level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_b6f1829e_d961_11ea_8ab3_e15df2ad3e50row3_col0\" class=\"data row3 col0\" >31.300486</td>\n",
       "                        <td id=\"T_b6f1829e_d961_11ea_8ab3_e15df2ad3e50row3_col1\" class=\"data row3 col1\" >17.441123</td>\n",
       "                        <td id=\"T_b6f1829e_d961_11ea_8ab3_e15df2ad3e50row3_col2\" class=\"data row3 col2\" >77.499574</td>\n",
       "                        <td id=\"T_b6f1829e_d961_11ea_8ab3_e15df2ad3e50row3_col3\" class=\"data row3 col3\" >60.942363</td>\n",
       "                        <td id=\"T_b6f1829e_d961_11ea_8ab3_e15df2ad3e50row3_col4\" class=\"data row3 col4\" >14.183986</td>\n",
       "                        <td id=\"T_b6f1829e_d961_11ea_8ab3_e15df2ad3e50row3_col5\" class=\"data row3 col5\" >10.703336</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b6f1829e_d961_11ea_8ab3_e15df2ad3e50level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_b6f1829e_d961_11ea_8ab3_e15df2ad3e50row4_col0\" class=\"data row4 col0\" >30.791579</td>\n",
       "                        <td id=\"T_b6f1829e_d961_11ea_8ab3_e15df2ad3e50row4_col1\" class=\"data row4 col1\" >17.137586</td>\n",
       "                        <td id=\"T_b6f1829e_d961_11ea_8ab3_e15df2ad3e50row4_col2\" class=\"data row4 col2\" >75.959740</td>\n",
       "                        <td id=\"T_b6f1829e_d961_11ea_8ab3_e15df2ad3e50row4_col3\" class=\"data row4 col3\" >59.099031</td>\n",
       "                        <td id=\"T_b6f1829e_d961_11ea_8ab3_e15df2ad3e50row4_col4\" class=\"data row4 col4\" >14.187750</td>\n",
       "                        <td id=\"T_b6f1829e_d961_11ea_8ab3_e15df2ad3e50row4_col5\" class=\"data row4 col5\" >10.638295</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b6f1829e_d961_11ea_8ab3_e15df2ad3e50level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_b6f1829e_d961_11ea_8ab3_e15df2ad3e50row5_col0\" class=\"data row5 col0\" >33.939001</td>\n",
       "                        <td id=\"T_b6f1829e_d961_11ea_8ab3_e15df2ad3e50row5_col1\" class=\"data row5 col1\" >19.463654</td>\n",
       "                        <td id=\"T_b6f1829e_d961_11ea_8ab3_e15df2ad3e50row5_col2\" class=\"data row5 col2\" >82.762000</td>\n",
       "                        <td id=\"T_b6f1829e_d961_11ea_8ab3_e15df2ad3e50row5_col3\" class=\"data row5 col3\" >64.854810</td>\n",
       "                        <td id=\"T_b6f1829e_d961_11ea_8ab3_e15df2ad3e50row5_col4\" class=\"data row5 col4\" >16.412069</td>\n",
       "                        <td id=\"T_b6f1829e_d961_11ea_8ab3_e15df2ad3e50row5_col5\" class=\"data row5 col5\" >12.433144</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fab564197d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({'rmse_general': rmse_gen, \n",
    "                 \n",
    "                        'mae_general': mae_gen,\n",
    "                        \n",
    "                        'rmse_spike': rmse_spi,\n",
    "                 \n",
    "                        'mae_spike': mae_spi,\n",
    "                        \n",
    "                        'rmse_normal': rmse_nor,\n",
    "                    \n",
    "                        'mae_normal': mae_nor})\n",
    "\n",
    "def highlight_min(s):\n",
    "    '''\n",
    "    highlight the maximum in a Series yellow.\n",
    "    '''\n",
    "    is_max = s == s.min()\n",
    "    return ['background-color: yellow' if v else '' for v in is_max]\n",
    "\n",
    "results.style.apply(highlight_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
