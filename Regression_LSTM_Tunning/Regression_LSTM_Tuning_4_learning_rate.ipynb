{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Parameter Tuning\n",
    "    \n",
    "    Look for best learning rate "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\maria\\anaconda3\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from pandas) (1.18.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from python-dateutil>=2.6.1->pandas) (1.14.0)\n",
      "Requirement already satisfied: sklearn in c:\\users\\maria\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\maria\\anaconda3\\lib\\site-packages (from sklearn) (0.22.1)\n",
      "Requirement already satisfied: scipy>=0.17.0 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.4.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (0.14.1)\n",
      "Requirement already satisfied: numpy>=1.11.0 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.18.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install sklearn\n",
    "\n",
    "import pandas as pd;\n",
    "import numpy as np;\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data; set X and y; fill nan values and split in test and training  data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "data = pd.read_csv('Data_set_1_smaller.csv', index_col = 0)\n",
    "\n",
    "# for later use\n",
    "features_num = 15\n",
    "\n",
    "# 2018 data\n",
    "data = data.loc[data.index > 2018070000, :]\n",
    "\n",
    "# reset index\n",
    "data.reset_index(inplace = True)\n",
    "data.drop('index', axis = 1, inplace = True)\n",
    "\n",
    "# fill nan values\n",
    "data.fillna(method = 'ffill', inplace = True)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# divide data into train and test \n",
    "data_train, data_test = train_test_split(\n",
    "         data, test_size = 0.15, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply feature scaling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# data scaling  (including offer (y))\n",
    "sc_X = MinMaxScaler()\n",
    "data_train = sc_X.fit_transform(data_train)\n",
    "data_test = sc_X.transform(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the Keras libraries and packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LeakyReLU\n",
    "from keras import initializers\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "mae_gen = []\n",
    "rmse_gen = []\n",
    "mae_nor = []\n",
    "mae_spi = []\n",
    "rmse_nor = []\n",
    "rmse_spi = []\n",
    "hist_list = []\n",
    "y_pred_list = []\n",
    "prediction_list = []\n",
    "time_count = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare of data according to LSTM needs,  create regressor & tune:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/180\n",
      "65/65 [==============================] - 30s 466ms/step - loss: 0.2253 - mse: 0.2253 - mae: 0.3684 - val_loss: 0.0084 - val_mse: 0.0084 - val_mae: 0.0732\n",
      "Epoch 2/180\n",
      "65/65 [==============================] - 31s 473ms/step - loss: 0.1370 - mse: 0.1370 - mae: 0.2954 - val_loss: 0.0173 - val_mse: 0.0173 - val_mae: 0.1241\n",
      "Epoch 3/180\n",
      "65/65 [==============================] - 32s 489ms/step - loss: 0.0944 - mse: 0.0944 - mae: 0.2456 - val_loss: 0.0022 - val_mse: 0.0022 - val_mae: 0.0379\n",
      "Epoch 4/180\n",
      "65/65 [==============================] - 33s 505ms/step - loss: 0.0626 - mse: 0.0626 - mae: 0.1992 - val_loss: 0.0028 - val_mse: 0.0028 - val_mae: 0.0455\n",
      "Epoch 5/180\n",
      "65/65 [==============================] - 32s 500ms/step - loss: 0.0416 - mse: 0.0416 - mae: 0.1631 - val_loss: 0.0104 - val_mse: 0.0104 - val_mae: 0.0965\n",
      "Epoch 6/180\n",
      "65/65 [==============================] - 32s 489ms/step - loss: 0.0280 - mse: 0.0280 - mae: 0.1326 - val_loss: 0.0061 - val_mse: 0.0061 - val_mae: 0.0736\n",
      "Epoch 7/180\n",
      "65/65 [==============================] - 31s 484ms/step - loss: 0.0188 - mse: 0.0188 - mae: 0.1093 - val_loss: 0.0017 - val_mse: 0.0017 - val_mae: 0.0339\n",
      "Epoch 8/180\n",
      "65/65 [==============================] - 31s 475ms/step - loss: 0.0130 - mse: 0.0130 - mae: 0.0901 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0226\n",
      "Epoch 9/180\n",
      "65/65 [==============================] - 32s 493ms/step - loss: 0.0093 - mse: 0.0093 - mae: 0.0755 - val_loss: 0.0037 - val_mse: 0.0037 - val_mae: 0.0570\n",
      "Epoch 10/180\n",
      "65/65 [==============================] - 31s 476ms/step - loss: 0.0068 - mse: 0.0068 - mae: 0.0643 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0184\n",
      "Epoch 11/180\n",
      "65/65 [==============================] - 33s 513ms/step - loss: 0.0052 - mse: 0.0052 - mae: 0.0559 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0163\n",
      "Epoch 12/180\n",
      "65/65 [==============================] - 29s 454ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0482 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0166\n",
      "Epoch 13/180\n",
      "65/65 [==============================] - 32s 486ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0425 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 14/180\n",
      "65/65 [==============================] - 30s 456ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0374 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0178\n",
      "Epoch 15/180\n",
      "65/65 [==============================] - 32s 485ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0332 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0172\n",
      "Epoch 16/180\n",
      "65/65 [==============================] - 30s 466ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0303 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0187\n",
      "Epoch 17/180\n",
      "65/65 [==============================] - 31s 480ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0276 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0171\n",
      "Epoch 18/180\n",
      "65/65 [==============================] - 31s 479ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0253 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0173\n",
      "Epoch 19/180\n",
      "65/65 [==============================] - 32s 489ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0239 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0187\n",
      "Epoch 20/180\n",
      "65/65 [==============================] - 33s 508ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0229 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0181\n",
      "Epoch 21/180\n",
      "65/65 [==============================] - 32s 487ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0218 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 22/180\n",
      "65/65 [==============================] - 33s 512ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0209 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 23/180\n",
      "65/65 [==============================] - 33s 511ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0205 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0189\n",
      "Epoch 24/180\n",
      "65/65 [==============================] - 33s 511ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0201 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0187\n",
      "Epoch 25/180\n",
      "65/65 [==============================] - 30s 462ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0197 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0191\n",
      "Epoch 26/180\n",
      "65/65 [==============================] - 32s 487ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0193 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0189\n",
      "Epoch 27/180\n",
      "65/65 [==============================] - 31s 485ms/step - loss: 9.9739e-04 - mse: 9.9739e-04 - mae: 0.0190 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0190\n",
      "Epoch 28/180\n",
      "65/65 [==============================] - 31s 484ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0192 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0192\n",
      "Epoch 29/180\n",
      "65/65 [==============================] - 32s 487ms/step - loss: 9.7680e-04 - mse: 9.7680e-04 - mae: 0.0187 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0187\n",
      "Epoch 30/180\n",
      "65/65 [==============================] - 31s 477ms/step - loss: 9.7374e-04 - mse: 9.7374e-04 - mae: 0.0187 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 31/180\n",
      "65/65 [==============================] - 30s 465ms/step - loss: 9.6886e-04 - mse: 9.6886e-04 - mae: 0.0187 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0188\n",
      "Epoch 32/180\n",
      "65/65 [==============================] - 31s 474ms/step - loss: 9.7231e-04 - mse: 9.7231e-04 - mae: 0.0185 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0190\n",
      "Epoch 33/180\n",
      "65/65 [==============================] - 31s 469ms/step - loss: 9.5705e-04 - mse: 9.5705e-04 - mae: 0.0184 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 34/180\n",
      "65/65 [==============================] - 30s 464ms/step - loss: 9.5532e-04 - mse: 9.5532e-04 - mae: 0.0183 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0184\n",
      "Epoch 35/180\n",
      "65/65 [==============================] - 30s 468ms/step - loss: 9.5707e-04 - mse: 9.5707e-04 - mae: 0.0183 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0189\n",
      "Epoch 36/180\n",
      "65/65 [==============================] - 28s 431ms/step - loss: 9.4892e-04 - mse: 9.4892e-04 - mae: 0.0181 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0182\n",
      "Epoch 37/180\n",
      "65/65 [==============================] - 31s 483ms/step - loss: 9.3535e-04 - mse: 9.3535e-04 - mae: 0.0181 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0187\n",
      "Epoch 38/180\n",
      "65/65 [==============================] - 32s 488ms/step - loss: 9.3608e-04 - mse: 9.3608e-04 - mae: 0.0181 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 39/180\n",
      "65/65 [==============================] - 32s 493ms/step - loss: 9.3645e-04 - mse: 9.3645e-04 - mae: 0.0181 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0188\n",
      "Epoch 40/180\n",
      "65/65 [==============================] - 42s 645ms/step - loss: 9.4718e-04 - mse: 9.4718e-04 - mae: 0.0181 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0183\n",
      "Epoch 41/180\n",
      "65/65 [==============================] - 39s 602ms/step - loss: 9.4282e-04 - mse: 9.4282e-04 - mae: 0.0181 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0181\n",
      "Epoch 42/180\n",
      "65/65 [==============================] - 40s 620ms/step - loss: 9.3281e-04 - mse: 9.3281e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0180\n",
      "Epoch 43/180\n",
      "65/65 [==============================] - 52s 804ms/step - loss: 9.3578e-04 - mse: 9.3578e-04 - mae: 0.0180 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 44/180\n",
      "65/65 [==============================] - 43s 657ms/step - loss: 9.3897e-04 - mse: 9.3897e-04 - mae: 0.0180 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0179\n",
      "Epoch 45/180\n",
      "65/65 [==============================] - 39s 601ms/step - loss: 9.3052e-04 - mse: 9.3052e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0182\n",
      "Epoch 46/180\n",
      "65/65 [==============================] - 40s 616ms/step - loss: 9.3186e-04 - mse: 9.3186e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0181\n",
      "Epoch 47/180\n",
      "65/65 [==============================] - 39s 606ms/step - loss: 9.3344e-04 - mse: 9.3344e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0182\n",
      "Epoch 48/180\n",
      "65/65 [==============================] - 39s 600ms/step - loss: 9.2615e-04 - mse: 9.2615e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 49/180\n",
      "65/65 [==============================] - 39s 603ms/step - loss: 9.2928e-04 - mse: 9.2928e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0181\n",
      "Epoch 50/180\n",
      "65/65 [==============================] - 39s 602ms/step - loss: 9.2942e-04 - mse: 9.2942e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0182\n",
      "Epoch 51/180\n",
      "65/65 [==============================] - 39s 595ms/step - loss: 9.2248e-04 - mse: 9.2248e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 52/180\n",
      "65/65 [==============================] - 39s 606ms/step - loss: 9.2419e-04 - mse: 9.2419e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0182\n",
      "Epoch 53/180\n",
      "65/65 [==============================] - 38s 582ms/step - loss: 9.2710e-04 - mse: 9.2710e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0181\n",
      "Epoch 54/180\n",
      "65/65 [==============================] - 38s 578ms/step - loss: 9.2958e-04 - mse: 9.2958e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0181\n",
      "Epoch 55/180\n",
      "65/65 [==============================] - 40s 621ms/step - loss: 9.2732e-04 - mse: 9.2732e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0179\n",
      "Epoch 56/180\n",
      "65/65 [==============================] - 40s 610ms/step - loss: 9.2864e-04 - mse: 9.2864e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0181\n",
      "Epoch 57/180\n",
      "65/65 [==============================] - 40s 614ms/step - loss: 9.3007e-04 - mse: 9.3007e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0179\n",
      "Epoch 58/180\n",
      "65/65 [==============================] - 39s 601ms/step - loss: 9.2353e-04 - mse: 9.2353e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0180\n",
      "Epoch 59/180\n",
      "65/65 [==============================] - 39s 607ms/step - loss: 9.2060e-04 - mse: 9.2060e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0178\n",
      "Epoch 60/180\n",
      "65/65 [==============================] - 39s 602ms/step - loss: 9.2090e-04 - mse: 9.2090e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0178\n",
      "Epoch 61/180\n",
      "65/65 [==============================] - 39s 595ms/step - loss: 9.2437e-04 - mse: 9.2437e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0179\n",
      "Epoch 62/180\n",
      "65/65 [==============================] - 39s 593ms/step - loss: 9.1773e-04 - mse: 9.1773e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0177\n",
      "Epoch 63/180\n",
      "65/65 [==============================] - 38s 587ms/step - loss: 9.1060e-04 - mse: 9.1060e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0178\n",
      "Epoch 64/180\n",
      "65/65 [==============================] - 38s 581ms/step - loss: 9.1391e-04 - mse: 9.1391e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0184\n",
      "Epoch 65/180\n",
      "65/65 [==============================] - 39s 600ms/step - loss: 9.1377e-04 - mse: 9.1377e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0180\n",
      "Epoch 66/180\n",
      "65/65 [==============================] - 39s 597ms/step - loss: 9.2178e-04 - mse: 9.2178e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0178\n",
      "Epoch 67/180\n",
      "65/65 [==============================] - 40s 614ms/step - loss: 9.1257e-04 - mse: 9.1257e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0178\n",
      "Epoch 68/180\n",
      "65/65 [==============================] - 39s 606ms/step - loss: 9.0971e-04 - mse: 9.0971e-04 - mae: 0.0176 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0178\n",
      "Epoch 69/180\n",
      "65/65 [==============================] - 40s 616ms/step - loss: 9.1108e-04 - mse: 9.1108e-04 - mae: 0.0175 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0177\n",
      "Epoch 70/180\n",
      "65/65 [==============================] - 40s 613ms/step - loss: 9.1663e-04 - mse: 9.1663e-04 - mae: 0.0176 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0176\n",
      "Epoch 71/180\n",
      "65/65 [==============================] - 38s 588ms/step - loss: 9.1089e-04 - mse: 9.1089e-04 - mae: 0.0176 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0177\n",
      "Epoch 72/180\n",
      "65/65 [==============================] - 38s 580ms/step - loss: 9.1037e-04 - mse: 9.1037e-04 - mae: 0.0176 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0178\n",
      "Epoch 73/180\n",
      "65/65 [==============================] - 37s 571ms/step - loss: 9.1128e-04 - mse: 9.1128e-04 - mae: 0.0176 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0178\n",
      "Epoch 74/180\n",
      "65/65 [==============================] - 41s 632ms/step - loss: 9.0852e-04 - mse: 9.0852e-04 - mae: 0.0176 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0181\n",
      "Epoch 75/180\n",
      "65/65 [==============================] - 42s 647ms/step - loss: 9.0600e-04 - mse: 9.0600e-04 - mae: 0.0175 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0180\n",
      "Epoch 76/180\n",
      "65/65 [==============================] - 42s 649ms/step - loss: 9.0300e-04 - mse: 9.0300e-04 - mae: 0.0175 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0177\n",
      "Epoch 77/180\n",
      "65/65 [==============================] - 39s 596ms/step - loss: 9.0647e-04 - mse: 9.0647e-04 - mae: 0.0174 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0175\n",
      "Epoch 78/180\n",
      "65/65 [==============================] - 40s 617ms/step - loss: 9.0446e-04 - mse: 9.0446e-04 - mae: 0.0174 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0175\n",
      "Epoch 79/180\n",
      "65/65 [==============================] - 41s 637ms/step - loss: 9.1041e-04 - mse: 9.1041e-04 - mae: 0.0176 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0180\n",
      "Epoch 80/180\n",
      "65/65 [==============================] - 42s 641ms/step - loss: 9.1454e-04 - mse: 9.1454e-04 - mae: 0.0176 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0179\n",
      "Epoch 81/180\n",
      "65/65 [==============================] - 42s 650ms/step - loss: 9.0796e-04 - mse: 9.0796e-04 - mae: 0.0175 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0179\n",
      "Epoch 82/180\n",
      "65/65 [==============================] - 39s 603ms/step - loss: 9.0263e-04 - mse: 9.0263e-04 - mae: 0.0175 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0178\n",
      "Epoch 83/180\n",
      "65/65 [==============================] - 38s 586ms/step - loss: 8.9820e-04 - mse: 8.9820e-04 - mae: 0.0173 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0174\n",
      "Epoch 84/180\n",
      "65/65 [==============================] - 39s 597ms/step - loss: 9.0521e-04 - mse: 9.0521e-04 - mae: 0.0174 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0177\n",
      "Epoch 85/180\n",
      "65/65 [==============================] - 41s 629ms/step - loss: 8.9954e-04 - mse: 8.9954e-04 - mae: 0.0174 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0179\n",
      "Epoch 86/180\n",
      "65/65 [==============================] - 39s 594ms/step - loss: 8.9954e-04 - mse: 8.9954e-04 - mae: 0.0173 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0175\n",
      "Epoch 87/180\n",
      "65/65 [==============================] - 38s 588ms/step - loss: 9.0931e-04 - mse: 9.0931e-04 - mae: 0.0175 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0177\n",
      "Epoch 88/180\n",
      "65/65 [==============================] - 39s 607ms/step - loss: 8.9644e-04 - mse: 8.9644e-04 - mae: 0.0173 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0177\n",
      "Epoch 89/180\n",
      "65/65 [==============================] - 39s 597ms/step - loss: 9.0358e-04 - mse: 9.0358e-04 - mae: 0.0175 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0174\n",
      "Epoch 90/180\n",
      "65/65 [==============================] - 38s 592ms/step - loss: 8.9894e-04 - mse: 8.9894e-04 - mae: 0.0173 - val_loss: 9.9582e-04 - val_mse: 9.9582e-04 - val_mae: 0.0176\n",
      "Epoch 91/180\n",
      "65/65 [==============================] - 43s 665ms/step - loss: 8.9591e-04 - mse: 8.9591e-04 - mae: 0.0173 - val_loss: 9.9362e-04 - val_mse: 9.9362e-04 - val_mae: 0.0176\n",
      "Epoch 92/180\n",
      "65/65 [==============================] - 35s 544ms/step - loss: 8.9297e-04 - mse: 8.9297e-04 - mae: 0.0172 - val_loss: 9.9298e-04 - val_mse: 9.9298e-04 - val_mae: 0.0175\n",
      "Epoch 93/180\n",
      "65/65 [==============================] - 35s 538ms/step - loss: 8.9362e-04 - mse: 8.9362e-04 - mae: 0.0173 - val_loss: 9.8936e-04 - val_mse: 9.8936e-04 - val_mae: 0.0177\n",
      "Epoch 94/180\n",
      "65/65 [==============================] - 36s 556ms/step - loss: 8.9156e-04 - mse: 8.9156e-04 - mae: 0.0173 - val_loss: 9.9055e-04 - val_mse: 9.9055e-04 - val_mae: 0.0177\n",
      "Epoch 95/180\n",
      "65/65 [==============================] - 38s 592ms/step - loss: 8.9436e-04 - mse: 8.9436e-04 - mae: 0.0173 - val_loss: 9.8721e-04 - val_mse: 9.8721e-04 - val_mae: 0.0175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/180\n",
      "65/65 [==============================] - 36s 553ms/step - loss: 8.8561e-04 - mse: 8.8561e-04 - mae: 0.0172 - val_loss: 9.8986e-04 - val_mse: 9.8986e-04 - val_mae: 0.0175\n",
      "Epoch 97/180\n",
      "65/65 [==============================] - 42s 645ms/step - loss: 8.9463e-04 - mse: 8.9463e-04 - mae: 0.0172 - val_loss: 9.8615e-04 - val_mse: 9.8615e-04 - val_mae: 0.0174\n",
      "Epoch 98/180\n",
      "65/65 [==============================] - 41s 634ms/step - loss: 8.9638e-04 - mse: 8.9638e-04 - mae: 0.0172 - val_loss: 9.8680e-04 - val_mse: 9.8680e-04 - val_mae: 0.0176\n",
      "Epoch 99/180\n",
      "65/65 [==============================] - 39s 599ms/step - loss: 8.9393e-04 - mse: 8.9393e-04 - mae: 0.0172 - val_loss: 9.8311e-04 - val_mse: 9.8311e-04 - val_mae: 0.0174\n",
      "Epoch 100/180\n",
      "65/65 [==============================] - 37s 565ms/step - loss: 8.8750e-04 - mse: 8.8750e-04 - mae: 0.0172 - val_loss: 9.8277e-04 - val_mse: 9.8277e-04 - val_mae: 0.0177\n",
      "Epoch 101/180\n",
      "65/65 [==============================] - 40s 610ms/step - loss: 8.8688e-04 - mse: 8.8688e-04 - mae: 0.0172 - val_loss: 9.7806e-04 - val_mse: 9.7806e-04 - val_mae: 0.0178\n",
      "Epoch 102/180\n",
      "65/65 [==============================] - 38s 590ms/step - loss: 8.9285e-04 - mse: 8.9285e-04 - mae: 0.0172 - val_loss: 9.8009e-04 - val_mse: 9.8009e-04 - val_mae: 0.0172\n",
      "Epoch 103/180\n",
      "65/65 [==============================] - 38s 580ms/step - loss: 8.8741e-04 - mse: 8.8741e-04 - mae: 0.0172 - val_loss: 9.7567e-04 - val_mse: 9.7567e-04 - val_mae: 0.0174\n",
      "Epoch 104/180\n",
      "65/65 [==============================] - 39s 607ms/step - loss: 8.9070e-04 - mse: 8.9070e-04 - mae: 0.0172 - val_loss: 9.7009e-04 - val_mse: 9.7009e-04 - val_mae: 0.0176\n",
      "Epoch 105/180\n",
      "65/65 [==============================] - 36s 549ms/step - loss: 8.8326e-04 - mse: 8.8326e-04 - mae: 0.0171 - val_loss: 9.7047e-04 - val_mse: 9.7047e-04 - val_mae: 0.0174\n",
      "Epoch 106/180\n",
      "65/65 [==============================] - 35s 540ms/step - loss: 8.8267e-04 - mse: 8.8267e-04 - mae: 0.0171 - val_loss: 9.7026e-04 - val_mse: 9.7026e-04 - val_mae: 0.0172\n",
      "Epoch 107/180\n",
      "65/65 [==============================] - 39s 593ms/step - loss: 8.8461e-04 - mse: 8.8461e-04 - mae: 0.0171 - val_loss: 9.6424e-04 - val_mse: 9.6424e-04 - val_mae: 0.0175\n",
      "Epoch 108/180\n",
      "65/65 [==============================] - 41s 636ms/step - loss: 8.8516e-04 - mse: 8.8516e-04 - mae: 0.0170 - val_loss: 9.6344e-04 - val_mse: 9.6344e-04 - val_mae: 0.0175\n",
      "Epoch 109/180\n",
      "65/65 [==============================] - 41s 624ms/step - loss: 8.8878e-04 - mse: 8.8878e-04 - mae: 0.0171 - val_loss: 9.6653e-04 - val_mse: 9.6653e-04 - val_mae: 0.0171\n",
      "Epoch 110/180\n",
      "65/65 [==============================] - 48s 740ms/step - loss: 8.7714e-04 - mse: 8.7714e-04 - mae: 0.0170 - val_loss: 9.6383e-04 - val_mse: 9.6383e-04 - val_mae: 0.0173\n",
      "Epoch 111/180\n",
      "65/65 [==============================] - 40s 622ms/step - loss: 8.7736e-04 - mse: 8.7736e-04 - mae: 0.0170 - val_loss: 9.5444e-04 - val_mse: 9.5444e-04 - val_mae: 0.0173\n",
      "Epoch 112/180\n",
      "65/65 [==============================] - 39s 595ms/step - loss: 8.8172e-04 - mse: 8.8172e-04 - mae: 0.0171 - val_loss: 9.5879e-04 - val_mse: 9.5879e-04 - val_mae: 0.0172\n",
      "Epoch 113/180\n",
      "65/65 [==============================] - 41s 631ms/step - loss: 8.8332e-04 - mse: 8.8332e-04 - mae: 0.0170 - val_loss: 9.5837e-04 - val_mse: 9.5837e-04 - val_mae: 0.0174\n",
      "Epoch 114/180\n",
      "65/65 [==============================] - 43s 656ms/step - loss: 8.7895e-04 - mse: 8.7895e-04 - mae: 0.0169 - val_loss: 9.5519e-04 - val_mse: 9.5519e-04 - val_mae: 0.0171\n",
      "Epoch 115/180\n",
      "65/65 [==============================] - 37s 575ms/step - loss: 8.7620e-04 - mse: 8.7620e-04 - mae: 0.0169 - val_loss: 9.5250e-04 - val_mse: 9.5250e-04 - val_mae: 0.0171\n",
      "Epoch 116/180\n",
      "65/65 [==============================] - 39s 602ms/step - loss: 8.7536e-04 - mse: 8.7536e-04 - mae: 0.0169 - val_loss: 9.5404e-04 - val_mse: 9.5404e-04 - val_mae: 0.0172\n",
      "Epoch 117/180\n",
      "65/65 [==============================] - 39s 593ms/step - loss: 8.7393e-04 - mse: 8.7393e-04 - mae: 0.0169 - val_loss: 9.5436e-04 - val_mse: 9.5436e-04 - val_mae: 0.0172\n",
      "Epoch 118/180\n",
      "65/65 [==============================] - 37s 573ms/step - loss: 8.7445e-04 - mse: 8.7445e-04 - mae: 0.0169 - val_loss: 9.5169e-04 - val_mse: 9.5169e-04 - val_mae: 0.0170\n",
      "Epoch 119/180\n",
      "65/65 [==============================] - 41s 627ms/step - loss: 8.7107e-04 - mse: 8.7107e-04 - mae: 0.0169 - val_loss: 9.4947e-04 - val_mse: 9.4947e-04 - val_mae: 0.0169\n",
      "Epoch 120/180\n",
      "65/65 [==============================] - 40s 611ms/step - loss: 8.6912e-04 - mse: 8.6912e-04 - mae: 0.0168 - val_loss: 9.4879e-04 - val_mse: 9.4879e-04 - val_mae: 0.0169\n",
      "Epoch 121/180\n",
      "65/65 [==============================] - 40s 622ms/step - loss: 8.7691e-04 - mse: 8.7691e-04 - mae: 0.0169 - val_loss: 9.4883e-04 - val_mse: 9.4883e-04 - val_mae: 0.0169\n",
      "Epoch 122/180\n",
      "65/65 [==============================] - 39s 600ms/step - loss: 8.6648e-04 - mse: 8.6648e-04 - mae: 0.0168 - val_loss: 9.5228e-04 - val_mse: 9.5228e-04 - val_mae: 0.0168\n",
      "Epoch 123/180\n",
      "65/65 [==============================] - 38s 580ms/step - loss: 8.6501e-04 - mse: 8.6501e-04 - mae: 0.0169 - val_loss: 9.4524e-04 - val_mse: 9.4524e-04 - val_mae: 0.0170\n",
      "Epoch 124/180\n",
      "65/65 [==============================] - 39s 599ms/step - loss: 8.6775e-04 - mse: 8.6775e-04 - mae: 0.0169 - val_loss: 9.4409e-04 - val_mse: 9.4409e-04 - val_mae: 0.0171\n",
      "Epoch 125/180\n",
      "65/65 [==============================] - 43s 654ms/step - loss: 8.6616e-04 - mse: 8.6616e-04 - mae: 0.0168 - val_loss: 9.4833e-04 - val_mse: 9.4833e-04 - val_mae: 0.0168\n",
      "Epoch 126/180\n",
      "65/65 [==============================] - 41s 625ms/step - loss: 8.6428e-04 - mse: 8.6428e-04 - mae: 0.0166 - val_loss: 9.4778e-04 - val_mse: 9.4778e-04 - val_mae: 0.0168\n",
      "Epoch 127/180\n",
      "65/65 [==============================] - 38s 581ms/step - loss: 8.6382e-04 - mse: 8.6382e-04 - mae: 0.0167 - val_loss: 9.4782e-04 - val_mse: 9.4782e-04 - val_mae: 0.0169\n",
      "Epoch 128/180\n",
      "65/65 [==============================] - 40s 610ms/step - loss: 8.6586e-04 - mse: 8.6586e-04 - mae: 0.0168 - val_loss: 9.4185e-04 - val_mse: 9.4185e-04 - val_mae: 0.0172\n",
      "Epoch 129/180\n",
      "65/65 [==============================] - 44s 683ms/step - loss: 8.6312e-04 - mse: 8.6312e-04 - mae: 0.0167 - val_loss: 9.4615e-04 - val_mse: 9.4615e-04 - val_mae: 0.0167\n",
      "Epoch 130/180\n",
      "65/65 [==============================] - 38s 578ms/step - loss: 8.5898e-04 - mse: 8.5898e-04 - mae: 0.0167 - val_loss: 9.4686e-04 - val_mse: 9.4686e-04 - val_mae: 0.0167\n",
      "Epoch 131/180\n",
      "65/65 [==============================] - 39s 607ms/step - loss: 8.6536e-04 - mse: 8.6536e-04 - mae: 0.0167 - val_loss: 9.4283e-04 - val_mse: 9.4283e-04 - val_mae: 0.0169\n",
      "Epoch 132/180\n",
      "65/65 [==============================] - 34s 523ms/step - loss: 8.5722e-04 - mse: 8.5722e-04 - mae: 0.0166 - val_loss: 9.4397e-04 - val_mse: 9.4397e-04 - val_mae: 0.0171\n",
      "Epoch 133/180\n",
      "65/65 [==============================] - 36s 560ms/step - loss: 8.5725e-04 - mse: 8.5725e-04 - mae: 0.0167 - val_loss: 9.4420e-04 - val_mse: 9.4420e-04 - val_mae: 0.0168\n",
      "Epoch 134/180\n",
      "65/65 [==============================] - 39s 600ms/step - loss: 8.6147e-04 - mse: 8.6147e-04 - mae: 0.0166 - val_loss: 9.4754e-04 - val_mse: 9.4754e-04 - val_mae: 0.0166\n",
      "Epoch 135/180\n",
      "65/65 [==============================] - 38s 591ms/step - loss: 8.5635e-04 - mse: 8.5635e-04 - mae: 0.0166 - val_loss: 9.4802e-04 - val_mse: 9.4802e-04 - val_mae: 0.0168\n",
      "Epoch 136/180\n",
      "65/65 [==============================] - 39s 604ms/step - loss: 8.6263e-04 - mse: 8.6263e-04 - mae: 0.0166 - val_loss: 9.5207e-04 - val_mse: 9.5207e-04 - val_mae: 0.0165\n",
      "Epoch 137/180\n",
      "65/65 [==============================] - 40s 617ms/step - loss: 8.5804e-04 - mse: 8.5804e-04 - mae: 0.0166 - val_loss: 9.4759e-04 - val_mse: 9.4759e-04 - val_mae: 0.0168\n",
      "Epoch 138/180\n",
      "65/65 [==============================] - 33s 502ms/step - loss: 8.5585e-04 - mse: 8.5585e-04 - mae: 0.0166 - val_loss: 9.4942e-04 - val_mse: 9.4942e-04 - val_mae: 0.0166\n",
      "Epoch 139/180\n",
      "65/65 [==============================] - 32s 489ms/step - loss: 8.5659e-04 - mse: 8.5659e-04 - mae: 0.0166 - val_loss: 9.5331e-04 - val_mse: 9.5331e-04 - val_mae: 0.0167\n",
      "Epoch 140/180\n",
      "65/65 [==============================] - 33s 513ms/step - loss: 8.4905e-04 - mse: 8.4905e-04 - mae: 0.0164 - val_loss: 9.4437e-04 - val_mse: 9.4437e-04 - val_mae: 0.0168\n",
      "Epoch 141/180\n",
      "65/65 [==============================] - 33s 507ms/step - loss: 8.5056e-04 - mse: 8.5056e-04 - mae: 0.0164 - val_loss: 9.5248e-04 - val_mse: 9.5248e-04 - val_mae: 0.0167\n",
      "Epoch 142/180\n",
      "65/65 [==============================] - 32s 487ms/step - loss: 8.4853e-04 - mse: 8.4853e-04 - mae: 0.0164 - val_loss: 9.5161e-04 - val_mse: 9.5161e-04 - val_mae: 0.0168\n",
      "Epoch 143/180\n",
      "65/65 [==============================] - 31s 481ms/step - loss: 8.4533e-04 - mse: 8.4533e-04 - mae: 0.0164 - val_loss: 9.5349e-04 - val_mse: 9.5349e-04 - val_mae: 0.0169\n",
      "Epoch 144/180\n",
      "65/65 [==============================] - 34s 527ms/step - loss: 8.5402e-04 - mse: 8.5402e-04 - mae: 0.0165 - val_loss: 9.5009e-04 - val_mse: 9.5009e-04 - val_mae: 0.0171\n",
      "Epoch 145/180\n",
      "65/65 [==============================] - 33s 506ms/step - loss: 8.4902e-04 - mse: 8.4902e-04 - mae: 0.0165 - val_loss: 9.5209e-04 - val_mse: 9.5209e-04 - val_mae: 0.0168\n",
      "Epoch 146/180\n",
      "65/65 [==============================] - 34s 523ms/step - loss: 8.4952e-04 - mse: 8.4952e-04 - mae: 0.0164 - val_loss: 9.5125e-04 - val_mse: 9.5125e-04 - val_mae: 0.0171\n",
      "Epoch 147/180\n",
      "65/65 [==============================] - 34s 517ms/step - loss: 8.4455e-04 - mse: 8.4455e-04 - mae: 0.0164 - val_loss: 9.5369e-04 - val_mse: 9.5369e-04 - val_mae: 0.0169\n",
      "Epoch 148/180\n",
      "65/65 [==============================] - 33s 507ms/step - loss: 8.4249e-04 - mse: 8.4249e-04 - mae: 0.0163 - val_loss: 9.5442e-04 - val_mse: 9.5442e-04 - val_mae: 0.0169\n",
      "Epoch 149/180\n",
      "65/65 [==============================] - 31s 484ms/step - loss: 8.4870e-04 - mse: 8.4870e-04 - mae: 0.0165 - val_loss: 9.5590e-04 - val_mse: 9.5590e-04 - val_mae: 0.0168\n",
      "Epoch 150/180\n",
      "65/65 [==============================] - 31s 478ms/step - loss: 8.4446e-04 - mse: 8.4446e-04 - mae: 0.0163 - val_loss: 9.5172e-04 - val_mse: 9.5172e-04 - val_mae: 0.0169\n",
      "Epoch 151/180\n",
      "65/65 [==============================] - 34s 520ms/step - loss: 8.4629e-04 - mse: 8.4629e-04 - mae: 0.0164 - val_loss: 9.5132e-04 - val_mse: 9.5132e-04 - val_mae: 0.0169\n",
      "Epoch 152/180\n",
      "65/65 [==============================] - 32s 489ms/step - loss: 8.3981e-04 - mse: 8.3981e-04 - mae: 0.0163 - val_loss: 9.5221e-04 - val_mse: 9.5221e-04 - val_mae: 0.0165\n",
      "Epoch 153/180\n",
      "65/65 [==============================] - 36s 553ms/step - loss: 8.3902e-04 - mse: 8.3902e-04 - mae: 0.0163 - val_loss: 9.4185e-04 - val_mse: 9.4185e-04 - val_mae: 0.0169\n",
      "Epoch 154/180\n",
      "65/65 [==============================] - 37s 566ms/step - loss: 8.3594e-04 - mse: 8.3594e-04 - mae: 0.0163 - val_loss: 9.4252e-04 - val_mse: 9.4252e-04 - val_mae: 0.0167\n",
      "Epoch 155/180\n",
      "65/65 [==============================] - 34s 518ms/step - loss: 8.3188e-04 - mse: 8.3188e-04 - mae: 0.0162 - val_loss: 9.3554e-04 - val_mse: 9.3554e-04 - val_mae: 0.0168\n",
      "Epoch 156/180\n",
      "65/65 [==============================] - 34s 517ms/step - loss: 8.4095e-04 - mse: 8.4095e-04 - mae: 0.0163 - val_loss: 9.2700e-04 - val_mse: 9.2700e-04 - val_mae: 0.0170\n",
      "Epoch 157/180\n",
      "65/65 [==============================] - 34s 526ms/step - loss: 8.3609e-04 - mse: 8.3609e-04 - mae: 0.0163 - val_loss: 9.2893e-04 - val_mse: 9.2893e-04 - val_mae: 0.0171\n",
      "Epoch 158/180\n",
      "65/65 [==============================] - 42s 642ms/step - loss: 8.3155e-04 - mse: 8.3155e-04 - mae: 0.0162 - val_loss: 9.3263e-04 - val_mse: 9.3263e-04 - val_mae: 0.0166\n",
      "Epoch 159/180\n",
      "65/65 [==============================] - 42s 641ms/step - loss: 8.3482e-04 - mse: 8.3482e-04 - mae: 0.0162 - val_loss: 9.3855e-04 - val_mse: 9.3855e-04 - val_mae: 0.0166\n",
      "Epoch 160/180\n",
      "65/65 [==============================] - 33s 513ms/step - loss: 8.3561e-04 - mse: 8.3561e-04 - mae: 0.0162 - val_loss: 9.2544e-04 - val_mse: 9.2544e-04 - val_mae: 0.0164\n",
      "Epoch 161/180\n",
      "65/65 [==============================] - 37s 566ms/step - loss: 8.3258e-04 - mse: 8.3258e-04 - mae: 0.0162 - val_loss: 9.2953e-04 - val_mse: 9.2953e-04 - val_mae: 0.0164\n",
      "Epoch 162/180\n",
      "65/65 [==============================] - 37s 572ms/step - loss: 8.3179e-04 - mse: 8.3179e-04 - mae: 0.0162 - val_loss: 9.3360e-04 - val_mse: 9.3360e-04 - val_mae: 0.0166\n",
      "Epoch 163/180\n",
      "65/65 [==============================] - 39s 600ms/step - loss: 8.2652e-04 - mse: 8.2652e-04 - mae: 0.0161 - val_loss: 9.3450e-04 - val_mse: 9.3450e-04 - val_mae: 0.0163\n",
      "Epoch 164/180\n",
      "65/65 [==============================] - 50s 770ms/step - loss: 8.3160e-04 - mse: 8.3160e-04 - mae: 0.0162 - val_loss: 9.2849e-04 - val_mse: 9.2849e-04 - val_mae: 0.0167\n",
      "Epoch 165/180\n",
      "65/65 [==============================] - 55s 852ms/step - loss: 8.2560e-04 - mse: 8.2560e-04 - mae: 0.0161 - val_loss: 9.3393e-04 - val_mse: 9.3393e-04 - val_mae: 0.0166\n",
      "Epoch 166/180\n",
      "65/65 [==============================] - 53s 810ms/step - loss: 8.2314e-04 - mse: 8.2314e-04 - mae: 0.0161 - val_loss: 9.4781e-04 - val_mse: 9.4781e-04 - val_mae: 0.0164\n",
      "Epoch 167/180\n",
      "65/65 [==============================] - 52s 805ms/step - loss: 8.2523e-04 - mse: 8.2523e-04 - mae: 0.0162 - val_loss: 9.2793e-04 - val_mse: 9.2793e-04 - val_mae: 0.0167\n",
      "Epoch 168/180\n",
      "65/65 [==============================] - 51s 787ms/step - loss: 8.2506e-04 - mse: 8.2506e-04 - mae: 0.0161 - val_loss: 9.1854e-04 - val_mse: 9.1854e-04 - val_mae: 0.0167\n",
      "Epoch 169/180\n",
      "65/65 [==============================] - 54s 831ms/step - loss: 8.2145e-04 - mse: 8.2145e-04 - mae: 0.0160 - val_loss: 9.2707e-04 - val_mse: 9.2707e-04 - val_mae: 0.0166\n",
      "Epoch 170/180\n",
      "65/65 [==============================] - 53s 814ms/step - loss: 8.1838e-04 - mse: 8.1838e-04 - mae: 0.0161 - val_loss: 9.2523e-04 - val_mse: 9.2523e-04 - val_mae: 0.0167\n",
      "Epoch 171/180\n",
      "65/65 [==============================] - 53s 820ms/step - loss: 8.1404e-04 - mse: 8.1404e-04 - mae: 0.0160 - val_loss: 9.3205e-04 - val_mse: 9.3205e-04 - val_mae: 0.0165\n",
      "Epoch 172/180\n",
      "65/65 [==============================] - 51s 781ms/step - loss: 8.1989e-04 - mse: 8.1989e-04 - mae: 0.0161 - val_loss: 9.3842e-04 - val_mse: 9.3842e-04 - val_mae: 0.0162\n",
      "Epoch 173/180\n",
      "65/65 [==============================] - 52s 802ms/step - loss: 8.1530e-04 - mse: 8.1530e-04 - mae: 0.0160 - val_loss: 9.5379e-04 - val_mse: 9.5379e-04 - val_mae: 0.0163\n",
      "Epoch 174/180\n",
      "65/65 [==============================] - 52s 807ms/step - loss: 8.1825e-04 - mse: 8.1825e-04 - mae: 0.0160 - val_loss: 9.4508e-04 - val_mse: 9.4508e-04 - val_mae: 0.0167\n",
      "Epoch 175/180\n",
      "65/65 [==============================] - 58s 893ms/step - loss: 8.2135e-04 - mse: 8.2135e-04 - mae: 0.0159 - val_loss: 9.3543e-04 - val_mse: 9.3543e-04 - val_mae: 0.0166\n",
      "Epoch 176/180\n",
      "65/65 [==============================] - 61s 946ms/step - loss: 8.1074e-04 - mse: 8.1074e-04 - mae: 0.0159 - val_loss: 9.3494e-04 - val_mse: 9.3494e-04 - val_mae: 0.0164\n",
      "Epoch 177/180\n",
      "65/65 [==============================] - 52s 807ms/step - loss: 8.1678e-04 - mse: 8.1678e-04 - mae: 0.0160 - val_loss: 9.4961e-04 - val_mse: 9.4961e-04 - val_mae: 0.0165\n",
      "Epoch 178/180\n",
      "65/65 [==============================] - 57s 875ms/step - loss: 8.1435e-04 - mse: 8.1435e-04 - mae: 0.0159 - val_loss: 9.4708e-04 - val_mse: 9.4708e-04 - val_mae: 0.0163\n",
      "Epoch 179/180\n",
      "65/65 [==============================] - 54s 828ms/step - loss: 8.0995e-04 - mse: 8.0995e-04 - mae: 0.0159 - val_loss: 9.5430e-04 - val_mse: 9.5430e-04 - val_mae: 0.0163\n",
      "Epoch 180/180\n",
      "65/65 [==============================] - 56s 863ms/step - loss: 8.1049e-04 - mse: 8.1049e-04 - mae: 0.0159 - val_loss: 9.4203e-04 - val_mse: 9.4203e-04 - val_mae: 0.0171\n",
      "Epoch 1/180\n",
      "65/65 [==============================] - 63s 963ms/step - loss: 0.3405 - mse: 0.3405 - mae: 0.3887 - val_loss: 0.0485 - val_mse: 0.0485 - val_mae: 0.2180\n",
      "Epoch 2/180\n",
      "65/65 [==============================] - 57s 883ms/step - loss: 0.0749 - mse: 0.0749 - mae: 0.2173 - val_loss: 0.0215 - val_mse: 0.0215 - val_mae: 0.1442\n",
      "Epoch 3/180\n",
      "65/65 [==============================] - 57s 878ms/step - loss: 0.0301 - mse: 0.0301 - mae: 0.1382 - val_loss: 0.0037 - val_mse: 0.0037 - val_mae: 0.0503\n",
      "Epoch 4/180\n",
      "65/65 [==============================] - 54s 828ms/step - loss: 0.0101 - mse: 0.0101 - mae: 0.0786 - val_loss: 0.0023 - val_mse: 0.0023 - val_mae: 0.0431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/180\n",
      "65/65 [==============================] - 60s 917ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0508 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0178\n",
      "Epoch 6/180\n",
      "65/65 [==============================] - 55s 841ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0345 - val_loss: 0.0017 - val_mse: 0.0017 - val_mae: 0.0251\n",
      "Epoch 7/180\n",
      "65/65 [==============================] - 55s 843ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0259 - val_loss: 0.0014 - val_mse: 0.0014 - val_mae: 0.0197\n",
      "Epoch 8/180\n",
      "65/65 [==============================] - 60s 925ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0216 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0170\n",
      "Epoch 9/180\n",
      "65/65 [==============================] - 61s 939ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0200 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0164\n",
      "Epoch 10/180\n",
      "65/65 [==============================] - 57s 883ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0192 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0164\n",
      "Epoch 11/180\n",
      "65/65 [==============================] - 54s 829ms/step - loss: 9.9334e-04 - mse: 9.9334e-04 - mae: 0.0190 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0161\n",
      "Epoch 12/180\n",
      "65/65 [==============================] - 56s 867ms/step - loss: 9.7592e-04 - mse: 9.7592e-04 - mae: 0.0186 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 13/180\n",
      "65/65 [==============================] - 59s 912ms/step - loss: 9.5946e-04 - mse: 9.5946e-04 - mae: 0.0184 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0165\n",
      "Epoch 14/180\n",
      "65/65 [==============================] - 56s 869ms/step - loss: 9.5102e-04 - mse: 9.5102e-04 - mae: 0.0183 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0170\n",
      "Epoch 15/180\n",
      "65/65 [==============================] - 57s 882ms/step - loss: 9.3996e-04 - mse: 9.3996e-04 - mae: 0.0181 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0173\n",
      "Epoch 16/180\n",
      "65/65 [==============================] - 57s 871ms/step - loss: 9.3582e-04 - mse: 9.3582e-04 - mae: 0.0180 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0172\n",
      "Epoch 17/180\n",
      "65/65 [==============================] - 59s 903ms/step - loss: 9.2971e-04 - mse: 9.2971e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0175\n",
      "Epoch 18/180\n",
      "65/65 [==============================] - 62s 949ms/step - loss: 9.3123e-04 - mse: 9.3123e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0175\n",
      "Epoch 19/180\n",
      "65/65 [==============================] - 60s 931ms/step - loss: 9.2164e-04 - mse: 9.2164e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0177\n",
      "Epoch 20/180\n",
      "65/65 [==============================] - 54s 832ms/step - loss: 9.2233e-04 - mse: 9.2233e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0174\n",
      "Epoch 21/180\n",
      "65/65 [==============================] - 55s 842ms/step - loss: 9.1866e-04 - mse: 9.1866e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0177\n",
      "Epoch 22/180\n",
      "65/65 [==============================] - 51s 786ms/step - loss: 9.1852e-04 - mse: 9.1852e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0175\n",
      "Epoch 23/180\n",
      "65/65 [==============================] - 53s 821ms/step - loss: 9.1870e-04 - mse: 9.1870e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0177\n",
      "Epoch 24/180\n",
      "65/65 [==============================] - 50s 775ms/step - loss: 9.1473e-04 - mse: 9.1473e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0178\n",
      "Epoch 25/180\n",
      "65/65 [==============================] - 51s 786ms/step - loss: 9.1609e-04 - mse: 9.1609e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0178\n",
      "Epoch 26/180\n",
      "65/65 [==============================] - 53s 813ms/step - loss: 9.1463e-04 - mse: 9.1463e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0178\n",
      "Epoch 27/180\n",
      "65/65 [==============================] - 53s 813ms/step - loss: 9.1311e-04 - mse: 9.1311e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0180\n",
      "Epoch 28/180\n",
      "65/65 [==============================] - 54s 828ms/step - loss: 9.1334e-04 - mse: 9.1334e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0180\n",
      "Epoch 29/180\n",
      "65/65 [==============================] - 53s 808ms/step - loss: 9.1360e-04 - mse: 9.1360e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0181\n",
      "Epoch 30/180\n",
      "65/65 [==============================] - 52s 796ms/step - loss: 9.1128e-04 - mse: 9.1128e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0184\n",
      "Epoch 31/180\n",
      "65/65 [==============================] - 51s 779ms/step - loss: 9.1055e-04 - mse: 9.1055e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0184\n",
      "Epoch 32/180\n",
      "65/65 [==============================] - 52s 802ms/step - loss: 9.1157e-04 - mse: 9.1157e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 33/180\n",
      "65/65 [==============================] - 54s 837ms/step - loss: 9.1153e-04 - mse: 9.1153e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0188\n",
      "Epoch 34/180\n",
      "65/65 [==============================] - 55s 844ms/step - loss: 9.1144e-04 - mse: 9.1144e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 35/180\n",
      "65/65 [==============================] - 52s 793ms/step - loss: 9.1120e-04 - mse: 9.1120e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 36/180\n",
      "65/65 [==============================] - 51s 780ms/step - loss: 9.1178e-04 - mse: 9.1178e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 37/180\n",
      "65/65 [==============================] - 51s 792ms/step - loss: 9.1126e-04 - mse: 9.1126e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0187\n",
      "Epoch 38/180\n",
      "65/65 [==============================] - 51s 778ms/step - loss: 9.1024e-04 - mse: 9.1024e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0187\n",
      "Epoch 39/180\n",
      "65/65 [==============================] - 51s 782ms/step - loss: 9.0986e-04 - mse: 9.0986e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0187\n",
      "Epoch 40/180\n",
      "65/65 [==============================] - 49s 748ms/step - loss: 9.1107e-04 - mse: 9.1107e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0187\n",
      "Epoch 41/180\n",
      "65/65 [==============================] - 51s 787ms/step - loss: 9.1197e-04 - mse: 9.1197e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0188\n",
      "Epoch 42/180\n",
      "65/65 [==============================] - 52s 793ms/step - loss: 9.1066e-04 - mse: 9.1066e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0188\n",
      "Epoch 43/180\n",
      "65/65 [==============================] - 54s 823ms/step - loss: 9.1058e-04 - mse: 9.1058e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0188\n",
      "Epoch 44/180\n",
      "65/65 [==============================] - 52s 793ms/step - loss: 9.1009e-04 - mse: 9.1009e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0187\n",
      "Epoch 45/180\n",
      "65/65 [==============================] - 52s 795ms/step - loss: 9.1126e-04 - mse: 9.1126e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0188\n",
      "Epoch 46/180\n",
      "65/65 [==============================] - 51s 790ms/step - loss: 9.1050e-04 - mse: 9.1050e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0188\n",
      "Epoch 47/180\n",
      "65/65 [==============================] - 51s 781ms/step - loss: 9.1224e-04 - mse: 9.1224e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0188\n",
      "Epoch 48/180\n",
      "65/65 [==============================] - 53s 812ms/step - loss: 9.1131e-04 - mse: 9.1131e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0188\n",
      "Epoch 49/180\n",
      "65/65 [==============================] - 57s 882ms/step - loss: 9.1198e-04 - mse: 9.1198e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0189\n",
      "Epoch 50/180\n",
      "65/65 [==============================] - 55s 852ms/step - loss: 9.1024e-04 - mse: 9.1024e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0190\n",
      "Epoch 51/180\n",
      "65/65 [==============================] - 55s 848ms/step - loss: 9.1051e-04 - mse: 9.1051e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0189\n",
      "Epoch 52/180\n",
      "65/65 [==============================] - 46s 715ms/step - loss: 9.1098e-04 - mse: 9.1098e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0189\n",
      "Epoch 53/180\n",
      "65/65 [==============================] - 46s 713ms/step - loss: 9.1158e-04 - mse: 9.1158e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 54/180\n",
      "65/65 [==============================] - 47s 720ms/step - loss: 9.1025e-04 - mse: 9.1025e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 55/180\n",
      "65/65 [==============================] - 47s 727ms/step - loss: 9.1125e-04 - mse: 9.1125e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0184\n",
      "Epoch 56/180\n",
      "65/65 [==============================] - 48s 735ms/step - loss: 9.1158e-04 - mse: 9.1158e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0189\n",
      "Epoch 57/180\n",
      "65/65 [==============================] - 47s 730ms/step - loss: 9.0927e-04 - mse: 9.0927e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 58/180\n",
      "65/65 [==============================] - 48s 735ms/step - loss: 9.0989e-04 - mse: 9.0989e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0187\n",
      "Epoch 59/180\n",
      "65/65 [==============================] - 48s 737ms/step - loss: 9.0968e-04 - mse: 9.0968e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 60/180\n",
      "65/65 [==============================] - 47s 728ms/step - loss: 9.1112e-04 - mse: 9.1112e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 61/180\n",
      "65/65 [==============================] - 47s 719ms/step - loss: 9.1041e-04 - mse: 9.1041e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0187\n",
      "Epoch 62/180\n",
      "65/65 [==============================] - 47s 725ms/step - loss: 9.1085e-04 - mse: 9.1085e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 63/180\n",
      "65/65 [==============================] - 48s 743ms/step - loss: 9.1055e-04 - mse: 9.1055e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0187\n",
      "Epoch 64/180\n",
      "65/65 [==============================] - 47s 717ms/step - loss: 9.0894e-04 - mse: 9.0894e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0187\n",
      "Epoch 65/180\n",
      "65/65 [==============================] - 47s 725ms/step - loss: 9.1112e-04 - mse: 9.1112e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 66/180\n",
      "65/65 [==============================] - 46s 715ms/step - loss: 9.1037e-04 - mse: 9.1037e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0187\n",
      "Epoch 67/180\n",
      "65/65 [==============================] - 46s 711ms/step - loss: 9.1051e-04 - mse: 9.1051e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0187\n",
      "Epoch 68/180\n",
      "65/65 [==============================] - 46s 711ms/step - loss: 9.1096e-04 - mse: 9.1096e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0187\n",
      "Epoch 69/180\n",
      "65/65 [==============================] - 45s 695ms/step - loss: 9.1059e-04 - mse: 9.1059e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0187\n",
      "Epoch 70/180\n",
      "65/65 [==============================] - 48s 734ms/step - loss: 9.1084e-04 - mse: 9.1084e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 71/180\n",
      "65/65 [==============================] - 46s 710ms/step - loss: 9.0930e-04 - mse: 9.0930e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0188\n",
      "Epoch 72/180\n",
      "65/65 [==============================] - 46s 715ms/step - loss: 9.1062e-04 - mse: 9.1062e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 73/180\n",
      "65/65 [==============================] - 46s 706ms/step - loss: 9.0813e-04 - mse: 9.0813e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 74/180\n",
      "65/65 [==============================] - 47s 723ms/step - loss: 9.1075e-04 - mse: 9.1075e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 75/180\n",
      "65/65 [==============================] - 46s 706ms/step - loss: 9.0824e-04 - mse: 9.0824e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 76/180\n",
      "65/65 [==============================] - 46s 708ms/step - loss: 9.1045e-04 - mse: 9.1045e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 77/180\n",
      "65/65 [==============================] - 46s 710ms/step - loss: 9.0980e-04 - mse: 9.0980e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 78/180\n",
      "65/65 [==============================] - 48s 732ms/step - loss: 9.0855e-04 - mse: 9.0855e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0187\n",
      "Epoch 79/180\n",
      "65/65 [==============================] - 46s 702ms/step - loss: 9.0883e-04 - mse: 9.0883e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0184\n",
      "Epoch 80/180\n",
      "65/65 [==============================] - 45s 694ms/step - loss: 9.1073e-04 - mse: 9.1073e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0184\n",
      "Epoch 81/180\n",
      "65/65 [==============================] - 45s 692ms/step - loss: 9.1041e-04 - mse: 9.1041e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0187\n",
      "Epoch 82/180\n",
      "65/65 [==============================] - 45s 699ms/step - loss: 9.0832e-04 - mse: 9.0832e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 83/180\n",
      "65/65 [==============================] - 45s 686ms/step - loss: 9.0706e-04 - mse: 9.0706e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0184\n",
      "Epoch 84/180\n",
      "65/65 [==============================] - 45s 688ms/step - loss: 9.0679e-04 - mse: 9.0679e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0184\n",
      "Epoch 85/180\n",
      "65/65 [==============================] - 46s 704ms/step - loss: 9.0753e-04 - mse: 9.0753e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0184\n",
      "Epoch 86/180\n",
      "65/65 [==============================] - 47s 730ms/step - loss: 9.0526e-04 - mse: 9.0526e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 87/180\n",
      "65/65 [==============================] - 47s 720ms/step - loss: 9.0710e-04 - mse: 9.0710e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0184\n",
      "Epoch 88/180\n",
      "65/65 [==============================] - 46s 714ms/step - loss: 9.0447e-04 - mse: 9.0447e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0184\n",
      "Epoch 89/180\n",
      "65/65 [==============================] - 47s 729ms/step - loss: 9.0615e-04 - mse: 9.0615e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0184\n",
      "Epoch 90/180\n",
      "65/65 [==============================] - 46s 707ms/step - loss: 9.0659e-04 - mse: 9.0659e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0184\n",
      "Epoch 91/180\n",
      "65/65 [==============================] - 46s 710ms/step - loss: 9.0477e-04 - mse: 9.0477e-04 - mae: 0.0175 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0184\n",
      "Epoch 92/180\n",
      "65/65 [==============================] - 46s 703ms/step - loss: 9.0714e-04 - mse: 9.0714e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0183\n",
      "Epoch 93/180\n",
      "65/65 [==============================] - 47s 721ms/step - loss: 9.0511e-04 - mse: 9.0511e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0184\n",
      "Epoch 94/180\n",
      "65/65 [==============================] - 46s 706ms/step - loss: 9.0331e-04 - mse: 9.0331e-04 - mae: 0.0175 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0184\n",
      "Epoch 95/180\n",
      "65/65 [==============================] - 45s 695ms/step - loss: 9.0555e-04 - mse: 9.0555e-04 - mae: 0.0175 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0184\n",
      "Epoch 96/180\n",
      "65/65 [==============================] - 45s 699ms/step - loss: 9.0548e-04 - mse: 9.0548e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0183\n",
      "Epoch 97/180\n",
      "65/65 [==============================] - 44s 684ms/step - loss: 9.0197e-04 - mse: 9.0197e-04 - mae: 0.0175 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0182\n",
      "Epoch 98/180\n",
      "65/65 [==============================] - 46s 705ms/step - loss: 9.0610e-04 - mse: 9.0610e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/180\n",
      "65/65 [==============================] - 45s 700ms/step - loss: 9.0642e-04 - mse: 9.0642e-04 - mae: 0.0175 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0182\n",
      "Epoch 100/180\n",
      "65/65 [==============================] - 45s 698ms/step - loss: 9.0377e-04 - mse: 9.0377e-04 - mae: 0.0175 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0182\n",
      "Epoch 101/180\n",
      "65/65 [==============================] - 47s 718ms/step - loss: 9.0184e-04 - mse: 9.0184e-04 - mae: 0.0175 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0182\n",
      "Epoch 102/180\n",
      "65/65 [==============================] - 46s 700ms/step - loss: 9.0319e-04 - mse: 9.0319e-04 - mae: 0.0175 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0183\n",
      "Epoch 103/180\n",
      "65/65 [==============================] - 46s 704ms/step - loss: 8.9946e-04 - mse: 8.9946e-04 - mae: 0.0175 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0181\n",
      "Epoch 104/180\n",
      "65/65 [==============================] - 46s 711ms/step - loss: 9.0155e-04 - mse: 9.0155e-04 - mae: 0.0175 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0183\n",
      "Epoch 105/180\n",
      "65/65 [==============================] - 45s 694ms/step - loss: 9.0081e-04 - mse: 9.0081e-04 - mae: 0.0175 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0182\n",
      "Epoch 106/180\n",
      "65/65 [==============================] - 45s 693ms/step - loss: 9.0028e-04 - mse: 9.0028e-04 - mae: 0.0175 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0180\n",
      "Epoch 107/180\n",
      "65/65 [==============================] - 45s 694ms/step - loss: 8.9768e-04 - mse: 8.9768e-04 - mae: 0.0175 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0181\n",
      "Epoch 108/180\n",
      "65/65 [==============================] - 45s 697ms/step - loss: 8.9900e-04 - mse: 8.9900e-04 - mae: 0.0175 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0181\n",
      "Epoch 109/180\n",
      "65/65 [==============================] - 46s 705ms/step - loss: 9.0046e-04 - mse: 9.0046e-04 - mae: 0.0175 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0181\n",
      "Epoch 110/180\n",
      "65/65 [==============================] - 46s 701ms/step - loss: 9.0124e-04 - mse: 9.0124e-04 - mae: 0.0175 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0181\n",
      "Epoch 111/180\n",
      "65/65 [==============================] - 45s 690ms/step - loss: 8.9908e-04 - mse: 8.9908e-04 - mae: 0.0174 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0178\n",
      "Epoch 112/180\n",
      "65/65 [==============================] - 45s 693ms/step - loss: 8.9753e-04 - mse: 8.9753e-04 - mae: 0.0174 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0181\n",
      "Epoch 113/180\n",
      "65/65 [==============================] - 45s 697ms/step - loss: 8.9930e-04 - mse: 8.9930e-04 - mae: 0.0174 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0179\n",
      "Epoch 114/180\n",
      "65/65 [==============================] - 44s 682ms/step - loss: 8.9774e-04 - mse: 8.9774e-04 - mae: 0.0174 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0178\n",
      "Epoch 115/180\n",
      "65/65 [==============================] - 46s 702ms/step - loss: 8.9523e-04 - mse: 8.9523e-04 - mae: 0.0174 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0177\n",
      "Epoch 116/180\n",
      "65/65 [==============================] - 46s 703ms/step - loss: 8.9464e-04 - mse: 8.9464e-04 - mae: 0.0173 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0176\n",
      "Epoch 117/180\n",
      "65/65 [==============================] - 46s 702ms/step - loss: 8.9522e-04 - mse: 8.9522e-04 - mae: 0.0174 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0177\n",
      "Epoch 118/180\n",
      "65/65 [==============================] - 45s 692ms/step - loss: 8.9336e-04 - mse: 8.9336e-04 - mae: 0.0173 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0178\n",
      "Epoch 119/180\n",
      "65/65 [==============================] - 44s 681ms/step - loss: 8.8755e-04 - mse: 8.8755e-04 - mae: 0.0172 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0175\n",
      "Epoch 120/180\n",
      "65/65 [==============================] - 44s 681ms/step - loss: 8.8905e-04 - mse: 8.8905e-04 - mae: 0.0172 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0175\n",
      "Epoch 121/180\n",
      "65/65 [==============================] - 44s 682ms/step - loss: 8.9568e-04 - mse: 8.9568e-04 - mae: 0.0173 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0179\n",
      "Epoch 122/180\n",
      "65/65 [==============================] - 44s 674ms/step - loss: 8.9167e-04 - mse: 8.9167e-04 - mae: 0.0173 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0179\n",
      "Epoch 123/180\n",
      "65/65 [==============================] - 44s 682ms/step - loss: 8.9199e-04 - mse: 8.9199e-04 - mae: 0.0173 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0174\n",
      "Epoch 124/180\n",
      "65/65 [==============================] - 45s 693ms/step - loss: 8.9269e-04 - mse: 8.9269e-04 - mae: 0.0173 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0175\n",
      "Epoch 125/180\n",
      "65/65 [==============================] - 46s 709ms/step - loss: 8.8994e-04 - mse: 8.8994e-04 - mae: 0.0172 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0177\n",
      "Epoch 126/180\n",
      "65/65 [==============================] - 46s 703ms/step - loss: 8.8989e-04 - mse: 8.8989e-04 - mae: 0.0173 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0177\n",
      "Epoch 127/180\n",
      "65/65 [==============================] - 46s 702ms/step - loss: 8.9215e-04 - mse: 8.9215e-04 - mae: 0.0173 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0178\n",
      "Epoch 128/180\n",
      "65/65 [==============================] - 45s 695ms/step - loss: 8.8865e-04 - mse: 8.8865e-04 - mae: 0.0173 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0172\n",
      "Epoch 129/180\n",
      "65/65 [==============================] - 45s 697ms/step - loss: 8.8918e-04 - mse: 8.8918e-04 - mae: 0.0172 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0171\n",
      "Epoch 130/180\n",
      "65/65 [==============================] - 45s 695ms/step - loss: 8.8402e-04 - mse: 8.8402e-04 - mae: 0.0171 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0176\n",
      "Epoch 131/180\n",
      "65/65 [==============================] - 45s 695ms/step - loss: 8.8918e-04 - mse: 8.8918e-04 - mae: 0.0173 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0175\n",
      "Epoch 132/180\n",
      "65/65 [==============================] - 46s 705ms/step - loss: 8.9410e-04 - mse: 8.9410e-04 - mae: 0.0172 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0176\n",
      "Epoch 133/180\n",
      "65/65 [==============================] - 46s 711ms/step - loss: 8.8298e-04 - mse: 8.8298e-04 - mae: 0.0171 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0176\n",
      "Epoch 134/180\n",
      "65/65 [==============================] - 48s 734ms/step - loss: 8.8682e-04 - mse: 8.8682e-04 - mae: 0.0172 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0176\n",
      "Epoch 135/180\n",
      "65/65 [==============================] - 46s 710ms/step - loss: 8.9627e-04 - mse: 8.9627e-04 - mae: 0.0174 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0180\n",
      "Epoch 136/180\n",
      "65/65 [==============================] - 46s 705ms/step - loss: 8.9628e-04 - mse: 8.9628e-04 - mae: 0.0173 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0177\n",
      "Epoch 137/180\n",
      "65/65 [==============================] - 49s 747ms/step - loss: 8.9657e-04 - mse: 8.9657e-04 - mae: 0.0174 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0179\n",
      "Epoch 138/180\n",
      "65/65 [==============================] - 47s 728ms/step - loss: 8.9468e-04 - mse: 8.9468e-04 - mae: 0.0174 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0178\n",
      "Epoch 139/180\n",
      "65/65 [==============================] - 44s 677ms/step - loss: 8.9056e-04 - mse: 8.9056e-04 - mae: 0.0173 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0176\n",
      "Epoch 140/180\n",
      "65/65 [==============================] - 44s 681ms/step - loss: 8.8886e-04 - mse: 8.8886e-04 - mae: 0.0173 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0179\n",
      "Epoch 141/180\n",
      "65/65 [==============================] - 44s 670ms/step - loss: 8.8985e-04 - mse: 8.8985e-04 - mae: 0.0173 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0178\n",
      "Epoch 142/180\n",
      "65/65 [==============================] - 43s 664ms/step - loss: 8.8951e-04 - mse: 8.8951e-04 - mae: 0.0173 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0177\n",
      "Epoch 143/180\n",
      "65/65 [==============================] - 43s 657ms/step - loss: 8.8861e-04 - mse: 8.8861e-04 - mae: 0.0172 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0173\n",
      "Epoch 144/180\n",
      "65/65 [==============================] - 44s 677ms/step - loss: 8.8855e-04 - mse: 8.8855e-04 - mae: 0.0172 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0173\n",
      "Epoch 145/180\n",
      "65/65 [==============================] - 43s 668ms/step - loss: 8.8774e-04 - mse: 8.8774e-04 - mae: 0.0172 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0177\n",
      "Epoch 146/180\n",
      "65/65 [==============================] - 52s 800ms/step - loss: 8.8781e-04 - mse: 8.8781e-04 - mae: 0.0172 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0175\n",
      "Epoch 147/180\n",
      "65/65 [==============================] - 48s 734ms/step - loss: 8.8028e-04 - mse: 8.8028e-04 - mae: 0.0171 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0174\n",
      "Epoch 148/180\n",
      "65/65 [==============================] - 47s 719ms/step - loss: 8.8617e-04 - mse: 8.8617e-04 - mae: 0.0172 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0174\n",
      "Epoch 149/180\n",
      "65/65 [==============================] - 49s 752ms/step - loss: 8.8496e-04 - mse: 8.8496e-04 - mae: 0.0172 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0175\n",
      "Epoch 150/180\n",
      "65/65 [==============================] - 47s 721ms/step - loss: 8.8626e-04 - mse: 8.8626e-04 - mae: 0.0172 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0173\n",
      "Epoch 151/180\n",
      "65/65 [==============================] - 46s 711ms/step - loss: 8.9071e-04 - mse: 8.9071e-04 - mae: 0.0172 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0180\n",
      "Epoch 152/180\n",
      "65/65 [==============================] - 47s 728ms/step - loss: 8.8304e-04 - mse: 8.8304e-04 - mae: 0.0170 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0174\n",
      "Epoch 153/180\n",
      "65/65 [==============================] - 47s 728ms/step - loss: 8.8192e-04 - mse: 8.8192e-04 - mae: 0.0172 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0174\n",
      "Epoch 154/180\n",
      "65/65 [==============================] - 44s 676ms/step - loss: 8.8108e-04 - mse: 8.8108e-04 - mae: 0.0171 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0174\n",
      "Epoch 155/180\n",
      "65/65 [==============================] - 45s 700ms/step - loss: 8.7606e-04 - mse: 8.7606e-04 - mae: 0.0170 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0174\n",
      "Epoch 156/180\n",
      "65/65 [==============================] - 46s 701ms/step - loss: 8.7913e-04 - mse: 8.7913e-04 - mae: 0.0171 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0171\n",
      "Epoch 157/180\n",
      "65/65 [==============================] - 45s 690ms/step - loss: 8.8312e-04 - mse: 8.8312e-04 - mae: 0.0171 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0177\n",
      "Epoch 158/180\n",
      "65/65 [==============================] - 44s 684ms/step - loss: 8.8131e-04 - mse: 8.8131e-04 - mae: 0.0171 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0174\n",
      "Epoch 159/180\n",
      "65/65 [==============================] - 45s 685ms/step - loss: 8.8176e-04 - mse: 8.8176e-04 - mae: 0.0171 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0176\n",
      "Epoch 160/180\n",
      "65/65 [==============================] - 45s 691ms/step - loss: 8.8057e-04 - mse: 8.8057e-04 - mae: 0.0171 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0169\n",
      "Epoch 161/180\n",
      "65/65 [==============================] - 45s 689ms/step - loss: 8.8078e-04 - mse: 8.8078e-04 - mae: 0.0171 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0173\n",
      "Epoch 162/180\n",
      "65/65 [==============================] - 44s 682ms/step - loss: 8.7864e-04 - mse: 8.7864e-04 - mae: 0.0170 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0176\n",
      "Epoch 163/180\n",
      "65/65 [==============================] - 46s 701ms/step - loss: 8.7925e-04 - mse: 8.7925e-04 - mae: 0.0170 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0173\n",
      "Epoch 164/180\n",
      "65/65 [==============================] - 44s 682ms/step - loss: 8.7761e-04 - mse: 8.7761e-04 - mae: 0.0171 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0177\n",
      "Epoch 165/180\n",
      "65/65 [==============================] - 45s 698ms/step - loss: 8.8187e-04 - mse: 8.8187e-04 - mae: 0.0171 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0174\n",
      "Epoch 166/180\n",
      "65/65 [==============================] - 44s 684ms/step - loss: 8.7488e-04 - mse: 8.7488e-04 - mae: 0.0169 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0169\n",
      "Epoch 167/180\n",
      "65/65 [==============================] - 45s 693ms/step - loss: 8.7639e-04 - mse: 8.7639e-04 - mae: 0.0170 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0171\n",
      "Epoch 168/180\n",
      "65/65 [==============================] - 45s 692ms/step - loss: 8.6988e-04 - mse: 8.6988e-04 - mae: 0.0170 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0165\n",
      "Epoch 169/180\n",
      "65/65 [==============================] - 46s 712ms/step - loss: 8.7137e-04 - mse: 8.7137e-04 - mae: 0.0169 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0174\n",
      "Epoch 170/180\n",
      "65/65 [==============================] - 44s 682ms/step - loss: 8.6430e-04 - mse: 8.6430e-04 - mae: 0.0168 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0170\n",
      "Epoch 171/180\n",
      "65/65 [==============================] - 45s 689ms/step - loss: 8.7455e-04 - mse: 8.7455e-04 - mae: 0.0170 - val_loss: 9.9998e-04 - val_mse: 9.9998e-04 - val_mae: 0.0171\n",
      "Epoch 172/180\n",
      "65/65 [==============================] - 44s 683ms/step - loss: 8.6697e-04 - mse: 8.6697e-04 - mae: 0.0169 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0173\n",
      "Epoch 173/180\n",
      "65/65 [==============================] - 44s 673ms/step - loss: 8.7131e-04 - mse: 8.7131e-04 - mae: 0.0168 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0173\n",
      "Epoch 174/180\n",
      "65/65 [==============================] - 44s 670ms/step - loss: 8.7694e-04 - mse: 8.7694e-04 - mae: 0.0170 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0170\n",
      "Epoch 175/180\n",
      "65/65 [==============================] - 43s 668ms/step - loss: 8.6478e-04 - mse: 8.6478e-04 - mae: 0.0169 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0172\n",
      "Epoch 176/180\n",
      "65/65 [==============================] - 43s 656ms/step - loss: 8.7224e-04 - mse: 8.7224e-04 - mae: 0.0169 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0174\n",
      "Epoch 177/180\n",
      "65/65 [==============================] - 43s 668ms/step - loss: 8.7202e-04 - mse: 8.7202e-04 - mae: 0.0169 - val_loss: 9.7378e-04 - val_mse: 9.7378e-04 - val_mae: 0.0168\n",
      "Epoch 178/180\n",
      "65/65 [==============================] - 43s 662ms/step - loss: 8.7173e-04 - mse: 8.7173e-04 - mae: 0.0170 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0172\n",
      "Epoch 179/180\n",
      "65/65 [==============================] - 44s 681ms/step - loss: 8.6478e-04 - mse: 8.6478e-04 - mae: 0.0168 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0168\n",
      "Epoch 180/180\n",
      "65/65 [==============================] - 44s 676ms/step - loss: 8.6812e-04 - mse: 8.6812e-04 - mae: 0.0168 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0173\n",
      "Epoch 1/180\n",
      "65/65 [==============================] - 50s 769ms/step - loss: 1.2775 - mse: 1.2775 - mae: 0.3310 - val_loss: 0.0273 - val_mse: 0.0273 - val_mae: 0.1632\n",
      "Epoch 2/180\n",
      "65/65 [==============================] - 47s 724ms/step - loss: 0.0052 - mse: 0.0052 - mae: 0.0532 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0238\n",
      "Epoch 3/180\n",
      "65/65 [==============================] - 46s 706ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0243 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0161\n",
      "Epoch 4/180\n",
      "65/65 [==============================] - 46s 711ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0198 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0164\n",
      "Epoch 5/180\n",
      "65/65 [==============================] - 46s 709ms/step - loss: 9.6116e-04 - mse: 9.6116e-04 - mae: 0.0185 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0164\n",
      "Epoch 6/180\n",
      "65/65 [==============================] - 46s 713ms/step - loss: 9.3895e-04 - mse: 9.3895e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 7/180\n",
      "65/65 [==============================] - 47s 718ms/step - loss: 9.3916e-04 - mse: 9.3916e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 8/180\n",
      "65/65 [==============================] - 46s 711ms/step - loss: 9.3914e-04 - mse: 9.3914e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 9/180\n",
      "65/65 [==============================] - 46s 712ms/step - loss: 9.3912e-04 - mse: 9.3912e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 10/180\n",
      "65/65 [==============================] - 47s 718ms/step - loss: 9.3910e-04 - mse: 9.3910e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 11/180\n",
      "65/65 [==============================] - 46s 715ms/step - loss: 9.3911e-04 - mse: 9.3911e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/180\n",
      "65/65 [==============================] - 46s 711ms/step - loss: 9.3911e-04 - mse: 9.3911e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 13/180\n",
      "65/65 [==============================] - 47s 717ms/step - loss: 9.3911e-04 - mse: 9.3911e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 14/180\n",
      "65/65 [==============================] - 48s 740ms/step - loss: 9.3910e-04 - mse: 9.3910e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 15/180\n",
      "65/65 [==============================] - 46s 709ms/step - loss: 9.3910e-04 - mse: 9.3910e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 16/180\n",
      "65/65 [==============================] - 48s 736ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 17/180\n",
      "65/65 [==============================] - 49s 759ms/step - loss: 9.3910e-04 - mse: 9.3910e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 18/180\n",
      "65/65 [==============================] - 51s 781ms/step - loss: 9.3910e-04 - mse: 9.3910e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 19/180\n",
      "65/65 [==============================] - 46s 714ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 20/180\n",
      "65/65 [==============================] - 47s 724ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 21/180\n",
      "65/65 [==============================] - 48s 737ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 22/180\n",
      "65/65 [==============================] - 48s 740ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 23/180\n",
      "65/65 [==============================] - 49s 754ms/step - loss: 9.3910e-04 - mse: 9.3910e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 24/180\n",
      "65/65 [==============================] - 52s 795ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 25/180\n",
      "65/65 [==============================] - 50s 774ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 26/180\n",
      "65/65 [==============================] - 50s 767ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 27/180\n",
      "65/65 [==============================] - 50s 762ms/step - loss: 9.3908e-04 - mse: 9.3908e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 28/180\n",
      "65/65 [==============================] - 49s 754ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 29/180\n",
      "65/65 [==============================] - 51s 780ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 30/180\n",
      "65/65 [==============================] - 49s 761ms/step - loss: 9.3910e-04 - mse: 9.3910e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 31/180\n",
      "65/65 [==============================] - 50s 766ms/step - loss: 9.3910e-04 - mse: 9.3910e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 32/180\n",
      "65/65 [==============================] - 49s 751ms/step - loss: 9.3910e-04 - mse: 9.3910e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 33/180\n",
      "65/65 [==============================] - 49s 754ms/step - loss: 9.3911e-04 - mse: 9.3911e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 34/180\n",
      "65/65 [==============================] - 50s 762ms/step - loss: 9.3910e-04 - mse: 9.3910e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 35/180\n",
      "65/65 [==============================] - 50s 765ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 36/180\n",
      "65/65 [==============================] - 50s 775ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 37/180\n",
      "65/65 [==============================] - 48s 742ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 38/180\n",
      "65/65 [==============================] - 49s 751ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 39/180\n",
      "65/65 [==============================] - 50s 774ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 40/180\n",
      "65/65 [==============================] - 49s 748ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 41/180\n",
      "65/65 [==============================] - 49s 747ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 42/180\n",
      "65/65 [==============================] - 48s 733ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 43/180\n",
      "65/65 [==============================] - 50s 775ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 44/180\n",
      "65/65 [==============================] - 47s 728ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 45/180\n",
      "65/65 [==============================] - 48s 735ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 46/180\n",
      "65/65 [==============================] - 48s 736ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 47/180\n",
      "65/65 [==============================] - 48s 738ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 48/180\n",
      "65/65 [==============================] - 48s 738ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 49/180\n",
      "65/65 [==============================] - 49s 753ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 50/180\n",
      "65/65 [==============================] - 48s 741ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 51/180\n",
      "65/65 [==============================] - 49s 755ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 52/180\n",
      "65/65 [==============================] - 48s 743ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 53/180\n",
      "65/65 [==============================] - 49s 748ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 54/180\n",
      "65/65 [==============================] - 48s 741ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 55/180\n",
      "65/65 [==============================] - 48s 746ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 56/180\n",
      "65/65 [==============================] - 48s 745ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 57/180\n",
      "65/65 [==============================] - 49s 746ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 58/180\n",
      "65/65 [==============================] - 51s 789ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/180\n",
      "65/65 [==============================] - 51s 781ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 60/180\n",
      "65/65 [==============================] - 49s 759ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 61/180\n",
      "65/65 [==============================] - 50s 769ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 62/180\n",
      "65/65 [==============================] - 50s 766ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 63/180\n",
      "65/65 [==============================] - 49s 757ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 64/180\n",
      "65/65 [==============================] - 49s 761ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 65/180\n",
      "65/65 [==============================] - 50s 775ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 66/180\n",
      "65/65 [==============================] - 50s 771ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 67/180\n",
      "65/65 [==============================] - 50s 773ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 68/180\n",
      "65/65 [==============================] - 50s 770ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 69/180\n",
      "65/65 [==============================] - 49s 753ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 70/180\n",
      "65/65 [==============================] - 49s 758ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 71/180\n",
      "65/65 [==============================] - 49s 759ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 72/180\n",
      "65/65 [==============================] - 51s 779ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 73/180\n",
      "65/65 [==============================] - 50s 769ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 74/180\n",
      "65/65 [==============================] - 49s 756ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 75/180\n",
      "65/65 [==============================] - 50s 770ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 76/180\n",
      "65/65 [==============================] - 50s 764ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 77/180\n",
      "65/65 [==============================] - 51s 777ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 78/180\n",
      "65/65 [==============================] - 49s 757ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 79/180\n",
      "65/65 [==============================] - 50s 773ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 80/180\n",
      "65/65 [==============================] - 50s 770ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 81/180\n",
      "65/65 [==============================] - 49s 755ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 82/180\n",
      "65/65 [==============================] - 50s 766ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 83/180\n",
      "65/65 [==============================] - 50s 768ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 84/180\n",
      "65/65 [==============================] - 50s 771ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 85/180\n",
      "65/65 [==============================] - 50s 767ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 86/180\n",
      "65/65 [==============================] - 51s 783ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 87/180\n",
      "65/65 [==============================] - 50s 770ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 88/180\n",
      "65/65 [==============================] - 50s 764ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 89/180\n",
      "65/65 [==============================] - 50s 774ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 90/180\n",
      "65/65 [==============================] - 50s 765ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 91/180\n",
      "65/65 [==============================] - 50s 770ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 92/180\n",
      "65/65 [==============================] - 49s 758ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 93/180\n",
      "65/65 [==============================] - 51s 778ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 94/180\n",
      "65/65 [==============================] - 50s 772ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 95/180\n",
      "65/65 [==============================] - 49s 758ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 96/180\n",
      "65/65 [==============================] - 49s 757ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 97/180\n",
      "65/65 [==============================] - 49s 761ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 98/180\n",
      "65/65 [==============================] - 48s 743ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 99/180\n",
      "65/65 [==============================] - 49s 753ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 100/180\n",
      "65/65 [==============================] - 50s 767ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 101/180\n",
      "65/65 [==============================] - 49s 753ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 102/180\n",
      "65/65 [==============================] - 48s 743ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 103/180\n",
      "65/65 [==============================] - 48s 744ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 104/180\n",
      "65/65 [==============================] - 48s 738ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 105/180\n",
      "65/65 [==============================] - 48s 741ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106/180\n",
      "65/65 [==============================] - 49s 754ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 107/180\n",
      "65/65 [==============================] - 49s 747ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 108/180\n",
      "65/65 [==============================] - 50s 771ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 109/180\n",
      "65/65 [==============================] - 50s 762ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 110/180\n",
      "65/65 [==============================] - 54s 833ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 111/180\n",
      "65/65 [==============================] - 50s 769ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 112/180\n",
      "65/65 [==============================] - 48s 741ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 113/180\n",
      "65/65 [==============================] - 49s 759ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 114/180\n",
      "65/65 [==============================] - 50s 773ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 115/180\n",
      "65/65 [==============================] - 50s 768ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 116/180\n",
      "65/65 [==============================] - 48s 742ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 117/180\n",
      "65/65 [==============================] - 49s 748ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 118/180\n",
      "65/65 [==============================] - 49s 752ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 119/180\n",
      "65/65 [==============================] - 49s 748ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 120/180\n",
      "65/65 [==============================] - 50s 762ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 121/180\n",
      "65/65 [==============================] - 49s 746ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 122/180\n",
      "65/65 [==============================] - 50s 769ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 123/180\n",
      "65/65 [==============================] - 49s 752ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 124/180\n",
      "65/65 [==============================] - 49s 754ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 125/180\n",
      "65/65 [==============================] - 47s 729ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 126/180\n",
      "65/65 [==============================] - 48s 742ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 127/180\n",
      "65/65 [==============================] - 48s 738ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 128/180\n",
      "65/65 [==============================] - 48s 743ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 129/180\n",
      "65/65 [==============================] - 49s 759ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 130/180\n",
      "65/65 [==============================] - 50s 772ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 131/180\n",
      "65/65 [==============================] - 50s 766ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 132/180\n",
      "65/65 [==============================] - 50s 763ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 133/180\n",
      "65/65 [==============================] - 50s 765ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 134/180\n",
      "65/65 [==============================] - 49s 746ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 135/180\n",
      "65/65 [==============================] - 49s 755ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 136/180\n",
      "65/65 [==============================] - 50s 765ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 137/180\n",
      "65/65 [==============================] - 49s 761ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 138/180\n",
      "65/65 [==============================] - 48s 739ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 139/180\n",
      "65/65 [==============================] - 48s 741ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 140/180\n",
      "65/65 [==============================] - 48s 733ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 141/180\n",
      "65/65 [==============================] - 48s 743ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 142/180\n",
      "65/65 [==============================] - 48s 736ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 143/180\n",
      "65/65 [==============================] - 48s 740ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 144/180\n",
      "65/65 [==============================] - 50s 771ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 145/180\n",
      "65/65 [==============================] - 48s 734ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 146/180\n",
      "65/65 [==============================] - 48s 737ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 147/180\n",
      "65/65 [==============================] - 48s 734ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 148/180\n",
      "65/65 [==============================] - 48s 734ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 149/180\n",
      "65/65 [==============================] - 48s 736ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 150/180\n",
      "65/65 [==============================] - 48s 734ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 151/180\n",
      "65/65 [==============================] - 50s 766ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 152/180\n",
      "65/65 [==============================] - 48s 735ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 153/180\n",
      "65/65 [==============================] - 48s 740ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 154/180\n",
      "65/65 [==============================] - 48s 746ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 155/180\n",
      "65/65 [==============================] - 48s 745ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 156/180\n",
      "65/65 [==============================] - 48s 743ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 157/180\n",
      "65/65 [==============================] - 49s 759ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 158/180\n",
      "65/65 [==============================] - 49s 757ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 159/180\n",
      "65/65 [==============================] - 49s 750ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 160/180\n",
      "65/65 [==============================] - 48s 732ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 161/180\n",
      "65/65 [==============================] - 48s 733ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 162/180\n",
      "65/65 [==============================] - 48s 736ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 163/180\n",
      "65/65 [==============================] - 48s 743ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 164/180\n",
      "65/65 [==============================] - 48s 744ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 165/180\n",
      "65/65 [==============================] - 49s 755ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 166/180\n",
      "65/65 [==============================] - 50s 765ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 167/180\n",
      "65/65 [==============================] - 50s 762ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 168/180\n",
      "65/65 [==============================] - 49s 758ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 169/180\n",
      "65/65 [==============================] - 49s 757ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 170/180\n",
      "65/65 [==============================] - 50s 774ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 171/180\n",
      "65/65 [==============================] - 50s 771ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 172/180\n",
      "65/65 [==============================] - 49s 761ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 173/180\n",
      "65/65 [==============================] - 50s 771ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 174/180\n",
      "65/65 [==============================] - 50s 775ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 175/180\n",
      "65/65 [==============================] - 50s 768ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 176/180\n",
      "65/65 [==============================] - 50s 776ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 177/180\n",
      "65/65 [==============================] - 51s 777ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 178/180\n",
      "65/65 [==============================] - 51s 781ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 179/180\n",
      "65/65 [==============================] - 50s 764ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 180/180\n",
      "65/65 [==============================] - 51s 781ms/step - loss: 9.3909e-04 - mse: 9.3909e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 1/180\n",
      "65/65 [==============================] - 56s 868ms/step - loss: 16.0243 - mse: 16.0243 - mae: 2.4766 - val_loss: 7.5464 - val_mse: 7.5464 - val_mae: 2.7469\n",
      "Epoch 2/180\n",
      "65/65 [==============================] - 52s 807ms/step - loss: 9.3867 - mse: 9.3867 - mae: 3.0366 - val_loss: 7.2108 - val_mse: 7.2108 - val_mae: 2.6851\n",
      "Epoch 3/180\n",
      "65/65 [==============================] - 53s 809ms/step - loss: 9.3016 - mse: 9.3016 - mae: 3.0273 - val_loss: 10.0682 - val_mse: 10.0682 - val_mae: 3.1729\n",
      "Epoch 4/180\n",
      "65/65 [==============================] - 53s 813ms/step - loss: 9.3259 - mse: 9.3259 - mae: 3.0388 - val_loss: 8.8796 - val_mse: 8.8796 - val_mae: 2.9797\n",
      "Epoch 5/180\n",
      "65/65 [==============================] - 53s 809ms/step - loss: 9.2866 - mse: 9.2866 - mae: 3.0309 - val_loss: 7.2769 - val_mse: 7.2769 - val_mae: 2.6974\n",
      "Epoch 6/180\n",
      "65/65 [==============================] - 54s 829ms/step - loss: 9.3188 - mse: 9.3188 - mae: 3.0390 - val_loss: 10.5499 - val_mse: 10.5499 - val_mae: 3.2479\n",
      "Epoch 7/180\n",
      "65/65 [==============================] - 54s 824ms/step - loss: 9.3305 - mse: 9.3305 - mae: 3.0414 - val_loss: 12.1512 - val_mse: 12.1512 - val_mae: 3.4857\n",
      "Epoch 8/180\n",
      "65/65 [==============================] - 54s 823ms/step - loss: 9.3965 - mse: 9.3965 - mae: 3.0438 - val_loss: 7.4141 - val_mse: 7.4141 - val_mae: 2.7227\n",
      "Epoch 9/180\n",
      "65/65 [==============================] - 53s 816ms/step - loss: 9.1782 - mse: 9.1782 - mae: 3.0119 - val_loss: 11.0598 - val_mse: 11.0598 - val_mae: 3.3255\n",
      "Epoch 10/180\n",
      "65/65 [==============================] - 53s 821ms/step - loss: 9.4289 - mse: 9.4289 - mae: 3.0562 - val_loss: 10.4434 - val_mse: 10.4434 - val_mae: 3.2315\n",
      "Epoch 11/180\n",
      "65/65 [==============================] - 54s 830ms/step - loss: 9.3011 - mse: 9.3011 - mae: 3.0335 - val_loss: 11.2357 - val_mse: 11.2357 - val_mae: 3.3518\n",
      "Epoch 12/180\n",
      "65/65 [==============================] - 53s 816ms/step - loss: 9.2768 - mse: 9.2768 - mae: 3.0260 - val_loss: 8.6322 - val_mse: 8.6322 - val_mae: 2.9379\n",
      "Epoch 13/180\n",
      "65/65 [==============================] - 53s 812ms/step - loss: 9.4489 - mse: 9.4489 - mae: 3.0596 - val_loss: 7.9283 - val_mse: 7.9283 - val_mae: 2.8155\n",
      "Epoch 14/180\n",
      "65/65 [==============================] - 53s 811ms/step - loss: 9.2639 - mse: 9.2639 - mae: 3.0280 - val_loss: 8.2986 - val_mse: 8.2986 - val_mae: 2.8805\n",
      "Epoch 15/180\n",
      "65/65 [==============================] - 52s 807ms/step - loss: 9.3442 - mse: 9.3442 - mae: 3.0447 - val_loss: 8.0287 - val_mse: 8.0287 - val_mae: 2.8333\n",
      "Epoch 16/180\n",
      "65/65 [==============================] - 52s 801ms/step - loss: 9.2767 - mse: 9.2767 - mae: 3.0329 - val_loss: 9.4079 - val_mse: 9.4079 - val_mae: 3.0670\n",
      "Epoch 17/180\n",
      "65/65 [==============================] - 53s 813ms/step - loss: 9.3405 - mse: 9.3405 - mae: 3.0421 - val_loss: 8.4502 - val_mse: 8.4502 - val_mae: 2.9067\n",
      "Epoch 18/180\n",
      "65/65 [==============================] - 53s 815ms/step - loss: 9.2952 - mse: 9.2952 - mae: 3.0345 - val_loss: 8.8168 - val_mse: 8.8168 - val_mae: 2.9691\n",
      "Epoch 19/180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 52s 806ms/step - loss: 9.2592 - mse: 9.2592 - mae: 3.0296 - val_loss: 8.9366 - val_mse: 8.9366 - val_mae: 2.9892\n",
      "Epoch 20/180\n",
      "65/65 [==============================] - 53s 822ms/step - loss: 9.3547 - mse: 9.3547 - mae: 3.0433 - val_loss: 10.8680 - val_mse: 10.8680 - val_mae: 3.2965\n",
      "Epoch 21/180\n",
      "65/65 [==============================] - 53s 822ms/step - loss: 9.3368 - mse: 9.3368 - mae: 3.0434 - val_loss: 7.8954 - val_mse: 7.8954 - val_mae: 2.8097\n",
      "Epoch 22/180\n",
      "65/65 [==============================] - 52s 803ms/step - loss: 9.2651 - mse: 9.2651 - mae: 3.0277 - val_loss: 8.0733 - val_mse: 8.0733 - val_mae: 2.8412\n",
      "Epoch 23/180\n",
      "65/65 [==============================] - 53s 811ms/step - loss: 9.4013 - mse: 9.4013 - mae: 3.0532 - val_loss: 8.9976 - val_mse: 8.9976 - val_mae: 2.9994\n",
      "Epoch 24/180\n",
      "65/65 [==============================] - 53s 813ms/step - loss: 9.2284 - mse: 9.2284 - mae: 3.0250 - val_loss: 9.1673 - val_mse: 9.1673 - val_mae: 3.0276\n",
      "Epoch 25/180\n",
      "65/65 [==============================] - 52s 806ms/step - loss: 9.4514 - mse: 9.4514 - mae: 3.0569 - val_loss: 8.8163 - val_mse: 8.8163 - val_mae: 2.9690\n",
      "Epoch 26/180\n",
      "65/65 [==============================] - 53s 811ms/step - loss: 9.2654 - mse: 9.2654 - mae: 3.0291 - val_loss: 8.0223 - val_mse: 8.0223 - val_mae: 2.8322\n",
      "Epoch 27/180\n",
      "65/65 [==============================] - 52s 807ms/step - loss: 9.3866 - mse: 9.3866 - mae: 3.0514 - val_loss: 9.2325 - val_mse: 9.2325 - val_mae: 3.0383\n",
      "Epoch 28/180\n",
      "65/65 [==============================] - 53s 808ms/step - loss: 9.3228 - mse: 9.3228 - mae: 3.0353 - val_loss: 7.4131 - val_mse: 7.4131 - val_mae: 2.7225\n",
      "Epoch 29/180\n",
      "65/65 [==============================] - 52s 799ms/step - loss: 9.2482 - mse: 9.2482 - mae: 3.0165 - val_loss: 8.7884 - val_mse: 8.7884 - val_mae: 2.9643\n",
      "Epoch 30/180\n",
      "65/65 [==============================] - 51s 790ms/step - loss: 9.2337 - mse: 9.2337 - mae: 3.0232 - val_loss: 10.4906 - val_mse: 10.4906 - val_mae: 3.2387\n",
      "Epoch 31/180\n",
      "65/65 [==============================] - 51s 783ms/step - loss: 9.2449 - mse: 9.2449 - mae: 3.0234 - val_loss: 9.8083 - val_mse: 9.8083 - val_mae: 3.1316\n",
      "Epoch 32/180\n",
      "65/65 [==============================] - 51s 786ms/step - loss: 9.4839 - mse: 9.4839 - mae: 3.0575 - val_loss: 11.8382 - val_mse: 11.8382 - val_mae: 3.4405\n",
      "Epoch 33/180\n",
      "65/65 [==============================] - 53s 821ms/step - loss: 9.3519 - mse: 9.3519 - mae: 3.0407 - val_loss: 10.0404 - val_mse: 10.0404 - val_mae: 3.1685\n",
      "Epoch 34/180\n",
      "65/65 [==============================] - 51s 789ms/step - loss: 9.2054 - mse: 9.2054 - mae: 3.0155 - val_loss: 8.9283 - val_mse: 8.9283 - val_mae: 2.9878\n",
      "Epoch 35/180\n",
      "65/65 [==============================] - 53s 820ms/step - loss: 9.3277 - mse: 9.3277 - mae: 3.0415 - val_loss: 9.2606 - val_mse: 9.2606 - val_mae: 3.0429\n",
      "Epoch 36/180\n",
      "65/65 [==============================] - 52s 794ms/step - loss: 9.3078 - mse: 9.3078 - mae: 3.0336 - val_loss: 9.8313 - val_mse: 9.8313 - val_mae: 3.1353\n",
      "Epoch 37/180\n",
      "65/65 [==============================] - 51s 792ms/step - loss: 9.3839 - mse: 9.3839 - mae: 3.0476 - val_loss: 8.4055 - val_mse: 8.4055 - val_mae: 2.8990\n",
      "Epoch 38/180\n",
      "65/65 [==============================] - 52s 798ms/step - loss: 9.2123 - mse: 9.2123 - mae: 3.0133 - val_loss: 10.3083 - val_mse: 10.3083 - val_mae: 3.2105\n",
      "Epoch 39/180\n",
      "65/65 [==============================] - 52s 799ms/step - loss: 9.3867 - mse: 9.3867 - mae: 3.0501 - val_loss: 10.6564 - val_mse: 10.6564 - val_mae: 3.2642\n",
      "Epoch 40/180\n",
      "65/65 [==============================] - 53s 810ms/step - loss: 9.3603 - mse: 9.3603 - mae: 3.0470 - val_loss: 9.4109 - val_mse: 9.4109 - val_mae: 3.0675\n",
      "Epoch 41/180\n",
      "65/65 [==============================] - 51s 781ms/step - loss: 9.3052 - mse: 9.3052 - mae: 3.0361 - val_loss: 10.5386 - val_mse: 10.5386 - val_mae: 3.2462\n",
      "Epoch 42/180\n",
      "65/65 [==============================] - 51s 788ms/step - loss: 9.4596 - mse: 9.4596 - mae: 3.0619 - val_loss: 8.5604 - val_mse: 8.5604 - val_mae: 2.9256\n",
      "Epoch 43/180\n",
      "65/65 [==============================] - 51s 784ms/step - loss: 9.1803 - mse: 9.1803 - mae: 3.0121 - val_loss: 8.6503 - val_mse: 8.6503 - val_mae: 2.9410\n",
      "Epoch 44/180\n",
      "65/65 [==============================] - 52s 794ms/step - loss: 9.3099 - mse: 9.3099 - mae: 3.0382 - val_loss: 8.3123 - val_mse: 8.3123 - val_mae: 2.8829\n",
      "Epoch 45/180\n",
      "65/65 [==============================] - 52s 802ms/step - loss: 9.3043 - mse: 9.3043 - mae: 3.0330 - val_loss: 8.1636 - val_mse: 8.1636 - val_mae: 2.8570\n",
      "Epoch 46/180\n",
      "65/65 [==============================] - 51s 790ms/step - loss: 9.3424 - mse: 9.3424 - mae: 3.0425 - val_loss: 9.0161 - val_mse: 9.0161 - val_mae: 3.0025\n",
      "Epoch 47/180\n",
      "65/65 [==============================] - 53s 816ms/step - loss: 9.3282 - mse: 9.3282 - mae: 3.0418 - val_loss: 11.8084 - val_mse: 11.8084 - val_mae: 3.4362\n",
      "Epoch 48/180\n",
      "65/65 [==============================] - 50s 776ms/step - loss: 9.3356 - mse: 9.3356 - mae: 3.0397 - val_loss: 10.7777 - val_mse: 10.7777 - val_mae: 3.2828\n",
      "Epoch 49/180\n",
      "65/65 [==============================] - 51s 777ms/step - loss: 9.3513 - mse: 9.3513 - mae: 3.0414 - val_loss: 8.7611 - val_mse: 8.7611 - val_mae: 2.9597\n",
      "Epoch 50/180\n",
      "65/65 [==============================] - 51s 788ms/step - loss: 9.3415 - mse: 9.3415 - mae: 3.0394 - val_loss: 7.9889 - val_mse: 7.9889 - val_mae: 2.8263\n",
      "Epoch 51/180\n",
      "65/65 [==============================] - 51s 786ms/step - loss: 9.2308 - mse: 9.2308 - mae: 3.0246 - val_loss: 10.2903 - val_mse: 10.2903 - val_mae: 3.2077\n",
      "Epoch 52/180\n",
      "65/65 [==============================] - 51s 786ms/step - loss: 9.3060 - mse: 9.3060 - mae: 3.0338 - val_loss: 9.9091 - val_mse: 9.9091 - val_mae: 3.1477\n",
      "Epoch 53/180\n",
      "65/65 [==============================] - 51s 790ms/step - loss: 9.4027 - mse: 9.4027 - mae: 3.0524 - val_loss: 9.0316 - val_mse: 9.0316 - val_mae: 3.0051\n",
      "Epoch 54/180\n",
      "65/65 [==============================] - 53s 815ms/step - loss: 9.2833 - mse: 9.2833 - mae: 3.0354 - val_loss: 9.3650 - val_mse: 9.3650 - val_mae: 3.0601\n",
      "Epoch 55/180\n",
      "65/65 [==============================] - 53s 814ms/step - loss: 9.2760 - mse: 9.2760 - mae: 3.0329 - val_loss: 9.8066 - val_mse: 9.8066 - val_mae: 3.1314\n",
      "Epoch 56/180\n",
      "65/65 [==============================] - 52s 802ms/step - loss: 9.4038 - mse: 9.4038 - mae: 3.0548 - val_loss: 7.9124 - val_mse: 7.9124 - val_mae: 2.8127\n",
      "Epoch 57/180\n",
      "65/65 [==============================] - 52s 796ms/step - loss: 9.2923 - mse: 9.2923 - mae: 3.0310 - val_loss: 8.0532 - val_mse: 8.0532 - val_mae: 2.8376\n",
      "Epoch 58/180\n",
      "65/65 [==============================] - 52s 800ms/step - loss: 9.2564 - mse: 9.2564 - mae: 3.0259 - val_loss: 10.5768 - val_mse: 10.5768 - val_mae: 3.2520\n",
      "Epoch 59/180\n",
      "65/65 [==============================] - 52s 797ms/step - loss: 9.4018 - mse: 9.4018 - mae: 3.0478 - val_loss: 7.9912 - val_mse: 7.9912 - val_mae: 2.8267\n",
      "Epoch 60/180\n",
      "65/65 [==============================] - 52s 794ms/step - loss: 9.3899 - mse: 9.3899 - mae: 3.0502 - val_loss: 9.9558 - val_mse: 9.9558 - val_mae: 3.1551\n",
      "Epoch 61/180\n",
      "65/65 [==============================] - 52s 801ms/step - loss: 9.2072 - mse: 9.2072 - mae: 3.0198 - val_loss: 9.0388 - val_mse: 9.0388 - val_mae: 3.0063\n",
      "Epoch 62/180\n",
      "65/65 [==============================] - 51s 790ms/step - loss: 9.4231 - mse: 9.4231 - mae: 3.0569 - val_loss: 9.9979 - val_mse: 9.9979 - val_mae: 3.1618\n",
      "Epoch 63/180\n",
      "65/65 [==============================] - 51s 786ms/step - loss: 9.2861 - mse: 9.2861 - mae: 3.0327 - val_loss: 9.8393 - val_mse: 9.8393 - val_mae: 3.1366\n",
      "Epoch 64/180\n",
      "65/65 [==============================] - 50s 774ms/step - loss: 9.3641 - mse: 9.3641 - mae: 3.0491 - val_loss: 8.8733 - val_mse: 8.8733 - val_mae: 2.9786\n",
      "Epoch 65/180\n",
      "65/65 [==============================] - 51s 792ms/step - loss: 9.3143 - mse: 9.3143 - mae: 3.0390 - val_loss: 7.6446 - val_mse: 7.6446 - val_mae: 2.7647\n",
      "Epoch 66/180\n",
      "65/65 [==============================] - 52s 797ms/step - loss: 9.3589 - mse: 9.3589 - mae: 3.0470 - val_loss: 10.0268 - val_mse: 10.0268 - val_mae: 3.1663\n",
      "Epoch 67/180\n",
      "65/65 [==============================] - 52s 804ms/step - loss: 9.3172 - mse: 9.3172 - mae: 3.0391 - val_loss: 10.0023 - val_mse: 10.0023 - val_mae: 3.1625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/180\n",
      "65/65 [==============================] - 53s 823ms/step - loss: 9.2835 - mse: 9.2835 - mae: 3.0333 - val_loss: 8.7452 - val_mse: 8.7452 - val_mae: 2.9570\n",
      "Epoch 69/180\n",
      "65/65 [==============================] - 52s 795ms/step - loss: 9.3148 - mse: 9.3148 - mae: 3.0348 - val_loss: 9.9759 - val_mse: 9.9759 - val_mae: 3.1583\n",
      "Epoch 70/180\n",
      "65/65 [==============================] - 51s 790ms/step - loss: 9.4107 - mse: 9.4107 - mae: 3.0546 - val_loss: 10.2327 - val_mse: 10.2327 - val_mae: 3.1987\n",
      "Epoch 71/180\n",
      "65/65 [==============================] - 50s 775ms/step - loss: 9.2767 - mse: 9.2767 - mae: 3.0308 - val_loss: 8.1733 - val_mse: 8.1733 - val_mae: 2.8587\n",
      "Epoch 72/180\n",
      "65/65 [==============================] - 51s 788ms/step - loss: 9.3434 - mse: 9.3434 - mae: 3.0417 - val_loss: 8.7067 - val_mse: 8.7067 - val_mae: 2.9505\n",
      "Epoch 73/180\n",
      "65/65 [==============================] - 52s 804ms/step - loss: 9.2305 - mse: 9.2305 - mae: 3.0238 - val_loss: 8.7876 - val_mse: 8.7876 - val_mae: 2.9642\n",
      "Epoch 74/180\n",
      "65/65 [==============================] - 53s 808ms/step - loss: 9.3554 - mse: 9.3554 - mae: 3.0423 - val_loss: 11.1667 - val_mse: 11.1667 - val_mae: 3.3415\n",
      "Epoch 75/180\n",
      "65/65 [==============================] - 52s 793ms/step - loss: 9.3540 - mse: 9.3540 - mae: 3.0465 - val_loss: 9.5865 - val_mse: 9.5865 - val_mae: 3.0960\n",
      "Epoch 76/180\n",
      "65/65 [==============================] - 51s 787ms/step - loss: 9.3007 - mse: 9.3007 - mae: 3.0361 - val_loss: 8.7010 - val_mse: 8.7010 - val_mae: 2.9496\n",
      "Epoch 77/180\n",
      "65/65 [==============================] - 51s 792ms/step - loss: 9.3318 - mse: 9.3318 - mae: 3.0399 - val_loss: 8.4309 - val_mse: 8.4309 - val_mae: 2.9034\n",
      "Epoch 78/180\n",
      "65/65 [==============================] - 51s 779ms/step - loss: 9.3687 - mse: 9.3687 - mae: 3.0464 - val_loss: 7.9207 - val_mse: 7.9207 - val_mae: 2.8142\n",
      "Epoch 79/180\n",
      "65/65 [==============================] - 52s 793ms/step - loss: 9.3639 - mse: 9.3639 - mae: 3.0457 - val_loss: 9.5367 - val_mse: 9.5367 - val_mae: 3.0880\n",
      "Epoch 80/180\n",
      "65/65 [==============================] - 51s 787ms/step - loss: 9.2311 - mse: 9.2311 - mae: 3.0201 - val_loss: 9.4140 - val_mse: 9.4140 - val_mae: 3.0680\n",
      "Epoch 81/180\n",
      "65/65 [==============================] - 52s 805ms/step - loss: 9.3703 - mse: 9.3703 - mae: 3.0409 - val_loss: 7.8009 - val_mse: 7.8009 - val_mae: 2.7928\n",
      "Epoch 82/180\n",
      "65/65 [==============================] - 51s 780ms/step - loss: 9.2806 - mse: 9.2806 - mae: 3.0306 - val_loss: 9.9541 - val_mse: 9.9541 - val_mae: 3.1548\n",
      "Epoch 83/180\n",
      "65/65 [==============================] - 51s 782ms/step - loss: 9.3704 - mse: 9.3704 - mae: 3.0482 - val_loss: 8.7294 - val_mse: 8.7294 - val_mae: 2.9544\n",
      "Epoch 84/180\n",
      "65/65 [==============================] - 50s 776ms/step - loss: 9.3484 - mse: 9.3484 - mae: 3.0436 - val_loss: 7.9725 - val_mse: 7.9725 - val_mae: 2.8234\n",
      "Epoch 85/180\n",
      "65/65 [==============================] - 50s 775ms/step - loss: 9.3501 - mse: 9.3501 - mae: 3.0438 - val_loss: 9.3964 - val_mse: 9.3964 - val_mae: 3.0652\n",
      "Epoch 86/180\n",
      "65/65 [==============================] - 50s 773ms/step - loss: 9.3241 - mse: 9.3241 - mae: 3.0355 - val_loss: 8.3154 - val_mse: 8.3154 - val_mae: 2.8834\n",
      "Epoch 87/180\n",
      "65/65 [==============================] - 51s 783ms/step - loss: 9.3204 - mse: 9.3204 - mae: 3.0416 - val_loss: 8.1366 - val_mse: 8.1366 - val_mae: 2.8523\n",
      "Epoch 88/180\n",
      "65/65 [==============================] - 52s 804ms/step - loss: 9.3140 - mse: 9.3140 - mae: 3.0378 - val_loss: 9.4209 - val_mse: 9.4209 - val_mae: 3.0692\n",
      "Epoch 89/180\n",
      "65/65 [==============================] - 53s 812ms/step - loss: 9.3578 - mse: 9.3578 - mae: 3.0458 - val_loss: 8.8381 - val_mse: 8.8381 - val_mae: 2.9727\n",
      "Epoch 90/180\n",
      "65/65 [==============================] - 53s 822ms/step - loss: 9.2477 - mse: 9.2477 - mae: 3.0294 - val_loss: 9.4055 - val_mse: 9.4055 - val_mae: 3.0667\n",
      "Epoch 91/180\n",
      "65/65 [==============================] - 53s 823ms/step - loss: 9.2825 - mse: 9.2825 - mae: 3.0320 - val_loss: 9.5574 - val_mse: 9.5574 - val_mae: 3.0913\n",
      "Epoch 92/180\n",
      "65/65 [==============================] - 53s 815ms/step - loss: 9.3268 - mse: 9.3268 - mae: 3.0412 - val_loss: 9.1682 - val_mse: 9.1682 - val_mae: 3.0277\n",
      "Epoch 93/180\n",
      "65/65 [==============================] - 53s 817ms/step - loss: 9.2745 - mse: 9.2745 - mae: 3.0319 - val_loss: 10.8546 - val_mse: 10.8546 - val_mae: 3.2945\n",
      "Epoch 94/180\n",
      "65/65 [==============================] - 52s 800ms/step - loss: 9.4150 - mse: 9.4150 - mae: 3.0492 - val_loss: 8.0353 - val_mse: 8.0353 - val_mae: 2.8345\n",
      "Epoch 95/180\n",
      "65/65 [==============================] - 54s 825ms/step - loss: 9.2933 - mse: 9.2933 - mae: 3.0320 - val_loss: 9.8498 - val_mse: 9.8498 - val_mae: 3.1383\n",
      "Epoch 96/180\n",
      "65/65 [==============================] - 53s 816ms/step - loss: 9.3773 - mse: 9.3773 - mae: 3.0498 - val_loss: 8.5292 - val_mse: 8.5292 - val_mae: 2.9203\n",
      "Epoch 97/180\n",
      "65/65 [==============================] - 53s 819ms/step - loss: 9.2757 - mse: 9.2757 - mae: 3.0315 - val_loss: 11.2045 - val_mse: 11.2045 - val_mae: 3.3471\n",
      "Epoch 98/180\n",
      "65/65 [==============================] - 54s 836ms/step - loss: 9.4537 - mse: 9.4537 - mae: 3.0601 - val_loss: 9.5138 - val_mse: 9.5138 - val_mae: 3.0843\n",
      "Epoch 99/180\n",
      "65/65 [==============================] - 54s 836ms/step - loss: 9.2184 - mse: 9.2184 - mae: 3.0253 - val_loss: 9.4534 - val_mse: 9.4534 - val_mae: 3.0745\n",
      "Epoch 100/180\n",
      "65/65 [==============================] - 53s 819ms/step - loss: 9.3455 - mse: 9.3455 - mae: 3.0457 - val_loss: 9.9151 - val_mse: 9.9151 - val_mae: 3.1486\n",
      "Epoch 101/180\n",
      "65/65 [==============================] - 53s 818ms/step - loss: 9.3059 - mse: 9.3059 - mae: 3.0367 - val_loss: 10.7246 - val_mse: 10.7246 - val_mae: 3.2747\n",
      "Epoch 102/180\n",
      "65/65 [==============================] - 53s 820ms/step - loss: 9.3668 - mse: 9.3668 - mae: 3.0481 - val_loss: 10.0853 - val_mse: 10.0853 - val_mae: 3.1756\n",
      "Epoch 103/180\n",
      "65/65 [==============================] - 53s 818ms/step - loss: 9.3167 - mse: 9.3167 - mae: 3.0423 - val_loss: 8.0340 - val_mse: 8.0340 - val_mae: 2.8342\n",
      "Epoch 104/180\n",
      "65/65 [==============================] - 54s 836ms/step - loss: 9.3976 - mse: 9.3976 - mae: 3.0497 - val_loss: 8.8472 - val_mse: 8.8472 - val_mae: 2.9742\n",
      "Epoch 105/180\n",
      "65/65 [==============================] - 53s 820ms/step - loss: 9.2674 - mse: 9.2674 - mae: 3.0277 - val_loss: 9.5262 - val_mse: 9.5262 - val_mae: 3.0863\n",
      "Epoch 106/180\n",
      "65/65 [==============================] - 53s 822ms/step - loss: 9.3809 - mse: 9.3809 - mae: 3.0507 - val_loss: 9.4314 - val_mse: 9.4314 - val_mae: 3.0709\n",
      "Epoch 107/180\n",
      "65/65 [==============================] - 53s 815ms/step - loss: 9.2759 - mse: 9.2759 - mae: 3.0328 - val_loss: 9.4089 - val_mse: 9.4089 - val_mae: 3.0672\n",
      "Epoch 108/180\n",
      "65/65 [==============================] - 53s 822ms/step - loss: 9.3584 - mse: 9.3584 - mae: 3.0445 - val_loss: 9.2646 - val_mse: 9.2646 - val_mae: 3.0436\n",
      "Epoch 109/180\n",
      "65/65 [==============================] - 53s 815ms/step - loss: 9.3383 - mse: 9.3383 - mae: 3.0392 - val_loss: 11.3061 - val_mse: 11.3061 - val_mae: 3.3623\n",
      "Epoch 110/180\n",
      "65/65 [==============================] - 53s 817ms/step - loss: 9.3242 - mse: 9.3242 - mae: 3.0409 - val_loss: 8.3438 - val_mse: 8.3438 - val_mae: 2.8884\n",
      "Epoch 111/180\n",
      "65/65 [==============================] - 53s 818ms/step - loss: 9.3026 - mse: 9.3026 - mae: 3.0371 - val_loss: 9.6197 - val_mse: 9.6197 - val_mae: 3.1014\n",
      "Epoch 112/180\n",
      "65/65 [==============================] - 52s 806ms/step - loss: 9.3444 - mse: 9.3444 - mae: 3.0439 - val_loss: 9.1810 - val_mse: 9.1810 - val_mae: 3.0298\n",
      "Epoch 113/180\n",
      "65/65 [==============================] - 53s 817ms/step - loss: 9.3939 - mse: 9.3939 - mae: 3.0477 - val_loss: 10.3543 - val_mse: 10.3543 - val_mae: 3.2176\n",
      "Epoch 114/180\n",
      "65/65 [==============================] - 54s 832ms/step - loss: 9.2329 - mse: 9.2329 - mae: 3.0279 - val_loss: 8.4865 - val_mse: 8.4865 - val_mae: 2.9130\n",
      "Epoch 115/180\n",
      "65/65 [==============================] - 55s 842ms/step - loss: 9.3361 - mse: 9.3361 - mae: 3.0409 - val_loss: 10.2469 - val_mse: 10.2469 - val_mae: 3.2009\n",
      "Epoch 116/180\n",
      "65/65 [==============================] - 54s 828ms/step - loss: 9.3140 - mse: 9.3140 - mae: 3.0396 - val_loss: 8.5154 - val_mse: 8.5154 - val_mae: 2.9179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/180\n",
      "65/65 [==============================] - 53s 814ms/step - loss: 9.3092 - mse: 9.3092 - mae: 3.0385 - val_loss: 7.4452 - val_mse: 7.4452 - val_mae: 2.7284\n",
      "Epoch 118/180\n",
      "65/65 [==============================] - 52s 797ms/step - loss: 9.3244 - mse: 9.3244 - mae: 3.0401 - val_loss: 9.4462 - val_mse: 9.4462 - val_mae: 3.0733\n",
      "Epoch 119/180\n",
      "65/65 [==============================] - 51s 789ms/step - loss: 9.3046 - mse: 9.3046 - mae: 3.0301 - val_loss: 7.7277 - val_mse: 7.7277 - val_mae: 2.7797\n",
      "Epoch 120/180\n",
      "65/65 [==============================] - 53s 809ms/step - loss: 9.3578 - mse: 9.3578 - mae: 3.0443 - val_loss: 9.2754 - val_mse: 9.2754 - val_mae: 3.0454\n",
      "Epoch 121/180\n",
      "65/65 [==============================] - 52s 806ms/step - loss: 9.3356 - mse: 9.3356 - mae: 3.0327 - val_loss: 7.4278 - val_mse: 7.4278 - val_mae: 2.7252\n",
      "Epoch 122/180\n",
      "65/65 [==============================] - 52s 807ms/step - loss: 9.2581 - mse: 9.2581 - mae: 3.0258 - val_loss: 9.3813 - val_mse: 9.3813 - val_mae: 3.0627\n",
      "Epoch 123/180\n",
      "65/65 [==============================] - 52s 795ms/step - loss: 9.4203 - mse: 9.4203 - mae: 3.0525 - val_loss: 10.4216 - val_mse: 10.4216 - val_mae: 3.2281\n",
      "Epoch 124/180\n",
      "65/65 [==============================] - 52s 799ms/step - loss: 9.2525 - mse: 9.2525 - mae: 3.0288 - val_loss: 9.3142 - val_mse: 9.3142 - val_mae: 3.0517\n",
      "Epoch 125/180\n",
      "65/65 [==============================] - 52s 800ms/step - loss: 9.3550 - mse: 9.3550 - mae: 3.0385 - val_loss: 10.1066 - val_mse: 10.1066 - val_mae: 3.1789\n",
      "Epoch 126/180\n",
      "65/65 [==============================] - 51s 786ms/step - loss: 9.3250 - mse: 9.3250 - mae: 3.0421 - val_loss: 8.4899 - val_mse: 8.4899 - val_mae: 2.9136\n",
      "Epoch 127/180\n",
      "65/65 [==============================] - 51s 779ms/step - loss: 9.3511 - mse: 9.3511 - mae: 3.0455 - val_loss: 8.8009 - val_mse: 8.8009 - val_mae: 2.9664\n",
      "Epoch 128/180\n",
      "65/65 [==============================] - 52s 796ms/step - loss: 9.2785 - mse: 9.2785 - mae: 3.0327 - val_loss: 10.4826 - val_mse: 10.4826 - val_mae: 3.2375\n",
      "Epoch 129/180\n",
      "65/65 [==============================] - 51s 790ms/step - loss: 9.3483 - mse: 9.3483 - mae: 3.0427 - val_loss: 11.0609 - val_mse: 11.0609 - val_mae: 3.3256\n",
      "Epoch 130/180\n",
      "65/65 [==============================] - 52s 793ms/step - loss: 9.2940 - mse: 9.2940 - mae: 3.0298 - val_loss: 9.6853 - val_mse: 9.6853 - val_mae: 3.1119\n",
      "Epoch 131/180\n",
      "65/65 [==============================] - 51s 790ms/step - loss: 9.3494 - mse: 9.3494 - mae: 3.0449 - val_loss: 9.4223 - val_mse: 9.4223 - val_mae: 3.0694\n",
      "Epoch 132/180\n",
      "65/65 [==============================] - 50s 775ms/step - loss: 9.3438 - mse: 9.3438 - mae: 3.0406 - val_loss: 7.6808 - val_mse: 7.6808 - val_mae: 2.7712\n",
      "Epoch 133/180\n",
      "65/65 [==============================] - 51s 791ms/step - loss: 9.3525 - mse: 9.3525 - mae: 3.0445 - val_loss: 7.9624 - val_mse: 7.9624 - val_mae: 2.8216\n",
      "Epoch 134/180\n",
      "65/65 [==============================] - 51s 788ms/step - loss: 9.2852 - mse: 9.2852 - mae: 3.0328 - val_loss: 10.6384 - val_mse: 10.6384 - val_mae: 3.2615\n",
      "Epoch 135/180\n",
      "65/65 [==============================] - 52s 794ms/step - loss: 9.3725 - mse: 9.3725 - mae: 3.0499 - val_loss: 9.2460 - val_mse: 9.2460 - val_mae: 3.0405\n",
      "Epoch 136/180\n",
      "65/65 [==============================] - 52s 807ms/step - loss: 9.3679 - mse: 9.3679 - mae: 3.0503 - val_loss: 8.9050 - val_mse: 8.9050 - val_mae: 2.9839\n",
      "Epoch 137/180\n",
      "65/65 [==============================] - 52s 801ms/step - loss: 9.1582 - mse: 9.1582 - mae: 3.0115 - val_loss: 9.9591 - val_mse: 9.9591 - val_mae: 3.1556\n",
      "Epoch 138/180\n",
      "65/65 [==============================] - 52s 793ms/step - loss: 9.3892 - mse: 9.3892 - mae: 3.0476 - val_loss: 7.9415 - val_mse: 7.9415 - val_mae: 2.8179\n",
      "Epoch 139/180\n",
      "65/65 [==============================] - 51s 786ms/step - loss: 9.2453 - mse: 9.2453 - mae: 3.0254 - val_loss: 9.9850 - val_mse: 9.9850 - val_mae: 3.1597\n",
      "Epoch 140/180\n",
      "65/65 [==============================] - 52s 799ms/step - loss: 9.3294 - mse: 9.3294 - mae: 3.0399 - val_loss: 8.7824 - val_mse: 8.7824 - val_mae: 2.9633\n",
      "Epoch 141/180\n",
      "65/65 [==============================] - 52s 807ms/step - loss: 9.3996 - mse: 9.3996 - mae: 3.0530 - val_loss: 9.6878 - val_mse: 9.6878 - val_mae: 3.1123\n",
      "Epoch 142/180\n",
      "65/65 [==============================] - 54s 827ms/step - loss: 9.3241 - mse: 9.3241 - mae: 3.0413 - val_loss: 9.8161 - val_mse: 9.8161 - val_mae: 3.1329\n",
      "Epoch 143/180\n",
      "65/65 [==============================] - 53s 815ms/step - loss: 9.2812 - mse: 9.2812 - mae: 3.0293 - val_loss: 8.5912 - val_mse: 8.5912 - val_mae: 2.9309\n",
      "Epoch 144/180\n",
      "65/65 [==============================] - 52s 804ms/step - loss: 9.2964 - mse: 9.2964 - mae: 3.0360 - val_loss: 9.0347 - val_mse: 9.0347 - val_mae: 3.0056\n",
      "Epoch 145/180\n",
      "65/65 [==============================] - 52s 796ms/step - loss: 9.3274 - mse: 9.3274 - mae: 3.0411 - val_loss: 9.8497 - val_mse: 9.8497 - val_mae: 3.1382\n",
      "Epoch 146/180\n",
      "65/65 [==============================] - 51s 790ms/step - loss: 9.3389 - mse: 9.3389 - mae: 3.0443 - val_loss: 7.8646 - val_mse: 7.8646 - val_mae: 2.8042\n",
      "Epoch 147/180\n",
      "65/65 [==============================] - 53s 817ms/step - loss: 9.3010 - mse: 9.3010 - mae: 3.0308 - val_loss: 7.4688 - val_mse: 7.4688 - val_mae: 2.7327\n",
      "Epoch 148/180\n",
      "65/65 [==============================] - 52s 803ms/step - loss: 9.3509 - mse: 9.3509 - mae: 3.0397 - val_loss: 7.8257 - val_mse: 7.8257 - val_mae: 2.7972\n",
      "Epoch 149/180\n",
      "65/65 [==============================] - 53s 813ms/step - loss: 9.3438 - mse: 9.3438 - mae: 3.0321 - val_loss: 10.1676 - val_mse: 10.1676 - val_mae: 3.1885\n",
      "Epoch 150/180\n",
      "65/65 [==============================] - 52s 793ms/step - loss: 9.2730 - mse: 9.2730 - mae: 3.0334 - val_loss: 8.7202 - val_mse: 8.7202 - val_mae: 2.9528\n",
      "Epoch 151/180\n",
      "65/65 [==============================] - 52s 794ms/step - loss: 9.3399 - mse: 9.3399 - mae: 3.0356 - val_loss: 9.7951 - val_mse: 9.7951 - val_mae: 3.1295\n",
      "Epoch 152/180\n",
      "65/65 [==============================] - 51s 789ms/step - loss: 9.2835 - mse: 9.2835 - mae: 3.0296 - val_loss: 8.2994 - val_mse: 8.2994 - val_mae: 2.8807\n",
      "Epoch 153/180\n",
      "65/65 [==============================] - 52s 803ms/step - loss: 9.3455 - mse: 9.3455 - mae: 3.0439 - val_loss: 10.1879 - val_mse: 10.1879 - val_mae: 3.1917\n",
      "Epoch 154/180\n",
      "65/65 [==============================] - 53s 815ms/step - loss: 9.3005 - mse: 9.3005 - mae: 3.0371 - val_loss: 9.6598 - val_mse: 9.6598 - val_mae: 3.1078\n",
      "Epoch 155/180\n",
      "65/65 [==============================] - 52s 798ms/step - loss: 9.3191 - mse: 9.3191 - mae: 3.0388 - val_loss: 9.2110 - val_mse: 9.2110 - val_mae: 3.0348\n",
      "Epoch 156/180\n",
      "65/65 [==============================] - 53s 820ms/step - loss: 9.3429 - mse: 9.3429 - mae: 3.0439 - val_loss: 8.1890 - val_mse: 8.1890 - val_mae: 2.8614\n",
      "Epoch 157/180\n",
      "65/65 [==============================] - 53s 816ms/step - loss: 9.3945 - mse: 9.3945 - mae: 3.0535 - val_loss: 9.3958 - val_mse: 9.3958 - val_mae: 3.0651\n",
      "Epoch 158/180\n",
      "65/65 [==============================] - 52s 800ms/step - loss: 9.2515 - mse: 9.2515 - mae: 3.0264 - val_loss: 11.7449 - val_mse: 11.7449 - val_mae: 3.4269\n",
      "Epoch 159/180\n",
      "65/65 [==============================] - 53s 816ms/step - loss: 9.3700 - mse: 9.3700 - mae: 3.0482 - val_loss: 8.3302 - val_mse: 8.3302 - val_mae: 2.8860\n",
      "Epoch 160/180\n",
      "65/65 [==============================] - 53s 809ms/step - loss: 9.2942 - mse: 9.2942 - mae: 3.0375 - val_loss: 10.5891 - val_mse: 10.5891 - val_mae: 3.2539\n",
      "Epoch 161/180\n",
      "65/65 [==============================] - 52s 795ms/step - loss: 9.2565 - mse: 9.2565 - mae: 3.0298 - val_loss: 9.2607 - val_mse: 9.2608 - val_mae: 3.0430\n",
      "Epoch 162/180\n",
      "65/65 [==============================] - 53s 809ms/step - loss: 9.4227 - mse: 9.4227 - mae: 3.0528 - val_loss: 10.0164 - val_mse: 10.0164 - val_mae: 3.1647\n",
      "Epoch 163/180\n",
      "65/65 [==============================] - 53s 815ms/step - loss: 9.2154 - mse: 9.2154 - mae: 3.0225 - val_loss: 11.1327 - val_mse: 11.1327 - val_mae: 3.3364\n",
      "Epoch 164/180\n",
      "65/65 [==============================] - 52s 806ms/step - loss: 9.3312 - mse: 9.3312 - mae: 3.0420 - val_loss: 9.0783 - val_mse: 9.0783 - val_mae: 3.0128\n",
      "Epoch 165/180\n",
      "65/65 [==============================] - 52s 801ms/step - loss: 9.4264 - mse: 9.4264 - mae: 3.0559 - val_loss: 10.7086 - val_mse: 10.7086 - val_mae: 3.2722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 166/180\n",
      "65/65 [==============================] - 52s 796ms/step - loss: 9.3159 - mse: 9.3159 - mae: 3.0370 - val_loss: 8.2071 - val_mse: 8.2071 - val_mae: 2.8646\n",
      "Epoch 167/180\n",
      "65/65 [==============================] - 51s 790ms/step - loss: 9.1820 - mse: 9.1820 - mae: 3.0134 - val_loss: 9.4739 - val_mse: 9.4739 - val_mae: 3.0778\n",
      "Epoch 168/180\n",
      "65/65 [==============================] - 52s 793ms/step - loss: 9.4161 - mse: 9.4161 - mae: 3.0566 - val_loss: 8.1156 - val_mse: 8.1156 - val_mae: 2.8486\n",
      "Epoch 169/180\n",
      "65/65 [==============================] - 52s 806ms/step - loss: 9.1926 - mse: 9.1926 - mae: 3.0180 - val_loss: 8.9084 - val_mse: 8.9084 - val_mae: 2.9845\n",
      "Epoch 170/180\n",
      "65/65 [==============================] - 52s 803ms/step - loss: 9.5001 - mse: 9.5001 - mae: 3.0582 - val_loss: 8.8724 - val_mse: 8.8724 - val_mae: 2.9785\n",
      "Epoch 171/180\n",
      "65/65 [==============================] - 51s 787ms/step - loss: 9.2896 - mse: 9.2896 - mae: 3.0291 - val_loss: 7.2129 - val_mse: 7.2129 - val_mae: 2.6855\n",
      "Epoch 172/180\n",
      "65/65 [==============================] - 51s 780ms/step - loss: 9.2420 - mse: 9.2420 - mae: 3.0232 - val_loss: 8.6511 - val_mse: 8.6511 - val_mae: 2.9411\n",
      "Epoch 173/180\n",
      "65/65 [==============================] - 50s 773ms/step - loss: 9.3267 - mse: 9.3267 - mae: 3.0381 - val_loss: 9.6105 - val_mse: 9.6105 - val_mae: 3.0999\n",
      "Epoch 174/180\n",
      "65/65 [==============================] - 51s 778ms/step - loss: 9.3742 - mse: 9.3742 - mae: 3.0474 - val_loss: 9.6907 - val_mse: 9.6907 - val_mae: 3.1128\n",
      "Epoch 175/180\n",
      "65/65 [==============================] - 51s 779ms/step - loss: 9.2955 - mse: 9.2955 - mae: 3.0360 - val_loss: 9.3382 - val_mse: 9.3382 - val_mae: 3.0557\n",
      "Epoch 176/180\n",
      "65/65 [==============================] - 52s 800ms/step - loss: 9.3222 - mse: 9.3222 - mae: 3.0391 - val_loss: 9.1145 - val_mse: 9.1145 - val_mae: 3.0188\n",
      "Epoch 177/180\n",
      "65/65 [==============================] - 51s 783ms/step - loss: 9.3310 - mse: 9.3310 - mae: 3.0389 - val_loss: 10.1088 - val_mse: 10.1088 - val_mae: 3.1793\n",
      "Epoch 178/180\n",
      "65/65 [==============================] - 50s 772ms/step - loss: 9.3429 - mse: 9.3429 - mae: 3.0435 - val_loss: 8.8040 - val_mse: 8.8040 - val_mae: 2.9670\n",
      "Epoch 179/180\n",
      "65/65 [==============================] - 51s 788ms/step - loss: 9.2768 - mse: 9.2768 - mae: 3.0319 - val_loss: 8.9815 - val_mse: 8.9815 - val_mae: 2.9967\n",
      "Epoch 180/180\n",
      "65/65 [==============================] - 51s 786ms/step - loss: 9.3594 - mse: 9.3594 - mae: 3.0413 - val_loss: 8.7683 - val_mse: 8.7683 - val_mae: 2.9609\n",
      "Epoch 1/180\n",
      "65/65 [==============================] - 56s 863ms/step - loss: 1349.4596 - mse: 1349.4596 - mae: 25.0314 - val_loss: 1000.5076 - val_mse: 1000.5076 - val_mae: 31.6285\n",
      "Epoch 2/180\n",
      "65/65 [==============================] - 52s 792ms/step - loss: 995.1655 - mse: 995.1655 - mae: 31.3571 - val_loss: 1011.0385 - val_mse: 1011.0385 - val_mae: 31.7964\n",
      "Epoch 3/180\n",
      "65/65 [==============================] - 52s 799ms/step - loss: 1005.1619 - mse: 1005.1619 - mae: 31.5402 - val_loss: 903.0953 - val_mse: 903.0953 - val_mae: 30.0515\n",
      "Epoch 4/180\n",
      "65/65 [==============================] - 51s 783ms/step - loss: 985.7661 - mse: 985.7661 - mae: 31.2064 - val_loss: 1164.3224 - val_mse: 1164.3224 - val_mae: 34.1217\n",
      "Epoch 5/180\n",
      "65/65 [==============================] - 52s 794ms/step - loss: 1004.3113 - mse: 1004.3113 - mae: 31.4909 - val_loss: 1069.4950 - val_mse: 1069.4950 - val_mae: 32.7028\n",
      "Epoch 6/180\n",
      "65/65 [==============================] - 53s 814ms/step - loss: 995.6878 - mse: 995.6878 - mae: 31.4007 - val_loss: 902.7582 - val_mse: 902.7582 - val_mae: 30.0453\n",
      "Epoch 7/180\n",
      "65/65 [==============================] - 53s 822ms/step - loss: 992.1577 - mse: 992.1577 - mae: 31.3793 - val_loss: 1021.0938 - val_mse: 1021.0938 - val_mae: 31.9542\n",
      "Epoch 8/180\n",
      "65/65 [==============================] - 54s 835ms/step - loss: 1005.2581 - mse: 1005.2581 - mae: 31.5613 - val_loss: 1048.6050 - val_mse: 1048.6049 - val_mae: 32.3821\n",
      "Epoch 9/180\n",
      "65/65 [==============================] - 54s 832ms/step - loss: 981.5992 - mse: 981.5992 - mae: 31.1803 - val_loss: 951.4299 - val_mse: 951.4299 - val_mae: 30.8417\n",
      "Epoch 10/180\n",
      "65/65 [==============================] - 54s 828ms/step - loss: 999.0421 - mse: 999.0420 - mae: 31.4495 - val_loss: 1095.7474 - val_mse: 1095.7474 - val_mae: 33.1016\n",
      "Epoch 11/180\n",
      "65/65 [==============================] - 55s 846ms/step - loss: 998.3409 - mse: 998.3409 - mae: 31.4806 - val_loss: 1071.0239 - val_mse: 1071.0239 - val_mae: 32.7265\n",
      "Epoch 12/180\n",
      "65/65 [==============================] - 54s 833ms/step - loss: 991.9380 - mse: 991.9380 - mae: 31.3548 - val_loss: 1114.5272 - val_mse: 1114.5272 - val_mae: 33.3839\n",
      "Epoch 13/180\n",
      "65/65 [==============================] - 54s 831ms/step - loss: 1003.9928 - mse: 1003.9928 - mae: 31.5075 - val_loss: 837.3566 - val_mse: 837.3566 - val_mae: 28.9368\n",
      "Epoch 14/180\n",
      "65/65 [==============================] - 54s 828ms/step - loss: 998.8177 - mse: 998.8177 - mae: 31.4654 - val_loss: 751.9951 - val_mse: 751.9951 - val_mae: 27.4224\n",
      "Epoch 15/180\n",
      "65/65 [==============================] - 54s 829ms/step - loss: 985.4636 - mse: 985.4636 - mae: 31.2547 - val_loss: 849.4811 - val_mse: 849.4811 - val_mae: 29.1446\n",
      "Epoch 16/180\n",
      "65/65 [==============================] - 55s 845ms/step - loss: 1000.3929 - mse: 1000.3928 - mae: 31.4972 - val_loss: 1106.1941 - val_mse: 1106.1941 - val_mae: 33.2591\n",
      "Epoch 17/180\n",
      "65/65 [==============================] - 52s 798ms/step - loss: 997.0090 - mse: 997.0090 - mae: 31.4541 - val_loss: 888.9744 - val_mse: 888.9744 - val_mae: 29.8143\n",
      "Epoch 18/180\n",
      "65/65 [==============================] - 52s 795ms/step - loss: 997.3433 - mse: 997.3433 - mae: 31.4367 - val_loss: 1284.2756 - val_mse: 1284.2756 - val_mae: 35.8363\n",
      "Epoch 19/180\n",
      "65/65 [==============================] - 53s 817ms/step - loss: 1002.5145 - mse: 1002.5145 - mae: 31.4516 - val_loss: 757.8214 - val_mse: 757.8214 - val_mae: 27.5285\n",
      "Epoch 20/180\n",
      "65/65 [==============================] - 53s 817ms/step - loss: 993.6012 - mse: 993.6012 - mae: 31.3902 - val_loss: 1065.1974 - val_mse: 1065.1974 - val_mae: 32.6372\n",
      "Epoch 21/180\n",
      "65/65 [==============================] - 52s 805ms/step - loss: 990.7753 - mse: 990.7753 - mae: 31.3642 - val_loss: 1126.2169 - val_mse: 1126.2169 - val_mae: 33.5583\n",
      "Epoch 22/180\n",
      "65/65 [==============================] - 53s 816ms/step - loss: 997.4058 - mse: 997.4058 - mae: 31.4356 - val_loss: 1036.8728 - val_mse: 1036.8728 - val_mae: 32.1998\n",
      "Epoch 23/180\n",
      "65/65 [==============================] - 53s 823ms/step - loss: 990.0572 - mse: 990.0572 - mae: 31.2999 - val_loss: 1004.7374 - val_mse: 1004.7374 - val_mae: 31.6937\n",
      "Epoch 24/180\n",
      "65/65 [==============================] - 53s 816ms/step - loss: 1001.4662 - mse: 1001.4662 - mae: 31.5313 - val_loss: 1147.3085 - val_mse: 1147.3085 - val_mae: 33.8719\n",
      "Epoch 25/180\n",
      "65/65 [==============================] - 53s 808ms/step - loss: 993.1622 - mse: 993.1622 - mae: 31.3198 - val_loss: 773.2242 - val_mse: 773.2242 - val_mae: 27.8053\n",
      "Epoch 26/180\n",
      "65/65 [==============================] - 53s 821ms/step - loss: 1004.9354 - mse: 1004.9354 - mae: 31.5081 - val_loss: 950.8325 - val_mse: 950.8325 - val_mae: 30.8354\n",
      "Epoch 27/180\n",
      "65/65 [==============================] - 53s 819ms/step - loss: 996.0377 - mse: 996.0377 - mae: 31.4222 - val_loss: 961.4280 - val_mse: 961.4280 - val_mae: 31.0069\n",
      "Epoch 28/180\n",
      "65/65 [==============================] - 53s 814ms/step - loss: 999.2441 - mse: 999.2441 - mae: 31.4795 - val_loss: 1104.3209 - val_mse: 1104.3209 - val_mae: 33.2313\n",
      "Epoch 29/180\n",
      "65/65 [==============================] - 54s 828ms/step - loss: 991.3363 - mse: 991.3363 - mae: 31.3596 - val_loss: 870.0743 - val_mse: 870.0743 - val_mae: 29.4944\n",
      "Epoch 30/180\n",
      "65/65 [==============================] - 54s 827ms/step - loss: 998.1109 - mse: 998.1109 - mae: 31.4539 - val_loss: 971.5341 - val_mse: 971.5341 - val_mae: 31.1689\n",
      "Epoch 31/180\n",
      "65/65 [==============================] - 52s 800ms/step - loss: 998.2004 - mse: 998.2004 - mae: 31.4593 - val_loss: 1017.9963 - val_mse: 1017.9963 - val_mae: 31.9060\n",
      "Epoch 32/180\n",
      "65/65 [==============================] - 52s 802ms/step - loss: 992.1761 - mse: 992.1761 - mae: 31.3431 - val_loss: 919.1195 - val_mse: 919.1195 - val_mae: 30.3154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/180\n",
      "65/65 [==============================] - 52s 797ms/step - loss: 998.9583 - mse: 998.9583 - mae: 31.4305 - val_loss: 858.3569 - val_mse: 858.3569 - val_mae: 29.2963\n",
      "Epoch 34/180\n",
      "65/65 [==============================] - 52s 798ms/step - loss: 994.9581 - mse: 994.9581 - mae: 31.4180 - val_loss: 891.9218 - val_mse: 891.9218 - val_mae: 29.8643\n",
      "Epoch 35/180\n",
      "65/65 [==============================] - 52s 799ms/step - loss: 995.4257 - mse: 995.4257 - mae: 31.4041 - val_loss: 901.1198 - val_mse: 901.1198 - val_mae: 30.0182\n",
      "Epoch 36/180\n",
      "65/65 [==============================] - 53s 809ms/step - loss: 999.1699 - mse: 999.1699 - mae: 31.4605 - val_loss: 876.4672 - val_mse: 876.4672 - val_mae: 29.6040\n",
      "Epoch 37/180\n",
      "65/65 [==============================] - 52s 799ms/step - loss: 991.7324 - mse: 991.7324 - mae: 31.3571 - val_loss: 1031.1510 - val_mse: 1031.1510 - val_mae: 32.1113\n",
      "Epoch 38/180\n",
      "65/65 [==============================] - 53s 811ms/step - loss: 1007.0225 - mse: 1007.0225 - mae: 31.5708 - val_loss: 716.3088 - val_mse: 716.3088 - val_mae: 26.7625\n",
      "Epoch 39/180\n",
      "65/65 [==============================] - 51s 792ms/step - loss: 988.1585 - mse: 988.1585 - mae: 31.2527 - val_loss: 1106.1479 - val_mse: 1106.1479 - val_mae: 33.2565\n",
      "Epoch 40/180\n",
      "65/65 [==============================] - 51s 786ms/step - loss: 1006.4133 - mse: 1006.4133 - mae: 31.5765 - val_loss: 902.2325 - val_mse: 902.2325 - val_mae: 30.0371\n",
      "Epoch 41/180\n",
      "65/65 [==============================] - 51s 783ms/step - loss: 987.2435 - mse: 987.2435 - mae: 31.2789 - val_loss: 1071.0120 - val_mse: 1071.0120 - val_mae: 32.7249\n",
      "Epoch 42/180\n",
      "65/65 [==============================] - 51s 788ms/step - loss: 1008.1630 - mse: 1008.1630 - mae: 31.5664 - val_loss: 945.9916 - val_mse: 945.9916 - val_mae: 30.7565\n",
      "Epoch 43/180\n",
      "65/65 [==============================] - 53s 822ms/step - loss: 985.9587 - mse: 985.9587 - mae: 31.2294 - val_loss: 1049.3651 - val_mse: 1049.3651 - val_mae: 32.3917\n",
      "Epoch 44/180\n",
      "65/65 [==============================] - 54s 835ms/step - loss: 997.1252 - mse: 997.1252 - mae: 31.3920 - val_loss: 1304.1097 - val_mse: 1304.1097 - val_mae: 36.1115\n",
      "Epoch 45/180\n",
      "65/65 [==============================] - 53s 817ms/step - loss: 998.3517 - mse: 998.3517 - mae: 31.4379 - val_loss: 990.1370 - val_mse: 990.1370 - val_mae: 31.4657\n",
      "Epoch 46/180\n",
      "65/65 [==============================] - 51s 791ms/step - loss: 997.3135 - mse: 997.3135 - mae: 31.4545 - val_loss: 987.1799 - val_mse: 987.1799 - val_mae: 31.4185\n",
      "Epoch 47/180\n",
      "65/65 [==============================] - 51s 790ms/step - loss: 999.8715 - mse: 999.8715 - mae: 31.4857 - val_loss: 1003.9033 - val_mse: 1003.9033 - val_mae: 31.6822\n",
      "Epoch 48/180\n",
      "65/65 [==============================] - 52s 801ms/step - loss: 1000.6862 - mse: 1000.6862 - mae: 31.5149 - val_loss: 1008.9229 - val_mse: 1008.9229 - val_mae: 31.7620\n",
      "Epoch 49/180\n",
      "65/65 [==============================] - 52s 799ms/step - loss: 988.3395 - mse: 988.3395 - mae: 31.2913 - val_loss: 1039.1388 - val_mse: 1039.1388 - val_mae: 32.2353\n",
      "Epoch 50/180\n",
      "65/65 [==============================] - 52s 803ms/step - loss: 1002.1680 - mse: 1002.1680 - mae: 31.5338 - val_loss: 1157.4808 - val_mse: 1157.4810 - val_mae: 34.0218\n",
      "Epoch 51/180\n",
      "65/65 [==============================] - 51s 781ms/step - loss: 1000.9759 - mse: 1000.9759 - mae: 31.5132 - val_loss: 871.2526 - val_mse: 871.2526 - val_mae: 29.5167\n",
      "Epoch 52/180\n",
      "65/65 [==============================] - 52s 798ms/step - loss: 995.6581 - mse: 995.6581 - mae: 31.4266 - val_loss: 897.1140 - val_mse: 897.1140 - val_mae: 29.9497\n",
      "Epoch 53/180\n",
      "65/65 [==============================] - 53s 817ms/step - loss: 986.8420 - mse: 986.8420 - mae: 31.2693 - val_loss: 1121.8059 - val_mse: 1121.8059 - val_mae: 33.4921\n",
      "Epoch 54/180\n",
      "65/65 [==============================] - 52s 797ms/step - loss: 996.7102 - mse: 996.7102 - mae: 31.4246 - val_loss: 1036.4996 - val_mse: 1036.4996 - val_mae: 32.1946\n",
      "Epoch 55/180\n",
      "65/65 [==============================] - 52s 798ms/step - loss: 1002.6670 - mse: 1002.6671 - mae: 31.4746 - val_loss: 916.6712 - val_mse: 916.6712 - val_mae: 30.2746\n",
      "Epoch 56/180\n",
      "65/65 [==============================] - 53s 815ms/step - loss: 1002.5689 - mse: 1002.5689 - mae: 31.5314 - val_loss: 836.9182 - val_mse: 836.9182 - val_mae: 28.9289\n",
      "Epoch 57/180\n",
      "65/65 [==============================] - 53s 813ms/step - loss: 992.2982 - mse: 992.2982 - mae: 31.2744 - val_loss: 978.3297 - val_mse: 978.3297 - val_mae: 31.2782\n",
      "Epoch 58/180\n",
      "65/65 [==============================] - 52s 803ms/step - loss: 982.8771 - mse: 982.8771 - mae: 31.1364 - val_loss: 1075.5153 - val_mse: 1075.5153 - val_mae: 32.7950\n",
      "Epoch 59/180\n",
      "65/65 [==============================] - 51s 787ms/step - loss: 995.3190 - mse: 995.3190 - mae: 31.3587 - val_loss: 1061.0209 - val_mse: 1061.0209 - val_mae: 32.5718\n",
      "Epoch 60/180\n",
      "65/65 [==============================] - 51s 792ms/step - loss: 1010.0369 - mse: 1010.0369 - mae: 31.6292 - val_loss: 1038.7043 - val_mse: 1038.7045 - val_mae: 32.2288\n",
      "Epoch 61/180\n",
      "65/65 [==============================] - 52s 796ms/step - loss: 986.4962 - mse: 986.4962 - mae: 31.2679 - val_loss: 1045.5170 - val_mse: 1045.5170 - val_mae: 32.3342\n",
      "Epoch 62/180\n",
      "65/65 [==============================] - 51s 785ms/step - loss: 995.3730 - mse: 995.3730 - mae: 31.4328 - val_loss: 1110.0326 - val_mse: 1110.0326 - val_mae: 33.3171\n",
      "Epoch 63/180\n",
      "65/65 [==============================] - 52s 803ms/step - loss: 1002.3099 - mse: 1002.3099 - mae: 31.5386 - val_loss: 962.9328 - val_mse: 962.9328 - val_mae: 31.0309\n",
      "Epoch 64/180\n",
      "65/65 [==============================] - 51s 789ms/step - loss: 989.7925 - mse: 989.7925 - mae: 31.3346 - val_loss: 1019.7422 - val_mse: 1019.7422 - val_mae: 31.9334\n",
      "Epoch 65/180\n",
      "65/65 [==============================] - 51s 788ms/step - loss: 989.7242 - mse: 989.7242 - mae: 31.3318 - val_loss: 1214.1688 - val_mse: 1214.1688 - val_mae: 34.8449\n",
      "Epoch 66/180\n",
      "65/65 [==============================] - 51s 788ms/step - loss: 1008.3902 - mse: 1008.3902 - mae: 31.6099 - val_loss: 1089.8046 - val_mse: 1089.8046 - val_mae: 33.0121\n",
      "Epoch 67/180\n",
      "65/65 [==============================] - 51s 791ms/step - loss: 986.9506 - mse: 986.9506 - mae: 31.2863 - val_loss: 1159.9703 - val_mse: 1159.9702 - val_mae: 34.0581\n",
      "Epoch 68/180\n",
      "65/65 [==============================] - 51s 792ms/step - loss: 1001.5807 - mse: 1001.5807 - mae: 31.5084 - val_loss: 865.5174 - val_mse: 865.5174 - val_mae: 29.4153\n",
      "Epoch 69/180\n",
      "65/65 [==============================] - 52s 799ms/step - loss: 994.2815 - mse: 994.2815 - mae: 31.4002 - val_loss: 865.0894 - val_mse: 865.0894 - val_mae: 29.4123\n",
      "Epoch 70/180\n",
      "65/65 [==============================] - 51s 792ms/step - loss: 1003.9888 - mse: 1003.9888 - mae: 31.5117 - val_loss: 959.6849 - val_mse: 959.6849 - val_mae: 30.9767\n",
      "Epoch 71/180\n",
      "65/65 [==============================] - 51s 784ms/step - loss: 994.0612 - mse: 994.0612 - mae: 31.3759 - val_loss: 788.2722 - val_mse: 788.2722 - val_mae: 28.0758\n",
      "Epoch 72/180\n",
      "65/65 [==============================] - 50s 768ms/step - loss: 1002.5029 - mse: 1002.5029 - mae: 31.5206 - val_loss: 887.6744 - val_mse: 887.6744 - val_mae: 29.7935\n",
      "Epoch 73/180\n",
      "65/65 [==============================] - 51s 784ms/step - loss: 984.6730 - mse: 984.6730 - mae: 31.2173 - val_loss: 1164.4390 - val_mse: 1164.4391 - val_mae: 34.1237\n",
      "Epoch 74/180\n",
      "65/65 [==============================] - 51s 784ms/step - loss: 1001.5704 - mse: 1001.5704 - mae: 31.4844 - val_loss: 892.2755 - val_mse: 892.2755 - val_mae: 29.8697\n",
      "Epoch 75/180\n",
      "65/65 [==============================] - 50s 776ms/step - loss: 994.4244 - mse: 994.4244 - mae: 31.4116 - val_loss: 1050.2209 - val_mse: 1050.2209 - val_mae: 32.4071\n",
      "Epoch 76/180\n",
      "65/65 [==============================] - 50s 773ms/step - loss: 1004.9561 - mse: 1004.9561 - mae: 31.5829 - val_loss: 837.4034 - val_mse: 837.4034 - val_mae: 28.9351\n",
      "Epoch 77/180\n",
      "65/65 [==============================] - 53s 809ms/step - loss: 990.0201 - mse: 990.0201 - mae: 31.3240 - val_loss: 852.2245 - val_mse: 852.2245 - val_mae: 29.1919\n",
      "Epoch 78/180\n",
      "65/65 [==============================] - 51s 788ms/step - loss: 1002.0788 - mse: 1002.0788 - mae: 31.4871 - val_loss: 1079.1912 - val_mse: 1079.1912 - val_mae: 32.8493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/180\n",
      "65/65 [==============================] - 53s 809ms/step - loss: 994.5077 - mse: 994.5077 - mae: 31.3859 - val_loss: 888.8495 - val_mse: 888.8495 - val_mae: 29.8135\n",
      "Epoch 80/180\n",
      "65/65 [==============================] - 52s 799ms/step - loss: 1001.8018 - mse: 1001.8018 - mae: 31.5233 - val_loss: 958.3121 - val_mse: 958.3121 - val_mae: 30.9557\n",
      "Epoch 81/180\n",
      "65/65 [==============================] - 52s 795ms/step - loss: 1000.0753 - mse: 1000.0753 - mae: 31.4313 - val_loss: 950.5861 - val_mse: 950.5861 - val_mae: 30.8312\n",
      "Epoch 82/180\n",
      "65/65 [==============================] - 50s 777ms/step - loss: 994.7231 - mse: 994.7231 - mae: 31.4336 - val_loss: 963.9595 - val_mse: 963.9595 - val_mae: 31.0475\n",
      "Epoch 83/180\n",
      "65/65 [==============================] - 51s 786ms/step - loss: 999.3581 - mse: 999.3581 - mae: 31.4722 - val_loss: 947.7867 - val_mse: 947.7867 - val_mae: 30.7860\n",
      "Epoch 84/180\n",
      "65/65 [==============================] - 52s 794ms/step - loss: 986.9896 - mse: 986.9896 - mae: 31.2094 - val_loss: 1122.2006 - val_mse: 1122.2006 - val_mae: 33.4991\n",
      "Epoch 85/180\n",
      "65/65 [==============================] - 51s 782ms/step - loss: 996.7588 - mse: 996.7588 - mae: 31.3337 - val_loss: 778.1366 - val_mse: 778.1366 - val_mae: 27.8949\n",
      "Epoch 86/180\n",
      "65/65 [==============================] - 51s 785ms/step - loss: 1007.5518 - mse: 1007.5518 - mae: 31.5972 - val_loss: 899.6667 - val_mse: 899.6667 - val_mae: 29.9944\n",
      "Epoch 87/180\n",
      "65/65 [==============================] - 51s 780ms/step - loss: 991.2115 - mse: 991.2115 - mae: 31.2849 - val_loss: 1150.5605 - val_mse: 1150.5605 - val_mae: 33.9185\n",
      "Epoch 88/180\n",
      "65/65 [==============================] - 51s 785ms/step - loss: 991.2890 - mse: 991.2890 - mae: 31.3197 - val_loss: 1050.0135 - val_mse: 1050.0135 - val_mae: 32.4037\n",
      "Epoch 89/180\n",
      "65/65 [==============================] - 52s 794ms/step - loss: 996.6906 - mse: 996.6906 - mae: 31.4501 - val_loss: 1077.5806 - val_mse: 1077.5806 - val_mae: 32.8259\n",
      "Epoch 90/180\n",
      "65/65 [==============================] - 52s 798ms/step - loss: 996.9185 - mse: 996.9185 - mae: 31.4655 - val_loss: 1116.9386 - val_mse: 1116.9386 - val_mae: 33.4199\n",
      "Epoch 91/180\n",
      "65/65 [==============================] - 54s 832ms/step - loss: 995.7917 - mse: 995.7917 - mae: 31.4025 - val_loss: 1185.6384 - val_mse: 1185.6384 - val_mae: 34.4328\n",
      "Epoch 92/180\n",
      "65/65 [==============================] - 53s 818ms/step - loss: 997.6804 - mse: 997.6804 - mae: 31.4462 - val_loss: 1016.6862 - val_mse: 1016.6862 - val_mae: 31.8823\n",
      "Epoch 93/180\n",
      "65/65 [==============================] - 54s 831ms/step - loss: 988.7817 - mse: 988.7817 - mae: 31.3192 - val_loss: 1087.1060 - val_mse: 1087.1060 - val_mae: 32.9712\n",
      "Epoch 94/180\n",
      "65/65 [==============================] - 52s 800ms/step - loss: 996.6301 - mse: 996.6301 - mae: 31.4493 - val_loss: 1184.1332 - val_mse: 1184.1332 - val_mae: 34.4111\n",
      "Epoch 95/180\n",
      "65/65 [==============================] - 52s 795ms/step - loss: 994.1709 - mse: 994.1709 - mae: 31.2172 - val_loss: 837.3265 - val_mse: 837.3265 - val_mae: 28.9365\n",
      "Epoch 96/180\n",
      "65/65 [==============================] - 51s 791ms/step - loss: 1010.9606 - mse: 1010.9606 - mae: 31.5881 - val_loss: 967.9884 - val_mse: 967.9884 - val_mae: 31.1119\n",
      "Epoch 97/180\n",
      "65/65 [==============================] - 52s 799ms/step - loss: 989.8701 - mse: 989.8701 - mae: 31.3048 - val_loss: 970.4714 - val_mse: 970.4714 - val_mae: 31.1523\n",
      "Epoch 98/180\n",
      "65/65 [==============================] - 52s 807ms/step - loss: 987.0417 - mse: 987.0417 - mae: 31.2848 - val_loss: 1010.5947 - val_mse: 1010.5947 - val_mae: 31.7898\n",
      "Epoch 99/180\n",
      "65/65 [==============================] - 51s 783ms/step - loss: 999.1481 - mse: 999.1481 - mae: 31.4893 - val_loss: 887.4905 - val_mse: 887.4905 - val_mae: 29.7904\n",
      "Epoch 100/180\n",
      "65/65 [==============================] - 52s 804ms/step - loss: 995.8768 - mse: 995.8768 - mae: 31.4365 - val_loss: 919.2960 - val_mse: 919.2960 - val_mae: 30.3198\n",
      "Epoch 101/180\n",
      "65/65 [==============================] - 53s 818ms/step - loss: 996.9670 - mse: 996.9670 - mae: 31.4493 - val_loss: 918.9074 - val_mse: 918.9074 - val_mae: 30.3118\n",
      "Epoch 102/180\n",
      "65/65 [==============================] - 53s 813ms/step - loss: 996.9982 - mse: 996.9982 - mae: 31.4095 - val_loss: 845.5197 - val_mse: 845.5197 - val_mae: 29.0763\n",
      "Epoch 103/180\n",
      "65/65 [==============================] - 53s 821ms/step - loss: 993.3844 - mse: 993.3844 - mae: 31.3917 - val_loss: 936.1235 - val_mse: 936.1235 - val_mae: 30.5944\n",
      "Epoch 104/180\n",
      "65/65 [==============================] - 54s 828ms/step - loss: 999.2177 - mse: 999.2177 - mae: 31.4647 - val_loss: 741.2051 - val_mse: 741.2051 - val_mae: 27.2251\n",
      "Epoch 105/180\n",
      "65/65 [==============================] - 54s 834ms/step - loss: 990.9760 - mse: 990.9760 - mae: 31.3347 - val_loss: 1108.0939 - val_mse: 1108.0939 - val_mae: 33.2880\n",
      "Epoch 106/180\n",
      "65/65 [==============================] - 53s 815ms/step - loss: 1004.9869 - mse: 1004.9869 - mae: 31.5641 - val_loss: 1244.2970 - val_mse: 1244.2970 - val_mae: 35.2744\n",
      "Epoch 107/180\n",
      "65/65 [==============================] - 54s 833ms/step - loss: 991.1885 - mse: 991.1885 - mae: 31.2961 - val_loss: 1045.1034 - val_mse: 1045.1034 - val_mae: 32.3277\n",
      "Epoch 108/180\n",
      "65/65 [==============================] - 53s 819ms/step - loss: 994.0673 - mse: 994.0672 - mae: 31.3366 - val_loss: 1271.8054 - val_mse: 1271.8054 - val_mae: 35.6624\n",
      "Epoch 109/180\n",
      "65/65 [==============================] - 53s 814ms/step - loss: 1001.4446 - mse: 1001.4446 - mae: 31.4642 - val_loss: 679.4285 - val_mse: 679.4285 - val_mae: 26.0640\n",
      "Epoch 110/180\n",
      "65/65 [==============================] - 53s 819ms/step - loss: 992.7725 - mse: 992.7725 - mae: 31.3561 - val_loss: 1103.2112 - val_mse: 1103.2112 - val_mae: 33.2146\n",
      "Epoch 111/180\n",
      "65/65 [==============================] - 54s 828ms/step - loss: 996.1124 - mse: 996.1124 - mae: 31.4515 - val_loss: 1014.4933 - val_mse: 1014.4933 - val_mae: 31.8506\n",
      "Epoch 112/180\n",
      "65/65 [==============================] - 53s 819ms/step - loss: 998.6060 - mse: 998.6060 - mae: 31.4678 - val_loss: 873.0515 - val_mse: 873.0515 - val_mae: 29.5474\n",
      "Epoch 113/180\n",
      "65/65 [==============================] - 54s 833ms/step - loss: 997.3345 - mse: 997.3345 - mae: 31.4272 - val_loss: 972.7413 - val_mse: 972.7413 - val_mae: 31.1880\n",
      "Epoch 114/180\n",
      "65/65 [==============================] - 54s 831ms/step - loss: 996.1475 - mse: 996.1475 - mae: 31.4133 - val_loss: 986.3926 - val_mse: 986.3926 - val_mae: 31.4057\n",
      "Epoch 115/180\n",
      "65/65 [==============================] - 53s 817ms/step - loss: 999.0310 - mse: 999.0310 - mae: 31.4947 - val_loss: 815.9172 - val_mse: 815.9172 - val_mae: 28.5637\n",
      "Epoch 116/180\n",
      "65/65 [==============================] - 54s 836ms/step - loss: 994.5977 - mse: 994.5977 - mae: 31.4058 - val_loss: 1125.4984 - val_mse: 1125.4984 - val_mae: 33.5464\n",
      "Epoch 117/180\n",
      "65/65 [==============================] - 54s 829ms/step - loss: 993.0311 - mse: 993.0311 - mae: 31.3722 - val_loss: 902.1977 - val_mse: 902.1977 - val_mae: 30.0366\n",
      "Epoch 118/180\n",
      "65/65 [==============================] - 53s 815ms/step - loss: 1005.2525 - mse: 1005.2525 - mae: 31.5634 - val_loss: 1026.2971 - val_mse: 1026.2971 - val_mae: 32.0313\n",
      "Epoch 119/180\n",
      "65/65 [==============================] - 53s 809ms/step - loss: 1000.8663 - mse: 1000.8663 - mae: 31.4214 - val_loss: 867.5361 - val_mse: 867.5361 - val_mae: 29.4539\n",
      "Epoch 120/180\n",
      "65/65 [==============================] - 52s 805ms/step - loss: 990.9388 - mse: 990.9388 - mae: 31.3376 - val_loss: 690.6467 - val_mse: 690.6467 - val_mae: 26.2797\n",
      "Epoch 121/180\n",
      "65/65 [==============================] - 52s 800ms/step - loss: 996.4851 - mse: 996.4851 - mae: 31.2970 - val_loss: 934.1066 - val_mse: 934.1066 - val_mae: 30.5631\n",
      "Epoch 122/180\n",
      "65/65 [==============================] - 52s 795ms/step - loss: 999.1827 - mse: 999.1827 - mae: 31.4433 - val_loss: 873.4378 - val_mse: 873.4378 - val_mae: 29.5536\n",
      "Epoch 123/180\n",
      "65/65 [==============================] - 51s 785ms/step - loss: 994.3146 - mse: 994.3146 - mae: 31.3806 - val_loss: 906.4573 - val_mse: 906.4573 - val_mae: 30.1074\n",
      "Epoch 124/180\n",
      "65/65 [==============================] - 51s 786ms/step - loss: 992.8551 - mse: 992.8551 - mae: 31.3904 - val_loss: 977.9077 - val_mse: 977.9077 - val_mae: 31.2711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125/180\n",
      "65/65 [==============================] - 53s 813ms/step - loss: 995.5456 - mse: 995.5456 - mae: 31.4280 - val_loss: 1161.0590 - val_mse: 1161.0590 - val_mae: 34.0743\n",
      "Epoch 126/180\n",
      "65/65 [==============================] - 52s 796ms/step - loss: 1001.4174 - mse: 1001.4174 - mae: 31.5055 - val_loss: 920.1736 - val_mse: 920.1736 - val_mae: 30.3343\n",
      "Epoch 127/180\n",
      "65/65 [==============================] - 52s 799ms/step - loss: 999.1029 - mse: 999.1029 - mae: 31.4893 - val_loss: 770.5702 - val_mse: 770.5702 - val_mae: 27.7578\n",
      "Epoch 128/180\n",
      "65/65 [==============================] - 52s 801ms/step - loss: 996.1179 - mse: 996.1179 - mae: 31.3966 - val_loss: 1036.6444 - val_mse: 1036.6444 - val_mae: 32.1967\n",
      "Epoch 129/180\n",
      "65/65 [==============================] - 53s 810ms/step - loss: 984.5162 - mse: 984.5162 - mae: 31.2182 - val_loss: 955.0888 - val_mse: 955.0888 - val_mae: 30.9041\n",
      "Epoch 130/180\n",
      "65/65 [==============================] - 51s 779ms/step - loss: 1004.0728 - mse: 1004.0727 - mae: 31.5364 - val_loss: 841.8456 - val_mse: 841.8456 - val_mae: 29.0146\n",
      "Epoch 131/180\n",
      "65/65 [==============================] - 52s 800ms/step - loss: 990.4849 - mse: 990.4849 - mae: 31.3281 - val_loss: 979.0818 - val_mse: 979.0818 - val_mae: 31.2822\n",
      "Epoch 132/180\n",
      "65/65 [==============================] - 51s 787ms/step - loss: 1002.7931 - mse: 1002.7933 - mae: 31.5345 - val_loss: 975.7327 - val_mse: 975.7327 - val_mae: 31.2367\n",
      "Epoch 133/180\n",
      "65/65 [==============================] - 51s 781ms/step - loss: 993.0661 - mse: 993.0661 - mae: 31.3895 - val_loss: 897.6232 - val_mse: 897.6232 - val_mae: 29.9598\n",
      "Epoch 134/180\n",
      "65/65 [==============================] - 51s 791ms/step - loss: 1003.3318 - mse: 1003.3318 - mae: 31.5590 - val_loss: 872.4473 - val_mse: 872.4473 - val_mae: 29.5369\n",
      "Epoch 135/180\n",
      "65/65 [==============================] - 51s 790ms/step - loss: 988.8162 - mse: 988.8162 - mae: 31.3057 - val_loss: 1258.9119 - val_mse: 1258.9119 - val_mae: 35.4805\n",
      "Epoch 136/180\n",
      "65/65 [==============================] - 52s 794ms/step - loss: 994.8220 - mse: 994.8220 - mae: 31.4201 - val_loss: 1001.7549 - val_mse: 1001.7549 - val_mae: 31.6459\n",
      "Epoch 137/180\n",
      "65/65 [==============================] - 52s 798ms/step - loss: 1001.7451 - mse: 1001.7451 - mae: 31.4897 - val_loss: 885.8600 - val_mse: 885.8600 - val_mae: 29.7634\n",
      "Epoch 138/180\n",
      "65/65 [==============================] - 53s 808ms/step - loss: 993.2650 - mse: 993.2650 - mae: 31.3452 - val_loss: 993.0192 - val_mse: 993.0192 - val_mae: 31.5110\n",
      "Epoch 139/180\n",
      "65/65 [==============================] - 51s 778ms/step - loss: 991.6941 - mse: 991.6941 - mae: 31.3666 - val_loss: 888.2902 - val_mse: 888.2902 - val_mae: 29.8033\n",
      "Epoch 140/180\n",
      "65/65 [==============================] - 51s 780ms/step - loss: 1005.0012 - mse: 1005.0012 - mae: 31.5765 - val_loss: 885.5776 - val_mse: 885.5776 - val_mae: 29.7564\n",
      "Epoch 141/180\n",
      "65/65 [==============================] - 51s 785ms/step - loss: 990.4419 - mse: 990.4419 - mae: 31.2907 - val_loss: 1058.9507 - val_mse: 1058.9507 - val_mae: 32.5410\n",
      "Epoch 142/180\n",
      "65/65 [==============================] - 51s 787ms/step - loss: 991.9414 - mse: 991.9414 - mae: 31.3635 - val_loss: 872.8570 - val_mse: 872.8570 - val_mae: 29.5428\n",
      "Epoch 143/180\n",
      "65/65 [==============================] - 51s 781ms/step - loss: 999.6516 - mse: 999.6516 - mae: 31.4437 - val_loss: 982.9358 - val_mse: 982.9358 - val_mae: 31.3514\n",
      "Epoch 144/180\n",
      "65/65 [==============================] - 51s 783ms/step - loss: 1002.6413 - mse: 1002.6413 - mae: 31.5251 - val_loss: 1038.0458 - val_mse: 1038.0458 - val_mae: 32.2160\n",
      "Epoch 145/180\n",
      "65/65 [==============================] - 53s 815ms/step - loss: 985.3994 - mse: 985.3994 - mae: 31.2038 - val_loss: 846.5232 - val_mse: 846.5232 - val_mae: 29.0943\n",
      "Epoch 146/180\n",
      "65/65 [==============================] - 52s 799ms/step - loss: 992.4688 - mse: 992.4688 - mae: 31.3413 - val_loss: 888.6922 - val_mse: 888.6922 - val_mae: 29.8109\n",
      "Epoch 147/180\n",
      "65/65 [==============================] - 53s 819ms/step - loss: 999.6179 - mse: 999.6179 - mae: 31.4730 - val_loss: 964.9911 - val_mse: 964.9911 - val_mae: 31.0630\n",
      "Epoch 148/180\n",
      "65/65 [==============================] - 53s 808ms/step - loss: 993.6089 - mse: 993.6089 - mae: 31.3924 - val_loss: 1089.1267 - val_mse: 1089.1267 - val_mae: 33.0005\n",
      "Epoch 149/180\n",
      "65/65 [==============================] - 52s 806ms/step - loss: 1002.7321 - mse: 1002.7321 - mae: 31.5466 - val_loss: 916.0681 - val_mse: 916.0681 - val_mae: 30.2654\n",
      "Epoch 150/180\n",
      "65/65 [==============================] - 52s 796ms/step - loss: 1002.3521 - mse: 1002.3520 - mae: 31.5267 - val_loss: 913.6816 - val_mse: 913.6816 - val_mae: 30.2270\n",
      "Epoch 151/180\n",
      "65/65 [==============================] - 51s 789ms/step - loss: 984.7684 - mse: 984.7684 - mae: 31.2408 - val_loss: 877.2779 - val_mse: 877.2779 - val_mae: 29.6181\n",
      "Epoch 152/180\n",
      "65/65 [==============================] - 52s 802ms/step - loss: 1008.6902 - mse: 1008.6902 - mae: 31.5787 - val_loss: 1067.4844 - val_mse: 1067.4844 - val_mae: 32.6673\n",
      "Epoch 153/180\n",
      "65/65 [==============================] - 51s 778ms/step - loss: 994.4631 - mse: 994.4631 - mae: 31.3972 - val_loss: 941.2846 - val_mse: 941.2846 - val_mae: 30.6802\n",
      "Epoch 154/180\n",
      "65/65 [==============================] - 51s 785ms/step - loss: 997.4660 - mse: 997.4660 - mae: 31.4339 - val_loss: 898.6719 - val_mse: 898.6719 - val_mae: 29.9777\n",
      "Epoch 155/180\n",
      "65/65 [==============================] - 51s 786ms/step - loss: 995.3885 - mse: 995.3885 - mae: 31.4188 - val_loss: 981.6946 - val_mse: 981.6946 - val_mae: 31.3320\n",
      "Epoch 156/180\n",
      "65/65 [==============================] - 51s 792ms/step - loss: 999.5530 - mse: 999.5530 - mae: 31.4776 - val_loss: 1068.0121 - val_mse: 1068.0121 - val_mae: 32.6798\n",
      "Epoch 157/180\n",
      "65/65 [==============================] - 51s 791ms/step - loss: 992.9856 - mse: 992.9856 - mae: 31.3851 - val_loss: 1156.4164 - val_mse: 1156.4164 - val_mae: 34.0057\n",
      "Epoch 158/180\n",
      "65/65 [==============================] - 52s 803ms/step - loss: 992.8843 - mse: 992.8843 - mae: 31.3800 - val_loss: 1008.7311 - val_mse: 1008.7311 - val_mae: 31.7603\n",
      "Epoch 159/180\n",
      "65/65 [==============================] - 54s 827ms/step - loss: 1004.9684 - mse: 1004.9684 - mae: 31.5618 - val_loss: 783.2213 - val_mse: 783.2213 - val_mae: 27.9861\n",
      "Epoch 160/180\n",
      "65/65 [==============================] - 52s 796ms/step - loss: 992.0868 - mse: 992.0868 - mae: 31.3590 - val_loss: 1169.3035 - val_mse: 1169.3035 - val_mae: 34.1948\n",
      "Epoch 161/180\n",
      "65/65 [==============================] - 52s 797ms/step - loss: 1005.9763 - mse: 1005.9763 - mae: 31.4939 - val_loss: 759.6095 - val_mse: 759.6095 - val_mae: 27.5601\n",
      "Epoch 162/180\n",
      "65/65 [==============================] - 52s 797ms/step - loss: 988.2654 - mse: 988.2654 - mae: 31.2399 - val_loss: 1125.8951 - val_mse: 1125.8951 - val_mae: 33.5543\n",
      "Epoch 163/180\n",
      "65/65 [==============================] - 51s 780ms/step - loss: 1007.8044 - mse: 1007.8044 - mae: 31.6091 - val_loss: 1068.5330 - val_mse: 1068.5330 - val_mae: 32.6884\n",
      "Epoch 164/180\n",
      "65/65 [==============================] - 52s 793ms/step - loss: 991.6693 - mse: 991.6693 - mae: 31.3687 - val_loss: 956.3947 - val_mse: 956.3947 - val_mae: 30.9248\n",
      "Epoch 165/180\n",
      "65/65 [==============================] - 52s 799ms/step - loss: 988.1732 - mse: 988.1732 - mae: 31.3243 - val_loss: 1119.9333 - val_mse: 1119.9333 - val_mae: 33.4651\n",
      "Epoch 166/180\n",
      "65/65 [==============================] - 53s 815ms/step - loss: 1004.5290 - mse: 1004.5290 - mae: 31.5646 - val_loss: 851.5513 - val_mse: 851.5513 - val_mae: 29.1811\n",
      "Epoch 167/180\n",
      "65/65 [==============================] - 53s 809ms/step - loss: 992.8436 - mse: 992.8436 - mae: 31.3318 - val_loss: 894.5357 - val_mse: 894.5357 - val_mae: 29.9062\n",
      "Epoch 168/180\n",
      "65/65 [==============================] - 52s 803ms/step - loss: 993.0312 - mse: 993.0312 - mae: 31.3911 - val_loss: 927.7712 - val_mse: 927.7712 - val_mae: 30.4593\n",
      "Epoch 169/180\n",
      "65/65 [==============================] - 51s 791ms/step - loss: 1001.0023 - mse: 1001.0023 - mae: 31.5184 - val_loss: 994.3414 - val_mse: 994.3414 - val_mae: 31.5330\n",
      "Epoch 170/180\n",
      "65/65 [==============================] - 54s 825ms/step - loss: 989.4408 - mse: 989.4408 - mae: 31.3173 - val_loss: 1259.9537 - val_mse: 1259.9537 - val_mae: 35.4934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 171/180\n",
      "65/65 [==============================] - 53s 813ms/step - loss: 1000.1096 - mse: 1000.1094 - mae: 31.4761 - val_loss: 1067.3875 - val_mse: 1067.3875 - val_mae: 32.6699\n",
      "Epoch 172/180\n",
      "65/65 [==============================] - 53s 816ms/step - loss: 994.2800 - mse: 994.2800 - mae: 31.3946 - val_loss: 1057.3909 - val_mse: 1057.3909 - val_mae: 32.5174\n",
      "Epoch 173/180\n",
      "65/65 [==============================] - 53s 808ms/step - loss: 997.6727 - mse: 997.6727 - mae: 31.4377 - val_loss: 1054.2012 - val_mse: 1054.2012 - val_mae: 32.4682\n",
      "Epoch 174/180\n",
      "65/65 [==============================] - 51s 783ms/step - loss: 992.0836 - mse: 992.0836 - mae: 31.3356 - val_loss: 960.5771 - val_mse: 960.5771 - val_mae: 30.9916\n",
      "Epoch 175/180\n",
      "65/65 [==============================] - 50s 774ms/step - loss: 1004.5898 - mse: 1004.5898 - mae: 31.5382 - val_loss: 1103.0768 - val_mse: 1103.0768 - val_mae: 33.2125\n",
      "Epoch 176/180\n",
      "65/65 [==============================] - 51s 792ms/step - loss: 991.3817 - mse: 991.3817 - mae: 31.3259 - val_loss: 942.7054 - val_mse: 942.7054 - val_mae: 30.7030\n",
      "Epoch 177/180\n",
      "65/65 [==============================] - 51s 788ms/step - loss: 1004.6430 - mse: 1004.6430 - mae: 31.5269 - val_loss: 1166.5780 - val_mse: 1166.5780 - val_mae: 34.1551\n",
      "Epoch 178/180\n",
      "65/65 [==============================] - 51s 787ms/step - loss: 995.9842 - mse: 995.9842 - mae: 31.4234 - val_loss: 1041.5140 - val_mse: 1041.5140 - val_mae: 32.2724\n",
      "Epoch 179/180\n",
      "65/65 [==============================] - 53s 815ms/step - loss: 991.5222 - mse: 991.5222 - mae: 31.3671 - val_loss: 856.7369 - val_mse: 856.7369 - val_mae: 29.2700\n",
      "Epoch 180/180\n",
      "65/65 [==============================] - 54s 827ms/step - loss: 996.5905 - mse: 996.5905 - mae: 31.4045 - val_loss: 1280.4609 - val_mse: 1280.4609 - val_mae: 35.7835\n"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "steps = 96\n",
    "n_hidden = 1\n",
    "units = 150\n",
    "batch_size = 96\n",
    "\n",
    "# parameters:\n",
    "learning_range =  [0.0001, 0.001, 0.01, 0.1, 1]\n",
    "\n",
    "\n",
    "# function to split data into correct shape for RNN\n",
    "def split_data(X, y, steps):\n",
    "    X_, y_ = list(), list()\n",
    "    for i in range(steps, len(y)):\n",
    "        X_.append(X[i - steps : i, :])\n",
    "        y_.append(y[i]) \n",
    "    return np.array(X_), np.array(y_)\n",
    "\n",
    "# function to cut data set so it can be divisible by the batch_size\n",
    "def cut_data(data, batch_size):\n",
    "     # see if it is divisivel\n",
    "    condition = data.shape[0] % batch_size\n",
    "    if condition == 0:\n",
    "        return data\n",
    "    else:\n",
    "        return data[: -condition]\n",
    "\n",
    "# divide features and labels\n",
    "X_train = data_train[:, 0:15] \n",
    "y_train = data_train[:, -1]\n",
    "X_test = data_test[:, 0:15] \n",
    "y_test = data_test[:, -1] \n",
    "\n",
    "# divide data into train and test \n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "         X_train, y_train, test_size = 0.15, shuffle=False)\n",
    "\n",
    "# put data into correct shape\n",
    "X_train, y_train = split_data(X_train, y_train, steps)\n",
    "X_test, y_test = split_data(X_test, y_test, steps)\n",
    "X_val, y_val = split_data(X_val, y_val, steps)\n",
    "\n",
    "X_train = cut_data(X_train, batch_size)\n",
    "y_train = cut_data(y_train, batch_size)\n",
    "X_test = cut_data(X_test, batch_size)\n",
    "y_test = cut_data(y_test, batch_size)\n",
    "X_val = cut_data(X_val, batch_size)\n",
    "y_val = cut_data(y_val, batch_size)\n",
    "\n",
    "# inverse of test set should not be inside the loop \n",
    "y_test = (y_test * sc_X.data_range_[15]) + (sc_X.data_min_[15])\n",
    "               \n",
    "for i in learning_range:\n",
    "    \n",
    "    # design the LSTM\n",
    "    def regressor_tunning(kernel_initializer = 'he_normal',\n",
    "                          bias_initializer = initializers.Ones()):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        if n_hidden == 0:\n",
    "            model.add(LSTM(units = units,                    \n",
    "                           batch_input_shape = (batch_size, steps, features_num), \n",
    "                           stateful = True,\n",
    "                           kernel_initializer = kernel_initializer,\n",
    "                           bias_initializer = bias_initializer))\n",
    "            model.add(LeakyReLU(alpha = 0.2))\n",
    "            model.add(Dropout(0.2))\n",
    "        else:\n",
    "            model.add(LSTM(units = units,                    \n",
    "                           batch_input_shape = (batch_size, steps, features_num), \n",
    "                           stateful = True,\n",
    "                           return_sequences = True,\n",
    "                           kernel_initializer = kernel_initializer,\n",
    "                           bias_initializer = bias_initializer))\n",
    "            model.add(LeakyReLU(alpha = 0.2))\n",
    "            model.add(Dropout(0.2))\n",
    "            model.add(LSTM(units = units, \n",
    "                           batch_input_shape = (batch_size, steps, features_num), \n",
    "                           stateful = True,\n",
    "                           kernel_initializer = kernel_initializer,\n",
    "                           bias_initializer = bias_initializer))\n",
    "            model.add(LeakyReLU(alpha = 0.2))\n",
    "            model.add(Dropout(0.2))\n",
    "        model.add(Dense(1, activation='linear'))\n",
    "        optimizer = optimizers.RMSprop(lr = i)\n",
    "        model.compile(loss = 'mse', metrics = ['mse', 'mae'], optimizer = optimizer)\n",
    "        return model\n",
    "\n",
    "    model = regressor_tunning()\n",
    "\n",
    "    # fitting the LSTM to the training set\n",
    "    history = model.fit(X_train,\n",
    "                        y_train, \n",
    "                        batch_size = batch_size, \n",
    "                        epochs = 180,\n",
    "                        shuffle = False, \n",
    "                        validation_data = (X_val, y_val))\n",
    "    \n",
    "    model.reset_states()\n",
    "    \n",
    "    # make new predicitons with test set\n",
    "    y_pred = model.predict(X_test, batch_size = batch_size)\n",
    "    \n",
    "    # prices col = 15\n",
    "    y_pred = (y_pred * sc_X.data_range_[15]) + (sc_X.data_min_[15])\n",
    "\n",
    "    y_pred_list.append(y_pred)\n",
    "    \n",
    "    from sklearn.metrics import mean_squared_error as mse\n",
    "    from sklearn.metrics import mean_absolute_error as mae\n",
    "\n",
    "    rmse_error = mse(y_test, y_pred, squared = False)\n",
    "    mae_error = mae(y_test, y_pred)\n",
    "    \n",
    "    rmse_gen.append(rmse_error)\n",
    "    mae_gen.append(mae_error)\n",
    "    \n",
    "    # =============================================================================\n",
    "    # Metrics evaluation on spike regions\n",
    "    # =============================================================================\n",
    "    \n",
    "    y_spike_occ = pd.read_csv('Spike_binary_1std.csv', usecols = [6])\n",
    "    \n",
    "    # create array same size as y_test\n",
    "    y_spike_occ = y_spike_occ.iloc[- len(y_test):]\n",
    "    y_spike_occ = pd.Series(y_spike_occ.iloc[:,0]).values\n",
    "    \n",
    "    # smal adjustment\n",
    "    y_test = pd.Series(y_test)\n",
    "    y_test.replace(0, 0.0001,inplace = True)\n",
    "\n",
    "    # select y_pred and y_test only for regions with spikes\n",
    "    y_test_spike = (y_test.T * y_spike_occ).T\n",
    "    y_pred_spike = (y_pred.T * y_spike_occ).T\n",
    "    y_test_spike = y_test_spike[y_test_spike != 0]\n",
    "    y_pred_spike = y_pred_spike[y_pred_spike != 0]\n",
    "    \n",
    "    # calculate metric\n",
    "    rmse_spike = mse(y_test_spike, y_pred_spike, squared = False)\n",
    "    mae_spike = mae(y_test_spike, y_pred_spike)\n",
    "    \n",
    "    rmse_spi.append(rmse_spike)\n",
    "    mae_spi.append(mae_spike)\n",
    "    \n",
    "    # =============================================================================\n",
    "    # Metric evaluation on normal regions\n",
    "    # =============================================================================\n",
    "    \n",
    "    # inverse y_spike_occ so the only normal occurences are chosen\n",
    "    y_normal_occ = (y_spike_occ - 1) * (-1)\n",
    "    \n",
    "    # sanity check\n",
    "    y_normal_occ.sum() + y_spike_occ.sum() # gives the correct total \n",
    "    \n",
    "    # select y_pred and y_test only for normal regions\n",
    "    y_test_normal = (y_test.T * y_normal_occ).T\n",
    "    y_pred_normal = (y_pred.T * y_normal_occ).T\n",
    "    y_test_normal = y_test_normal[y_test_normal != 0.00]\n",
    "    y_pred_normal = y_pred_normal[y_pred_normal != 0.00]\n",
    "    \n",
    "    # calculate metric\n",
    "    rmse_normal = mse(y_test_normal, y_pred_normal, squared = False)\n",
    "    mae_normal = mae(y_test_normal, y_pred_normal)\n",
    "    \n",
    "    rmse_nor.append(rmse_normal)\n",
    "    mae_nor.append(mae_normal)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse_general</th>\n",
       "      <th>mae_general</th>\n",
       "      <th>rmse_spike</th>\n",
       "      <th>mae_spike</th>\n",
       "      <th>rmse_normal</th>\n",
       "      <th>mae_normal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0001</th>\n",
       "      <td>32.601976</td>\n",
       "      <td>20.337302</td>\n",
       "      <td>29.907247</td>\n",
       "      <td>19.861724</td>\n",
       "      <td>32.983513</td>\n",
       "      <td>20.407951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0010</th>\n",
       "      <td>33.070140</td>\n",
       "      <td>22.769643</td>\n",
       "      <td>29.792108</td>\n",
       "      <td>22.155887</td>\n",
       "      <td>33.529777</td>\n",
       "      <td>22.860819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0100</th>\n",
       "      <td>33.846575</td>\n",
       "      <td>17.150002</td>\n",
       "      <td>29.830015</td>\n",
       "      <td>15.918361</td>\n",
       "      <td>34.403270</td>\n",
       "      <td>17.332968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1000</th>\n",
       "      <td>4404.038809</td>\n",
       "      <td>4403.913695</td>\n",
       "      <td>4400.573603</td>\n",
       "      <td>4400.473635</td>\n",
       "      <td>4404.553347</td>\n",
       "      <td>4404.424731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0000</th>\n",
       "      <td>53658.562148</td>\n",
       "      <td>53658.551879</td>\n",
       "      <td>53655.120017</td>\n",
       "      <td>53655.111818</td>\n",
       "      <td>53659.073472</td>\n",
       "      <td>53659.062915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        rmse_general   mae_general    rmse_spike     mae_spike   rmse_normal  \\\n",
       "0.0001     32.601976     20.337302     29.907247     19.861724     32.983513   \n",
       "0.0010     33.070140     22.769643     29.792108     22.155887     33.529777   \n",
       "0.0100     33.846575     17.150002     29.830015     15.918361     34.403270   \n",
       "0.1000   4404.038809   4403.913695   4400.573603   4400.473635   4404.553347   \n",
       "1.0000  53658.562148  53658.551879  53655.120017  53655.111818  53659.073472   \n",
       "\n",
       "          mae_normal  \n",
       "0.0001     20.407951  \n",
       "0.0010     22.860819  \n",
       "0.0100     17.332968  \n",
       "0.1000   4404.424731  \n",
       "1.0000  53659.062915  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({                      \n",
    "                        'rmse_general': rmse_gen, \n",
    "                 \n",
    "                        'mae_general': mae_gen,\n",
    "                        \n",
    "                        'rmse_spike': rmse_spi,\n",
    "                 \n",
    "                        'mae_spike': mae_spi,\n",
    "                        \n",
    "                        'rmse_normal': rmse_nor,\n",
    "                    \n",
    "                        'mae_normal': mae_nor}, index = learning_range)\n",
    "\n",
    "results.to_csv('Results_LSTM_4_learning_rate.csv')\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_0ce1e6f6_d0b0_11ea_8877_7cb27da2bf47row0_col0 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_0ce1e6f6_d0b0_11ea_8877_7cb27da2bf47row0_col4 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_0ce1e6f6_d0b0_11ea_8877_7cb27da2bf47row1_col2 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_0ce1e6f6_d0b0_11ea_8877_7cb27da2bf47row2_col1 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_0ce1e6f6_d0b0_11ea_8877_7cb27da2bf47row2_col3 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_0ce1e6f6_d0b0_11ea_8877_7cb27da2bf47row2_col5 {\n",
       "            background-color:  yellow;\n",
       "        }</style><table id=\"T_0ce1e6f6_d0b0_11ea_8877_7cb27da2bf47\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >rmse_general</th>        <th class=\"col_heading level0 col1\" >mae_general</th>        <th class=\"col_heading level0 col2\" >rmse_spike</th>        <th class=\"col_heading level0 col3\" >mae_spike</th>        <th class=\"col_heading level0 col4\" >rmse_normal</th>        <th class=\"col_heading level0 col5\" >mae_normal</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_0ce1e6f6_d0b0_11ea_8877_7cb27da2bf47level0_row0\" class=\"row_heading level0 row0\" >0.0001</th>\n",
       "                        <td id=\"T_0ce1e6f6_d0b0_11ea_8877_7cb27da2bf47row0_col0\" class=\"data row0 col0\" >32.601976</td>\n",
       "                        <td id=\"T_0ce1e6f6_d0b0_11ea_8877_7cb27da2bf47row0_col1\" class=\"data row0 col1\" >20.337302</td>\n",
       "                        <td id=\"T_0ce1e6f6_d0b0_11ea_8877_7cb27da2bf47row0_col2\" class=\"data row0 col2\" >29.907247</td>\n",
       "                        <td id=\"T_0ce1e6f6_d0b0_11ea_8877_7cb27da2bf47row0_col3\" class=\"data row0 col3\" >19.861724</td>\n",
       "                        <td id=\"T_0ce1e6f6_d0b0_11ea_8877_7cb27da2bf47row0_col4\" class=\"data row0 col4\" >32.983513</td>\n",
       "                        <td id=\"T_0ce1e6f6_d0b0_11ea_8877_7cb27da2bf47row0_col5\" class=\"data row0 col5\" >20.407951</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0ce1e6f6_d0b0_11ea_8877_7cb27da2bf47level0_row1\" class=\"row_heading level0 row1\" >0.001</th>\n",
       "                        <td id=\"T_0ce1e6f6_d0b0_11ea_8877_7cb27da2bf47row1_col0\" class=\"data row1 col0\" >33.070140</td>\n",
       "                        <td id=\"T_0ce1e6f6_d0b0_11ea_8877_7cb27da2bf47row1_col1\" class=\"data row1 col1\" >22.769643</td>\n",
       "                        <td id=\"T_0ce1e6f6_d0b0_11ea_8877_7cb27da2bf47row1_col2\" class=\"data row1 col2\" >29.792108</td>\n",
       "                        <td id=\"T_0ce1e6f6_d0b0_11ea_8877_7cb27da2bf47row1_col3\" class=\"data row1 col3\" >22.155887</td>\n",
       "                        <td id=\"T_0ce1e6f6_d0b0_11ea_8877_7cb27da2bf47row1_col4\" class=\"data row1 col4\" >33.529777</td>\n",
       "                        <td id=\"T_0ce1e6f6_d0b0_11ea_8877_7cb27da2bf47row1_col5\" class=\"data row1 col5\" >22.860819</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0ce1e6f6_d0b0_11ea_8877_7cb27da2bf47level0_row2\" class=\"row_heading level0 row2\" >0.01</th>\n",
       "                        <td id=\"T_0ce1e6f6_d0b0_11ea_8877_7cb27da2bf47row2_col0\" class=\"data row2 col0\" >33.846575</td>\n",
       "                        <td id=\"T_0ce1e6f6_d0b0_11ea_8877_7cb27da2bf47row2_col1\" class=\"data row2 col1\" >17.150002</td>\n",
       "                        <td id=\"T_0ce1e6f6_d0b0_11ea_8877_7cb27da2bf47row2_col2\" class=\"data row2 col2\" >29.830015</td>\n",
       "                        <td id=\"T_0ce1e6f6_d0b0_11ea_8877_7cb27da2bf47row2_col3\" class=\"data row2 col3\" >15.918361</td>\n",
       "                        <td id=\"T_0ce1e6f6_d0b0_11ea_8877_7cb27da2bf47row2_col4\" class=\"data row2 col4\" >34.403270</td>\n",
       "                        <td id=\"T_0ce1e6f6_d0b0_11ea_8877_7cb27da2bf47row2_col5\" class=\"data row2 col5\" >17.332968</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0ce1e6f6_d0b0_11ea_8877_7cb27da2bf47level0_row3\" class=\"row_heading level0 row3\" >0.1</th>\n",
       "                        <td id=\"T_0ce1e6f6_d0b0_11ea_8877_7cb27da2bf47row3_col0\" class=\"data row3 col0\" >4404.038809</td>\n",
       "                        <td id=\"T_0ce1e6f6_d0b0_11ea_8877_7cb27da2bf47row3_col1\" class=\"data row3 col1\" >4403.913695</td>\n",
       "                        <td id=\"T_0ce1e6f6_d0b0_11ea_8877_7cb27da2bf47row3_col2\" class=\"data row3 col2\" >4400.573603</td>\n",
       "                        <td id=\"T_0ce1e6f6_d0b0_11ea_8877_7cb27da2bf47row3_col3\" class=\"data row3 col3\" >4400.473635</td>\n",
       "                        <td id=\"T_0ce1e6f6_d0b0_11ea_8877_7cb27da2bf47row3_col4\" class=\"data row3 col4\" >4404.553347</td>\n",
       "                        <td id=\"T_0ce1e6f6_d0b0_11ea_8877_7cb27da2bf47row3_col5\" class=\"data row3 col5\" >4404.424731</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0ce1e6f6_d0b0_11ea_8877_7cb27da2bf47level0_row4\" class=\"row_heading level0 row4\" >1.0</th>\n",
       "                        <td id=\"T_0ce1e6f6_d0b0_11ea_8877_7cb27da2bf47row4_col0\" class=\"data row4 col0\" >53658.562148</td>\n",
       "                        <td id=\"T_0ce1e6f6_d0b0_11ea_8877_7cb27da2bf47row4_col1\" class=\"data row4 col1\" >53658.551879</td>\n",
       "                        <td id=\"T_0ce1e6f6_d0b0_11ea_8877_7cb27da2bf47row4_col2\" class=\"data row4 col2\" >53655.120017</td>\n",
       "                        <td id=\"T_0ce1e6f6_d0b0_11ea_8877_7cb27da2bf47row4_col3\" class=\"data row4 col3\" >53655.111818</td>\n",
       "                        <td id=\"T_0ce1e6f6_d0b0_11ea_8877_7cb27da2bf47row4_col4\" class=\"data row4 col4\" >53659.073472</td>\n",
       "                        <td id=\"T_0ce1e6f6_d0b0_11ea_8877_7cb27da2bf47row4_col5\" class=\"data row4 col5\" >53659.062915</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x19f31f3a2c8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def highlight_min(s):\n",
    "    '''\n",
    "    highlight the maximum in a Series yellow.\n",
    "    '''\n",
    "    is_max = s == s.min()\n",
    "    return ['background-color: yellow' if v else '' for v in is_max]\n",
    "\n",
    "results.style.apply(highlight_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
