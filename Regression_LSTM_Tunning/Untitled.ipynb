{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# LSTM.py\n",
    "# =============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from numpy.random import seed\n",
    "#from tensorflow import set_random_seed\n",
    "\n",
    "# To get the same results every time\n",
    "#seed(1)\n",
    "#set_random_seed(1)\n",
    "\n",
    "# Read data from csv files\n",
    "# offers = pd.read_csv('Offers.csv', parse_dates=True, index_col=0)\n",
    "# bids = pd.read_csv('Bids.csv', parse_dates=True, index_col=0)\n",
    "# X = pd.read_csv('Features.csv', parse_dates=True, index_col=0)\n",
    "\n",
    "# Get rid of extreme values\n",
    "# offers = offers[offers < 2000]\n",
    "# bids = bids[bids > -250]\n",
    "\n",
    "# Connect all together\n",
    "# data = pd.concat([X, offers], axis=1, sort=True)\n",
    "\n",
    "# Sort data\n",
    "# data.sort_index(inplace=True)\n",
    "\n",
    "# Keep only data from 2018 (for simplicity)\n",
    "# data = data.loc[data.index > 2018000000, :]\n",
    "\n",
    "# Handle missing data\n",
    "# data.fillna(data.median(), inplace=True)\n",
    "\n",
    "# Predict 1h ahead instead of same time\n",
    "# data['Offers'] = data['Offers'].shift(-2)\n",
    "# data['Offers'].fillna(method='ffill', inplace=True)\n",
    "\n",
    "# ********************* Feature Selection *********************\n",
    "\n",
    "# if 'Bids' in data.columns:\n",
    "    # data.drop('Bids', axis=1, inplace=True)\n",
    "\n",
    "## Based on Correlation threshold\n",
    "#def corr_thresh(df, thr):\n",
    "#    \"\"\"df: last column is the output\"\"\"\n",
    "#    corr = df.corr()\n",
    "#    features = list(corr['Offers'].iloc[:-1][abs(corr['Offers'].iloc[:-1]) < thr].index)\n",
    "#    for j in df.columns[:-1]:\n",
    "#        if j in features:\n",
    "#            df.drop(j, axis=1, inplace=True)\n",
    "#    return df\n",
    "#\n",
    "#\n",
    "\n",
    "# All-in\n",
    "X = data.iloc[:, :-1]\n",
    "y = data['Offers']\n",
    "\n",
    "# *************************************************************\n",
    "\n",
    "df_train, df_test = train_test_split(data, test_size=0.2,\n",
    "                                     random_state=0, shuffle=False)\n",
    "\n",
    "# scale the feature MinMax, build array\n",
    "x = df_train.loc[:, :].values\n",
    "min_max_scaler = MinMaxScaler()\n",
    "x_train = min_max_scaler.fit_transform(x)\n",
    "x_test = min_max_scaler.transform(df_test.loc[:, :])\n",
    "\n",
    "\n",
    "# Function that creates the 3D array that LSTM needs\n",
    "def build_timeseries(mat, y_col_index, time_steps):\n",
    "\n",
    "    io_pairs = mat.shape[0] - time_steps\n",
    "    features = mat.shape[1]\n",
    "    x = np.zeros((io_pairs, time_steps, features))\n",
    "    y = np.zeros((io_pairs,))\n",
    "\n",
    "    for i in range(io_pairs):\n",
    "        x[i] = mat[i:time_steps+i]\n",
    "        y[i] = mat[time_steps+i, y_col_index]\n",
    "    print(\"Length of time-series i/o\", x.shape, y.shape)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "# Function that trims the dataset to be divisible by the batch size\n",
    "def trim_dataset(mat, batch_size):\n",
    "    no_of_rows_drop = mat.shape[0] % batch_size\n",
    "    if(no_of_rows_drop > 0):\n",
    "        return mat[:-no_of_rows_drop]\n",
    "    else:\n",
    "        return mat\n",
    "\n",
    "\n",
    "# Calculate running time\n",
    "start_time = time.time()\n",
    "\n",
    "time_st = 96  # SPs to look back to predict the price in next day\n",
    "y_col = data.columns.get_loc(\"Offers\")  # Output column\n",
    "batch_s = 100  # Number of time steps checked before weight update\n",
    "epoch = 5  # Number of epochs\n",
    "unit = 20  # Number of neurons in the output of a hidden layer\n",
    "r = 2  # For rounding\n",
    "a = 0.1  # For LeakyReLU\n",
    "\n",
    "# Create training set\n",
    "X_train, y_train = build_timeseries(x_train, y_col, time_st)\n",
    "X_train = trim_dataset(X_train, batch_s)\n",
    "y_train = trim_dataset(y_train, batch_s)\n",
    "\n",
    "# Create validation and test set\n",
    "X_temp, y_temp = build_timeseries(x_test, y_col, time_st)\n",
    "X_val, X_test_t = np.split(trim_dataset(X_temp, batch_s), 2)\n",
    "y_val, y_test_t = np.split(trim_dataset(y_temp, batch_s), 2)\n",
    "\n",
    "\n",
    "# Build the LSTM model\n",
    "lstm = Sequential()\n",
    "lstm.add(LSTM(units=unit, \n",
    "              batch_input_shape=(batch_s, time_st, X_train.shape[2]), \n",
    "              stateful=True,\n",
    "              kernel_initializer='random_uniform'))\n",
    "lstm.add(Dropout(0.3))\n",
    "lstm.add(Dense(unit, activation='linear'))\n",
    "lstm.add(LeakyReLU(alpha=a))\n",
    "lstm.add(Dense(1, activation='linear'))\n",
    "lstm.compile(loss='mae', optimizer='Nadam',\n",
    "             metrics=['mse', 'mae'])\n",
    "\n",
    "# Callbacks\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=10),\n",
    "             ModelCheckpoint(filepath='best_model.h5',\n",
    "                             monitor='val_loss',\n",
    "                             save_best_only=True,\n",
    "                             mode='min', verbose=1)]\n",
    "\n",
    "hist = lstm.fit(X_train, y_train, epochs=epoch, verbose=1, batch_size=batch_s,\n",
    "                shuffle=False, callbacks=callbacks,\n",
    "                validation_data=(trim_dataset(X_val, batch_s),\n",
    "                                 trim_dataset(y_val, batch_s)))\n",
    "\n",
    "lstm_best = load_model('best_model.h5')\n",
    "\n",
    "y_pred_t = lstm_best.predict(trim_dataset(X_test_t, batch_s),\n",
    "                             batch_size=batch_s)\n",
    "y_pred_t = y_pred_t.flatten()\n",
    "y_test_t = trim_dataset(y_test_t, batch_s)\n",
    "\n",
    "# Cannot use min_max_scaler.inverse_transform(y_pred) since this refers to\n",
    "# all the features (not only the closing price)\n",
    "y_pred = (y_pred_t * min_max_scaler.data_range_[y_col]) + min_max_scaler.data_min_[y_col]\n",
    "y_test = (y_test_t * min_max_scaler.data_range_[y_col]) + min_max_scaler.data_min_[y_col]\n",
    "\n",
    "r = 3\n",
    "print('')\n",
    "print(\"   ******** Evaluation Metrics for the LSTM model ********    \")\n",
    "print(\"Mean Absolute Error (test set):\")\n",
    "print(round(metrics.mean_absolute_error(y_test, y_pred), r))\n",
    "print(\"Mean Squared Error (test set):\")\n",
    "print(round(metrics.mean_squared_error(y_test, y_pred), r))\n",
    "print(\"Root Mean Squared Error (test set):\")\n",
    "print(round(np.sqrt(metrics.mean_squared_error(y_test, y_pred)), r))\n",
    "print('Direction Accuracy:', direction_accuracy(y_test, y_pred))\n",
    "rt = round(time.time() - start_time, r)\n",
    "print('Running time:', rt)\n",
    "\n",
    "# Plots\n",
    "plt.rc('xtick', labelsize=16)\n",
    "plt.rc('ytick', labelsize=16)\n",
    "\n",
    "fig = plt.figure(1, figsize=(11, 5), dpi=150)\n",
    "axes = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "axes.plot(range(len(y_test[700:900])), y_test[700:900], zorder=1, lw=3,\n",
    "          color='red', label='Real Price')\n",
    "axes.plot(y_pred[700:900], zorder=2, lw=3,\n",
    "          color='blue', label='Predicted Price')\n",
    "axes.plot(y_pred[700:900]-y_test[700:900],\n",
    "          zorder=0, lw=3, color='green', label='Residual Error')\n",
    "axes.set_title('LSTM (Real vs Predicted values)',\n",
    "               fontsize=18)\n",
    "axes.set_xlabel('Day and SP', fontsize=16)\n",
    "axes.set_ylabel('Offer price and Residual Error', fontsize=16)\n",
    "axes.legend(loc='best', fontsize=16)\n",
    "axes.grid(True)\n",
    "axes.autoscale()\n",
    "\n",
    "s = 50\n",
    "fig = plt.figure(2, figsize=(11, 5), dpi=150)\n",
    "axes = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "axes.plot(hist.history['loss'], zorder=1, lw=3,\n",
    "          color='red', label='Training Loss')\n",
    "axes.scatter(list(range(0, len(hist.history['loss']))),\n",
    "             hist.history['loss'], zorder=1,\n",
    "             color='red', s=s)\n",
    "axes.plot(hist.history['val_loss'], zorder=2, lw=3,\n",
    "          color='blue', label='Validation Loss')\n",
    "axes.scatter(list(range(0, len(hist.history['val_loss']))),\n",
    "             hist.history['val_loss'], zorder=1,\n",
    "             color='blue', s=s)\n",
    "axes.set_title('LSTM - Model Loss',\n",
    "               fontsize=18)\n",
    "axes.set_xlabel('Epoch', fontsize=16)\n",
    "axes.set_ylabel('Loss', fontsize=16)\n",
    "axes.legend(loc='best', fontsize=16)\n",
    "axes.grid(True)\n",
    "axes.autoscale()\n",
    "\n",
    "np.savetxt('LSTM_y_test.csv', y_test, delimiter=\",\")\n",
    "np.savetxt('LSTM_y_pred.csv', y_pred, delimiter=\",\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
