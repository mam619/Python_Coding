{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression LSTM with best parameters\n",
    "    find the best prediction window to apply w/ lr = 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\maria\\anaconda3\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from pandas) (1.18.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from python-dateutil>=2.6.1->pandas) (1.14.0)\n",
      "Requirement already satisfied: sklearn in c:\\users\\maria\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\maria\\anaconda3\\lib\\site-packages (from sklearn) (0.22.1)\n",
      "Requirement already satisfied: scipy>=0.17.0 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.11.0 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.18.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (0.14.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\maria\\anaconda3\\lib\\site-packages (3.1.3)\n",
      "Requirement already satisfied: numpy>=1.11 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from matplotlib) (1.18.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from matplotlib) (2.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: six in c:\\users\\maria\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib) (1.14.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\maria\\anaconda3\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib) (45.2.0.post20200210)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install sklearn\n",
    "!pip install matplotlib\n",
    "\n",
    "import pandas as pd;\n",
    "import numpy as np;\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "date =  [2018010000, \n",
    "         2018030000, \n",
    "         2018050000,\n",
    "         2018070000, \n",
    "         2018090000, \n",
    "         2018110000]\n",
    "\n",
    "# parameters\n",
    "steps = 96\n",
    "n_hidden = 2\n",
    "units = 150\n",
    "batch_size = 336\n",
    "epochs = 100\n",
    "features_num = 14\n",
    "\n",
    "# lists to append results\n",
    "mae_gen = []\n",
    "mae_nor = []\n",
    "mae_spi = []\n",
    "rmse_gen = []\n",
    "rmse_nor = []\n",
    "rmse_spi = []\n",
    "y_pred_list = []\n",
    "time_count = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import keras libraries, packages and data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LeakyReLU\n",
    "from keras import initializers\n",
    "from keras import optimizers\n",
    "\n",
    "# import data\n",
    "data_full = pd.read_csv('Data_set_1_smaller_(1).csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create loop for different dates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n",
      "C:\\Users\\maria\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:6245: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "37/37 [==============================] - 53s 1s/step - loss: 0.3685 - mse: 0.3685 - mae: 0.3985 - val_loss: 0.0561 - val_mse: 0.0561 - val_mae: 0.2350\n",
      "Epoch 2/100\n",
      "37/37 [==============================] - 51s 1s/step - loss: 0.1164 - mse: 0.1164 - mae: 0.2717 - val_loss: 0.0461 - val_mse: 0.0461 - val_mae: 0.2132\n",
      "Epoch 3/100\n",
      "37/37 [==============================] - 56s 2s/step - loss: 0.0623 - mse: 0.0623 - mae: 0.2011 - val_loss: 0.0057 - val_mse: 0.0057 - val_mae: 0.0711\n",
      "Epoch 4/100\n",
      "37/37 [==============================] - 54s 1s/step - loss: 0.0371 - mse: 0.0371 - mae: 0.1539 - val_loss: 0.0163 - val_mse: 0.0163 - val_mae: 0.1257\n",
      "Epoch 5/100\n",
      "37/37 [==============================] - 58s 2s/step - loss: 0.0193 - mse: 0.0193 - mae: 0.1090 - val_loss: 9.3821e-04 - val_mse: 9.3821e-04 - val_mae: 0.0265\n",
      "Epoch 6/100\n",
      "37/37 [==============================] - 52s 1s/step - loss: 0.0119 - mse: 0.0119 - mae: 0.0857 - val_loss: 0.0109 - val_mse: 0.0109 - val_mae: 0.1018\n",
      "Epoch 7/100\n",
      "37/37 [==============================] - 739s 20s/step - loss: 0.0075 - mse: 0.0075 - mae: 0.0670 - val_loss: 0.0064 - val_mse: 0.0064 - val_mae: 0.0769\n",
      "Epoch 8/100\n",
      "37/37 [==============================] - 56s 2s/step - loss: 0.0051 - mse: 0.0051 - mae: 0.0534 - val_loss: 6.2653e-04 - val_mse: 6.2653e-04 - val_mae: 0.0179\n",
      "Epoch 9/100\n",
      "37/37 [==============================] - 57s 2s/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0426 - val_loss: 8.1526e-04 - val_mse: 8.1526e-04 - val_mae: 0.0166\n",
      "Epoch 10/100\n",
      "37/37 [==============================] - 57s 2s/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0351 - val_loss: 0.0015 - val_mse: 0.0015 - val_mae: 0.0295\n",
      "Epoch 11/100\n",
      "37/37 [==============================] - 57s 2s/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0344 - val_loss: 6.4070e-04 - val_mse: 6.4070e-04 - val_mae: 0.0164\n",
      "Epoch 12/100\n",
      "37/37 [==============================] - 60s 2s/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0291 - val_loss: 6.1514e-04 - val_mse: 6.1514e-04 - val_mae: 0.0181\n",
      "Epoch 13/100\n",
      "37/37 [==============================] - 59s 2s/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0262 - val_loss: 7.6742e-04 - val_mse: 7.6742e-04 - val_mae: 0.0232\n",
      "Epoch 14/100\n",
      "37/37 [==============================] - 59s 2s/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0261 - val_loss: 6.7216e-04 - val_mse: 6.7216e-04 - val_mae: 0.0209\n",
      "Epoch 15/100\n",
      "37/37 [==============================] - 58s 2s/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0250 - val_loss: 9.2204e-04 - val_mse: 9.2204e-04 - val_mae: 0.0265\n",
      "Epoch 16/100\n",
      "37/37 [==============================] - 54s 1s/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0243 - val_loss: 7.9364e-04 - val_mse: 7.9364e-04 - val_mae: 0.0239\n",
      "Epoch 17/100\n",
      "37/37 [==============================] - 48s 1s/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0231 - val_loss: 7.2671e-04 - val_mse: 7.2671e-04 - val_mae: 0.0224\n",
      "Epoch 18/100\n",
      "37/37 [==============================] - 50s 1s/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0230 - val_loss: 7.4943e-04 - val_mse: 7.4943e-04 - val_mae: 0.0230\n",
      "Epoch 19/100\n",
      "37/37 [==============================] - 54s 1s/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0225 - val_loss: 6.6686e-04 - val_mse: 6.6686e-04 - val_mae: 0.0210\n",
      "Epoch 20/100\n",
      "37/37 [==============================] - 59s 2s/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0224 - val_loss: 6.8938e-04 - val_mse: 6.8938e-04 - val_mae: 0.0216\n",
      "Epoch 21/100\n",
      "37/37 [==============================] - 50s 1s/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0219 - val_loss: 7.4482e-04 - val_mse: 7.4482e-04 - val_mae: 0.0229\n",
      "Epoch 22/100\n",
      "37/37 [==============================] - 59s 2s/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0219 - val_loss: 6.5494e-04 - val_mse: 6.5494e-04 - val_mae: 0.0207\n",
      "Epoch 23/100\n",
      "37/37 [==============================] - 57s 2s/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0216 - val_loss: 6.5076e-04 - val_mse: 6.5076e-04 - val_mae: 0.0206\n",
      "Epoch 24/100\n",
      "37/37 [==============================] - 59s 2s/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0215 - val_loss: 6.8078e-04 - val_mse: 6.8078e-04 - val_mae: 0.0214\n",
      "Epoch 25/100\n",
      "37/37 [==============================] - 51s 1s/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0214 - val_loss: 7.0050e-04 - val_mse: 7.0050e-04 - val_mae: 0.0219\n",
      "Epoch 26/100\n",
      "37/37 [==============================] - 58s 2s/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0214 - val_loss: 6.2555e-04 - val_mse: 6.2555e-04 - val_mae: 0.0199\n",
      "Epoch 27/100\n",
      "37/37 [==============================] - 52s 1s/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0212 - val_loss: 6.2226e-04 - val_mse: 6.2226e-04 - val_mae: 0.0198\n",
      "Epoch 28/100\n",
      "37/37 [==============================] - 53s 1s/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0212 - val_loss: 6.5663e-04 - val_mse: 6.5663e-04 - val_mae: 0.0208\n",
      "Epoch 29/100\n",
      "37/37 [==============================] - 58s 2s/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0211 - val_loss: 6.5455e-04 - val_mse: 6.5455e-04 - val_mae: 0.0208\n",
      "Epoch 30/100\n",
      "37/37 [==============================] - 57s 2s/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0211 - val_loss: 6.0973e-04 - val_mse: 6.0973e-04 - val_mae: 0.0195\n",
      "Epoch 31/100\n",
      "37/37 [==============================] - 58s 2s/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0209 - val_loss: 6.3757e-04 - val_mse: 6.3757e-04 - val_mae: 0.0204\n",
      "Epoch 32/100\n",
      "37/37 [==============================] - 59s 2s/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0209 - val_loss: 6.1819e-04 - val_mse: 6.1819e-04 - val_mae: 0.0198\n",
      "Epoch 33/100\n",
      "37/37 [==============================] - 59s 2s/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0206 - val_loss: 6.2083e-04 - val_mse: 6.2083e-04 - val_mae: 0.0200\n",
      "Epoch 34/100\n",
      "37/37 [==============================] - 54s 1s/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0208 - val_loss: 5.9135e-04 - val_mse: 5.9135e-04 - val_mae: 0.0190\n",
      "Epoch 35/100\n",
      "37/37 [==============================] - 55s 1s/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0207 - val_loss: 5.9042e-04 - val_mse: 5.9042e-04 - val_mae: 0.0190\n",
      "Epoch 36/100\n",
      "37/37 [==============================] - 80s 2s/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0206 - val_loss: 5.9560e-04 - val_mse: 5.9560e-04 - val_mae: 0.0192\n",
      "Epoch 37/100\n",
      "37/37 [==============================] - 51s 1s/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0205 - val_loss: 5.7802e-04 - val_mse: 5.7802e-04 - val_mae: 0.0187\n",
      "Epoch 38/100\n",
      "37/37 [==============================] - 59s 2s/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0204 - val_loss: 5.6780e-04 - val_mse: 5.6780e-04 - val_mae: 0.0185\n",
      "Epoch 39/100\n",
      "37/37 [==============================] - 61s 2s/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0201 - val_loss: 5.4376e-04 - val_mse: 5.4376e-04 - val_mae: 0.0175\n",
      "Epoch 40/100\n",
      "37/37 [==============================] - 60s 2s/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0205 - val_loss: 5.3838e-04 - val_mse: 5.3838e-04 - val_mae: 0.0172\n",
      "Epoch 41/100\n",
      "37/37 [==============================] - 60s 2s/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0203 - val_loss: 5.6662e-04 - val_mse: 5.6662e-04 - val_mae: 0.0183\n",
      "Epoch 42/100\n",
      "37/37 [==============================] - 59s 2s/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0198 - val_loss: 5.3989e-04 - val_mse: 5.3989e-04 - val_mae: 0.0175\n",
      "Epoch 43/100\n",
      "37/37 [==============================] - 60s 2s/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0203 - val_loss: 5.2530e-04 - val_mse: 5.2530e-04 - val_mae: 0.0170\n",
      "Epoch 44/100\n",
      "37/37 [==============================] - 59s 2s/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0196 - val_loss: 5.3162e-04 - val_mse: 5.3162e-04 - val_mae: 0.0173\n",
      "Epoch 45/100\n",
      "37/37 [==============================] - 60s 2s/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0203 - val_loss: 5.2590e-04 - val_mse: 5.2590e-04 - val_mae: 0.0170\n",
      "Epoch 46/100\n",
      "37/37 [==============================] - 57s 2s/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0190 - val_loss: 5.3570e-04 - val_mse: 5.3570e-04 - val_mae: 0.0175\n",
      "Epoch 47/100\n",
      "37/37 [==============================] - 59s 2s/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0212 - val_loss: 5.0470e-04 - val_mse: 5.0470e-04 - val_mae: 0.0157\n",
      "Epoch 48/100\n",
      "37/37 [==============================] - 61s 2s/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0185 - val_loss: 5.0886e-04 - val_mse: 5.0886e-04 - val_mae: 0.0164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100\n",
      "37/37 [==============================] - 54s 1s/step - loss: 9.8261e-04 - mse: 9.8261e-04 - mae: 0.0179 - val_loss: 5.5802e-04 - val_mse: 5.5802e-04 - val_mae: 0.0187\n",
      "Epoch 50/100\n",
      "37/37 [==============================] - 61s 2s/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0200 - val_loss: 4.9979e-04 - val_mse: 4.9979e-04 - val_mae: 0.0161\n",
      "Epoch 51/100\n",
      "37/37 [==============================] - 68s 2s/step - loss: 9.8474e-04 - mse: 9.8474e-04 - mae: 0.0184 - val_loss: 5.1739e-04 - val_mse: 5.1739e-04 - val_mae: 0.0168\n",
      "Epoch 52/100\n",
      "37/37 [==============================] - 57s 2s/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0194 - val_loss: 4.9075e-04 - val_mse: 4.9075e-04 - val_mae: 0.0157\n",
      "Epoch 53/100\n",
      "37/37 [==============================] - 56s 2s/step - loss: 9.1849e-04 - mse: 9.1849e-04 - mae: 0.0175 - val_loss: 5.6269e-04 - val_mse: 5.6269e-04 - val_mae: 0.0187\n",
      "Epoch 54/100\n",
      "37/37 [==============================] - 59s 2s/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0203 - val_loss: 5.0773e-04 - val_mse: 5.0773e-04 - val_mae: 0.0161\n",
      "Epoch 55/100\n",
      "37/37 [==============================] - 58s 2s/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0191 - val_loss: 4.9952e-04 - val_mse: 4.9952e-04 - val_mae: 0.0161\n",
      "Epoch 56/100\n",
      "37/37 [==============================] - 59s 2s/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0196 - val_loss: 4.9642e-04 - val_mse: 4.9642e-04 - val_mae: 0.0163\n",
      "Epoch 57/100\n",
      "37/37 [==============================] - 78s 2s/step - loss: 9.6353e-04 - mse: 9.6353e-04 - mae: 0.0180 - val_loss: 5.1054e-04 - val_mse: 5.1054e-04 - val_mae: 0.0168\n",
      "Epoch 58/100\n",
      "37/37 [==============================] - 58s 2s/step - loss: 8.7967e-04 - mse: 8.7967e-04 - mae: 0.0176 - val_loss: 5.4593e-04 - val_mse: 5.4593e-04 - val_mae: 0.0180\n",
      "Epoch 59/100\n",
      "37/37 [==============================] - 65s 2s/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0191 - val_loss: 4.9507e-04 - val_mse: 4.9507e-04 - val_mae: 0.0162\n",
      "Epoch 60/100\n",
      "37/37 [==============================] - 74s 2s/step - loss: 9.0826e-04 - mse: 9.0826e-04 - mae: 0.0178 - val_loss: 5.0464e-04 - val_mse: 5.0464e-04 - val_mae: 0.0165\n",
      "Epoch 61/100\n",
      "37/37 [==============================] - 55s 1s/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0194 - val_loss: 4.8482e-04 - val_mse: 4.8482e-04 - val_mae: 0.0158\n",
      "Epoch 62/100\n",
      "37/37 [==============================] - 85s 2s/step - loss: 8.2886e-04 - mse: 8.2886e-04 - mae: 0.0172 - val_loss: 5.3809e-04 - val_mse: 5.3809e-04 - val_mae: 0.0180\n",
      "Epoch 63/100\n",
      "37/37 [==============================] - 85s 2s/step - loss: 8.2635e-04 - mse: 8.2635e-04 - mae: 0.0172 - val_loss: 5.5610e-04 - val_mse: 5.5610e-04 - val_mae: 0.0188\n",
      "Epoch 64/100\n",
      "37/37 [==============================] - 70s 2s/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0190 - val_loss: 4.8755e-04 - val_mse: 4.8755e-04 - val_mae: 0.0158\n",
      "Epoch 65/100\n",
      "37/37 [==============================] - 91s 2s/step - loss: 9.5928e-04 - mse: 9.5928e-04 - mae: 0.0175 - val_loss: 5.1736e-04 - val_mse: 5.1736e-04 - val_mae: 0.0173\n",
      "Epoch 66/100\n",
      "37/37 [==============================] - 64s 2s/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0190 - val_loss: 4.8816e-04 - val_mse: 4.8816e-04 - val_mae: 0.0161\n",
      "Epoch 67/100\n",
      "37/37 [==============================] - 74s 2s/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0188 - val_loss: 4.8175e-04 - val_mse: 4.8175e-04 - val_mae: 0.0156\n",
      "Epoch 68/100\n",
      "37/37 [==============================] - 60s 2s/step - loss: 9.5131e-04 - mse: 9.5131e-04 - mae: 0.0180 - val_loss: 4.7966e-04 - val_mse: 4.7966e-04 - val_mae: 0.0157\n",
      "Epoch 69/100\n",
      "37/37 [==============================] - 64s 2s/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0180 - val_loss: 5.1195e-04 - val_mse: 5.1195e-04 - val_mae: 0.0170\n",
      "Epoch 70/100\n",
      "37/37 [==============================] - 77s 2s/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0189 - val_loss: 4.9160e-04 - val_mse: 4.9160e-04 - val_mae: 0.0164\n",
      "Epoch 71/100\n",
      "37/37 [==============================] - 57s 2s/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0187 - val_loss: 4.9679e-04 - val_mse: 4.9679e-04 - val_mae: 0.0164\n",
      "Epoch 72/100\n",
      "37/37 [==============================] - 53s 1s/step - loss: 9.1209e-04 - mse: 9.1209e-04 - mae: 0.0176 - val_loss: 4.9275e-04 - val_mse: 4.9275e-04 - val_mae: 0.0165\n",
      "Epoch 73/100\n",
      "37/37 [==============================] - 54s 1s/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0190 - val_loss: 4.7467e-04 - val_mse: 4.7467e-04 - val_mae: 0.0155\n",
      "Epoch 74/100\n",
      "37/37 [==============================] - 54s 1s/step - loss: 9.7871e-04 - mse: 9.7871e-04 - mae: 0.0182 - val_loss: 4.7612e-04 - val_mse: 4.7612e-04 - val_mae: 0.0158\n",
      "Epoch 75/100\n",
      "37/37 [==============================] - 55s 1s/step - loss: 7.8450e-04 - mse: 7.8450e-04 - mae: 0.0172 - val_loss: 4.9195e-04 - val_mse: 4.9195e-04 - val_mae: 0.0165\n",
      "Epoch 76/100\n",
      "37/37 [==============================] - 63s 2s/step - loss: 7.7243e-04 - mse: 7.7243e-04 - mae: 0.0170 - val_loss: 4.7596e-04 - val_mse: 4.7596e-04 - val_mae: 0.0159\n",
      "Epoch 77/100\n",
      "37/37 [==============================] - 56s 2s/step - loss: 7.7868e-04 - mse: 7.7868e-04 - mae: 0.0169 - val_loss: 4.9102e-04 - val_mse: 4.9102e-04 - val_mae: 0.0166\n",
      "Epoch 78/100\n",
      "37/37 [==============================] - 55s 1s/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0189 - val_loss: 4.5251e-04 - val_mse: 4.5251e-04 - val_mae: 0.0148\n",
      "Epoch 79/100\n",
      "37/37 [==============================] - 64s 2s/step - loss: 9.5899e-04 - mse: 9.5899e-04 - mae: 0.0180 - val_loss: 4.6283e-04 - val_mse: 4.6283e-04 - val_mae: 0.0152\n",
      "Epoch 80/100\n",
      "37/37 [==============================] - 53s 1s/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0191 - val_loss: 4.5785e-04 - val_mse: 4.5785e-04 - val_mae: 0.0148\n",
      "Epoch 81/100\n",
      "37/37 [==============================] - 52s 1s/step - loss: 7.9767e-04 - mse: 7.9767e-04 - mae: 0.0171 - val_loss: 4.5550e-04 - val_mse: 4.5550e-04 - val_mae: 0.0152\n",
      "Epoch 82/100\n",
      "37/37 [==============================] - 50s 1s/step - loss: 7.9855e-04 - mse: 7.9855e-04 - mae: 0.0170 - val_loss: 5.2228e-04 - val_mse: 5.2228e-04 - val_mae: 0.0178\n",
      "Epoch 83/100\n",
      "37/37 [==============================] - 52s 1s/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0183 - val_loss: 4.5553e-04 - val_mse: 4.5553e-04 - val_mae: 0.0146\n",
      "Epoch 84/100\n",
      "37/37 [==============================] - 51s 1s/step - loss: 9.1231e-04 - mse: 9.1231e-04 - mae: 0.0177 - val_loss: 4.4315e-04 - val_mse: 4.4315e-04 - val_mae: 0.0144\n",
      "Epoch 85/100\n",
      "37/37 [==============================] - 60s 2s/step - loss: 8.9030e-04 - mse: 8.9030e-04 - mae: 0.0169 - val_loss: 4.7453e-04 - val_mse: 4.7453e-04 - val_mae: 0.0159\n",
      "Epoch 86/100\n",
      "37/37 [==============================] - 54s 1s/step - loss: 9.3262e-04 - mse: 9.3262e-04 - mae: 0.0175 - val_loss: 4.5017e-04 - val_mse: 4.5017e-04 - val_mae: 0.0149\n",
      "Epoch 87/100\n",
      "37/37 [==============================] - 60s 2s/step - loss: 9.0234e-04 - mse: 9.0234e-04 - mae: 0.0172 - val_loss: 4.5336e-04 - val_mse: 4.5336e-04 - val_mae: 0.0147\n",
      "Epoch 88/100\n",
      "37/37 [==============================] - 51s 1s/step - loss: 9.6090e-04 - mse: 9.6090e-04 - mae: 0.0177 - val_loss: 4.4166e-04 - val_mse: 4.4166e-04 - val_mae: 0.0146\n",
      "Epoch 89/100\n",
      "37/37 [==============================] - 53s 1s/step - loss: 7.9893e-04 - mse: 7.9893e-04 - mae: 0.0168 - val_loss: 4.5640e-04 - val_mse: 4.5640e-04 - val_mae: 0.0153\n",
      "Epoch 90/100\n",
      "37/37 [==============================] - 53s 1s/step - loss: 8.3513e-04 - mse: 8.3513e-04 - mae: 0.0168 - val_loss: 4.4681e-04 - val_mse: 4.4681e-04 - val_mae: 0.0150\n",
      "Epoch 91/100\n",
      "37/37 [==============================] - 63s 2s/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0176 - val_loss: 4.4481e-04 - val_mse: 4.4481e-04 - val_mae: 0.0144\n",
      "Epoch 92/100\n",
      "37/37 [==============================] - 64s 2s/step - loss: 8.8100e-04 - mse: 8.8100e-04 - mae: 0.0172 - val_loss: 4.3020e-04 - val_mse: 4.3020e-04 - val_mae: 0.0139\n",
      "Epoch 93/100\n",
      "37/37 [==============================] - 60s 2s/step - loss: 7.8159e-04 - mse: 7.8159e-04 - mae: 0.0165 - val_loss: 4.3942e-04 - val_mse: 4.3942e-04 - val_mae: 0.0142\n",
      "Epoch 94/100\n",
      "37/37 [==============================] - 63s 2s/step - loss: 8.9724e-04 - mse: 8.9724e-04 - mae: 0.0175 - val_loss: 4.5037e-04 - val_mse: 4.5037e-04 - val_mae: 0.0148\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 70s 2s/step - loss: 8.7315e-04 - mse: 8.7315e-04 - mae: 0.0170 - val_loss: 4.6805e-04 - val_mse: 4.6805e-04 - val_mae: 0.0157\n",
      "Epoch 96/100\n",
      "37/37 [==============================] - 65s 2s/step - loss: 8.5059e-04 - mse: 8.5059e-04 - mae: 0.0169 - val_loss: 4.4684e-04 - val_mse: 4.4684e-04 - val_mae: 0.0149\n",
      "Epoch 97/100\n",
      "37/37 [==============================] - 65s 2s/step - loss: 8.6993e-04 - mse: 8.6993e-04 - mae: 0.0170 - val_loss: 4.3309e-04 - val_mse: 4.3309e-04 - val_mae: 0.0141\n",
      "Epoch 98/100\n",
      "37/37 [==============================] - 55s 1s/step - loss: 8.3257e-04 - mse: 8.3257e-04 - mae: 0.0169 - val_loss: 4.3846e-04 - val_mse: 4.3846e-04 - val_mae: 0.0146\n",
      "Epoch 99/100\n",
      "37/37 [==============================] - 60s 2s/step - loss: 8.8323e-04 - mse: 8.8323e-04 - mae: 0.0174 - val_loss: 4.2582e-04 - val_mse: 4.2582e-04 - val_mae: 0.0138\n",
      "Epoch 100/100\n",
      "37/37 [==============================] - 67s 2s/step - loss: 9.1242e-04 - mse: 9.1242e-04 - mae: 0.0167 - val_loss: 4.4220e-04 - val_mse: 4.4220e-04 - val_mae: 0.0141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n",
      "C:\\Users\\maria\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:6245: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "split_data() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-c751153a675d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[1;31m# put data into correct shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m     \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplit_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m     \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplit_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplit_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: split_data() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "# function to split data into correct shape for RNN\n",
    "def split_data(X, y, steps):\n",
    "    X_, y_ = list(), list()\n",
    "    for i in range(steps, len(y)):\n",
    "        X_.append(X[i - steps : i, :])\n",
    "        y_.append(y[i]) \n",
    "    return np.array(X_), np.array(y_)\n",
    "\n",
    "# function to cut data set so it can be divisible by the batch_size\n",
    "def cut_data(data, batch_size):\n",
    "     # see if it is divisivel\n",
    "    condition = data.shape[0] % batch_size\n",
    "    if condition == 0:\n",
    "        return data\n",
    "    else:\n",
    "        return data[: -condition]\n",
    "\n",
    "# design the LSTM\n",
    "def regressor_tunning(kernel_initializer = 'he_uniform',\n",
    "                      bias_initializer = initializers.Ones()):\n",
    "    model = Sequential()\n",
    "    if n_hidden == 1:\n",
    "        model.add(LSTM(units = units,                    \n",
    "                       batch_input_shape = (batch_size, steps, features_num), \n",
    "                       stateful = True,\n",
    "                       kernel_initializer = kernel_initializer,\n",
    "                       bias_initializer = bias_initializer))\n",
    "        model.add(LeakyReLU(alpha = 0.2))\n",
    "        model.add(Dropout(0.2))\n",
    "    else:\n",
    "        model.add(LSTM(units = units,                    \n",
    "                       batch_input_shape = (batch_size, steps, features_num), \n",
    "                       stateful = True,\n",
    "                       return_sequences = True,\n",
    "                       kernel_initializer = kernel_initializer,\n",
    "                       bias_initializer = bias_initializer))\n",
    "        model.add(LeakyReLU(alpha = 0.2))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(LSTM(units = units, \n",
    "                       batch_input_shape = (batch_size, steps, features_num), \n",
    "                       stateful = True,\n",
    "                       kernel_initializer = kernel_initializer,\n",
    "                       bias_initializer = bias_initializer))\n",
    "        model.add(LeakyReLU(alpha = 0.2))\n",
    "        model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    optimizer = optimizers.RMSprop()\n",
    "    model.compile(loss = 'mse', metrics = ['mse', 'mae'], optimizer = optimizer)\n",
    "    return model\n",
    "\n",
    "  \n",
    "# LOOP STARTS\n",
    "for i in date:\n",
    "    start_time = time.time()\n",
    "    # data\n",
    "    data = data_full.loc[data_full.index > i, :]\n",
    "\n",
    "    # reset index\n",
    "    data.reset_index(inplace = True)\n",
    "    data.drop('index', axis = 1, inplace = True)\n",
    "\n",
    "    # fill nan values in the whole data set\n",
    "    data.fillna(data.mean(), inplace = True)\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    # divide data into train and test \n",
    "    data_train, data_test = train_test_split(\n",
    "             data, test_size = 0.15, shuffle=False)  \n",
    "    \n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "    # data scaling  (including offer (y))\n",
    "    sc_X = MinMaxScaler()\n",
    "    data_train = sc_X.fit_transform(data_train)\n",
    "    data_test = sc_X.transform(data_test)\n",
    "    \n",
    "    # divide features and labels\n",
    "    X_train = data_train[:, 0:14] \n",
    "    y_train = data_train[:, -1]\n",
    "    X_test = data_test[:, 0:14] \n",
    "    y_test = data_test[:, -1] \n",
    "\n",
    "    # divide data into train and test \n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "             X_train, y_train, test_size = 0.15, shuffle=False)\n",
    "\n",
    "    # put data into correct shape\n",
    "    X_train, y_train = split_data(X_train, y_train, steps)\n",
    "    X_test, y_test = split_data(X_test, y_test, steps)\n",
    "    X_val, y_val = split_data(X_val, y_val, steps)\n",
    "\n",
    "    X_train = cut_data(X_train, batch_size)\n",
    "    y_train = cut_data(y_train, batch_size)\n",
    "    X_test = cut_data(X_test, batch_size)\n",
    "    y_test = cut_data(y_test, batch_size)\n",
    "    X_val = cut_data(X_val, batch_size)\n",
    "    y_val = cut_data(y_val, batch_size)\n",
    "\n",
    "    model = regressor_tunning()\n",
    "    \n",
    "    # fitting the LSTM to the training set\n",
    "    history = model.fit(X_train,\n",
    "                        y_train, \n",
    "                        batch_size = batch_size, \n",
    "                        epochs = epochs,\n",
    "                        shuffle = False, \n",
    "                        validation_data = (X_val, y_val))\n",
    "    \n",
    "    model.reset_states()\n",
    "    \n",
    "    # make new predicitons with test set\n",
    "    y_pred = model.predict(X_test, batch_size = batch_size)\n",
    "    \n",
    "    # prices col = 15 (inverso should not be used as scalling was made with the whole data set)\n",
    "    y_pred = (y_pred * sc_X.data_range_[14]) + (sc_X.data_min_[14])\n",
    "    y_test = (y_test * sc_X.data_range_[14]) + (sc_X.data_min_[14])\n",
    "\n",
    "    # smal adjustment\n",
    "    y_test = pd.Series(y_test)\n",
    "    y_test.replace(0, 0.0001,inplace = True)\n",
    "    \n",
    "    y_pred_list.append(y_pred)\n",
    "    \n",
    "    from sklearn.metrics import mean_squared_error as mse\n",
    "    from sklearn.metrics import mean_absolute_error as mae\n",
    "\n",
    "    rmse_error = mse(y_test, y_pred, squared = False)\n",
    "    mae_error = mae(y_test, y_pred)\n",
    "    \n",
    "    rmse_gen.append(rmse_error)\n",
    "    mae_gen.append(mae_error)\n",
    "    \n",
    "    # =============================================================================\n",
    "    # Metrics evaluation on spike regions\n",
    "    # =============================================================================\n",
    "    \n",
    "    # Need to process data with spike occurences the same way as features\n",
    "    data = pd.read_csv('Spike_binary_1std.csv', index_col = 0)\n",
    "\n",
    "    # set predictive window according with tuning best results\n",
    "    data = data.loc[data.index > i, :]\n",
    "\n",
    "    # make sure shaded area will correspond to values outputed by LSTM\n",
    "    data.reset_index(drop = True, inplace = True)\n",
    "\n",
    "    # fill_nan is already made - so lets split data into test and train\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    # divide data into train and test \n",
    "    shade_train, shade_test = train_test_split(\n",
    "             data, test_size = 0.15, shuffle = False)\n",
    "\n",
    "    # reset index of testing data\n",
    "    shade_test.reset_index(drop = True, inplace = True)\n",
    "\n",
    "    # function to split data into correct shape for RNN\n",
    "    def split_data(shade_test, steps):\n",
    "        y_spike_occ = list()\n",
    "        upper_lim = list()\n",
    "        lower_lim = list()\n",
    "        for i in range(steps, len(shade_test.index)):\n",
    "            y_spike_occ.append(shade_test['spike_occurance'][i])\n",
    "            upper_lim.append(shade_test['spike_upperlim'][i])\n",
    "            lower_lim.append(shade_test['spike_lowerlim'][i])\n",
    "        return np.array(y_spike_occ), np.array(upper_lim), np.array(lower_lim)\n",
    "\n",
    "    # function to cut data set so it can be divisible by the batch_size\n",
    "    def cut_data(data, batch_size):\n",
    "         # see if it is divisivel\n",
    "        condition = data.shape[0] % batch_size\n",
    "        if condition == 0:\n",
    "            return data\n",
    "        else:\n",
    "            return data[: -condition]\n",
    "    \n",
    "    # shape y_spike_occ for the right size to compare results in normal and spike regions\n",
    "    y_spike_occ, spike_upperlim, spike_lowerlim = split_data(shade_test, steps)\n",
    "    y_spike_occ = cut_data(y_spike_occ, batch_size)\n",
    "\n",
    "    # continue\n",
    "    \n",
    "    # select y_pred and y_test only for regions with spikes\n",
    "    y_test_spike = (y_test.T * y_spike_occ).T\n",
    "    y_pred_spike = (y_pred.T * y_spike_occ).T\n",
    "    y_test_spike = y_test_spike[y_test_spike != 0]\n",
    "    y_pred_spike = y_pred_spike[y_pred_spike != 0]\n",
    "    \n",
    "    # calculate metric\n",
    "    rmse_spike = mse(y_test_spike, y_pred_spike, squared = False)\n",
    "    mae_spike = mae(y_test_spike, y_pred_spike)\n",
    "    \n",
    "    rmse_spi.append(rmse_spike)\n",
    "    mae_spi.append(mae_spike)\n",
    "    \n",
    "    # =============================================================================\n",
    "    # Metric evaluation on normal regions\n",
    "    # =============================================================================\n",
    "    \n",
    "    # inverse y_spike_occ so the only normal occurences are chosen\n",
    "    y_normal_occ = (y_spike_occ - 1) * (-1)\n",
    "    \n",
    "    # sanity check\n",
    "    y_normal_occ.sum() + y_spike_occ.sum() # gives the correct total \n",
    "    \n",
    "    # select y_pred and y_test only for normal regions\n",
    "    y_test_normal = (y_test.T * y_normal_occ).T\n",
    "    y_pred_normal = (y_pred.T * y_normal_occ).T\n",
    "    y_test_normal = y_test_normal[y_test_normal != 0.00]\n",
    "    y_pred_normal = y_pred_normal[y_pred_normal != 0.00]\n",
    "    \n",
    "    # calculate metric\n",
    "    rmse_normal = mse(y_test_normal, y_pred_normal, squared = False)\n",
    "    mae_normal = mae(y_test_normal, y_pred_normal)\n",
    "    \n",
    "    rmse_nor.append(rmse_normal)\n",
    "    mae_nor.append(mae_normal)\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    time_count.append(elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({                        \n",
    "                        'rmse_general': rmse_gen, \n",
    "                 \n",
    "                        'mae_general': mae_gen,\n",
    "                        \n",
    "                        'rmse_spike': rmse_spi,\n",
    "                 \n",
    "                        'mae_spike': mae_spi,\n",
    "                        \n",
    "                        'rmse_normal': rmse_nor,\n",
    "                    \n",
    "                        'mae_normal': mae_nor,\n",
    "    \n",
    "                        'time': time_count})\n",
    "\n",
    "y_pred = pd.DataFrame({'dates': date,\n",
    "                       'Predicitons': y_pred_list})\n",
    "\n",
    "y_pred.to_csv('Pedictions_LSTM_5_prediction_window.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_min(s):\n",
    "    '''\n",
    "    highlight the maximum in a Series yellow.\n",
    "    '''\n",
    "    is_max = s == s.min()\n",
    "    return ['background-color: yellow' if v else '' for v in is_max]\n",
    "\n",
    "results.style.apply(highlight_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "dates_labels = ['12 ',\n",
    "                '10 ',\n",
    "                '8 ',\n",
    "                '6 ',\n",
    "                '4 ',\n",
    "                '2 ']\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.minorticks_on()\n",
    "plt.grid(which='major', linestyle='-', linewidth='0.5')\n",
    "plt.grid(which='minor', linestyle=':', linewidth='0.5')\n",
    "plt.title('LSTM: Averaged RMSE for different\\n predictive windows')\n",
    "plt.plot(rmse_gen, label = 'Overall error')\n",
    "plt.plot(rmse_spi, label = 'Spike regions')\n",
    "plt.plot(rmse_nor, label = 'Normal regions')\n",
    "plt.legend()\n",
    "plt.ylabel('RMSE (£/MWh)')\n",
    "plt.xlabel('Predictive window (in months)')\n",
    "plt.xticks([0,1,2,3,4,5], dates_labels)\n",
    "plt.tight_layout()\n",
    "plt.savefig('RMSE_predictive_window.png')\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.minorticks_on()\n",
    "plt.grid(which='major', linestyle='-', linewidth='0.5')\n",
    "plt.grid(which='minor', linestyle=':', linewidth='0.5')\n",
    "plt.title('LSTM: Averaged MAE for different\\n predictive windows')\n",
    "plt.plot(mae_gen, label = 'Overall error')\n",
    "plt.plot(mae_spi, label = 'Spike regions')\n",
    "plt.plot(mae_nor, label = 'Normal regions')\n",
    "plt.legend()\n",
    "plt.ylabel('MAE (£/MWh)')\n",
    "plt.xlabel('Predictive window (in months)')\n",
    "plt.xticks([0,1,2,3,4,5], dates_labels)\n",
    "plt.tight_layout()\n",
    "plt.savefig('MAE_predictive_window.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
