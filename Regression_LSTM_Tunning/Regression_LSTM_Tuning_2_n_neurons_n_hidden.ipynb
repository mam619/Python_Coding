{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Parameter Tunning \n",
    "    \n",
    "    Look at n_neurons & n_hidden layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\maria\\anaconda3\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from pandas) (1.18.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from python-dateutil>=2.6.1->pandas) (1.14.0)\n",
      "Requirement already satisfied: sklearn in c:\\users\\maria\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\maria\\anaconda3\\lib\\site-packages (from sklearn) (0.22.1)\n",
      "Requirement already satisfied: numpy>=1.11.0 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.18.1)\n",
      "Requirement already satisfied: scipy>=0.17.0 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.4.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (0.14.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install sklearn\n",
    "\n",
    "import pandas as pd;\n",
    "import numpy as np;\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data; set X and y; fill nan values and split in test and training  data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "data = pd.read_csv('Data_set_1_smaller.csv', index_col = 0)\n",
    "\n",
    "# for later use\n",
    "features_num = 15\n",
    "\n",
    "# 2018 data\n",
    "data = data.loc[data.index > 2018070000, :]\n",
    "\n",
    "# reset index\n",
    "data.reset_index(inplace = True)\n",
    "data.drop('index', axis = 1, inplace = True)\n",
    "\n",
    "# fill nan values\n",
    "data.fillna(method = 'ffill', inplace = True)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# divide data into train and test \n",
    "data_train, data_test = train_test_split(\n",
    "         data, test_size = 0.15, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply feature scaling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# data scaling  (including offer (y))\n",
    "sc_X = MinMaxScaler()\n",
    "data_train = sc_X.fit_transform(data_train)\n",
    "data_test = sc_X.transform(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LeakyReLU\n",
    "from keras import initializers\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "mae_cv = []\n",
    "mse_cv = []\n",
    "mae_gen = []\n",
    "mse_gen  =[]\n",
    "rmse_gen = []\n",
    "mae_nor = []\n",
    "mae_spi = []\n",
    "mse_nor = []\n",
    "mse_spi = []\n",
    "rmse_nor = []\n",
    "rmse_spi = []\n",
    "hist_list = []\n",
    "y_pred_list = []\n",
    "prediction_list = []\n",
    "time_count = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare of data according to LSTM needs,  create regressor & tune:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/180\n",
      "65/65 [==============================] - 23s 351ms/step - loss: 0.1158 - mse: 0.1158 - mae: 0.2701 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0425\n",
      "Epoch 2/180\n",
      "65/65 [==============================] - 20s 311ms/step - loss: 0.0632 - mse: 0.0632 - mae: 0.2009 - val_loss: 0.0021 - val_mse: 0.0021 - val_mae: 0.0329\n",
      "Epoch 3/180\n",
      "65/65 [==============================] - 19s 286ms/step - loss: 0.0409 - mse: 0.0409 - mae: 0.1608 - val_loss: 0.0014 - val_mse: 0.0014 - val_mae: 0.0242\n",
      "Epoch 4/180\n",
      "65/65 [==============================] - 19s 297ms/step - loss: 0.0281 - mse: 0.0281 - mae: 0.1328 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0199\n",
      "Epoch 5/180\n",
      "65/65 [==============================] - 19s 297ms/step - loss: 0.0203 - mse: 0.0203 - mae: 0.1122 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0234\n",
      "Epoch 6/180\n",
      "65/65 [==============================] - 19s 291ms/step - loss: 0.0152 - mse: 0.0152 - mae: 0.0974 - val_loss: 0.0014 - val_mse: 0.0014 - val_mae: 0.0223\n",
      "Epoch 7/180\n",
      "65/65 [==============================] - 19s 286ms/step - loss: 0.0122 - mse: 0.0122 - mae: 0.0874 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0176\n",
      "Epoch 8/180\n",
      "65/65 [==============================] - 20s 307ms/step - loss: 0.0100 - mse: 0.0100 - mae: 0.0785 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0171\n",
      "Epoch 9/180\n",
      "65/65 [==============================] - 19s 298ms/step - loss: 0.0084 - mse: 0.0084 - mae: 0.0715 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0173\n",
      "Epoch 10/180\n",
      "65/65 [==============================] - 19s 296ms/step - loss: 0.0072 - mse: 0.0072 - mae: 0.0660 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0172\n",
      "Epoch 11/180\n",
      "65/65 [==============================] - 20s 304ms/step - loss: 0.0065 - mse: 0.0065 - mae: 0.0630 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0171\n",
      "Epoch 12/180\n",
      "65/65 [==============================] - 18s 277ms/step - loss: 0.0057 - mse: 0.0057 - mae: 0.0583 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0190\n",
      "Epoch 13/180\n",
      "65/65 [==============================] - 19s 292ms/step - loss: 0.0052 - mse: 0.0052 - mae: 0.0557 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0197\n",
      "Epoch 14/180\n",
      "65/65 [==============================] - 19s 291ms/step - loss: 0.0048 - mse: 0.0048 - mae: 0.0533 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 15/180\n",
      "65/65 [==============================] - 18s 284ms/step - loss: 0.0045 - mse: 0.0045 - mae: 0.0508 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0196\n",
      "Epoch 16/180\n",
      "65/65 [==============================] - 19s 286ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0467 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0177\n",
      "Epoch 17/180\n",
      "65/65 [==============================] - 18s 280ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0444 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0184\n",
      "Epoch 18/180\n",
      "65/65 [==============================] - 18s 272ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0422 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0207\n",
      "Epoch 19/180\n",
      "65/65 [==============================] - 18s 272ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0402 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0194\n",
      "Epoch 20/180\n",
      "65/65 [==============================] - 20s 301ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0380 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 21/180\n",
      "65/65 [==============================] - 18s 282ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0368 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0190\n",
      "Epoch 22/180\n",
      "65/65 [==============================] - 18s 270ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0349 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0203\n",
      "Epoch 23/180\n",
      "65/65 [==============================] - 18s 280ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0343 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0187\n",
      "Epoch 24/180\n",
      "65/65 [==============================] - 18s 274ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0334 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0205\n",
      "Epoch 25/180\n",
      "65/65 [==============================] - 18s 272ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0316 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0198\n",
      "Epoch 26/180\n",
      "65/65 [==============================] - 19s 289ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0306 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0192\n",
      "Epoch 27/180\n",
      "65/65 [==============================] - 18s 277ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0295 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0200\n",
      "Epoch 28/180\n",
      "65/65 [==============================] - 18s 276ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0291 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0201\n",
      "Epoch 29/180\n",
      "65/65 [==============================] - 19s 287ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0281 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0181\n",
      "Epoch 30/180\n",
      "65/65 [==============================] - 20s 309ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0270 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0182\n",
      "Epoch 31/180\n",
      "65/65 [==============================] - 20s 305ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0266 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0189\n",
      "Epoch 32/180\n",
      "65/65 [==============================] - 20s 301ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0262 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0182\n",
      "Epoch 33/180\n",
      "65/65 [==============================] - 19s 297ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0250 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0183\n",
      "Epoch 34/180\n",
      "65/65 [==============================] - 20s 303ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0243 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 35/180\n",
      "65/65 [==============================] - 19s 296ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0243 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0181\n",
      "Epoch 36/180\n",
      "65/65 [==============================] - 20s 303ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0235 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0188\n",
      "Epoch 37/180\n",
      "65/65 [==============================] - 19s 293ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0233 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0183\n",
      "Epoch 38/180\n",
      "65/65 [==============================] - 19s 295ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0230 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0192\n",
      "Epoch 39/180\n",
      "65/65 [==============================] - 19s 296ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0223 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0191\n",
      "Epoch 40/180\n",
      "65/65 [==============================] - 20s 303ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0217 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0192\n",
      "Epoch 41/180\n",
      "65/65 [==============================] - 19s 299ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0220 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0196\n",
      "Epoch 42/180\n",
      "65/65 [==============================] - 19s 296ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0213 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0191\n",
      "Epoch 43/180\n",
      "65/65 [==============================] - 19s 294ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0208 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0189\n",
      "Epoch 44/180\n",
      "65/65 [==============================] - 18s 281ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0208 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0197\n",
      "Epoch 45/180\n",
      "65/65 [==============================] - 19s 288ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0206 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0190\n",
      "Epoch 46/180\n",
      "65/65 [==============================] - 19s 292ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0203 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0190\n",
      "Epoch 47/180\n",
      "65/65 [==============================] - 19s 291ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0200 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0193\n",
      "Epoch 48/180\n",
      "65/65 [==============================] - 16s 241ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0199 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0187\n",
      "Epoch 49/180\n",
      "65/65 [==============================] - 15s 223ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0198 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0187\n",
      "Epoch 50/180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 14s 208ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0197 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 51/180\n",
      "65/65 [==============================] - 14s 209ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0194 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0189\n",
      "Epoch 52/180\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0193 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 53/180\n",
      "65/65 [==============================] - 14s 209ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0193 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 54/180\n",
      "65/65 [==============================] - 14s 209ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0190 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0189\n",
      "Epoch 55/180\n",
      "65/65 [==============================] - 14s 210ms/step - loss: 9.9157e-04 - mse: 9.9157e-04 - mae: 0.0189 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 56/180\n",
      "65/65 [==============================] - 16s 240ms/step - loss: 9.8719e-04 - mse: 9.8719e-04 - mae: 0.0188 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 57/180\n",
      "65/65 [==============================] - 14s 211ms/step - loss: 9.7152e-04 - mse: 9.7152e-04 - mae: 0.0187 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 58/180\n",
      "65/65 [==============================] - 14s 208ms/step - loss: 9.6552e-04 - mse: 9.6552e-04 - mae: 0.0186 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 59/180\n",
      "65/65 [==============================] - 13s 202ms/step - loss: 9.7162e-04 - mse: 9.7162e-04 - mae: 0.0187 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 60/180\n",
      "65/65 [==============================] - 13s 201ms/step - loss: 9.6246e-04 - mse: 9.6246e-04 - mae: 0.0184 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 61/180\n",
      "65/65 [==============================] - 14s 210ms/step - loss: 9.5686e-04 - mse: 9.5686e-04 - mae: 0.0183 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0184\n",
      "Epoch 62/180\n",
      "65/65 [==============================] - 15s 228ms/step - loss: 9.6260e-04 - mse: 9.6260e-04 - mae: 0.0184 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0187\n",
      "Epoch 63/180\n",
      "65/65 [==============================] - 14s 211ms/step - loss: 9.4735e-04 - mse: 9.4735e-04 - mae: 0.0182 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0184\n",
      "Epoch 64/180\n",
      "65/65 [==============================] - 13s 201ms/step - loss: 9.5590e-04 - mse: 9.5590e-04 - mae: 0.0181 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0187\n",
      "Epoch 65/180\n",
      "65/65 [==============================] - 14s 214ms/step - loss: 9.5075e-04 - mse: 9.5075e-04 - mae: 0.0182 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0184\n",
      "Epoch 66/180\n",
      "65/65 [==============================] - 13s 207ms/step - loss: 9.4457e-04 - mse: 9.4457e-04 - mae: 0.0181 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0187\n",
      "Epoch 67/180\n",
      "65/65 [==============================] - 14s 208ms/step - loss: 9.4453e-04 - mse: 9.4453e-04 - mae: 0.0181 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 68/180\n",
      "65/65 [==============================] - 14s 211ms/step - loss: 9.4076e-04 - mse: 9.4076e-04 - mae: 0.0181 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0183\n",
      "Epoch 69/180\n",
      "65/65 [==============================] - 13s 201ms/step - loss: 9.3706e-04 - mse: 9.3706e-04 - mae: 0.0181 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 70/180\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 9.3947e-04 - mse: 9.3947e-04 - mae: 0.0181 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 71/180\n",
      "65/65 [==============================] - 13s 201ms/step - loss: 9.3563e-04 - mse: 9.3563e-04 - mae: 0.0181 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 72/180\n",
      "65/65 [==============================] - 13s 201ms/step - loss: 9.3394e-04 - mse: 9.3394e-04 - mae: 0.0181 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0184\n",
      "Epoch 73/180\n",
      "65/65 [==============================] - 14s 209ms/step - loss: 9.3195e-04 - mse: 9.3195e-04 - mae: 0.0180 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 74/180\n",
      "65/65 [==============================] - 14s 218ms/step - loss: 9.2542e-04 - mse: 9.2542e-04 - mae: 0.0180 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 75/180\n",
      "65/65 [==============================] - 13s 206ms/step - loss: 9.3291e-04 - mse: 9.3291e-04 - mae: 0.0180 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 76/180\n",
      "65/65 [==============================] - 13s 200ms/step - loss: 9.3458e-04 - mse: 9.3458e-04 - mae: 0.0181 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 77/180\n",
      "65/65 [==============================] - 17s 264ms/step - loss: 9.2650e-04 - mse: 9.2650e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 78/180\n",
      "65/65 [==============================] - 14s 212ms/step - loss: 9.3080e-04 - mse: 9.3080e-04 - mae: 0.0180 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 79/180\n",
      "65/65 [==============================] - 13s 201ms/step - loss: 9.2489e-04 - mse: 9.2489e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 80/180\n",
      "65/65 [==============================] - 13s 200ms/step - loss: 9.2888e-04 - mse: 9.2888e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 81/180\n",
      "65/65 [==============================] - 13s 200ms/step - loss: 9.2594e-04 - mse: 9.2594e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0183\n",
      "Epoch 82/180\n",
      "65/65 [==============================] - 14s 219ms/step - loss: 9.2405e-04 - mse: 9.2405e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 83/180\n",
      "65/65 [==============================] - 13s 207ms/step - loss: 9.2228e-04 - mse: 9.2228e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 84/180\n",
      "65/65 [==============================] - 17s 256ms/step - loss: 9.2071e-04 - mse: 9.2071e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 85/180\n",
      "65/65 [==============================] - 18s 279ms/step - loss: 9.2723e-04 - mse: 9.2723e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 86/180\n",
      "65/65 [==============================] - 20s 315ms/step - loss: 9.2304e-04 - mse: 9.2304e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 87/180\n",
      "65/65 [==============================] - 15s 238ms/step - loss: 9.2085e-04 - mse: 9.2085e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0184\n",
      "Epoch 88/180\n",
      "65/65 [==============================] - 15s 228ms/step - loss: 9.1822e-04 - mse: 9.1822e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 89/180\n",
      "65/65 [==============================] - 16s 240ms/step - loss: 9.1878e-04 - mse: 9.1878e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 90/180\n",
      "65/65 [==============================] - 15s 227ms/step - loss: 9.1617e-04 - mse: 9.1617e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 91/180\n",
      "65/65 [==============================] - 14s 222ms/step - loss: 9.1817e-04 - mse: 9.1817e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 92/180\n",
      "65/65 [==============================] - 15s 235ms/step - loss: 9.1426e-04 - mse: 9.1426e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0184\n",
      "Epoch 93/180\n",
      "65/65 [==============================] - 15s 232ms/step - loss: 9.1650e-04 - mse: 9.1650e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 94/180\n",
      "65/65 [==============================] - 15s 228ms/step - loss: 9.1910e-04 - mse: 9.1910e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 95/180\n",
      "65/65 [==============================] - 15s 224ms/step - loss: 9.1692e-04 - mse: 9.1693e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 96/180\n",
      "65/65 [==============================] - 14s 223ms/step - loss: 9.1571e-04 - mse: 9.1571e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 97/180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 15s 237ms/step - loss: 9.1504e-04 - mse: 9.1504e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 98/180\n",
      "65/65 [==============================] - 15s 232ms/step - loss: 9.1416e-04 - mse: 9.1416e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 99/180\n",
      "65/65 [==============================] - 15s 226ms/step - loss: 9.1485e-04 - mse: 9.1485e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 100/180\n",
      "65/65 [==============================] - 15s 231ms/step - loss: 9.1348e-04 - mse: 9.1348e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0187\n",
      "Epoch 101/180\n",
      "65/65 [==============================] - 15s 223ms/step - loss: 9.1149e-04 - mse: 9.1149e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 102/180\n",
      "65/65 [==============================] - 15s 230ms/step - loss: 9.1474e-04 - mse: 9.1474e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0187\n",
      "Epoch 103/180\n",
      "65/65 [==============================] - 16s 241ms/step - loss: 9.1349e-04 - mse: 9.1349e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 104/180\n",
      "65/65 [==============================] - 15s 235ms/step - loss: 9.1463e-04 - mse: 9.1463e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 105/180\n",
      "65/65 [==============================] - 16s 240ms/step - loss: 9.1252e-04 - mse: 9.1252e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0187\n",
      "Epoch 106/180\n",
      "65/65 [==============================] - 15s 227ms/step - loss: 9.1238e-04 - mse: 9.1238e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0187\n",
      "Epoch 107/180\n",
      "65/65 [==============================] - 15s 229ms/step - loss: 9.1208e-04 - mse: 9.1208e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0188\n",
      "Epoch 108/180\n",
      "65/65 [==============================] - 15s 223ms/step - loss: 9.1132e-04 - mse: 9.1132e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0188\n",
      "Epoch 109/180\n",
      "65/65 [==============================] - 14s 223ms/step - loss: 9.1056e-04 - mse: 9.1056e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 110/180\n",
      "65/65 [==============================] - 15s 223ms/step - loss: 9.1459e-04 - mse: 9.1459e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0187\n",
      "Epoch 111/180\n",
      "65/65 [==============================] - 15s 228ms/step - loss: 9.1039e-04 - mse: 9.1039e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 112/180\n",
      "65/65 [==============================] - 15s 228ms/step - loss: 9.0705e-04 - mse: 9.0705e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0184\n",
      "Epoch 113/180\n",
      "65/65 [==============================] - 15s 238ms/step - loss: 9.0932e-04 - mse: 9.0932e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0187\n",
      "Epoch 114/180\n",
      "65/65 [==============================] - 15s 227ms/step - loss: 9.0471e-04 - mse: 9.0471e-04 - mae: 0.0177 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0186\n",
      "Epoch 115/180\n",
      "65/65 [==============================] - 14s 222ms/step - loss: 9.0822e-04 - mse: 9.0822e-04 - mae: 0.0177 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0187\n",
      "Epoch 116/180\n",
      "65/65 [==============================] - 14s 223ms/step - loss: 9.0598e-04 - mse: 9.0598e-04 - mae: 0.0177 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0186\n",
      "Epoch 117/180\n",
      "65/65 [==============================] - 15s 234ms/step - loss: 9.0197e-04 - mse: 9.0197e-04 - mae: 0.0176 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0185\n",
      "Epoch 118/180\n",
      "65/65 [==============================] - 16s 244ms/step - loss: 9.0192e-04 - mse: 9.0192e-04 - mae: 0.0176 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0184\n",
      "Epoch 119/180\n",
      "65/65 [==============================] - 14s 221ms/step - loss: 9.0093e-04 - mse: 9.0093e-04 - mae: 0.0176 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0183\n",
      "Epoch 120/180\n",
      "65/65 [==============================] - 14s 216ms/step - loss: 8.9483e-04 - mse: 8.9483e-04 - mae: 0.0175 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0182\n",
      "Epoch 121/180\n",
      "65/65 [==============================] - 15s 236ms/step - loss: 8.9685e-04 - mse: 8.9685e-04 - mae: 0.0176 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0184\n",
      "Epoch 122/180\n",
      "65/65 [==============================] - 15s 226ms/step - loss: 8.9606e-04 - mse: 8.9606e-04 - mae: 0.0176 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0181\n",
      "Epoch 123/180\n",
      "65/65 [==============================] - 15s 226ms/step - loss: 8.9271e-04 - mse: 8.9271e-04 - mae: 0.0174 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0183\n",
      "Epoch 124/180\n",
      "65/65 [==============================] - 15s 225ms/step - loss: 8.9175e-04 - mse: 8.9175e-04 - mae: 0.0175 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0182\n",
      "Epoch 125/180\n",
      "65/65 [==============================] - 14s 219ms/step - loss: 8.9119e-04 - mse: 8.9119e-04 - mae: 0.0174 - val_loss: 9.8333e-04 - val_mse: 9.8333e-04 - val_mae: 0.0179\n",
      "Epoch 126/180\n",
      "65/65 [==============================] - 15s 227ms/step - loss: 8.8786e-04 - mse: 8.8786e-04 - mae: 0.0174 - val_loss: 9.6656e-04 - val_mse: 9.6656e-04 - val_mae: 0.0180\n",
      "Epoch 127/180\n",
      "65/65 [==============================] - 15s 228ms/step - loss: 8.8647e-04 - mse: 8.8647e-04 - mae: 0.0173 - val_loss: 9.5768e-04 - val_mse: 9.5768e-04 - val_mae: 0.0178\n",
      "Epoch 128/180\n",
      "65/65 [==============================] - 14s 218ms/step - loss: 8.8610e-04 - mse: 8.8610e-04 - mae: 0.0173 - val_loss: 9.4266e-04 - val_mse: 9.4266e-04 - val_mae: 0.0183\n",
      "Epoch 129/180\n",
      "65/65 [==============================] - 16s 246ms/step - loss: 8.7548e-04 - mse: 8.7548e-04 - mae: 0.0172 - val_loss: 9.2839e-04 - val_mse: 9.2839e-04 - val_mae: 0.0180\n",
      "Epoch 130/180\n",
      "65/65 [==============================] - 16s 241ms/step - loss: 8.7975e-04 - mse: 8.7975e-04 - mae: 0.0172 - val_loss: 9.1768e-04 - val_mse: 9.1768e-04 - val_mae: 0.0182\n",
      "Epoch 131/180\n",
      "65/65 [==============================] - 15s 236ms/step - loss: 8.7855e-04 - mse: 8.7855e-04 - mae: 0.0172 - val_loss: 9.0384e-04 - val_mse: 9.0384e-04 - val_mae: 0.0181\n",
      "Epoch 132/180\n",
      "65/65 [==============================] - 16s 239ms/step - loss: 8.7034e-04 - mse: 8.7034e-04 - mae: 0.0170 - val_loss: 8.9539e-04 - val_mse: 8.9539e-04 - val_mae: 0.0177\n",
      "Epoch 133/180\n",
      "65/65 [==============================] - 16s 248ms/step - loss: 8.7604e-04 - mse: 8.7604e-04 - mae: 0.0171 - val_loss: 8.8558e-04 - val_mse: 8.8558e-04 - val_mae: 0.0176\n",
      "Epoch 134/180\n",
      "65/65 [==============================] - 15s 233ms/step - loss: 8.7050e-04 - mse: 8.7050e-04 - mae: 0.0170 - val_loss: 8.8781e-04 - val_mse: 8.8781e-04 - val_mae: 0.0178\n",
      "Epoch 135/180\n",
      "65/65 [==============================] - 16s 250ms/step - loss: 8.6959e-04 - mse: 8.6959e-04 - mae: 0.0170 - val_loss: 8.8559e-04 - val_mse: 8.8559e-04 - val_mae: 0.0178\n",
      "Epoch 136/180\n",
      "65/65 [==============================] - 16s 245ms/step - loss: 8.7091e-04 - mse: 8.7091e-04 - mae: 0.0169 - val_loss: 8.8853e-04 - val_mse: 8.8853e-04 - val_mae: 0.0184\n",
      "Epoch 137/180\n",
      "65/65 [==============================] - 17s 258ms/step - loss: 8.6604e-04 - mse: 8.6604e-04 - mae: 0.0169 - val_loss: 8.6898e-04 - val_mse: 8.6898e-04 - val_mae: 0.0180\n",
      "Epoch 138/180\n",
      "65/65 [==============================] - 16s 248ms/step - loss: 8.6313e-04 - mse: 8.6313e-04 - mae: 0.0169 - val_loss: 8.7076e-04 - val_mse: 8.7076e-04 - val_mae: 0.0170\n",
      "Epoch 139/180\n",
      "65/65 [==============================] - 15s 224ms/step - loss: 8.6575e-04 - mse: 8.6575e-04 - mae: 0.0169 - val_loss: 8.7581e-04 - val_mse: 8.7581e-04 - val_mae: 0.0182\n",
      "Epoch 140/180\n",
      "65/65 [==============================] - 15s 224ms/step - loss: 8.6827e-04 - mse: 8.6827e-04 - mae: 0.0169 - val_loss: 8.6817e-04 - val_mse: 8.6817e-04 - val_mae: 0.0181\n",
      "Epoch 141/180\n",
      "65/65 [==============================] - 16s 249ms/step - loss: 8.5954e-04 - mse: 8.5954e-04 - mae: 0.0169 - val_loss: 8.8053e-04 - val_mse: 8.8053e-04 - val_mae: 0.0185\n",
      "Epoch 142/180\n",
      "65/65 [==============================] - 17s 263ms/step - loss: 8.6539e-04 - mse: 8.6539e-04 - mae: 0.0169 - val_loss: 8.7342e-04 - val_mse: 8.7342e-04 - val_mae: 0.0185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143/180\n",
      "65/65 [==============================] - 15s 223ms/step - loss: 8.6139e-04 - mse: 8.6139e-04 - mae: 0.0169 - val_loss: 8.4613e-04 - val_mse: 8.4613e-04 - val_mae: 0.0182\n",
      "Epoch 144/180\n",
      "65/65 [==============================] - 15s 226ms/step - loss: 8.6587e-04 - mse: 8.6587e-04 - mae: 0.0170 - val_loss: 8.6869e-04 - val_mse: 8.6869e-04 - val_mae: 0.0187\n",
      "Epoch 145/180\n",
      "65/65 [==============================] - 15s 237ms/step - loss: 8.5755e-04 - mse: 8.5755e-04 - mae: 0.0168 - val_loss: 8.7831e-04 - val_mse: 8.7831e-04 - val_mae: 0.0186\n",
      "Epoch 146/180\n",
      "65/65 [==============================] - 15s 225ms/step - loss: 8.5980e-04 - mse: 8.5980e-04 - mae: 0.0168 - val_loss: 8.4720e-04 - val_mse: 8.4720e-04 - val_mae: 0.0179\n",
      "Epoch 147/180\n",
      "65/65 [==============================] - 14s 223ms/step - loss: 8.5843e-04 - mse: 8.5843e-04 - mae: 0.0168 - val_loss: 8.6682e-04 - val_mse: 8.6682e-04 - val_mae: 0.0184\n",
      "Epoch 148/180\n",
      "65/65 [==============================] - 14s 221ms/step - loss: 8.5656e-04 - mse: 8.5656e-04 - mae: 0.0167 - val_loss: 8.6772e-04 - val_mse: 8.6772e-04 - val_mae: 0.0186\n",
      "Epoch 149/180\n",
      "65/65 [==============================] - 15s 225ms/step - loss: 8.5700e-04 - mse: 8.5700e-04 - mae: 0.0167 - val_loss: 8.6565e-04 - val_mse: 8.6565e-04 - val_mae: 0.0185\n",
      "Epoch 150/180\n",
      "65/65 [==============================] - 17s 257ms/step - loss: 8.5052e-04 - mse: 8.5052e-04 - mae: 0.0167 - val_loss: 8.4984e-04 - val_mse: 8.4984e-04 - val_mae: 0.0182\n",
      "Epoch 151/180\n",
      "65/65 [==============================] - 15s 233ms/step - loss: 8.4940e-04 - mse: 8.4940e-04 - mae: 0.0166 - val_loss: 8.5501e-04 - val_mse: 8.5501e-04 - val_mae: 0.0184\n",
      "Epoch 152/180\n",
      "65/65 [==============================] - 17s 259ms/step - loss: 8.5403e-04 - mse: 8.5403e-04 - mae: 0.0166 - val_loss: 8.7139e-04 - val_mse: 8.7139e-04 - val_mae: 0.0183\n",
      "Epoch 153/180\n",
      "65/65 [==============================] - 16s 247ms/step - loss: 8.5827e-04 - mse: 8.5827e-04 - mae: 0.0166 - val_loss: 8.9705e-04 - val_mse: 8.9705e-04 - val_mae: 0.0189\n",
      "Epoch 154/180\n",
      "65/65 [==============================] - 18s 276ms/step - loss: 8.4846e-04 - mse: 8.4846e-04 - mae: 0.0166 - val_loss: 8.8135e-04 - val_mse: 8.8135e-04 - val_mae: 0.0186\n",
      "Epoch 155/180\n",
      "65/65 [==============================] - 16s 248ms/step - loss: 8.5062e-04 - mse: 8.5062e-04 - mae: 0.0166 - val_loss: 8.8232e-04 - val_mse: 8.8232e-04 - val_mae: 0.0189\n",
      "Epoch 156/180\n",
      "65/65 [==============================] - 15s 232ms/step - loss: 8.4622e-04 - mse: 8.4622e-04 - mae: 0.0166 - val_loss: 8.9882e-04 - val_mse: 8.9882e-04 - val_mae: 0.0189\n",
      "Epoch 157/180\n",
      "65/65 [==============================] - 15s 226ms/step - loss: 8.4596e-04 - mse: 8.4596e-04 - mae: 0.0165 - val_loss: 8.8098e-04 - val_mse: 8.8098e-04 - val_mae: 0.0184\n",
      "Epoch 158/180\n",
      "65/65 [==============================] - 14s 221ms/step - loss: 8.4017e-04 - mse: 8.4017e-04 - mae: 0.0164 - val_loss: 9.1566e-04 - val_mse: 9.1566e-04 - val_mae: 0.0190\n",
      "Epoch 159/180\n",
      "65/65 [==============================] - 14s 220ms/step - loss: 8.5370e-04 - mse: 8.5370e-04 - mae: 0.0165 - val_loss: 8.9037e-04 - val_mse: 8.9037e-04 - val_mae: 0.0186\n",
      "Epoch 160/180\n",
      "65/65 [==============================] - 15s 226ms/step - loss: 8.4278e-04 - mse: 8.4278e-04 - mae: 0.0164 - val_loss: 9.0745e-04 - val_mse: 9.0745e-04 - val_mae: 0.0189\n",
      "Epoch 161/180\n",
      "65/65 [==============================] - 14s 219ms/step - loss: 8.4538e-04 - mse: 8.4538e-04 - mae: 0.0165 - val_loss: 9.0494e-04 - val_mse: 9.0494e-04 - val_mae: 0.0189\n",
      "Epoch 162/180\n",
      "65/65 [==============================] - 16s 239ms/step - loss: 8.4854e-04 - mse: 8.4854e-04 - mae: 0.0165 - val_loss: 8.8276e-04 - val_mse: 8.8276e-04 - val_mae: 0.0185\n",
      "Epoch 163/180\n",
      "65/65 [==============================] - 19s 297ms/step - loss: 8.3962e-04 - mse: 8.3962e-04 - mae: 0.0164 - val_loss: 9.2308e-04 - val_mse: 9.2308e-04 - val_mae: 0.0190\n",
      "Epoch 164/180\n",
      "65/65 [==============================] - 18s 278ms/step - loss: 8.4530e-04 - mse: 8.4530e-04 - mae: 0.0164 - val_loss: 8.9153e-04 - val_mse: 8.9153e-04 - val_mae: 0.0186\n",
      "Epoch 165/180\n",
      "65/65 [==============================] - 15s 233ms/step - loss: 8.3726e-04 - mse: 8.3726e-04 - mae: 0.0163 - val_loss: 9.1666e-04 - val_mse: 9.1666e-04 - val_mae: 0.0187\n",
      "Epoch 166/180\n",
      "65/65 [==============================] - 15s 229ms/step - loss: 8.4180e-04 - mse: 8.4180e-04 - mae: 0.0164 - val_loss: 9.5457e-04 - val_mse: 9.5457e-04 - val_mae: 0.0196\n",
      "Epoch 167/180\n",
      "65/65 [==============================] - 15s 231ms/step - loss: 8.3464e-04 - mse: 8.3464e-04 - mae: 0.0163 - val_loss: 9.1384e-04 - val_mse: 9.1384e-04 - val_mae: 0.0187\n",
      "Epoch 168/180\n",
      "65/65 [==============================] - 15s 231ms/step - loss: 8.3791e-04 - mse: 8.3791e-04 - mae: 0.0163 - val_loss: 9.2492e-04 - val_mse: 9.2492e-04 - val_mae: 0.0189\n",
      "Epoch 169/180\n",
      "65/65 [==============================] - 16s 245ms/step - loss: 8.3404e-04 - mse: 8.3404e-04 - mae: 0.0163 - val_loss: 8.9534e-04 - val_mse: 8.9534e-04 - val_mae: 0.0183\n",
      "Epoch 170/180\n",
      "65/65 [==============================] - 17s 259ms/step - loss: 8.4081e-04 - mse: 8.4081e-04 - mae: 0.0164 - val_loss: 9.3693e-04 - val_mse: 9.3693e-04 - val_mae: 0.0194\n",
      "Epoch 171/180\n",
      "65/65 [==============================] - 17s 266ms/step - loss: 8.3797e-04 - mse: 8.3797e-04 - mae: 0.0163 - val_loss: 9.1941e-04 - val_mse: 9.1941e-04 - val_mae: 0.0188\n",
      "Epoch 172/180\n",
      "65/65 [==============================] - 16s 246ms/step - loss: 8.3266e-04 - mse: 8.3266e-04 - mae: 0.0163 - val_loss: 9.3752e-04 - val_mse: 9.3752e-04 - val_mae: 0.0192\n",
      "Epoch 173/180\n",
      "65/65 [==============================] - 15s 225ms/step - loss: 8.3325e-04 - mse: 8.3325e-04 - mae: 0.0163 - val_loss: 9.1826e-04 - val_mse: 9.1826e-04 - val_mae: 0.0186\n",
      "Epoch 174/180\n",
      "65/65 [==============================] - 16s 239ms/step - loss: 8.3987e-04 - mse: 8.3987e-04 - mae: 0.0164 - val_loss: 9.2208e-04 - val_mse: 9.2208e-04 - val_mae: 0.0189\n",
      "Epoch 175/180\n",
      "65/65 [==============================] - 16s 240ms/step - loss: 8.3292e-04 - mse: 8.3292e-04 - mae: 0.0164 - val_loss: 9.1504e-04 - val_mse: 9.1504e-04 - val_mae: 0.0187\n",
      "Epoch 176/180\n",
      "65/65 [==============================] - 15s 226ms/step - loss: 8.2993e-04 - mse: 8.2993e-04 - mae: 0.0162 - val_loss: 8.8721e-04 - val_mse: 8.8721e-04 - val_mae: 0.0173\n",
      "Epoch 177/180\n",
      "65/65 [==============================] - 14s 219ms/step - loss: 8.3318e-04 - mse: 8.3318e-04 - mae: 0.0163 - val_loss: 9.2202e-04 - val_mse: 9.2202e-04 - val_mae: 0.0187\n",
      "Epoch 178/180\n",
      "65/65 [==============================] - 14s 218ms/step - loss: 8.3308e-04 - mse: 8.3308e-04 - mae: 0.0162 - val_loss: 9.3461e-04 - val_mse: 9.3461e-04 - val_mae: 0.0192\n",
      "Epoch 179/180\n",
      "65/65 [==============================] - 14s 222ms/step - loss: 8.2830e-04 - mse: 8.2830e-04 - mae: 0.0161 - val_loss: 9.2281e-04 - val_mse: 9.2281e-04 - val_mae: 0.0186\n",
      "Epoch 180/180\n",
      "65/65 [==============================] - 16s 249ms/step - loss: 8.4627e-04 - mse: 8.4627e-04 - mae: 0.0163 - val_loss: 9.0527e-04 - val_mse: 9.0527e-04 - val_mae: 0.0188\n",
      "Epoch 1/180\n",
      "65/65 [==============================] - 39s 602ms/step - loss: 0.1426 - mse: 0.1426 - mae: 0.2960 - val_loss: 0.0048 - val_mse: 0.0048 - val_mae: 0.0591\n",
      "Epoch 2/180\n",
      "65/65 [==============================] - 41s 627ms/step - loss: 0.0791 - mse: 0.0791 - mae: 0.2238 - val_loss: 0.0015 - val_mse: 0.0015 - val_mae: 0.0262\n",
      "Epoch 3/180\n",
      "65/65 [==============================] - 37s 567ms/step - loss: 0.0485 - mse: 0.0485 - mae: 0.1752 - val_loss: 0.0017 - val_mse: 0.0017 - val_mae: 0.0293\n",
      "Epoch 4/180\n",
      "65/65 [==============================] - 38s 581ms/step - loss: 0.0316 - mse: 0.0316 - mae: 0.1414 - val_loss: 0.0024 - val_mse: 0.0024 - val_mae: 0.0415\n",
      "Epoch 5/180\n",
      "65/65 [==============================] - 38s 577ms/step - loss: 0.0220 - mse: 0.0220 - mae: 0.1178 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0234\n",
      "Epoch 6/180\n",
      "65/65 [==============================] - 40s 611ms/step - loss: 0.0152 - mse: 0.0152 - mae: 0.0972 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0189\n",
      "Epoch 7/180\n",
      "65/65 [==============================] - 41s 634ms/step - loss: 0.0119 - mse: 0.0119 - mae: 0.0862 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0234\n",
      "Epoch 8/180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 42s 652ms/step - loss: 0.0096 - mse: 0.0096 - mae: 0.0764 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0199\n",
      "Epoch 9/180\n",
      "65/65 [==============================] - 43s 663ms/step - loss: 0.0080 - mse: 0.0080 - mae: 0.0704 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0229\n",
      "Epoch 10/180\n",
      "65/65 [==============================] - 44s 673ms/step - loss: 0.0068 - mse: 0.0068 - mae: 0.0643 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0265\n",
      "Epoch 11/180\n",
      "65/65 [==============================] - 41s 626ms/step - loss: 0.0055 - mse: 0.0055 - mae: 0.0578 - val_loss: 0.0015 - val_mse: 0.0015 - val_mae: 0.0334\n",
      "Epoch 12/180\n",
      "65/65 [==============================] - 38s 591ms/step - loss: 0.0047 - mse: 0.0047 - mae: 0.0528 - val_loss: 0.0015 - val_mse: 0.0015 - val_mae: 0.0326\n",
      "Epoch 13/180\n",
      "65/65 [==============================] - 42s 645ms/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0499 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0292\n",
      "Epoch 14/180\n",
      "65/65 [==============================] - 40s 610ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0482 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0281\n",
      "Epoch 15/180\n",
      "65/65 [==============================] - 45s 699ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0462 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0288\n",
      "Epoch 16/180\n",
      "65/65 [==============================] - 39s 601ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0444 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0269\n",
      "Epoch 17/180\n",
      "65/65 [==============================] - 38s 587ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0423 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0246\n",
      "Epoch 18/180\n",
      "65/65 [==============================] - 38s 582ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0405 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0240\n",
      "Epoch 19/180\n",
      "65/65 [==============================] - 40s 617ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0383 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0236\n",
      "Epoch 20/180\n",
      "65/65 [==============================] - 39s 604ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0374 - val_loss: 9.2689e-04 - val_mse: 9.2689e-04 - val_mae: 0.0205\n",
      "Epoch 21/180\n",
      "65/65 [==============================] - 39s 599ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0357 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0244\n",
      "Epoch 22/180\n",
      "65/65 [==============================] - 41s 638ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0347 - val_loss: 9.4774e-04 - val_mse: 9.4774e-04 - val_mae: 0.0205\n",
      "Epoch 23/180\n",
      "65/65 [==============================] - 42s 648ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0332 - val_loss: 9.5630e-04 - val_mse: 9.5630e-04 - val_mae: 0.0213\n",
      "Epoch 24/180\n",
      "65/65 [==============================] - 36s 561ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0321 - val_loss: 9.4742e-04 - val_mse: 9.4742e-04 - val_mae: 0.0211\n",
      "Epoch 25/180\n",
      "65/65 [==============================] - 38s 586ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0308 - val_loss: 9.3907e-04 - val_mse: 9.3907e-04 - val_mae: 0.0209\n",
      "Epoch 26/180\n",
      "65/65 [==============================] - 37s 563ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0309 - val_loss: 9.6407e-04 - val_mse: 9.6407e-04 - val_mae: 0.0217\n",
      "Epoch 27/180\n",
      "65/65 [==============================] - 37s 571ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0296 - val_loss: 9.2001e-04 - val_mse: 9.2001e-04 - val_mae: 0.0199\n",
      "Epoch 28/180\n",
      "65/65 [==============================] - 45s 694ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0290 - val_loss: 9.7965e-04 - val_mse: 9.7965e-04 - val_mae: 0.0224\n",
      "Epoch 29/180\n",
      "65/65 [==============================] - 44s 682ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0276 - val_loss: 9.3414e-04 - val_mse: 9.3414e-04 - val_mae: 0.0201\n",
      "Epoch 30/180\n",
      "65/65 [==============================] - 42s 647ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0273 - val_loss: 9.5896e-04 - val_mse: 9.5896e-04 - val_mae: 0.0214\n",
      "Epoch 31/180\n",
      "65/65 [==============================] - 42s 643ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0265 - val_loss: 9.3938e-04 - val_mse: 9.3938e-04 - val_mae: 0.0204\n",
      "Epoch 32/180\n",
      "65/65 [==============================] - 41s 631ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0254 - val_loss: 9.3057e-04 - val_mse: 9.3057e-04 - val_mae: 0.0201\n",
      "Epoch 33/180\n",
      "65/65 [==============================] - 40s 614ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0253 - val_loss: 9.4192e-04 - val_mse: 9.4192e-04 - val_mae: 0.0202\n",
      "Epoch 34/180\n",
      "65/65 [==============================] - 39s 595ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0245 - val_loss: 9.7504e-04 - val_mse: 9.7504e-04 - val_mae: 0.0212\n",
      "Epoch 35/180\n",
      "65/65 [==============================] - 42s 650ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0242 - val_loss: 9.6588e-04 - val_mse: 9.6588e-04 - val_mae: 0.0200\n",
      "Epoch 36/180\n",
      "65/65 [==============================] - 39s 599ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0233 - val_loss: 9.8621e-04 - val_mse: 9.8621e-04 - val_mae: 0.0212\n",
      "Epoch 37/180\n",
      "65/65 [==============================] - 39s 597ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0233 - val_loss: 9.5272e-04 - val_mse: 9.5272e-04 - val_mae: 0.0197\n",
      "Epoch 38/180\n",
      "65/65 [==============================] - 39s 595ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0227 - val_loss: 9.6560e-04 - val_mse: 9.6560e-04 - val_mae: 0.0208\n",
      "Epoch 39/180\n",
      "65/65 [==============================] - 42s 645ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0223 - val_loss: 9.4502e-04 - val_mse: 9.4502e-04 - val_mae: 0.0190\n",
      "Epoch 40/180\n",
      "65/65 [==============================] - 41s 635ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0218 - val_loss: 9.5347e-04 - val_mse: 9.5347e-04 - val_mae: 0.0198\n",
      "Epoch 41/180\n",
      "65/65 [==============================] - 39s 600ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0214 - val_loss: 9.6437e-04 - val_mse: 9.6437e-04 - val_mae: 0.0205\n",
      "Epoch 42/180\n",
      "65/65 [==============================] - 39s 601ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0212 - val_loss: 9.6688e-04 - val_mse: 9.6688e-04 - val_mae: 0.0208\n",
      "Epoch 43/180\n",
      "65/65 [==============================] - 38s 577ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0211 - val_loss: 9.5092e-04 - val_mse: 9.5092e-04 - val_mae: 0.0191\n",
      "Epoch 44/180\n",
      "65/65 [==============================] - 39s 605ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0209 - val_loss: 9.5732e-04 - val_mse: 9.5732e-04 - val_mae: 0.0199\n",
      "Epoch 45/180\n",
      "65/65 [==============================] - 41s 625ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0205 - val_loss: 9.5484e-04 - val_mse: 9.5484e-04 - val_mae: 0.0191\n",
      "Epoch 46/180\n",
      "65/65 [==============================] - 37s 577ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0204 - val_loss: 9.7213e-04 - val_mse: 9.7213e-04 - val_mae: 0.0205\n",
      "Epoch 47/180\n",
      "65/65 [==============================] - 38s 581ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0201 - val_loss: 9.5426e-04 - val_mse: 9.5426e-04 - val_mae: 0.0196\n",
      "Epoch 48/180\n",
      "65/65 [==============================] - 39s 602ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0198 - val_loss: 9.5626e-04 - val_mse: 9.5626e-04 - val_mae: 0.0193\n",
      "Epoch 49/180\n",
      "65/65 [==============================] - 39s 600ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0197 - val_loss: 9.5331e-04 - val_mse: 9.5331e-04 - val_mae: 0.0192\n",
      "Epoch 50/180\n",
      "65/65 [==============================] - 38s 585ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0198 - val_loss: 9.5630e-04 - val_mse: 9.5630e-04 - val_mae: 0.0197\n",
      "Epoch 51/180\n",
      "65/65 [==============================] - 41s 623ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0197 - val_loss: 9.5776e-04 - val_mse: 9.5776e-04 - val_mae: 0.0194\n",
      "Epoch 52/180\n",
      "65/65 [==============================] - 44s 673ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0193 - val_loss: 9.5614e-04 - val_mse: 9.5614e-04 - val_mae: 0.0196\n",
      "Epoch 53/180\n",
      "65/65 [==============================] - 44s 682ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0193 - val_loss: 9.6185e-04 - val_mse: 9.6185e-04 - val_mae: 0.0202\n",
      "Epoch 54/180\n",
      "65/65 [==============================] - 45s 695ms/step - loss: 9.8970e-04 - mse: 9.8970e-04 - mae: 0.0190 - val_loss: 9.4856e-04 - val_mse: 9.4856e-04 - val_mae: 0.0191\n",
      "Epoch 55/180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 45s 688ms/step - loss: 9.9083e-04 - mse: 9.9083e-04 - mae: 0.0190 - val_loss: 9.5340e-04 - val_mse: 9.5340e-04 - val_mae: 0.0196\n",
      "Epoch 56/180\n",
      "65/65 [==============================] - 46s 700ms/step - loss: 9.8669e-04 - mse: 9.8669e-04 - mae: 0.0189 - val_loss: 9.4625e-04 - val_mse: 9.4625e-04 - val_mae: 0.0196\n",
      "Epoch 57/180\n",
      "65/65 [==============================] - 46s 711ms/step - loss: 9.8658e-04 - mse: 9.8658e-04 - mae: 0.0187 - val_loss: 9.5155e-04 - val_mse: 9.5155e-04 - val_mae: 0.0195\n",
      "Epoch 58/180\n",
      "65/65 [==============================] - 45s 689ms/step - loss: 9.7132e-04 - mse: 9.7132e-04 - mae: 0.0186 - val_loss: 9.4393e-04 - val_mse: 9.4393e-04 - val_mae: 0.0189\n",
      "Epoch 59/180\n",
      "65/65 [==============================] - 47s 728ms/step - loss: 9.6564e-04 - mse: 9.6564e-04 - mae: 0.0184 - val_loss: 9.4476e-04 - val_mse: 9.4476e-04 - val_mae: 0.0190\n",
      "Epoch 60/180\n",
      "65/65 [==============================] - 40s 611ms/step - loss: 9.6176e-04 - mse: 9.6176e-04 - mae: 0.0185 - val_loss: 9.5226e-04 - val_mse: 9.5226e-04 - val_mae: 0.0195\n",
      "Epoch 61/180\n",
      "65/65 [==============================] - 38s 581ms/step - loss: 9.5193e-04 - mse: 9.5193e-04 - mae: 0.0183 - val_loss: 9.5098e-04 - val_mse: 9.5098e-04 - val_mae: 0.0197\n",
      "Epoch 62/180\n",
      "65/65 [==============================] - 38s 581ms/step - loss: 9.5904e-04 - mse: 9.5904e-04 - mae: 0.0184 - val_loss: 9.5565e-04 - val_mse: 9.5565e-04 - val_mae: 0.0196\n",
      "Epoch 63/180\n",
      "65/65 [==============================] - 42s 650ms/step - loss: 9.5853e-04 - mse: 9.5853e-04 - mae: 0.0184 - val_loss: 9.5365e-04 - val_mse: 9.5365e-04 - val_mae: 0.0197\n",
      "Epoch 64/180\n",
      "65/65 [==============================] - 36s 556ms/step - loss: 9.4229e-04 - mse: 9.4229e-04 - mae: 0.0182 - val_loss: 9.5422e-04 - val_mse: 9.5422e-04 - val_mae: 0.0199\n",
      "Epoch 65/180\n",
      "65/65 [==============================] - 36s 554ms/step - loss: 9.4977e-04 - mse: 9.4977e-04 - mae: 0.0182 - val_loss: 9.5197e-04 - val_mse: 9.5197e-04 - val_mae: 0.0195\n",
      "Epoch 66/180\n",
      "65/65 [==============================] - 35s 545ms/step - loss: 9.4973e-04 - mse: 9.4973e-04 - mae: 0.0182 - val_loss: 9.4155e-04 - val_mse: 9.4155e-04 - val_mae: 0.0184\n",
      "Epoch 67/180\n",
      "65/65 [==============================] - 35s 544ms/step - loss: 9.4921e-04 - mse: 9.4921e-04 - mae: 0.0182 - val_loss: 9.4235e-04 - val_mse: 9.4235e-04 - val_mae: 0.0188\n",
      "Epoch 68/180\n",
      "65/65 [==============================] - 35s 546ms/step - loss: 9.3165e-04 - mse: 9.3165e-04 - mae: 0.0179 - val_loss: 9.3809e-04 - val_mse: 9.3809e-04 - val_mae: 0.0184\n",
      "Epoch 69/180\n",
      "65/65 [==============================] - 38s 577ms/step - loss: 9.4305e-04 - mse: 9.4305e-04 - mae: 0.0181 - val_loss: 9.4216e-04 - val_mse: 9.4216e-04 - val_mae: 0.0192\n",
      "Epoch 70/180\n",
      "65/65 [==============================] - 35s 543ms/step - loss: 9.2757e-04 - mse: 9.2757e-04 - mae: 0.0180 - val_loss: 9.5521e-04 - val_mse: 9.5521e-04 - val_mae: 0.0192\n",
      "Epoch 71/180\n",
      "65/65 [==============================] - 35s 536ms/step - loss: 9.2652e-04 - mse: 9.2652e-04 - mae: 0.0180 - val_loss: 9.5762e-04 - val_mse: 9.5762e-04 - val_mae: 0.0188\n",
      "Epoch 72/180\n",
      "65/65 [==============================] - 36s 553ms/step - loss: 9.2413e-04 - mse: 9.2413e-04 - mae: 0.0178 - val_loss: 9.4002e-04 - val_mse: 9.4002e-04 - val_mae: 0.0178\n",
      "Epoch 73/180\n",
      "65/65 [==============================] - 36s 551ms/step - loss: 9.2143e-04 - mse: 9.2143e-04 - mae: 0.0178 - val_loss: 9.4988e-04 - val_mse: 9.4988e-04 - val_mae: 0.0185\n",
      "Epoch 74/180\n",
      "65/65 [==============================] - 36s 559ms/step - loss: 9.1581e-04 - mse: 9.1581e-04 - mae: 0.0178 - val_loss: 9.4989e-04 - val_mse: 9.4989e-04 - val_mae: 0.0180\n",
      "Epoch 75/180\n",
      "65/65 [==============================] - 37s 563ms/step - loss: 9.1844e-04 - mse: 9.1844e-04 - mae: 0.0178 - val_loss: 9.5882e-04 - val_mse: 9.5882e-04 - val_mae: 0.0186\n",
      "Epoch 76/180\n",
      "65/65 [==============================] - 36s 547ms/step - loss: 9.0849e-04 - mse: 9.0849e-04 - mae: 0.0177 - val_loss: 9.5036e-04 - val_mse: 9.5036e-04 - val_mae: 0.0182\n",
      "Epoch 77/180\n",
      "65/65 [==============================] - 35s 536ms/step - loss: 9.1455e-04 - mse: 9.1455e-04 - mae: 0.0177 - val_loss: 9.4920e-04 - val_mse: 9.4920e-04 - val_mae: 0.0185\n",
      "Epoch 78/180\n",
      "65/65 [==============================] - 42s 652ms/step - loss: 8.9811e-04 - mse: 8.9811e-04 - mae: 0.0175 - val_loss: 9.5065e-04 - val_mse: 9.5065e-04 - val_mae: 0.0183\n",
      "Epoch 79/180\n",
      "65/65 [==============================] - 39s 594ms/step - loss: 9.0418e-04 - mse: 9.0418e-04 - mae: 0.0174 - val_loss: 9.4787e-04 - val_mse: 9.4787e-04 - val_mae: 0.0185\n",
      "Epoch 80/180\n",
      "65/65 [==============================] - 41s 626ms/step - loss: 9.0362e-04 - mse: 9.0362e-04 - mae: 0.0176 - val_loss: 9.4265e-04 - val_mse: 9.4265e-04 - val_mae: 0.0186\n",
      "Epoch 81/180\n",
      "65/65 [==============================] - 42s 639ms/step - loss: 9.0711e-04 - mse: 9.0711e-04 - mae: 0.0176 - val_loss: 9.7117e-04 - val_mse: 9.7117e-04 - val_mae: 0.0191\n",
      "Epoch 82/180\n",
      "65/65 [==============================] - 39s 599ms/step - loss: 9.0062e-04 - mse: 9.0062e-04 - mae: 0.0174 - val_loss: 9.4328e-04 - val_mse: 9.4328e-04 - val_mae: 0.0179\n",
      "Epoch 83/180\n",
      "65/65 [==============================] - 41s 634ms/step - loss: 8.8898e-04 - mse: 8.8898e-04 - mae: 0.0174 - val_loss: 9.4556e-04 - val_mse: 9.4556e-04 - val_mae: 0.0180\n",
      "Epoch 84/180\n",
      "65/65 [==============================] - 40s 620ms/step - loss: 9.0036e-04 - mse: 9.0036e-04 - mae: 0.0173 - val_loss: 9.4105e-04 - val_mse: 9.4105e-04 - val_mae: 0.0174\n",
      "Epoch 85/180\n",
      "65/65 [==============================] - 41s 635ms/step - loss: 8.9375e-04 - mse: 8.9375e-04 - mae: 0.0174 - val_loss: 9.4219e-04 - val_mse: 9.4219e-04 - val_mae: 0.0176\n",
      "Epoch 86/180\n",
      "65/65 [==============================] - 41s 624ms/step - loss: 8.9164e-04 - mse: 8.9164e-04 - mae: 0.0173 - val_loss: 9.6223e-04 - val_mse: 9.6223e-04 - val_mae: 0.0188\n",
      "Epoch 87/180\n",
      "65/65 [==============================] - 39s 606ms/step - loss: 8.9168e-04 - mse: 8.9168e-04 - mae: 0.0173 - val_loss: 9.6980e-04 - val_mse: 9.6980e-04 - val_mae: 0.0189\n",
      "Epoch 88/180\n",
      "65/65 [==============================] - 40s 608ms/step - loss: 8.8615e-04 - mse: 8.8615e-04 - mae: 0.0172 - val_loss: 9.5377e-04 - val_mse: 9.5377e-04 - val_mae: 0.0182\n",
      "Epoch 89/180\n",
      "65/65 [==============================] - 42s 639ms/step - loss: 8.8844e-04 - mse: 8.8844e-04 - mae: 0.0172 - val_loss: 9.4232e-04 - val_mse: 9.4232e-04 - val_mae: 0.0183\n",
      "Epoch 90/180\n",
      "65/65 [==============================] - 42s 644ms/step - loss: 8.8108e-04 - mse: 8.8108e-04 - mae: 0.0172 - val_loss: 9.8211e-04 - val_mse: 9.8211e-04 - val_mae: 0.0191\n",
      "Epoch 91/180\n",
      "65/65 [==============================] - 46s 713ms/step - loss: 8.8212e-04 - mse: 8.8212e-04 - mae: 0.0171 - val_loss: 9.7670e-04 - val_mse: 9.7670e-04 - val_mae: 0.0184\n",
      "Epoch 92/180\n",
      "65/65 [==============================] - 41s 631ms/step - loss: 8.8799e-04 - mse: 8.8799e-04 - mae: 0.0171 - val_loss: 9.6488e-04 - val_mse: 9.6488e-04 - val_mae: 0.0178\n",
      "Epoch 93/180\n",
      "65/65 [==============================] - 41s 625ms/step - loss: 8.7807e-04 - mse: 8.7807e-04 - mae: 0.0170 - val_loss: 9.8579e-04 - val_mse: 9.8579e-04 - val_mae: 0.0186\n",
      "Epoch 94/180\n",
      "65/65 [==============================] - 39s 600ms/step - loss: 8.6480e-04 - mse: 8.6480e-04 - mae: 0.0169 - val_loss: 9.4707e-04 - val_mse: 9.4707e-04 - val_mae: 0.0176\n",
      "Epoch 95/180\n",
      "65/65 [==============================] - 38s 592ms/step - loss: 8.8692e-04 - mse: 8.8692e-04 - mae: 0.0173 - val_loss: 9.6271e-04 - val_mse: 9.6271e-04 - val_mae: 0.0184\n",
      "Epoch 96/180\n",
      "65/65 [==============================] - 40s 622ms/step - loss: 8.6362e-04 - mse: 8.6362e-04 - mae: 0.0168 - val_loss: 9.7321e-04 - val_mse: 9.7321e-04 - val_mae: 0.0182\n",
      "Epoch 97/180\n",
      "65/65 [==============================] - 38s 587ms/step - loss: 8.7273e-04 - mse: 8.7273e-04 - mae: 0.0169 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0198\n",
      "Epoch 98/180\n",
      "65/65 [==============================] - 40s 616ms/step - loss: 8.6280e-04 - mse: 8.6280e-04 - mae: 0.0168 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0197\n",
      "Epoch 99/180\n",
      "65/65 [==============================] - 43s 657ms/step - loss: 8.6742e-04 - mse: 8.6742e-04 - mae: 0.0168 - val_loss: 9.8865e-04 - val_mse: 9.8865e-04 - val_mae: 0.0178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/180\n",
      "65/65 [==============================] - 41s 637ms/step - loss: 8.6611e-04 - mse: 8.6611e-04 - mae: 0.0168 - val_loss: 9.6934e-04 - val_mse: 9.6934e-04 - val_mae: 0.0173\n",
      "Epoch 101/180\n",
      "65/65 [==============================] - 40s 616ms/step - loss: 8.6857e-04 - mse: 8.6857e-04 - mae: 0.0168 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0195\n",
      "Epoch 102/180\n",
      "65/65 [==============================] - 42s 644ms/step - loss: 8.6352e-04 - mse: 8.6352e-04 - mae: 0.0167 - val_loss: 9.7369e-04 - val_mse: 9.7369e-04 - val_mae: 0.0175\n",
      "Epoch 103/180\n",
      "65/65 [==============================] - 43s 656ms/step - loss: 8.6077e-04 - mse: 8.6077e-04 - mae: 0.0167 - val_loss: 9.8669e-04 - val_mse: 9.8669e-04 - val_mae: 0.0179\n",
      "Epoch 104/180\n",
      "65/65 [==============================] - 45s 687ms/step - loss: 8.5904e-04 - mse: 8.5904e-04 - mae: 0.0167 - val_loss: 9.9508e-04 - val_mse: 9.9508e-04 - val_mae: 0.0180\n",
      "Epoch 105/180\n",
      "65/65 [==============================] - 39s 608ms/step - loss: 8.5496e-04 - mse: 8.5496e-04 - mae: 0.0166 - val_loss: 9.6121e-04 - val_mse: 9.6121e-04 - val_mae: 0.0176\n",
      "Epoch 106/180\n",
      "65/65 [==============================] - 41s 626ms/step - loss: 8.6069e-04 - mse: 8.6069e-04 - mae: 0.0166 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0185\n",
      "Epoch 107/180\n",
      "65/65 [==============================] - 41s 633ms/step - loss: 8.5577e-04 - mse: 8.5577e-04 - mae: 0.0166 - val_loss: 9.9831e-04 - val_mse: 9.9831e-04 - val_mae: 0.0180\n",
      "Epoch 108/180\n",
      "65/65 [==============================] - 41s 638ms/step - loss: 8.4906e-04 - mse: 8.4906e-04 - mae: 0.0166 - val_loss: 9.8006e-04 - val_mse: 9.8006e-04 - val_mae: 0.0180\n",
      "Epoch 109/180\n",
      "65/65 [==============================] - 41s 626ms/step - loss: 8.4533e-04 - mse: 8.4533e-04 - mae: 0.0165 - val_loss: 9.9246e-04 - val_mse: 9.9246e-04 - val_mae: 0.0181\n",
      "Epoch 110/180\n",
      "65/65 [==============================] - 44s 670ms/step - loss: 8.4694e-04 - mse: 8.4694e-04 - mae: 0.0165 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0188\n",
      "Epoch 111/180\n",
      "65/65 [==============================] - 43s 660ms/step - loss: 8.4788e-04 - mse: 8.4788e-04 - mae: 0.0166 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0188\n",
      "Epoch 112/180\n",
      "65/65 [==============================] - 43s 654ms/step - loss: 8.4057e-04 - mse: 8.4057e-04 - mae: 0.0164 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0184\n",
      "Epoch 113/180\n",
      "65/65 [==============================] - 41s 628ms/step - loss: 8.4139e-04 - mse: 8.4139e-04 - mae: 0.0164 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0187\n",
      "Epoch 114/180\n",
      "65/65 [==============================] - 38s 585ms/step - loss: 8.3892e-04 - mse: 8.3892e-04 - mae: 0.0163 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0183\n",
      "Epoch 115/180\n",
      "65/65 [==============================] - 40s 617ms/step - loss: 8.5364e-04 - mse: 8.5364e-04 - mae: 0.0167 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0211\n",
      "Epoch 116/180\n",
      "65/65 [==============================] - 45s 693ms/step - loss: 8.4759e-04 - mse: 8.4759e-04 - mae: 0.0164 - val_loss: 9.6787e-04 - val_mse: 9.6787e-04 - val_mae: 0.0191\n",
      "Epoch 117/180\n",
      "65/65 [==============================] - 45s 687ms/step - loss: 8.4750e-04 - mse: 8.4750e-04 - mae: 0.0167 - val_loss: 9.6365e-04 - val_mse: 9.6365e-04 - val_mae: 0.0174\n",
      "Epoch 118/180\n",
      "65/65 [==============================] - 43s 660ms/step - loss: 8.3597e-04 - mse: 8.3597e-04 - mae: 0.0164 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0194\n",
      "Epoch 119/180\n",
      "65/65 [==============================] - 50s 763ms/step - loss: 8.3795e-04 - mse: 8.3795e-04 - mae: 0.0164 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0180\n",
      "Epoch 120/180\n",
      "65/65 [==============================] - 45s 700ms/step - loss: 8.3709e-04 - mse: 8.3709e-04 - mae: 0.0164 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0194\n",
      "Epoch 121/180\n",
      "65/65 [==============================] - 43s 659ms/step - loss: 8.1872e-04 - mse: 8.1872e-04 - mae: 0.0161 - val_loss: 9.5750e-04 - val_mse: 9.5750e-04 - val_mae: 0.0175\n",
      "Epoch 122/180\n",
      "65/65 [==============================] - 44s 675ms/step - loss: 8.3696e-04 - mse: 8.3696e-04 - mae: 0.0164 - val_loss: 9.7630e-04 - val_mse: 9.7630e-04 - val_mae: 0.0177\n",
      "Epoch 123/180\n",
      "65/65 [==============================] - 41s 635ms/step - loss: 8.2952e-04 - mse: 8.2952e-04 - mae: 0.0162 - val_loss: 9.6699e-04 - val_mse: 9.6699e-04 - val_mae: 0.0173\n",
      "Epoch 124/180\n",
      "65/65 [==============================] - 39s 603ms/step - loss: 8.3346e-04 - mse: 8.3346e-04 - mae: 0.0163 - val_loss: 9.8734e-04 - val_mse: 9.8734e-04 - val_mae: 0.0179\n",
      "Epoch 125/180\n",
      "65/65 [==============================] - 38s 578ms/step - loss: 8.2404e-04 - mse: 8.2404e-04 - mae: 0.0162 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0196\n",
      "Epoch 126/180\n",
      "65/65 [==============================] - 39s 601ms/step - loss: 8.3041e-04 - mse: 8.3041e-04 - mae: 0.0163 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0225\n",
      "Epoch 127/180\n",
      "65/65 [==============================] - 42s 645ms/step - loss: 8.3007e-04 - mse: 8.3007e-04 - mae: 0.0162 - val_loss: 9.6357e-04 - val_mse: 9.6357e-04 - val_mae: 0.0168\n",
      "Epoch 128/180\n",
      "65/65 [==============================] - 41s 636ms/step - loss: 8.1540e-04 - mse: 8.1540e-04 - mae: 0.0163 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0182\n",
      "Epoch 129/180\n",
      "65/65 [==============================] - 41s 630ms/step - loss: 8.1789e-04 - mse: 8.1789e-04 - mae: 0.0160 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0193\n",
      "Epoch 130/180\n",
      "65/65 [==============================] - 41s 625ms/step - loss: 8.1477e-04 - mse: 8.1477e-04 - mae: 0.0160 - val_loss: 9.4901e-04 - val_mse: 9.4901e-04 - val_mae: 0.0167\n",
      "Epoch 131/180\n",
      "65/65 [==============================] - 38s 587ms/step - loss: 8.1994e-04 - mse: 8.1994e-04 - mae: 0.0161 - val_loss: 9.7651e-04 - val_mse: 9.7651e-04 - val_mae: 0.0172\n",
      "Epoch 132/180\n",
      "65/65 [==============================] - 43s 664ms/step - loss: 8.0589e-04 - mse: 8.0589e-04 - mae: 0.0160 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0173\n",
      "Epoch 133/180\n",
      "65/65 [==============================] - 39s 593ms/step - loss: 8.1409e-04 - mse: 8.1409e-04 - mae: 0.0162 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0208\n",
      "Epoch 134/180\n",
      "65/65 [==============================] - 38s 588ms/step - loss: 8.2179e-04 - mse: 8.2179e-04 - mae: 0.0160 - val_loss: 9.6491e-04 - val_mse: 9.6491e-04 - val_mae: 0.0176\n",
      "Epoch 135/180\n",
      "65/65 [==============================] - 40s 618ms/step - loss: 8.1176e-04 - mse: 8.1176e-04 - mae: 0.0160 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0175\n",
      "Epoch 136/180\n",
      "65/65 [==============================] - 42s 642ms/step - loss: 8.1112e-04 - mse: 8.1112e-04 - mae: 0.0160 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0174\n",
      "Epoch 137/180\n",
      "65/65 [==============================] - 40s 616ms/step - loss: 8.1120e-04 - mse: 8.1120e-04 - mae: 0.0160 - val_loss: 9.7465e-04 - val_mse: 9.7465e-04 - val_mae: 0.0170\n",
      "Epoch 138/180\n",
      "65/65 [==============================] - 39s 604ms/step - loss: 8.0523e-04 - mse: 8.0523e-04 - mae: 0.0159 - val_loss: 9.6899e-04 - val_mse: 9.6899e-04 - val_mae: 0.0169\n",
      "Epoch 139/180\n",
      "65/65 [==============================] - 40s 620ms/step - loss: 8.0353e-04 - mse: 8.0353e-04 - mae: 0.0158 - val_loss: 9.9097e-04 - val_mse: 9.9097e-04 - val_mae: 0.0175\n",
      "Epoch 140/180\n",
      "65/65 [==============================] - 39s 593ms/step - loss: 7.9978e-04 - mse: 7.9978e-04 - mae: 0.0158 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0179\n",
      "Epoch 141/180\n",
      "65/65 [==============================] - 38s 588ms/step - loss: 7.9485e-04 - mse: 7.9485e-04 - mae: 0.0158 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0181\n",
      "Epoch 142/180\n",
      "65/65 [==============================] - 42s 644ms/step - loss: 8.0023e-04 - mse: 8.0023e-04 - mae: 0.0158 - val_loss: 9.9281e-04 - val_mse: 9.9281e-04 - val_mae: 0.0177\n",
      "Epoch 143/180\n",
      "65/65 [==============================] - 40s 613ms/step - loss: 8.0036e-04 - mse: 8.0036e-04 - mae: 0.0158 - val_loss: 9.9069e-04 - val_mse: 9.9069e-04 - val_mae: 0.0165\n",
      "Epoch 144/180\n",
      "65/65 [==============================] - 40s 618ms/step - loss: 8.0431e-04 - mse: 8.0431e-04 - mae: 0.0159 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0192\n",
      "Epoch 145/180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 41s 638ms/step - loss: 8.0501e-04 - mse: 8.0501e-04 - mae: 0.0159 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0191\n",
      "Epoch 146/180\n",
      "65/65 [==============================] - 40s 613ms/step - loss: 8.0143e-04 - mse: 8.0143e-04 - mae: 0.0158 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0183\n",
      "Epoch 147/180\n",
      "65/65 [==============================] - 39s 608ms/step - loss: 7.9866e-04 - mse: 7.9866e-04 - mae: 0.0158 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0183\n",
      "Epoch 148/180\n",
      "65/65 [==============================] - 38s 586ms/step - loss: 7.9063e-04 - mse: 7.9063e-04 - mae: 0.0158 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0183\n",
      "Epoch 149/180\n",
      "65/65 [==============================] - 37s 574ms/step - loss: 7.9625e-04 - mse: 7.9625e-04 - mae: 0.0159 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0193\n",
      "Epoch 150/180\n",
      "65/65 [==============================] - 37s 573ms/step - loss: 7.8431e-04 - mse: 7.8431e-04 - mae: 0.0157 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0176\n",
      "Epoch 151/180\n",
      "65/65 [==============================] - 38s 588ms/step - loss: 8.0560e-04 - mse: 8.0560e-04 - mae: 0.0161 - val_loss: 9.8860e-04 - val_mse: 9.8860e-04 - val_mae: 0.0174\n",
      "Epoch 152/180\n",
      "65/65 [==============================] - 37s 568ms/step - loss: 7.8834e-04 - mse: 7.8834e-04 - mae: 0.0159 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0192\n",
      "Epoch 153/180\n",
      "65/65 [==============================] - 38s 577ms/step - loss: 7.9353e-04 - mse: 7.9354e-04 - mae: 0.0157 - val_loss: 9.9855e-04 - val_mse: 9.9855e-04 - val_mae: 0.0177\n",
      "Epoch 154/180\n",
      "65/65 [==============================] - 38s 583ms/step - loss: 7.8552e-04 - mse: 7.8552e-04 - mae: 0.0159 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0178\n",
      "Epoch 155/180\n",
      "65/65 [==============================] - 36s 551ms/step - loss: 7.9513e-04 - mse: 7.9513e-04 - mae: 0.0158 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0188\n",
      "Epoch 156/180\n",
      "65/65 [==============================] - 34s 526ms/step - loss: 7.9841e-04 - mse: 7.9841e-04 - mae: 0.0157 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0178\n",
      "Epoch 157/180\n",
      "65/65 [==============================] - 35s 545ms/step - loss: 7.9557e-04 - mse: 7.9557e-04 - mae: 0.0157 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0193\n",
      "Epoch 158/180\n",
      "65/65 [==============================] - 36s 561ms/step - loss: 7.8966e-04 - mse: 7.8966e-04 - mae: 0.0157 - val_loss: 9.4493e-04 - val_mse: 9.4493e-04 - val_mae: 0.0171\n",
      "Epoch 159/180\n",
      "65/65 [==============================] - 35s 537ms/step - loss: 7.8379e-04 - mse: 7.8379e-04 - mae: 0.0157 - val_loss: 9.8121e-04 - val_mse: 9.8121e-04 - val_mae: 0.0167\n",
      "Epoch 160/180\n",
      "65/65 [==============================] - 35s 540ms/step - loss: 7.8013e-04 - mse: 7.8013e-04 - mae: 0.0156 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0170\n",
      "Epoch 161/180\n",
      "65/65 [==============================] - 36s 559ms/step - loss: 8.0251e-04 - mse: 8.0251e-04 - mae: 0.0160 - val_loss: 9.4255e-04 - val_mse: 9.4255e-04 - val_mae: 0.0162\n",
      "Epoch 162/180\n",
      "65/65 [==============================] - 35s 539ms/step - loss: 7.8750e-04 - mse: 7.8750e-04 - mae: 0.0158 - val_loss: 9.2880e-04 - val_mse: 9.2880e-04 - val_mae: 0.0169\n",
      "Epoch 163/180\n",
      "65/65 [==============================] - 36s 555ms/step - loss: 7.8385e-04 - mse: 7.8385e-04 - mae: 0.0156 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0172\n",
      "Epoch 164/180\n",
      "65/65 [==============================] - 35s 537ms/step - loss: 7.9200e-04 - mse: 7.9200e-04 - mae: 0.0157 - val_loss: 9.2889e-04 - val_mse: 9.2889e-04 - val_mae: 0.0170\n",
      "Epoch 165/180\n",
      "65/65 [==============================] - 36s 548ms/step - loss: 8.0543e-04 - mse: 8.0543e-04 - mae: 0.0159 - val_loss: 9.6425e-04 - val_mse: 9.6425e-04 - val_mae: 0.0165\n",
      "Epoch 166/180\n",
      "65/65 [==============================] - 36s 558ms/step - loss: 7.8069e-04 - mse: 7.8069e-04 - mae: 0.0156 - val_loss: 9.5959e-04 - val_mse: 9.5959e-04 - val_mae: 0.0160\n",
      "Epoch 167/180\n",
      "65/65 [==============================] - 37s 576ms/step - loss: 7.9710e-04 - mse: 7.9710e-04 - mae: 0.0159 - val_loss: 9.3984e-04 - val_mse: 9.3984e-04 - val_mae: 0.0158\n",
      "Epoch 168/180\n",
      "65/65 [==============================] - 39s 595ms/step - loss: 7.9666e-04 - mse: 7.9666e-04 - mae: 0.0160 - val_loss: 9.3704e-04 - val_mse: 9.3704e-04 - val_mae: 0.0164\n",
      "Epoch 169/180\n",
      "65/65 [==============================] - 37s 576ms/step - loss: 7.6167e-04 - mse: 7.6167e-04 - mae: 0.0156 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0180\n",
      "Epoch 170/180\n",
      "65/65 [==============================] - 38s 591ms/step - loss: 7.8986e-04 - mse: 7.8986e-04 - mae: 0.0158 - val_loss: 9.7235e-04 - val_mse: 9.7235e-04 - val_mae: 0.0170\n",
      "Epoch 171/180\n",
      "65/65 [==============================] - 36s 555ms/step - loss: 8.1284e-04 - mse: 8.1284e-04 - mae: 0.0161 - val_loss: 9.5953e-04 - val_mse: 9.5953e-04 - val_mae: 0.0181\n",
      "Epoch 172/180\n",
      "65/65 [==============================] - 37s 571ms/step - loss: 7.7328e-04 - mse: 7.7328e-04 - mae: 0.0156 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0176\n",
      "Epoch 173/180\n",
      "65/65 [==============================] - 42s 639ms/step - loss: 7.6030e-04 - mse: 7.6030e-04 - mae: 0.0155 - val_loss: 9.9045e-04 - val_mse: 9.9045e-04 - val_mae: 0.0173\n",
      "Epoch 174/180\n",
      "65/65 [==============================] - 40s 612ms/step - loss: 7.8559e-04 - mse: 7.8559e-04 - mae: 0.0158 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0171\n",
      "Epoch 175/180\n",
      "65/65 [==============================] - 37s 562ms/step - loss: 7.7398e-04 - mse: 7.7398e-04 - mae: 0.0159 - val_loss: 9.5082e-04 - val_mse: 9.5082e-04 - val_mae: 0.0178\n",
      "Epoch 176/180\n",
      "61/65 [===========================>..] - ETA: 2s - loss: 6.6891e-04 - mse: 6.6891e-04 - mae: 0.0157"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "steps = 96\n",
    "#n_hidden = 1\n",
    "#units = 100\n",
    "batch_size = 96\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "# no hidden or one hidden layer\n",
    "parameters = {'n_hidden': [1, 2],\n",
    "              'units': [50, 100, 150, 200]}\n",
    "\n",
    "all_param = ParameterGrid(parameters)\n",
    "\n",
    "# function to split data into correct shape for RNN\n",
    "def split_data(X, y, steps):\n",
    "    X_, y_ = list(), list()\n",
    "    for i in range(steps, len(y)):\n",
    "        X_.append(X[i - steps : i, :])\n",
    "        y_.append(y[i]) \n",
    "    return np.array(X_), np.array(y_)\n",
    "\n",
    "# function to cut data set so it can be divisible by the batch_size\n",
    "def cut_data(data, batch_size):\n",
    "     # see if it is divisivel\n",
    "    condition = data.shape[0] % batch_size\n",
    "    if condition == 0:\n",
    "        return data\n",
    "    else:\n",
    "        return data[: -condition]\n",
    "\n",
    "# divide features and labels\n",
    "X_train = data_train[:, 0:15] \n",
    "y_train = data_train[:, -1]\n",
    "X_test = data_test[:, 0:15] \n",
    "y_test = data_test[:, -1] \n",
    "\n",
    "# divide data into train and test \n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "         X_train, y_train, test_size = 0.15, shuffle=False)\n",
    "\n",
    "# put data into correct shape\n",
    "X_train, y_train = split_data(X_train, y_train, steps)\n",
    "X_test, y_test = split_data(X_test, y_test, steps)\n",
    "X_val, y_val = split_data(X_val, y_val, steps)\n",
    "\n",
    "X_train = cut_data(X_train, batch_size)\n",
    "y_train = cut_data(y_train, batch_size)\n",
    "X_test = cut_data(X_test, batch_size)\n",
    "y_test = cut_data(y_test, batch_size)\n",
    "X_val = cut_data(X_val, batch_size)\n",
    "y_val = cut_data(y_val, batch_size)\n",
    "\n",
    "# design the LSTM\n",
    "def regressor_tunning(kernel_initializer = 'he_normal',\n",
    "                      bias_initializer = initializers.Ones()):\n",
    "    model = Sequential()\n",
    "    if n_hidden == 0:\n",
    "        model.add(LSTM(units = units,                    \n",
    "                       batch_input_shape = (batch_size, steps, features_num), \n",
    "                       stateful = True,\n",
    "                       kernel_initializer = kernel_initializer,\n",
    "                       bias_initializer = bias_initializer))\n",
    "        model.add(LeakyReLU(alpha = 0.2))\n",
    "        model.add(Dropout(0.2))\n",
    "    else:\n",
    "        model.add(LSTM(units = units,                    \n",
    "                       batch_input_shape = (batch_size, steps, features_num), \n",
    "                       stateful = True,\n",
    "                       return_sequences = True,\n",
    "                       kernel_initializer = kernel_initializer,\n",
    "                       bias_initializer = bias_initializer))\n",
    "        model.add(LeakyReLU(alpha = 0.2))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(LSTM(units = units, \n",
    "                       batch_input_shape = (batch_size, steps, features_num), \n",
    "                       stateful = True,\n",
    "                       kernel_initializer = kernel_initializer,\n",
    "                       bias_initializer = bias_initializer))\n",
    "        model.add(LeakyReLU(alpha = 0.2))\n",
    "        model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(loss = 'mse', metrics = ['mse', 'mae'], optimizer = 'Adamax')\n",
    "    return model\n",
    "\n",
    "# inverse of test set should not be inside the loop \n",
    "y_test = (y_test * sc_X.data_range_[15]) + (sc_X.data_min_[15])\n",
    "\n",
    "for i in range(len(all_param)):\n",
    "    \n",
    "    units = all_param[i]['units']\n",
    "    n_hidden = all_param[i]['n_hidden']\n",
    "    \n",
    "    model = regressor_tunning()\n",
    "\n",
    "    # fitting the LSTM to the training set\n",
    "    history = model.fit(X_train,\n",
    "                        y_train, \n",
    "                        batch_size = batch_size, \n",
    "                        epochs = 180,\n",
    "                        shuffle = False, \n",
    "                        validation_data = (X_val, y_val))\n",
    "    \n",
    "    model.reset_states()\n",
    "    \n",
    "    # make new predicitons with test set\n",
    "    y_pred = model.predict(X_test, batch_size = batch_size)\n",
    "    \n",
    "    # prices col = 15\n",
    "    y_pred = (y_pred * sc_X.data_range_[15]) + (sc_X.data_min_[15])\n",
    "\n",
    "    y_pred_list.append(y_pred)\n",
    "    \n",
    "    from sklearn.metrics import mean_squared_error as mse\n",
    "    from sklearn.metrics import mean_absolute_error as mae\n",
    "\n",
    "    rmse_error = mse(y_test, y_pred, squared = False)\n",
    "    mae_error = mae(y_test, y_pred)\n",
    "    \n",
    "    rmse_gen.append(rmse_error)\n",
    "    mae_gen.append(mae_error)\n",
    "    \n",
    "    # =============================================================================\n",
    "    # Metrics evaluation on spike regions\n",
    "    # =============================================================================\n",
    "    \n",
    "    y_spike_occ = pd.read_csv('Spike_binary_1std.csv', usecols = [6])\n",
    "    \n",
    "    # create array same size as y_test\n",
    "    y_spike_occ = y_spike_occ.iloc[- len(y_test):]\n",
    "    y_spike_occ = pd.Series(y_spike_occ.iloc[:,0]).values\n",
    "    \n",
    "    # smal adjustment\n",
    "    y_test = pd.Series(y_test)\n",
    "    y_test.replace(0, 0.0001,inplace = True)\n",
    "\n",
    "    # select y_pred and y_test only for regions with spikes\n",
    "    y_test_spike = (y_test.T * y_spike_occ).T\n",
    "    y_pred_spike = (y_pred.T * y_spike_occ).T\n",
    "    y_test_spike = y_test_spike[y_test_spike != 0]\n",
    "    y_pred_spike = y_pred_spike[y_pred_spike != 0]\n",
    "    \n",
    "    # calculate metric\n",
    "    rmse_spike = mse(y_test_spike, y_pred_spike, squared = False)\n",
    "    mae_spike = mae(y_test_spike, y_pred_spike)\n",
    "    \n",
    "    rmse_spi.append(rmse_spike)\n",
    "    mae_spi.append(mae_spike)\n",
    "    \n",
    "    # =============================================================================\n",
    "    # Metric evaluation on normal regions\n",
    "    # =============================================================================\n",
    "    \n",
    "    # inverse y_spike_occ so the only normal occurences are chosen\n",
    "    y_normal_occ = (y_spike_occ - 1) * (-1)\n",
    "    \n",
    "    # sanity check\n",
    "    y_normal_occ.sum() + y_spike_occ.sum() # gives the correct total \n",
    "    \n",
    "    # select y_pred and y_test only for normal regions\n",
    "    y_test_normal = (y_test.T * y_normal_occ).T\n",
    "    y_pred_normal = (y_pred.T * y_normal_occ).T\n",
    "    y_test_normal = y_test_normal[y_test_normal != 0.00]\n",
    "    y_pred_normal = y_pred_normal[y_pred_normal != 0.00]\n",
    "    \n",
    "    # calculate metric\n",
    "    rmse_normal = mse(y_test_normal, y_pred_normal, squared = False)\n",
    "    mae_normal = mae(y_test_normal, y_pred_normal)\n",
    "    \n",
    "    rmse_nor.append(rmse_normal)\n",
    "    mae_nor.append(mae_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({'all_param':all_param,\n",
    "                        \n",
    "                        'rmse_general': rmse_gen, \n",
    "                 \n",
    "                        'mae_general': mae_gen,\n",
    "                        \n",
    "                        'rmse_spike': rmse_spi,\n",
    "                 \n",
    "                        'mae_spike': mae_spi,\n",
    "                        \n",
    "                        'rmse_normal': rmse_nor,\n",
    "                    \n",
    "                        'mae_normal': mae_nor})\n",
    "\n",
    "results.to_csv('Results_LSTM_2_n_neurons_n_hidden.csv')\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({'rmse_general': rmse_gen, \n",
    "                 \n",
    "                        'mae_general': mae_gen,\n",
    "                        \n",
    "                        'rmse_spike': rmse_spi,\n",
    "                 \n",
    "                        'mae_spike': mae_spi,\n",
    "                        \n",
    "                        'rmse_normal': rmse_nor,\n",
    "                    \n",
    "                        'mae_normal': mae_nor})\n",
    "\n",
    "def highlight_min(s):\n",
    "    '''\n",
    "    highlight the maximum in a Series yellow.\n",
    "    '''\n",
    "    is_max = s == s.min()\n",
    "    return ['background-color: yellow' if v else '' for v in is_max]\n",
    "\n",
    "results.style.apply(highlight_min)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
