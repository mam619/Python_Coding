{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Parameter Tunning \n",
    "    \n",
    "    Look at n_neurons & n_hidden layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\maria\\anaconda3\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from pandas) (1.18.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from python-dateutil>=2.6.1->pandas) (1.14.0)\n",
      "Requirement already satisfied: sklearn in c:\\users\\maria\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\maria\\anaconda3\\lib\\site-packages (from sklearn) (0.22.1)\n",
      "Requirement already satisfied: numpy>=1.11.0 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.18.1)\n",
      "Requirement already satisfied: scipy>=0.17.0 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.4.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (0.14.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install sklearn\n",
    "\n",
    "import pandas as pd;\n",
    "import numpy as np;\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data; set X and y; fill nan values and split in test and training  data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "data = pd.read_csv('Data_set_1_smaller.csv', index_col = 0)\n",
    "\n",
    "# for later use\n",
    "features_num = 15\n",
    "\n",
    "# 2018 data\n",
    "data = data.loc[data.index > 2018070000, :]\n",
    "\n",
    "# reset index\n",
    "data.reset_index(inplace = True)\n",
    "data.drop('index', axis = 1, inplace = True)\n",
    "\n",
    "# fill nan values\n",
    "data.fillna(method = 'ffill', inplace = True)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# divide data into train and test \n",
    "data_train, data_test = train_test_split(\n",
    "         data, test_size = 0.15, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply feature scaling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# data scaling  (including offer (y))\n",
    "sc_X = MinMaxScaler()\n",
    "data_train = sc_X.fit_transform(data_train)\n",
    "data_test = sc_X.transform(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LeakyReLU\n",
    "from keras import initializers\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "mae_cv = []\n",
    "mse_cv = []\n",
    "mae_gen = []\n",
    "mse_gen  =[]\n",
    "rmse_gen = []\n",
    "mae_nor = []\n",
    "mae_spi = []\n",
    "mse_nor = []\n",
    "mse_spi = []\n",
    "rmse_nor = []\n",
    "rmse_spi = []\n",
    "hist_list = []\n",
    "y_pred_list = []\n",
    "prediction_list = []\n",
    "time_count = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare of data according to LSTM needs,  create regressor & tune:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/180\n",
      "65/65 [==============================] - 23s 351ms/step - loss: 0.1158 - mse: 0.1158 - mae: 0.2701 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0425\n",
      "Epoch 2/180\n",
      "65/65 [==============================] - 20s 311ms/step - loss: 0.0632 - mse: 0.0632 - mae: 0.2009 - val_loss: 0.0021 - val_mse: 0.0021 - val_mae: 0.0329\n",
      "Epoch 3/180\n",
      "65/65 [==============================] - 19s 286ms/step - loss: 0.0409 - mse: 0.0409 - mae: 0.1608 - val_loss: 0.0014 - val_mse: 0.0014 - val_mae: 0.0242\n",
      "Epoch 4/180\n",
      "65/65 [==============================] - 19s 297ms/step - loss: 0.0281 - mse: 0.0281 - mae: 0.1328 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0199\n",
      "Epoch 5/180\n",
      "65/65 [==============================] - 19s 297ms/step - loss: 0.0203 - mse: 0.0203 - mae: 0.1122 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0234\n",
      "Epoch 6/180\n",
      "65/65 [==============================] - 19s 291ms/step - loss: 0.0152 - mse: 0.0152 - mae: 0.0974 - val_loss: 0.0014 - val_mse: 0.0014 - val_mae: 0.0223\n",
      "Epoch 7/180\n",
      "65/65 [==============================] - 19s 286ms/step - loss: 0.0122 - mse: 0.0122 - mae: 0.0874 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0176\n",
      "Epoch 8/180\n",
      "65/65 [==============================] - 20s 307ms/step - loss: 0.0100 - mse: 0.0100 - mae: 0.0785 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0171\n",
      "Epoch 9/180\n",
      "65/65 [==============================] - 19s 298ms/step - loss: 0.0084 - mse: 0.0084 - mae: 0.0715 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0173\n",
      "Epoch 10/180\n",
      "65/65 [==============================] - 19s 296ms/step - loss: 0.0072 - mse: 0.0072 - mae: 0.0660 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0172\n",
      "Epoch 11/180\n",
      "65/65 [==============================] - 20s 304ms/step - loss: 0.0065 - mse: 0.0065 - mae: 0.0630 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0171\n",
      "Epoch 12/180\n",
      "65/65 [==============================] - 18s 277ms/step - loss: 0.0057 - mse: 0.0057 - mae: 0.0583 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0190\n",
      "Epoch 13/180\n",
      "65/65 [==============================] - 19s 292ms/step - loss: 0.0052 - mse: 0.0052 - mae: 0.0557 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0197\n",
      "Epoch 14/180\n",
      "65/65 [==============================] - 19s 291ms/step - loss: 0.0048 - mse: 0.0048 - mae: 0.0533 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 15/180\n",
      "65/65 [==============================] - 18s 284ms/step - loss: 0.0045 - mse: 0.0045 - mae: 0.0508 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0196\n",
      "Epoch 16/180\n",
      "65/65 [==============================] - 19s 286ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0467 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0177\n",
      "Epoch 17/180\n",
      "65/65 [==============================] - 18s 280ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0444 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0184\n",
      "Epoch 18/180\n",
      "65/65 [==============================] - 18s 272ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0422 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0207\n",
      "Epoch 19/180\n",
      "65/65 [==============================] - 18s 272ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0402 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0194\n",
      "Epoch 20/180\n",
      "65/65 [==============================] - 20s 301ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0380 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 21/180\n",
      "65/65 [==============================] - 18s 282ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0368 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0190\n",
      "Epoch 22/180\n",
      "65/65 [==============================] - 18s 270ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0349 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0203\n",
      "Epoch 23/180\n",
      "65/65 [==============================] - 18s 280ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0343 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0187\n",
      "Epoch 24/180\n",
      "65/65 [==============================] - 18s 274ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0334 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0205\n",
      "Epoch 25/180\n",
      "65/65 [==============================] - 18s 272ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0316 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0198\n",
      "Epoch 26/180\n",
      "65/65 [==============================] - 19s 289ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0306 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0192\n",
      "Epoch 27/180\n",
      "65/65 [==============================] - 18s 277ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0295 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0200\n",
      "Epoch 28/180\n",
      "65/65 [==============================] - 18s 276ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0291 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0201\n",
      "Epoch 29/180\n",
      "65/65 [==============================] - 19s 287ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0281 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0181\n",
      "Epoch 30/180\n",
      "65/65 [==============================] - 20s 309ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0270 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0182\n",
      "Epoch 31/180\n",
      "65/65 [==============================] - 20s 305ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0266 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0189\n",
      "Epoch 32/180\n",
      "65/65 [==============================] - 20s 301ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0262 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0182\n",
      "Epoch 33/180\n",
      "65/65 [==============================] - 19s 297ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0250 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0183\n",
      "Epoch 34/180\n",
      "65/65 [==============================] - 20s 303ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0243 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 35/180\n",
      "65/65 [==============================] - 19s 296ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0243 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0181\n",
      "Epoch 36/180\n",
      "65/65 [==============================] - 20s 303ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0235 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0188\n",
      "Epoch 37/180\n",
      "65/65 [==============================] - 19s 293ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0233 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0183\n",
      "Epoch 38/180\n",
      "65/65 [==============================] - 19s 295ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0230 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0192\n",
      "Epoch 39/180\n",
      "65/65 [==============================] - 19s 296ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0223 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0191\n",
      "Epoch 40/180\n",
      "65/65 [==============================] - 20s 303ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0217 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0192\n",
      "Epoch 41/180\n",
      "65/65 [==============================] - 19s 299ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0220 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0196\n",
      "Epoch 42/180\n",
      "65/65 [==============================] - 19s 296ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0213 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0191\n",
      "Epoch 43/180\n",
      "65/65 [==============================] - 19s 294ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0208 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0189\n",
      "Epoch 44/180\n",
      "65/65 [==============================] - 18s 281ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0208 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0197\n",
      "Epoch 45/180\n",
      "65/65 [==============================] - 19s 288ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0206 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0190\n",
      "Epoch 46/180\n",
      "65/65 [==============================] - 19s 292ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0203 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0190\n",
      "Epoch 47/180\n",
      "65/65 [==============================] - 19s 291ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0200 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0193\n",
      "Epoch 48/180\n",
      "65/65 [==============================] - 16s 241ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0199 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0187\n",
      "Epoch 49/180\n",
      "65/65 [==============================] - 15s 223ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0198 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0187\n",
      "Epoch 50/180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 14s 208ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0197 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 51/180\n",
      "65/65 [==============================] - 14s 209ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0194 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0189\n",
      "Epoch 52/180\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0193 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 53/180\n",
      "65/65 [==============================] - 14s 209ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0193 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 54/180\n",
      "65/65 [==============================] - 14s 209ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0190 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0189\n",
      "Epoch 55/180\n",
      "65/65 [==============================] - 14s 210ms/step - loss: 9.9157e-04 - mse: 9.9157e-04 - mae: 0.0189 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 56/180\n",
      "65/65 [==============================] - 16s 240ms/step - loss: 9.8719e-04 - mse: 9.8719e-04 - mae: 0.0188 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 57/180\n",
      "65/65 [==============================] - 14s 211ms/step - loss: 9.7152e-04 - mse: 9.7152e-04 - mae: 0.0187 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 58/180\n",
      "65/65 [==============================] - 14s 208ms/step - loss: 9.6552e-04 - mse: 9.6552e-04 - mae: 0.0186 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 59/180\n",
      "65/65 [==============================] - 13s 202ms/step - loss: 9.7162e-04 - mse: 9.7162e-04 - mae: 0.0187 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 60/180\n",
      "65/65 [==============================] - 13s 201ms/step - loss: 9.6246e-04 - mse: 9.6246e-04 - mae: 0.0184 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 61/180\n",
      "65/65 [==============================] - 14s 210ms/step - loss: 9.5686e-04 - mse: 9.5686e-04 - mae: 0.0183 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0184\n",
      "Epoch 62/180\n",
      "65/65 [==============================] - 15s 228ms/step - loss: 9.6260e-04 - mse: 9.6260e-04 - mae: 0.0184 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0187\n",
      "Epoch 63/180\n",
      "65/65 [==============================] - 14s 211ms/step - loss: 9.4735e-04 - mse: 9.4735e-04 - mae: 0.0182 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0184\n",
      "Epoch 64/180\n",
      "65/65 [==============================] - 13s 201ms/step - loss: 9.5590e-04 - mse: 9.5590e-04 - mae: 0.0181 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0187\n",
      "Epoch 65/180\n",
      "65/65 [==============================] - 14s 214ms/step - loss: 9.5075e-04 - mse: 9.5075e-04 - mae: 0.0182 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0184\n",
      "Epoch 66/180\n",
      "65/65 [==============================] - 13s 207ms/step - loss: 9.4457e-04 - mse: 9.4457e-04 - mae: 0.0181 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0187\n",
      "Epoch 67/180\n",
      "65/65 [==============================] - 14s 208ms/step - loss: 9.4453e-04 - mse: 9.4453e-04 - mae: 0.0181 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 68/180\n",
      "65/65 [==============================] - 14s 211ms/step - loss: 9.4076e-04 - mse: 9.4076e-04 - mae: 0.0181 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0183\n",
      "Epoch 69/180\n",
      "65/65 [==============================] - 13s 201ms/step - loss: 9.3706e-04 - mse: 9.3706e-04 - mae: 0.0181 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 70/180\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 9.3947e-04 - mse: 9.3947e-04 - mae: 0.0181 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 71/180\n",
      "65/65 [==============================] - 13s 201ms/step - loss: 9.3563e-04 - mse: 9.3563e-04 - mae: 0.0181 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 72/180\n",
      "65/65 [==============================] - 13s 201ms/step - loss: 9.3394e-04 - mse: 9.3394e-04 - mae: 0.0181 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0184\n",
      "Epoch 73/180\n",
      "65/65 [==============================] - 14s 209ms/step - loss: 9.3195e-04 - mse: 9.3195e-04 - mae: 0.0180 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 74/180\n",
      "65/65 [==============================] - 14s 218ms/step - loss: 9.2542e-04 - mse: 9.2542e-04 - mae: 0.0180 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 75/180\n",
      "65/65 [==============================] - 13s 206ms/step - loss: 9.3291e-04 - mse: 9.3291e-04 - mae: 0.0180 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 76/180\n",
      "65/65 [==============================] - 13s 200ms/step - loss: 9.3458e-04 - mse: 9.3458e-04 - mae: 0.0181 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 77/180\n",
      "65/65 [==============================] - 17s 264ms/step - loss: 9.2650e-04 - mse: 9.2650e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 78/180\n",
      "65/65 [==============================] - 14s 212ms/step - loss: 9.3080e-04 - mse: 9.3080e-04 - mae: 0.0180 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 79/180\n",
      "65/65 [==============================] - 13s 201ms/step - loss: 9.2489e-04 - mse: 9.2489e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 80/180\n",
      "65/65 [==============================] - 13s 200ms/step - loss: 9.2888e-04 - mse: 9.2888e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 81/180\n",
      "65/65 [==============================] - 13s 200ms/step - loss: 9.2594e-04 - mse: 9.2594e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0183\n",
      "Epoch 82/180\n",
      "65/65 [==============================] - 14s 219ms/step - loss: 9.2405e-04 - mse: 9.2405e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 83/180\n",
      "65/65 [==============================] - 13s 207ms/step - loss: 9.2228e-04 - mse: 9.2228e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 84/180\n",
      "65/65 [==============================] - 17s 256ms/step - loss: 9.2071e-04 - mse: 9.2071e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 85/180\n",
      "65/65 [==============================] - 18s 279ms/step - loss: 9.2723e-04 - mse: 9.2723e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 86/180\n",
      "65/65 [==============================] - 20s 315ms/step - loss: 9.2304e-04 - mse: 9.2304e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 87/180\n",
      "65/65 [==============================] - 15s 238ms/step - loss: 9.2085e-04 - mse: 9.2085e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0184\n",
      "Epoch 88/180\n",
      "65/65 [==============================] - 15s 228ms/step - loss: 9.1822e-04 - mse: 9.1822e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 89/180\n",
      "65/65 [==============================] - 16s 240ms/step - loss: 9.1878e-04 - mse: 9.1878e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 90/180\n",
      "65/65 [==============================] - 15s 227ms/step - loss: 9.1617e-04 - mse: 9.1617e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 91/180\n",
      "65/65 [==============================] - 14s 222ms/step - loss: 9.1817e-04 - mse: 9.1817e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 92/180\n",
      "65/65 [==============================] - 15s 235ms/step - loss: 9.1426e-04 - mse: 9.1426e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0184\n",
      "Epoch 93/180\n",
      "65/65 [==============================] - 15s 232ms/step - loss: 9.1650e-04 - mse: 9.1650e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 94/180\n",
      "65/65 [==============================] - 15s 228ms/step - loss: 9.1910e-04 - mse: 9.1910e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 95/180\n",
      "65/65 [==============================] - 15s 224ms/step - loss: 9.1692e-04 - mse: 9.1693e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 96/180\n",
      "65/65 [==============================] - 14s 223ms/step - loss: 9.1571e-04 - mse: 9.1571e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 97/180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 15s 237ms/step - loss: 9.1504e-04 - mse: 9.1504e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0185\n",
      "Epoch 98/180\n",
      "65/65 [==============================] - 15s 232ms/step - loss: 9.1416e-04 - mse: 9.1416e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 99/180\n",
      "65/65 [==============================] - 15s 226ms/step - loss: 9.1485e-04 - mse: 9.1485e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 100/180\n",
      "65/65 [==============================] - 15s 231ms/step - loss: 9.1348e-04 - mse: 9.1348e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0187\n",
      "Epoch 101/180\n",
      "65/65 [==============================] - 15s 223ms/step - loss: 9.1149e-04 - mse: 9.1149e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 102/180\n",
      "65/65 [==============================] - 15s 230ms/step - loss: 9.1474e-04 - mse: 9.1474e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0187\n",
      "Epoch 103/180\n",
      "65/65 [==============================] - 16s 241ms/step - loss: 9.1349e-04 - mse: 9.1349e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 104/180\n",
      "65/65 [==============================] - 15s 235ms/step - loss: 9.1463e-04 - mse: 9.1463e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 105/180\n",
      "65/65 [==============================] - 16s 240ms/step - loss: 9.1252e-04 - mse: 9.1252e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0187\n",
      "Epoch 106/180\n",
      "65/65 [==============================] - 15s 227ms/step - loss: 9.1238e-04 - mse: 9.1238e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0187\n",
      "Epoch 107/180\n",
      "65/65 [==============================] - 15s 229ms/step - loss: 9.1208e-04 - mse: 9.1208e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0188\n",
      "Epoch 108/180\n",
      "65/65 [==============================] - 15s 223ms/step - loss: 9.1132e-04 - mse: 9.1132e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0188\n",
      "Epoch 109/180\n",
      "65/65 [==============================] - 14s 223ms/step - loss: 9.1056e-04 - mse: 9.1056e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 110/180\n",
      "65/65 [==============================] - 15s 223ms/step - loss: 9.1459e-04 - mse: 9.1459e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0187\n",
      "Epoch 111/180\n",
      "65/65 [==============================] - 15s 228ms/step - loss: 9.1039e-04 - mse: 9.1039e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0186\n",
      "Epoch 112/180\n",
      "65/65 [==============================] - 15s 228ms/step - loss: 9.0705e-04 - mse: 9.0705e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0184\n",
      "Epoch 113/180\n",
      "65/65 [==============================] - 15s 238ms/step - loss: 9.0932e-04 - mse: 9.0932e-04 - mae: 0.0177 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0187\n",
      "Epoch 114/180\n",
      "65/65 [==============================] - 15s 227ms/step - loss: 9.0471e-04 - mse: 9.0471e-04 - mae: 0.0177 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0186\n",
      "Epoch 115/180\n",
      "65/65 [==============================] - 14s 222ms/step - loss: 9.0822e-04 - mse: 9.0822e-04 - mae: 0.0177 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0187\n",
      "Epoch 116/180\n",
      "65/65 [==============================] - 14s 223ms/step - loss: 9.0598e-04 - mse: 9.0598e-04 - mae: 0.0177 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0186\n",
      "Epoch 117/180\n",
      "65/65 [==============================] - 15s 234ms/step - loss: 9.0197e-04 - mse: 9.0197e-04 - mae: 0.0176 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0185\n",
      "Epoch 118/180\n",
      "65/65 [==============================] - 16s 244ms/step - loss: 9.0192e-04 - mse: 9.0192e-04 - mae: 0.0176 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0184\n",
      "Epoch 119/180\n",
      "65/65 [==============================] - 14s 221ms/step - loss: 9.0093e-04 - mse: 9.0093e-04 - mae: 0.0176 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0183\n",
      "Epoch 120/180\n",
      "65/65 [==============================] - 14s 216ms/step - loss: 8.9483e-04 - mse: 8.9483e-04 - mae: 0.0175 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0182\n",
      "Epoch 121/180\n",
      "65/65 [==============================] - 15s 236ms/step - loss: 8.9685e-04 - mse: 8.9685e-04 - mae: 0.0176 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0184\n",
      "Epoch 122/180\n",
      "65/65 [==============================] - 15s 226ms/step - loss: 8.9606e-04 - mse: 8.9606e-04 - mae: 0.0176 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0181\n",
      "Epoch 123/180\n",
      "65/65 [==============================] - 15s 226ms/step - loss: 8.9271e-04 - mse: 8.9271e-04 - mae: 0.0174 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0183\n",
      "Epoch 124/180\n",
      "65/65 [==============================] - 15s 225ms/step - loss: 8.9175e-04 - mse: 8.9175e-04 - mae: 0.0175 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0182\n",
      "Epoch 125/180\n",
      "65/65 [==============================] - 14s 219ms/step - loss: 8.9119e-04 - mse: 8.9119e-04 - mae: 0.0174 - val_loss: 9.8333e-04 - val_mse: 9.8333e-04 - val_mae: 0.0179\n",
      "Epoch 126/180\n",
      "65/65 [==============================] - 15s 227ms/step - loss: 8.8786e-04 - mse: 8.8786e-04 - mae: 0.0174 - val_loss: 9.6656e-04 - val_mse: 9.6656e-04 - val_mae: 0.0180\n",
      "Epoch 127/180\n",
      "65/65 [==============================] - 15s 228ms/step - loss: 8.8647e-04 - mse: 8.8647e-04 - mae: 0.0173 - val_loss: 9.5768e-04 - val_mse: 9.5768e-04 - val_mae: 0.0178\n",
      "Epoch 128/180\n",
      "65/65 [==============================] - 14s 218ms/step - loss: 8.8610e-04 - mse: 8.8610e-04 - mae: 0.0173 - val_loss: 9.4266e-04 - val_mse: 9.4266e-04 - val_mae: 0.0183\n",
      "Epoch 129/180\n",
      "65/65 [==============================] - 16s 246ms/step - loss: 8.7548e-04 - mse: 8.7548e-04 - mae: 0.0172 - val_loss: 9.2839e-04 - val_mse: 9.2839e-04 - val_mae: 0.0180\n",
      "Epoch 130/180\n",
      "65/65 [==============================] - 16s 241ms/step - loss: 8.7975e-04 - mse: 8.7975e-04 - mae: 0.0172 - val_loss: 9.1768e-04 - val_mse: 9.1768e-04 - val_mae: 0.0182\n",
      "Epoch 131/180\n",
      "65/65 [==============================] - 15s 236ms/step - loss: 8.7855e-04 - mse: 8.7855e-04 - mae: 0.0172 - val_loss: 9.0384e-04 - val_mse: 9.0384e-04 - val_mae: 0.0181\n",
      "Epoch 132/180\n",
      "65/65 [==============================] - 16s 239ms/step - loss: 8.7034e-04 - mse: 8.7034e-04 - mae: 0.0170 - val_loss: 8.9539e-04 - val_mse: 8.9539e-04 - val_mae: 0.0177\n",
      "Epoch 133/180\n",
      "65/65 [==============================] - 16s 248ms/step - loss: 8.7604e-04 - mse: 8.7604e-04 - mae: 0.0171 - val_loss: 8.8558e-04 - val_mse: 8.8558e-04 - val_mae: 0.0176\n",
      "Epoch 134/180\n",
      "65/65 [==============================] - 15s 233ms/step - loss: 8.7050e-04 - mse: 8.7050e-04 - mae: 0.0170 - val_loss: 8.8781e-04 - val_mse: 8.8781e-04 - val_mae: 0.0178\n",
      "Epoch 135/180\n",
      "65/65 [==============================] - 16s 250ms/step - loss: 8.6959e-04 - mse: 8.6959e-04 - mae: 0.0170 - val_loss: 8.8559e-04 - val_mse: 8.8559e-04 - val_mae: 0.0178\n",
      "Epoch 136/180\n",
      "65/65 [==============================] - 16s 245ms/step - loss: 8.7091e-04 - mse: 8.7091e-04 - mae: 0.0169 - val_loss: 8.8853e-04 - val_mse: 8.8853e-04 - val_mae: 0.0184\n",
      "Epoch 137/180\n",
      "65/65 [==============================] - 17s 258ms/step - loss: 8.6604e-04 - mse: 8.6604e-04 - mae: 0.0169 - val_loss: 8.6898e-04 - val_mse: 8.6898e-04 - val_mae: 0.0180\n",
      "Epoch 138/180\n",
      "65/65 [==============================] - 16s 248ms/step - loss: 8.6313e-04 - mse: 8.6313e-04 - mae: 0.0169 - val_loss: 8.7076e-04 - val_mse: 8.7076e-04 - val_mae: 0.0170\n",
      "Epoch 139/180\n",
      "65/65 [==============================] - 15s 224ms/step - loss: 8.6575e-04 - mse: 8.6575e-04 - mae: 0.0169 - val_loss: 8.7581e-04 - val_mse: 8.7581e-04 - val_mae: 0.0182\n",
      "Epoch 140/180\n",
      "65/65 [==============================] - 15s 224ms/step - loss: 8.6827e-04 - mse: 8.6827e-04 - mae: 0.0169 - val_loss: 8.6817e-04 - val_mse: 8.6817e-04 - val_mae: 0.0181\n",
      "Epoch 141/180\n",
      "65/65 [==============================] - 16s 249ms/step - loss: 8.5954e-04 - mse: 8.5954e-04 - mae: 0.0169 - val_loss: 8.8053e-04 - val_mse: 8.8053e-04 - val_mae: 0.0185\n",
      "Epoch 142/180\n",
      "65/65 [==============================] - 17s 263ms/step - loss: 8.6539e-04 - mse: 8.6539e-04 - mae: 0.0169 - val_loss: 8.7342e-04 - val_mse: 8.7342e-04 - val_mae: 0.0185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143/180\n",
      "65/65 [==============================] - 15s 223ms/step - loss: 8.6139e-04 - mse: 8.6139e-04 - mae: 0.0169 - val_loss: 8.4613e-04 - val_mse: 8.4613e-04 - val_mae: 0.0182\n",
      "Epoch 144/180\n",
      "65/65 [==============================] - 15s 226ms/step - loss: 8.6587e-04 - mse: 8.6587e-04 - mae: 0.0170 - val_loss: 8.6869e-04 - val_mse: 8.6869e-04 - val_mae: 0.0187\n",
      "Epoch 145/180\n",
      "65/65 [==============================] - 15s 237ms/step - loss: 8.5755e-04 - mse: 8.5755e-04 - mae: 0.0168 - val_loss: 8.7831e-04 - val_mse: 8.7831e-04 - val_mae: 0.0186\n",
      "Epoch 146/180\n",
      "65/65 [==============================] - 15s 225ms/step - loss: 8.5980e-04 - mse: 8.5980e-04 - mae: 0.0168 - val_loss: 8.4720e-04 - val_mse: 8.4720e-04 - val_mae: 0.0179\n",
      "Epoch 147/180\n",
      "65/65 [==============================] - 14s 223ms/step - loss: 8.5843e-04 - mse: 8.5843e-04 - mae: 0.0168 - val_loss: 8.6682e-04 - val_mse: 8.6682e-04 - val_mae: 0.0184\n",
      "Epoch 148/180\n",
      "65/65 [==============================] - 14s 221ms/step - loss: 8.5656e-04 - mse: 8.5656e-04 - mae: 0.0167 - val_loss: 8.6772e-04 - val_mse: 8.6772e-04 - val_mae: 0.0186\n",
      "Epoch 149/180\n",
      "65/65 [==============================] - 15s 225ms/step - loss: 8.5700e-04 - mse: 8.5700e-04 - mae: 0.0167 - val_loss: 8.6565e-04 - val_mse: 8.6565e-04 - val_mae: 0.0185\n",
      "Epoch 150/180\n",
      "65/65 [==============================] - 17s 257ms/step - loss: 8.5052e-04 - mse: 8.5052e-04 - mae: 0.0167 - val_loss: 8.4984e-04 - val_mse: 8.4984e-04 - val_mae: 0.0182\n",
      "Epoch 151/180\n",
      "65/65 [==============================] - 15s 233ms/step - loss: 8.4940e-04 - mse: 8.4940e-04 - mae: 0.0166 - val_loss: 8.5501e-04 - val_mse: 8.5501e-04 - val_mae: 0.0184\n",
      "Epoch 152/180\n",
      "65/65 [==============================] - 17s 259ms/step - loss: 8.5403e-04 - mse: 8.5403e-04 - mae: 0.0166 - val_loss: 8.7139e-04 - val_mse: 8.7139e-04 - val_mae: 0.0183\n",
      "Epoch 153/180\n",
      "65/65 [==============================] - 16s 247ms/step - loss: 8.5827e-04 - mse: 8.5827e-04 - mae: 0.0166 - val_loss: 8.9705e-04 - val_mse: 8.9705e-04 - val_mae: 0.0189\n",
      "Epoch 154/180\n",
      "65/65 [==============================] - 18s 276ms/step - loss: 8.4846e-04 - mse: 8.4846e-04 - mae: 0.0166 - val_loss: 8.8135e-04 - val_mse: 8.8135e-04 - val_mae: 0.0186\n",
      "Epoch 155/180\n",
      "65/65 [==============================] - 16s 248ms/step - loss: 8.5062e-04 - mse: 8.5062e-04 - mae: 0.0166 - val_loss: 8.8232e-04 - val_mse: 8.8232e-04 - val_mae: 0.0189\n",
      "Epoch 156/180\n",
      "65/65 [==============================] - 15s 232ms/step - loss: 8.4622e-04 - mse: 8.4622e-04 - mae: 0.0166 - val_loss: 8.9882e-04 - val_mse: 8.9882e-04 - val_mae: 0.0189\n",
      "Epoch 157/180\n",
      "65/65 [==============================] - 15s 226ms/step - loss: 8.4596e-04 - mse: 8.4596e-04 - mae: 0.0165 - val_loss: 8.8098e-04 - val_mse: 8.8098e-04 - val_mae: 0.0184\n",
      "Epoch 158/180\n",
      "65/65 [==============================] - 14s 221ms/step - loss: 8.4017e-04 - mse: 8.4017e-04 - mae: 0.0164 - val_loss: 9.1566e-04 - val_mse: 9.1566e-04 - val_mae: 0.0190\n",
      "Epoch 159/180\n",
      "65/65 [==============================] - 14s 220ms/step - loss: 8.5370e-04 - mse: 8.5370e-04 - mae: 0.0165 - val_loss: 8.9037e-04 - val_mse: 8.9037e-04 - val_mae: 0.0186\n",
      "Epoch 160/180\n",
      "65/65 [==============================] - 15s 226ms/step - loss: 8.4278e-04 - mse: 8.4278e-04 - mae: 0.0164 - val_loss: 9.0745e-04 - val_mse: 9.0745e-04 - val_mae: 0.0189\n",
      "Epoch 161/180\n",
      "65/65 [==============================] - 14s 219ms/step - loss: 8.4538e-04 - mse: 8.4538e-04 - mae: 0.0165 - val_loss: 9.0494e-04 - val_mse: 9.0494e-04 - val_mae: 0.0189\n",
      "Epoch 162/180\n",
      "65/65 [==============================] - 16s 239ms/step - loss: 8.4854e-04 - mse: 8.4854e-04 - mae: 0.0165 - val_loss: 8.8276e-04 - val_mse: 8.8276e-04 - val_mae: 0.0185\n",
      "Epoch 163/180\n",
      "65/65 [==============================] - 19s 297ms/step - loss: 8.3962e-04 - mse: 8.3962e-04 - mae: 0.0164 - val_loss: 9.2308e-04 - val_mse: 9.2308e-04 - val_mae: 0.0190\n",
      "Epoch 164/180\n",
      "65/65 [==============================] - 18s 278ms/step - loss: 8.4530e-04 - mse: 8.4530e-04 - mae: 0.0164 - val_loss: 8.9153e-04 - val_mse: 8.9153e-04 - val_mae: 0.0186\n",
      "Epoch 165/180\n",
      "65/65 [==============================] - 15s 233ms/step - loss: 8.3726e-04 - mse: 8.3726e-04 - mae: 0.0163 - val_loss: 9.1666e-04 - val_mse: 9.1666e-04 - val_mae: 0.0187\n",
      "Epoch 166/180\n",
      "65/65 [==============================] - 15s 229ms/step - loss: 8.4180e-04 - mse: 8.4180e-04 - mae: 0.0164 - val_loss: 9.5457e-04 - val_mse: 9.5457e-04 - val_mae: 0.0196\n",
      "Epoch 167/180\n",
      "65/65 [==============================] - 15s 231ms/step - loss: 8.3464e-04 - mse: 8.3464e-04 - mae: 0.0163 - val_loss: 9.1384e-04 - val_mse: 9.1384e-04 - val_mae: 0.0187\n",
      "Epoch 168/180\n",
      "65/65 [==============================] - 15s 231ms/step - loss: 8.3791e-04 - mse: 8.3791e-04 - mae: 0.0163 - val_loss: 9.2492e-04 - val_mse: 9.2492e-04 - val_mae: 0.0189\n",
      "Epoch 169/180\n",
      "65/65 [==============================] - 16s 245ms/step - loss: 8.3404e-04 - mse: 8.3404e-04 - mae: 0.0163 - val_loss: 8.9534e-04 - val_mse: 8.9534e-04 - val_mae: 0.0183\n",
      "Epoch 170/180\n",
      "65/65 [==============================] - 17s 259ms/step - loss: 8.4081e-04 - mse: 8.4081e-04 - mae: 0.0164 - val_loss: 9.3693e-04 - val_mse: 9.3693e-04 - val_mae: 0.0194\n",
      "Epoch 171/180\n",
      "65/65 [==============================] - 17s 266ms/step - loss: 8.3797e-04 - mse: 8.3797e-04 - mae: 0.0163 - val_loss: 9.1941e-04 - val_mse: 9.1941e-04 - val_mae: 0.0188\n",
      "Epoch 172/180\n",
      "65/65 [==============================] - 16s 246ms/step - loss: 8.3266e-04 - mse: 8.3266e-04 - mae: 0.0163 - val_loss: 9.3752e-04 - val_mse: 9.3752e-04 - val_mae: 0.0192\n",
      "Epoch 173/180\n",
      "65/65 [==============================] - 15s 225ms/step - loss: 8.3325e-04 - mse: 8.3325e-04 - mae: 0.0163 - val_loss: 9.1826e-04 - val_mse: 9.1826e-04 - val_mae: 0.0186\n",
      "Epoch 174/180\n",
      "65/65 [==============================] - 16s 239ms/step - loss: 8.3987e-04 - mse: 8.3987e-04 - mae: 0.0164 - val_loss: 9.2208e-04 - val_mse: 9.2208e-04 - val_mae: 0.0189\n",
      "Epoch 175/180\n",
      "65/65 [==============================] - 16s 240ms/step - loss: 8.3292e-04 - mse: 8.3292e-04 - mae: 0.0164 - val_loss: 9.1504e-04 - val_mse: 9.1504e-04 - val_mae: 0.0187\n",
      "Epoch 176/180\n",
      "65/65 [==============================] - 15s 226ms/step - loss: 8.2993e-04 - mse: 8.2993e-04 - mae: 0.0162 - val_loss: 8.8721e-04 - val_mse: 8.8721e-04 - val_mae: 0.0173\n",
      "Epoch 177/180\n",
      "65/65 [==============================] - 14s 219ms/step - loss: 8.3318e-04 - mse: 8.3318e-04 - mae: 0.0163 - val_loss: 9.2202e-04 - val_mse: 9.2202e-04 - val_mae: 0.0187\n",
      "Epoch 178/180\n",
      "65/65 [==============================] - 14s 218ms/step - loss: 8.3308e-04 - mse: 8.3308e-04 - mae: 0.0162 - val_loss: 9.3461e-04 - val_mse: 9.3461e-04 - val_mae: 0.0192\n",
      "Epoch 179/180\n",
      "65/65 [==============================] - 14s 222ms/step - loss: 8.2830e-04 - mse: 8.2830e-04 - mae: 0.0161 - val_loss: 9.2281e-04 - val_mse: 9.2281e-04 - val_mae: 0.0186\n",
      "Epoch 180/180\n",
      "65/65 [==============================] - 16s 249ms/step - loss: 8.4627e-04 - mse: 8.4627e-04 - mae: 0.0163 - val_loss: 9.0527e-04 - val_mse: 9.0527e-04 - val_mae: 0.0188\n",
      "Epoch 1/180\n",
      "65/65 [==============================] - 39s 602ms/step - loss: 0.1426 - mse: 0.1426 - mae: 0.2960 - val_loss: 0.0048 - val_mse: 0.0048 - val_mae: 0.0591\n",
      "Epoch 2/180\n",
      "65/65 [==============================] - 41s 627ms/step - loss: 0.0791 - mse: 0.0791 - mae: 0.2238 - val_loss: 0.0015 - val_mse: 0.0015 - val_mae: 0.0262\n",
      "Epoch 3/180\n",
      "65/65 [==============================] - 37s 567ms/step - loss: 0.0485 - mse: 0.0485 - mae: 0.1752 - val_loss: 0.0017 - val_mse: 0.0017 - val_mae: 0.0293\n",
      "Epoch 4/180\n",
      "65/65 [==============================] - 38s 581ms/step - loss: 0.0316 - mse: 0.0316 - mae: 0.1414 - val_loss: 0.0024 - val_mse: 0.0024 - val_mae: 0.0415\n",
      "Epoch 5/180\n",
      "65/65 [==============================] - 38s 577ms/step - loss: 0.0220 - mse: 0.0220 - mae: 0.1178 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0234\n",
      "Epoch 6/180\n",
      "65/65 [==============================] - 40s 611ms/step - loss: 0.0152 - mse: 0.0152 - mae: 0.0972 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0189\n",
      "Epoch 7/180\n",
      "65/65 [==============================] - 41s 634ms/step - loss: 0.0119 - mse: 0.0119 - mae: 0.0862 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0234\n",
      "Epoch 8/180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 42s 652ms/step - loss: 0.0096 - mse: 0.0096 - mae: 0.0764 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0199\n",
      "Epoch 9/180\n",
      "65/65 [==============================] - 43s 663ms/step - loss: 0.0080 - mse: 0.0080 - mae: 0.0704 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0229\n",
      "Epoch 10/180\n",
      "65/65 [==============================] - 44s 673ms/step - loss: 0.0068 - mse: 0.0068 - mae: 0.0643 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0265\n",
      "Epoch 11/180\n",
      "65/65 [==============================] - 41s 626ms/step - loss: 0.0055 - mse: 0.0055 - mae: 0.0578 - val_loss: 0.0015 - val_mse: 0.0015 - val_mae: 0.0334\n",
      "Epoch 12/180\n",
      "65/65 [==============================] - 38s 591ms/step - loss: 0.0047 - mse: 0.0047 - mae: 0.0528 - val_loss: 0.0015 - val_mse: 0.0015 - val_mae: 0.0326\n",
      "Epoch 13/180\n",
      "65/65 [==============================] - 42s 645ms/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0499 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0292\n",
      "Epoch 14/180\n",
      "65/65 [==============================] - 40s 610ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0482 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0281\n",
      "Epoch 15/180\n",
      "65/65 [==============================] - 45s 699ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0462 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0288\n",
      "Epoch 16/180\n",
      "65/65 [==============================] - 39s 601ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0444 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0269\n",
      "Epoch 17/180\n",
      "65/65 [==============================] - 38s 587ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0423 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0246\n",
      "Epoch 18/180\n",
      "65/65 [==============================] - 38s 582ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0405 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0240\n",
      "Epoch 19/180\n",
      "65/65 [==============================] - 40s 617ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0383 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0236\n",
      "Epoch 20/180\n",
      "65/65 [==============================] - 39s 604ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0374 - val_loss: 9.2689e-04 - val_mse: 9.2689e-04 - val_mae: 0.0205\n",
      "Epoch 21/180\n",
      "65/65 [==============================] - 39s 599ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0357 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0244\n",
      "Epoch 22/180\n",
      "65/65 [==============================] - 41s 638ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0347 - val_loss: 9.4774e-04 - val_mse: 9.4774e-04 - val_mae: 0.0205\n",
      "Epoch 23/180\n",
      "65/65 [==============================] - 42s 648ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0332 - val_loss: 9.5630e-04 - val_mse: 9.5630e-04 - val_mae: 0.0213\n",
      "Epoch 24/180\n",
      "65/65 [==============================] - 36s 561ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0321 - val_loss: 9.4742e-04 - val_mse: 9.4742e-04 - val_mae: 0.0211\n",
      "Epoch 25/180\n",
      "65/65 [==============================] - 38s 586ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0308 - val_loss: 9.3907e-04 - val_mse: 9.3907e-04 - val_mae: 0.0209\n",
      "Epoch 26/180\n",
      "65/65 [==============================] - 37s 563ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0309 - val_loss: 9.6407e-04 - val_mse: 9.6407e-04 - val_mae: 0.0217\n",
      "Epoch 27/180\n",
      "65/65 [==============================] - 37s 571ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0296 - val_loss: 9.2001e-04 - val_mse: 9.2001e-04 - val_mae: 0.0199\n",
      "Epoch 28/180\n",
      "65/65 [==============================] - 45s 694ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0290 - val_loss: 9.7965e-04 - val_mse: 9.7965e-04 - val_mae: 0.0224\n",
      "Epoch 29/180\n",
      "65/65 [==============================] - 44s 682ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0276 - val_loss: 9.3414e-04 - val_mse: 9.3414e-04 - val_mae: 0.0201\n",
      "Epoch 30/180\n",
      "65/65 [==============================] - 42s 647ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0273 - val_loss: 9.5896e-04 - val_mse: 9.5896e-04 - val_mae: 0.0214\n",
      "Epoch 31/180\n",
      "65/65 [==============================] - 42s 643ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0265 - val_loss: 9.3938e-04 - val_mse: 9.3938e-04 - val_mae: 0.0204\n",
      "Epoch 32/180\n",
      "65/65 [==============================] - 41s 631ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0254 - val_loss: 9.3057e-04 - val_mse: 9.3057e-04 - val_mae: 0.0201\n",
      "Epoch 33/180\n",
      "65/65 [==============================] - 40s 614ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0253 - val_loss: 9.4192e-04 - val_mse: 9.4192e-04 - val_mae: 0.0202\n",
      "Epoch 34/180\n",
      "65/65 [==============================] - 39s 595ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0245 - val_loss: 9.7504e-04 - val_mse: 9.7504e-04 - val_mae: 0.0212\n",
      "Epoch 35/180\n",
      "65/65 [==============================] - 42s 650ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0242 - val_loss: 9.6588e-04 - val_mse: 9.6588e-04 - val_mae: 0.0200\n",
      "Epoch 36/180\n",
      "65/65 [==============================] - 39s 599ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0233 - val_loss: 9.8621e-04 - val_mse: 9.8621e-04 - val_mae: 0.0212\n",
      "Epoch 37/180\n",
      "65/65 [==============================] - 39s 597ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0233 - val_loss: 9.5272e-04 - val_mse: 9.5272e-04 - val_mae: 0.0197\n",
      "Epoch 38/180\n",
      "65/65 [==============================] - 39s 595ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0227 - val_loss: 9.6560e-04 - val_mse: 9.6560e-04 - val_mae: 0.0208\n",
      "Epoch 39/180\n",
      "65/65 [==============================] - 42s 645ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0223 - val_loss: 9.4502e-04 - val_mse: 9.4502e-04 - val_mae: 0.0190\n",
      "Epoch 40/180\n",
      "65/65 [==============================] - 41s 635ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0218 - val_loss: 9.5347e-04 - val_mse: 9.5347e-04 - val_mae: 0.0198\n",
      "Epoch 41/180\n",
      "65/65 [==============================] - 39s 600ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0214 - val_loss: 9.6437e-04 - val_mse: 9.6437e-04 - val_mae: 0.0205\n",
      "Epoch 42/180\n",
      "65/65 [==============================] - 39s 601ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0212 - val_loss: 9.6688e-04 - val_mse: 9.6688e-04 - val_mae: 0.0208\n",
      "Epoch 43/180\n",
      "65/65 [==============================] - 38s 577ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0211 - val_loss: 9.5092e-04 - val_mse: 9.5092e-04 - val_mae: 0.0191\n",
      "Epoch 44/180\n",
      "65/65 [==============================] - 39s 605ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0209 - val_loss: 9.5732e-04 - val_mse: 9.5732e-04 - val_mae: 0.0199\n",
      "Epoch 45/180\n",
      "65/65 [==============================] - 41s 625ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0205 - val_loss: 9.5484e-04 - val_mse: 9.5484e-04 - val_mae: 0.0191\n",
      "Epoch 46/180\n",
      "65/65 [==============================] - 37s 577ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0204 - val_loss: 9.7213e-04 - val_mse: 9.7213e-04 - val_mae: 0.0205\n",
      "Epoch 47/180\n",
      "65/65 [==============================] - 38s 581ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0201 - val_loss: 9.5426e-04 - val_mse: 9.5426e-04 - val_mae: 0.0196\n",
      "Epoch 48/180\n",
      "65/65 [==============================] - 39s 602ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0198 - val_loss: 9.5626e-04 - val_mse: 9.5626e-04 - val_mae: 0.0193\n",
      "Epoch 49/180\n",
      "65/65 [==============================] - 39s 600ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0197 - val_loss: 9.5331e-04 - val_mse: 9.5331e-04 - val_mae: 0.0192\n",
      "Epoch 50/180\n",
      "65/65 [==============================] - 38s 585ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0198 - val_loss: 9.5630e-04 - val_mse: 9.5630e-04 - val_mae: 0.0197\n",
      "Epoch 51/180\n",
      "65/65 [==============================] - 41s 623ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0197 - val_loss: 9.5776e-04 - val_mse: 9.5776e-04 - val_mae: 0.0194\n",
      "Epoch 52/180\n",
      "65/65 [==============================] - 44s 673ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0193 - val_loss: 9.5614e-04 - val_mse: 9.5614e-04 - val_mae: 0.0196\n",
      "Epoch 53/180\n",
      "65/65 [==============================] - 44s 682ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0193 - val_loss: 9.6185e-04 - val_mse: 9.6185e-04 - val_mae: 0.0202\n",
      "Epoch 54/180\n",
      "65/65 [==============================] - 45s 695ms/step - loss: 9.8970e-04 - mse: 9.8970e-04 - mae: 0.0190 - val_loss: 9.4856e-04 - val_mse: 9.4856e-04 - val_mae: 0.0191\n",
      "Epoch 55/180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 45s 688ms/step - loss: 9.9083e-04 - mse: 9.9083e-04 - mae: 0.0190 - val_loss: 9.5340e-04 - val_mse: 9.5340e-04 - val_mae: 0.0196\n",
      "Epoch 56/180\n",
      "65/65 [==============================] - 46s 700ms/step - loss: 9.8669e-04 - mse: 9.8669e-04 - mae: 0.0189 - val_loss: 9.4625e-04 - val_mse: 9.4625e-04 - val_mae: 0.0196\n",
      "Epoch 57/180\n",
      "65/65 [==============================] - 46s 711ms/step - loss: 9.8658e-04 - mse: 9.8658e-04 - mae: 0.0187 - val_loss: 9.5155e-04 - val_mse: 9.5155e-04 - val_mae: 0.0195\n",
      "Epoch 58/180\n",
      "65/65 [==============================] - 45s 689ms/step - loss: 9.7132e-04 - mse: 9.7132e-04 - mae: 0.0186 - val_loss: 9.4393e-04 - val_mse: 9.4393e-04 - val_mae: 0.0189\n",
      "Epoch 59/180\n",
      "65/65 [==============================] - 47s 728ms/step - loss: 9.6564e-04 - mse: 9.6564e-04 - mae: 0.0184 - val_loss: 9.4476e-04 - val_mse: 9.4476e-04 - val_mae: 0.0190\n",
      "Epoch 60/180\n",
      "65/65 [==============================] - 40s 611ms/step - loss: 9.6176e-04 - mse: 9.6176e-04 - mae: 0.0185 - val_loss: 9.5226e-04 - val_mse: 9.5226e-04 - val_mae: 0.0195\n",
      "Epoch 61/180\n",
      "65/65 [==============================] - 38s 581ms/step - loss: 9.5193e-04 - mse: 9.5193e-04 - mae: 0.0183 - val_loss: 9.5098e-04 - val_mse: 9.5098e-04 - val_mae: 0.0197\n",
      "Epoch 62/180\n",
      "65/65 [==============================] - 38s 581ms/step - loss: 9.5904e-04 - mse: 9.5904e-04 - mae: 0.0184 - val_loss: 9.5565e-04 - val_mse: 9.5565e-04 - val_mae: 0.0196\n",
      "Epoch 63/180\n",
      "65/65 [==============================] - 42s 650ms/step - loss: 9.5853e-04 - mse: 9.5853e-04 - mae: 0.0184 - val_loss: 9.5365e-04 - val_mse: 9.5365e-04 - val_mae: 0.0197\n",
      "Epoch 64/180\n",
      "65/65 [==============================] - 36s 556ms/step - loss: 9.4229e-04 - mse: 9.4229e-04 - mae: 0.0182 - val_loss: 9.5422e-04 - val_mse: 9.5422e-04 - val_mae: 0.0199\n",
      "Epoch 65/180\n",
      "65/65 [==============================] - 36s 554ms/step - loss: 9.4977e-04 - mse: 9.4977e-04 - mae: 0.0182 - val_loss: 9.5197e-04 - val_mse: 9.5197e-04 - val_mae: 0.0195\n",
      "Epoch 66/180\n",
      "65/65 [==============================] - 35s 545ms/step - loss: 9.4973e-04 - mse: 9.4973e-04 - mae: 0.0182 - val_loss: 9.4155e-04 - val_mse: 9.4155e-04 - val_mae: 0.0184\n",
      "Epoch 67/180\n",
      "65/65 [==============================] - 35s 544ms/step - loss: 9.4921e-04 - mse: 9.4921e-04 - mae: 0.0182 - val_loss: 9.4235e-04 - val_mse: 9.4235e-04 - val_mae: 0.0188\n",
      "Epoch 68/180\n",
      "65/65 [==============================] - 35s 546ms/step - loss: 9.3165e-04 - mse: 9.3165e-04 - mae: 0.0179 - val_loss: 9.3809e-04 - val_mse: 9.3809e-04 - val_mae: 0.0184\n",
      "Epoch 69/180\n",
      "65/65 [==============================] - 38s 577ms/step - loss: 9.4305e-04 - mse: 9.4305e-04 - mae: 0.0181 - val_loss: 9.4216e-04 - val_mse: 9.4216e-04 - val_mae: 0.0192\n",
      "Epoch 70/180\n",
      "65/65 [==============================] - 35s 543ms/step - loss: 9.2757e-04 - mse: 9.2757e-04 - mae: 0.0180 - val_loss: 9.5521e-04 - val_mse: 9.5521e-04 - val_mae: 0.0192\n",
      "Epoch 71/180\n",
      "65/65 [==============================] - 35s 536ms/step - loss: 9.2652e-04 - mse: 9.2652e-04 - mae: 0.0180 - val_loss: 9.5762e-04 - val_mse: 9.5762e-04 - val_mae: 0.0188\n",
      "Epoch 72/180\n",
      "65/65 [==============================] - 36s 553ms/step - loss: 9.2413e-04 - mse: 9.2413e-04 - mae: 0.0178 - val_loss: 9.4002e-04 - val_mse: 9.4002e-04 - val_mae: 0.0178\n",
      "Epoch 73/180\n",
      "65/65 [==============================] - 36s 551ms/step - loss: 9.2143e-04 - mse: 9.2143e-04 - mae: 0.0178 - val_loss: 9.4988e-04 - val_mse: 9.4988e-04 - val_mae: 0.0185\n",
      "Epoch 74/180\n",
      "65/65 [==============================] - 36s 559ms/step - loss: 9.1581e-04 - mse: 9.1581e-04 - mae: 0.0178 - val_loss: 9.4989e-04 - val_mse: 9.4989e-04 - val_mae: 0.0180\n",
      "Epoch 75/180\n",
      "65/65 [==============================] - 37s 563ms/step - loss: 9.1844e-04 - mse: 9.1844e-04 - mae: 0.0178 - val_loss: 9.5882e-04 - val_mse: 9.5882e-04 - val_mae: 0.0186\n",
      "Epoch 76/180\n",
      "65/65 [==============================] - 36s 547ms/step - loss: 9.0849e-04 - mse: 9.0849e-04 - mae: 0.0177 - val_loss: 9.5036e-04 - val_mse: 9.5036e-04 - val_mae: 0.0182\n",
      "Epoch 77/180\n",
      "65/65 [==============================] - 35s 536ms/step - loss: 9.1455e-04 - mse: 9.1455e-04 - mae: 0.0177 - val_loss: 9.4920e-04 - val_mse: 9.4920e-04 - val_mae: 0.0185\n",
      "Epoch 78/180\n",
      "65/65 [==============================] - 42s 652ms/step - loss: 8.9811e-04 - mse: 8.9811e-04 - mae: 0.0175 - val_loss: 9.5065e-04 - val_mse: 9.5065e-04 - val_mae: 0.0183\n",
      "Epoch 79/180\n",
      "65/65 [==============================] - 39s 594ms/step - loss: 9.0418e-04 - mse: 9.0418e-04 - mae: 0.0174 - val_loss: 9.4787e-04 - val_mse: 9.4787e-04 - val_mae: 0.0185\n",
      "Epoch 80/180\n",
      "65/65 [==============================] - 41s 626ms/step - loss: 9.0362e-04 - mse: 9.0362e-04 - mae: 0.0176 - val_loss: 9.4265e-04 - val_mse: 9.4265e-04 - val_mae: 0.0186\n",
      "Epoch 81/180\n",
      "65/65 [==============================] - 42s 639ms/step - loss: 9.0711e-04 - mse: 9.0711e-04 - mae: 0.0176 - val_loss: 9.7117e-04 - val_mse: 9.7117e-04 - val_mae: 0.0191\n",
      "Epoch 82/180\n",
      "65/65 [==============================] - 39s 599ms/step - loss: 9.0062e-04 - mse: 9.0062e-04 - mae: 0.0174 - val_loss: 9.4328e-04 - val_mse: 9.4328e-04 - val_mae: 0.0179\n",
      "Epoch 83/180\n",
      "65/65 [==============================] - 41s 634ms/step - loss: 8.8898e-04 - mse: 8.8898e-04 - mae: 0.0174 - val_loss: 9.4556e-04 - val_mse: 9.4556e-04 - val_mae: 0.0180\n",
      "Epoch 84/180\n",
      "65/65 [==============================] - 40s 620ms/step - loss: 9.0036e-04 - mse: 9.0036e-04 - mae: 0.0173 - val_loss: 9.4105e-04 - val_mse: 9.4105e-04 - val_mae: 0.0174\n",
      "Epoch 85/180\n",
      "65/65 [==============================] - 41s 635ms/step - loss: 8.9375e-04 - mse: 8.9375e-04 - mae: 0.0174 - val_loss: 9.4219e-04 - val_mse: 9.4219e-04 - val_mae: 0.0176\n",
      "Epoch 86/180\n",
      "65/65 [==============================] - 41s 624ms/step - loss: 8.9164e-04 - mse: 8.9164e-04 - mae: 0.0173 - val_loss: 9.6223e-04 - val_mse: 9.6223e-04 - val_mae: 0.0188\n",
      "Epoch 87/180\n",
      "65/65 [==============================] - 39s 606ms/step - loss: 8.9168e-04 - mse: 8.9168e-04 - mae: 0.0173 - val_loss: 9.6980e-04 - val_mse: 9.6980e-04 - val_mae: 0.0189\n",
      "Epoch 88/180\n",
      "65/65 [==============================] - 40s 608ms/step - loss: 8.8615e-04 - mse: 8.8615e-04 - mae: 0.0172 - val_loss: 9.5377e-04 - val_mse: 9.5377e-04 - val_mae: 0.0182\n",
      "Epoch 89/180\n",
      "65/65 [==============================] - 42s 639ms/step - loss: 8.8844e-04 - mse: 8.8844e-04 - mae: 0.0172 - val_loss: 9.4232e-04 - val_mse: 9.4232e-04 - val_mae: 0.0183\n",
      "Epoch 90/180\n",
      "65/65 [==============================] - 42s 644ms/step - loss: 8.8108e-04 - mse: 8.8108e-04 - mae: 0.0172 - val_loss: 9.8211e-04 - val_mse: 9.8211e-04 - val_mae: 0.0191\n",
      "Epoch 91/180\n",
      "65/65 [==============================] - 46s 713ms/step - loss: 8.8212e-04 - mse: 8.8212e-04 - mae: 0.0171 - val_loss: 9.7670e-04 - val_mse: 9.7670e-04 - val_mae: 0.0184\n",
      "Epoch 92/180\n",
      "65/65 [==============================] - 41s 631ms/step - loss: 8.8799e-04 - mse: 8.8799e-04 - mae: 0.0171 - val_loss: 9.6488e-04 - val_mse: 9.6488e-04 - val_mae: 0.0178\n",
      "Epoch 93/180\n",
      "65/65 [==============================] - 41s 625ms/step - loss: 8.7807e-04 - mse: 8.7807e-04 - mae: 0.0170 - val_loss: 9.8579e-04 - val_mse: 9.8579e-04 - val_mae: 0.0186\n",
      "Epoch 94/180\n",
      "65/65 [==============================] - 39s 600ms/step - loss: 8.6480e-04 - mse: 8.6480e-04 - mae: 0.0169 - val_loss: 9.4707e-04 - val_mse: 9.4707e-04 - val_mae: 0.0176\n",
      "Epoch 95/180\n",
      "65/65 [==============================] - 38s 592ms/step - loss: 8.8692e-04 - mse: 8.8692e-04 - mae: 0.0173 - val_loss: 9.6271e-04 - val_mse: 9.6271e-04 - val_mae: 0.0184\n",
      "Epoch 96/180\n",
      "65/65 [==============================] - 40s 622ms/step - loss: 8.6362e-04 - mse: 8.6362e-04 - mae: 0.0168 - val_loss: 9.7321e-04 - val_mse: 9.7321e-04 - val_mae: 0.0182\n",
      "Epoch 97/180\n",
      "65/65 [==============================] - 38s 587ms/step - loss: 8.7273e-04 - mse: 8.7273e-04 - mae: 0.0169 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0198\n",
      "Epoch 98/180\n",
      "65/65 [==============================] - 40s 616ms/step - loss: 8.6280e-04 - mse: 8.6280e-04 - mae: 0.0168 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0197\n",
      "Epoch 99/180\n",
      "65/65 [==============================] - 43s 657ms/step - loss: 8.6742e-04 - mse: 8.6742e-04 - mae: 0.0168 - val_loss: 9.8865e-04 - val_mse: 9.8865e-04 - val_mae: 0.0178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/180\n",
      "65/65 [==============================] - 41s 637ms/step - loss: 8.6611e-04 - mse: 8.6611e-04 - mae: 0.0168 - val_loss: 9.6934e-04 - val_mse: 9.6934e-04 - val_mae: 0.0173\n",
      "Epoch 101/180\n",
      "65/65 [==============================] - 40s 616ms/step - loss: 8.6857e-04 - mse: 8.6857e-04 - mae: 0.0168 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0195\n",
      "Epoch 102/180\n",
      "65/65 [==============================] - 42s 644ms/step - loss: 8.6352e-04 - mse: 8.6352e-04 - mae: 0.0167 - val_loss: 9.7369e-04 - val_mse: 9.7369e-04 - val_mae: 0.0175\n",
      "Epoch 103/180\n",
      "65/65 [==============================] - 43s 656ms/step - loss: 8.6077e-04 - mse: 8.6077e-04 - mae: 0.0167 - val_loss: 9.8669e-04 - val_mse: 9.8669e-04 - val_mae: 0.0179\n",
      "Epoch 104/180\n",
      "65/65 [==============================] - 45s 687ms/step - loss: 8.5904e-04 - mse: 8.5904e-04 - mae: 0.0167 - val_loss: 9.9508e-04 - val_mse: 9.9508e-04 - val_mae: 0.0180\n",
      "Epoch 105/180\n",
      "65/65 [==============================] - 39s 608ms/step - loss: 8.5496e-04 - mse: 8.5496e-04 - mae: 0.0166 - val_loss: 9.6121e-04 - val_mse: 9.6121e-04 - val_mae: 0.0176\n",
      "Epoch 106/180\n",
      "65/65 [==============================] - 41s 626ms/step - loss: 8.6069e-04 - mse: 8.6069e-04 - mae: 0.0166 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0185\n",
      "Epoch 107/180\n",
      "65/65 [==============================] - 41s 633ms/step - loss: 8.5577e-04 - mse: 8.5577e-04 - mae: 0.0166 - val_loss: 9.9831e-04 - val_mse: 9.9831e-04 - val_mae: 0.0180\n",
      "Epoch 108/180\n",
      "65/65 [==============================] - 41s 638ms/step - loss: 8.4906e-04 - mse: 8.4906e-04 - mae: 0.0166 - val_loss: 9.8006e-04 - val_mse: 9.8006e-04 - val_mae: 0.0180\n",
      "Epoch 109/180\n",
      "65/65 [==============================] - 41s 626ms/step - loss: 8.4533e-04 - mse: 8.4533e-04 - mae: 0.0165 - val_loss: 9.9246e-04 - val_mse: 9.9246e-04 - val_mae: 0.0181\n",
      "Epoch 110/180\n",
      "65/65 [==============================] - 44s 670ms/step - loss: 8.4694e-04 - mse: 8.4694e-04 - mae: 0.0165 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0188\n",
      "Epoch 111/180\n",
      "65/65 [==============================] - 43s 660ms/step - loss: 8.4788e-04 - mse: 8.4788e-04 - mae: 0.0166 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0188\n",
      "Epoch 112/180\n",
      "65/65 [==============================] - 43s 654ms/step - loss: 8.4057e-04 - mse: 8.4057e-04 - mae: 0.0164 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0184\n",
      "Epoch 113/180\n",
      "65/65 [==============================] - 41s 628ms/step - loss: 8.4139e-04 - mse: 8.4139e-04 - mae: 0.0164 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0187\n",
      "Epoch 114/180\n",
      "65/65 [==============================] - 38s 585ms/step - loss: 8.3892e-04 - mse: 8.3892e-04 - mae: 0.0163 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0183\n",
      "Epoch 115/180\n",
      "65/65 [==============================] - 40s 617ms/step - loss: 8.5364e-04 - mse: 8.5364e-04 - mae: 0.0167 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0211\n",
      "Epoch 116/180\n",
      "65/65 [==============================] - 45s 693ms/step - loss: 8.4759e-04 - mse: 8.4759e-04 - mae: 0.0164 - val_loss: 9.6787e-04 - val_mse: 9.6787e-04 - val_mae: 0.0191\n",
      "Epoch 117/180\n",
      "65/65 [==============================] - 45s 687ms/step - loss: 8.4750e-04 - mse: 8.4750e-04 - mae: 0.0167 - val_loss: 9.6365e-04 - val_mse: 9.6365e-04 - val_mae: 0.0174\n",
      "Epoch 118/180\n",
      "65/65 [==============================] - 43s 660ms/step - loss: 8.3597e-04 - mse: 8.3597e-04 - mae: 0.0164 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0194\n",
      "Epoch 119/180\n",
      "65/65 [==============================] - 50s 763ms/step - loss: 8.3795e-04 - mse: 8.3795e-04 - mae: 0.0164 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0180\n",
      "Epoch 120/180\n",
      "65/65 [==============================] - 45s 700ms/step - loss: 8.3709e-04 - mse: 8.3709e-04 - mae: 0.0164 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0194\n",
      "Epoch 121/180\n",
      "65/65 [==============================] - 43s 659ms/step - loss: 8.1872e-04 - mse: 8.1872e-04 - mae: 0.0161 - val_loss: 9.5750e-04 - val_mse: 9.5750e-04 - val_mae: 0.0175\n",
      "Epoch 122/180\n",
      "65/65 [==============================] - 44s 675ms/step - loss: 8.3696e-04 - mse: 8.3696e-04 - mae: 0.0164 - val_loss: 9.7630e-04 - val_mse: 9.7630e-04 - val_mae: 0.0177\n",
      "Epoch 123/180\n",
      "65/65 [==============================] - 41s 635ms/step - loss: 8.2952e-04 - mse: 8.2952e-04 - mae: 0.0162 - val_loss: 9.6699e-04 - val_mse: 9.6699e-04 - val_mae: 0.0173\n",
      "Epoch 124/180\n",
      "65/65 [==============================] - 39s 603ms/step - loss: 8.3346e-04 - mse: 8.3346e-04 - mae: 0.0163 - val_loss: 9.8734e-04 - val_mse: 9.8734e-04 - val_mae: 0.0179\n",
      "Epoch 125/180\n",
      "65/65 [==============================] - 38s 578ms/step - loss: 8.2404e-04 - mse: 8.2404e-04 - mae: 0.0162 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0196\n",
      "Epoch 126/180\n",
      "65/65 [==============================] - 39s 601ms/step - loss: 8.3041e-04 - mse: 8.3041e-04 - mae: 0.0163 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0225\n",
      "Epoch 127/180\n",
      "65/65 [==============================] - 42s 645ms/step - loss: 8.3007e-04 - mse: 8.3007e-04 - mae: 0.0162 - val_loss: 9.6357e-04 - val_mse: 9.6357e-04 - val_mae: 0.0168\n",
      "Epoch 128/180\n",
      "65/65 [==============================] - 41s 636ms/step - loss: 8.1540e-04 - mse: 8.1540e-04 - mae: 0.0163 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0182\n",
      "Epoch 129/180\n",
      "65/65 [==============================] - 41s 630ms/step - loss: 8.1789e-04 - mse: 8.1789e-04 - mae: 0.0160 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0193\n",
      "Epoch 130/180\n",
      "65/65 [==============================] - 41s 625ms/step - loss: 8.1477e-04 - mse: 8.1477e-04 - mae: 0.0160 - val_loss: 9.4901e-04 - val_mse: 9.4901e-04 - val_mae: 0.0167\n",
      "Epoch 131/180\n",
      "65/65 [==============================] - 38s 587ms/step - loss: 8.1994e-04 - mse: 8.1994e-04 - mae: 0.0161 - val_loss: 9.7651e-04 - val_mse: 9.7651e-04 - val_mae: 0.0172\n",
      "Epoch 132/180\n",
      "65/65 [==============================] - 43s 664ms/step - loss: 8.0589e-04 - mse: 8.0589e-04 - mae: 0.0160 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0173\n",
      "Epoch 133/180\n",
      "65/65 [==============================] - 39s 593ms/step - loss: 8.1409e-04 - mse: 8.1409e-04 - mae: 0.0162 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0208\n",
      "Epoch 134/180\n",
      "65/65 [==============================] - 38s 588ms/step - loss: 8.2179e-04 - mse: 8.2179e-04 - mae: 0.0160 - val_loss: 9.6491e-04 - val_mse: 9.6491e-04 - val_mae: 0.0176\n",
      "Epoch 135/180\n",
      "65/65 [==============================] - 40s 618ms/step - loss: 8.1176e-04 - mse: 8.1176e-04 - mae: 0.0160 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0175\n",
      "Epoch 136/180\n",
      "65/65 [==============================] - 42s 642ms/step - loss: 8.1112e-04 - mse: 8.1112e-04 - mae: 0.0160 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0174\n",
      "Epoch 137/180\n",
      "65/65 [==============================] - 40s 616ms/step - loss: 8.1120e-04 - mse: 8.1120e-04 - mae: 0.0160 - val_loss: 9.7465e-04 - val_mse: 9.7465e-04 - val_mae: 0.0170\n",
      "Epoch 138/180\n",
      "65/65 [==============================] - 39s 604ms/step - loss: 8.0523e-04 - mse: 8.0523e-04 - mae: 0.0159 - val_loss: 9.6899e-04 - val_mse: 9.6899e-04 - val_mae: 0.0169\n",
      "Epoch 139/180\n",
      "65/65 [==============================] - 40s 620ms/step - loss: 8.0353e-04 - mse: 8.0353e-04 - mae: 0.0158 - val_loss: 9.9097e-04 - val_mse: 9.9097e-04 - val_mae: 0.0175\n",
      "Epoch 140/180\n",
      "65/65 [==============================] - 39s 593ms/step - loss: 7.9978e-04 - mse: 7.9978e-04 - mae: 0.0158 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0179\n",
      "Epoch 141/180\n",
      "65/65 [==============================] - 38s 588ms/step - loss: 7.9485e-04 - mse: 7.9485e-04 - mae: 0.0158 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0181\n",
      "Epoch 142/180\n",
      "65/65 [==============================] - 42s 644ms/step - loss: 8.0023e-04 - mse: 8.0023e-04 - mae: 0.0158 - val_loss: 9.9281e-04 - val_mse: 9.9281e-04 - val_mae: 0.0177\n",
      "Epoch 143/180\n",
      "65/65 [==============================] - 40s 613ms/step - loss: 8.0036e-04 - mse: 8.0036e-04 - mae: 0.0158 - val_loss: 9.9069e-04 - val_mse: 9.9069e-04 - val_mae: 0.0165\n",
      "Epoch 144/180\n",
      "65/65 [==============================] - 40s 618ms/step - loss: 8.0431e-04 - mse: 8.0431e-04 - mae: 0.0159 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0192\n",
      "Epoch 145/180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 41s 638ms/step - loss: 8.0501e-04 - mse: 8.0501e-04 - mae: 0.0159 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0191\n",
      "Epoch 146/180\n",
      "65/65 [==============================] - 40s 613ms/step - loss: 8.0143e-04 - mse: 8.0143e-04 - mae: 0.0158 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0183\n",
      "Epoch 147/180\n",
      "65/65 [==============================] - 39s 608ms/step - loss: 7.9866e-04 - mse: 7.9866e-04 - mae: 0.0158 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0183\n",
      "Epoch 148/180\n",
      "65/65 [==============================] - 38s 586ms/step - loss: 7.9063e-04 - mse: 7.9063e-04 - mae: 0.0158 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0183\n",
      "Epoch 149/180\n",
      "65/65 [==============================] - 37s 574ms/step - loss: 7.9625e-04 - mse: 7.9625e-04 - mae: 0.0159 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0193\n",
      "Epoch 150/180\n",
      "65/65 [==============================] - 37s 573ms/step - loss: 7.8431e-04 - mse: 7.8431e-04 - mae: 0.0157 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0176\n",
      "Epoch 151/180\n",
      "65/65 [==============================] - 38s 588ms/step - loss: 8.0560e-04 - mse: 8.0560e-04 - mae: 0.0161 - val_loss: 9.8860e-04 - val_mse: 9.8860e-04 - val_mae: 0.0174\n",
      "Epoch 152/180\n",
      "65/65 [==============================] - 37s 568ms/step - loss: 7.8834e-04 - mse: 7.8834e-04 - mae: 0.0159 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0192\n",
      "Epoch 153/180\n",
      "65/65 [==============================] - 38s 577ms/step - loss: 7.9353e-04 - mse: 7.9354e-04 - mae: 0.0157 - val_loss: 9.9855e-04 - val_mse: 9.9855e-04 - val_mae: 0.0177\n",
      "Epoch 154/180\n",
      "65/65 [==============================] - 38s 583ms/step - loss: 7.8552e-04 - mse: 7.8552e-04 - mae: 0.0159 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0178\n",
      "Epoch 155/180\n",
      "65/65 [==============================] - 36s 551ms/step - loss: 7.9513e-04 - mse: 7.9513e-04 - mae: 0.0158 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0188\n",
      "Epoch 156/180\n",
      "65/65 [==============================] - 34s 526ms/step - loss: 7.9841e-04 - mse: 7.9841e-04 - mae: 0.0157 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0178\n",
      "Epoch 157/180\n",
      "65/65 [==============================] - 35s 545ms/step - loss: 7.9557e-04 - mse: 7.9557e-04 - mae: 0.0157 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0193\n",
      "Epoch 158/180\n",
      "65/65 [==============================] - 36s 561ms/step - loss: 7.8966e-04 - mse: 7.8966e-04 - mae: 0.0157 - val_loss: 9.4493e-04 - val_mse: 9.4493e-04 - val_mae: 0.0171\n",
      "Epoch 159/180\n",
      "65/65 [==============================] - 35s 537ms/step - loss: 7.8379e-04 - mse: 7.8379e-04 - mae: 0.0157 - val_loss: 9.8121e-04 - val_mse: 9.8121e-04 - val_mae: 0.0167\n",
      "Epoch 160/180\n",
      "65/65 [==============================] - 35s 540ms/step - loss: 7.8013e-04 - mse: 7.8013e-04 - mae: 0.0156 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0170\n",
      "Epoch 161/180\n",
      "65/65 [==============================] - 36s 559ms/step - loss: 8.0251e-04 - mse: 8.0251e-04 - mae: 0.0160 - val_loss: 9.4255e-04 - val_mse: 9.4255e-04 - val_mae: 0.0162\n",
      "Epoch 162/180\n",
      "65/65 [==============================] - 35s 539ms/step - loss: 7.8750e-04 - mse: 7.8750e-04 - mae: 0.0158 - val_loss: 9.2880e-04 - val_mse: 9.2880e-04 - val_mae: 0.0169\n",
      "Epoch 163/180\n",
      "65/65 [==============================] - 36s 555ms/step - loss: 7.8385e-04 - mse: 7.8385e-04 - mae: 0.0156 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0172\n",
      "Epoch 164/180\n",
      "65/65 [==============================] - 35s 537ms/step - loss: 7.9200e-04 - mse: 7.9200e-04 - mae: 0.0157 - val_loss: 9.2889e-04 - val_mse: 9.2889e-04 - val_mae: 0.0170\n",
      "Epoch 165/180\n",
      "65/65 [==============================] - 36s 548ms/step - loss: 8.0543e-04 - mse: 8.0543e-04 - mae: 0.0159 - val_loss: 9.6425e-04 - val_mse: 9.6425e-04 - val_mae: 0.0165\n",
      "Epoch 166/180\n",
      "65/65 [==============================] - 36s 558ms/step - loss: 7.8069e-04 - mse: 7.8069e-04 - mae: 0.0156 - val_loss: 9.5959e-04 - val_mse: 9.5959e-04 - val_mae: 0.0160\n",
      "Epoch 167/180\n",
      "65/65 [==============================] - 37s 576ms/step - loss: 7.9710e-04 - mse: 7.9710e-04 - mae: 0.0159 - val_loss: 9.3984e-04 - val_mse: 9.3984e-04 - val_mae: 0.0158\n",
      "Epoch 168/180\n",
      "65/65 [==============================] - 39s 595ms/step - loss: 7.9666e-04 - mse: 7.9666e-04 - mae: 0.0160 - val_loss: 9.3704e-04 - val_mse: 9.3704e-04 - val_mae: 0.0164\n",
      "Epoch 169/180\n",
      "65/65 [==============================] - 37s 576ms/step - loss: 7.6167e-04 - mse: 7.6167e-04 - mae: 0.0156 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0180\n",
      "Epoch 170/180\n",
      "65/65 [==============================] - 38s 591ms/step - loss: 7.8986e-04 - mse: 7.8986e-04 - mae: 0.0158 - val_loss: 9.7235e-04 - val_mse: 9.7235e-04 - val_mae: 0.0170\n",
      "Epoch 171/180\n",
      "65/65 [==============================] - 36s 555ms/step - loss: 8.1284e-04 - mse: 8.1284e-04 - mae: 0.0161 - val_loss: 9.5953e-04 - val_mse: 9.5953e-04 - val_mae: 0.0181\n",
      "Epoch 172/180\n",
      "65/65 [==============================] - 37s 571ms/step - loss: 7.7328e-04 - mse: 7.7328e-04 - mae: 0.0156 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0176\n",
      "Epoch 173/180\n",
      "65/65 [==============================] - 42s 639ms/step - loss: 7.6030e-04 - mse: 7.6030e-04 - mae: 0.0155 - val_loss: 9.9045e-04 - val_mse: 9.9045e-04 - val_mae: 0.0173\n",
      "Epoch 174/180\n",
      "65/65 [==============================] - 40s 612ms/step - loss: 7.8559e-04 - mse: 7.8559e-04 - mae: 0.0158 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0171\n",
      "Epoch 175/180\n",
      "65/65 [==============================] - 37s 562ms/step - loss: 7.7398e-04 - mse: 7.7398e-04 - mae: 0.0159 - val_loss: 9.5082e-04 - val_mse: 9.5082e-04 - val_mae: 0.0178\n",
      "Epoch 176/180\n",
      "65/65 [==============================] - 37s 565ms/step - loss: 7.7822e-04 - mse: 7.7822e-04 - mae: 0.0157 - val_loss: 9.7782e-04 - val_mse: 9.7782e-04 - val_mae: 0.0170\n",
      "Epoch 177/180\n",
      "65/65 [==============================] - 37s 564ms/step - loss: 7.4854e-04 - mse: 7.4854e-04 - mae: 0.0154 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0183\n",
      "Epoch 178/180\n",
      "65/65 [==============================] - 47s 722ms/step - loss: 8.0006e-04 - mse: 8.0006e-04 - mae: 0.0160 - val_loss: 9.6454e-04 - val_mse: 9.6454e-04 - val_mae: 0.0184\n",
      "Epoch 179/180\n",
      "65/65 [==============================] - 42s 639ms/step - loss: 7.8170e-04 - mse: 7.8170e-04 - mae: 0.0159 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0197\n",
      "Epoch 180/180\n",
      "65/65 [==============================] - 40s 616ms/step - loss: 7.7982e-04 - mse: 7.7982e-04 - mae: 0.0159 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0179\n",
      "Epoch 1/180\n",
      "65/65 [==============================] - 50s 770ms/step - loss: 0.2061 - mse: 0.2061 - mae: 0.3562 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0265\n",
      "Epoch 2/180\n",
      "65/65 [==============================] - 57s 873ms/step - loss: 0.1202 - mse: 0.1202 - mae: 0.2767 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0232\n",
      "Epoch 3/180\n",
      "65/65 [==============================] - 53s 815ms/step - loss: 0.0893 - mse: 0.0893 - mae: 0.2379 - val_loss: 0.0029 - val_mse: 0.0029 - val_mae: 0.0376\n",
      "Epoch 4/180\n",
      "65/65 [==============================] - 56s 854ms/step - loss: 0.0569 - mse: 0.0569 - mae: 0.1894 - val_loss: 0.0032 - val_mse: 0.0032 - val_mae: 0.0383\n",
      "Epoch 5/180\n",
      "65/65 [==============================] - 57s 875ms/step - loss: 0.0400 - mse: 0.0400 - mae: 0.1592 - val_loss: 0.0024 - val_mse: 0.0024 - val_mae: 0.0319\n",
      "Epoch 6/180\n",
      "65/65 [==============================] - 55s 851ms/step - loss: 0.0293 - mse: 0.0293 - mae: 0.1369 - val_loss: 0.0028 - val_mse: 0.0028 - val_mae: 0.0366\n",
      "Epoch 7/180\n",
      "65/65 [==============================] - 54s 838ms/step - loss: 0.0210 - mse: 0.0210 - mae: 0.1144 - val_loss: 0.0023 - val_mse: 0.0023 - val_mae: 0.0331\n",
      "Epoch 8/180\n",
      "65/65 [==============================] - 57s 883ms/step - loss: 0.0169 - mse: 0.0169 - mae: 0.1030 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0232\n",
      "Epoch 9/180\n",
      "65/65 [==============================] - 52s 799ms/step - loss: 0.0137 - mse: 0.0137 - mae: 0.0920 - val_loss: 0.0016 - val_mse: 0.0016 - val_mae: 0.0223\n",
      "Epoch 10/180\n",
      "65/65 [==============================] - 59s 906ms/step - loss: 0.0109 - mse: 0.0109 - mae: 0.0824 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0248\n",
      "Epoch 11/180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 54s 832ms/step - loss: 0.0091 - mse: 0.0091 - mae: 0.0753 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0210\n",
      "Epoch 12/180\n",
      "65/65 [==============================] - 55s 853ms/step - loss: 0.0078 - mse: 0.0078 - mae: 0.0693 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0174\n",
      "Epoch 13/180\n",
      "65/65 [==============================] - 54s 827ms/step - loss: 0.0068 - mse: 0.0068 - mae: 0.0644 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0195\n",
      "Epoch 14/180\n",
      "65/65 [==============================] - 59s 900ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0603 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0218\n",
      "Epoch 15/180\n",
      "65/65 [==============================] - 57s 882ms/step - loss: 0.0053 - mse: 0.0053 - mae: 0.0562 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0256\n",
      "Epoch 16/180\n",
      "65/65 [==============================] - 61s 945ms/step - loss: 0.0049 - mse: 0.0049 - mae: 0.0540 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0267\n",
      "Epoch 17/180\n",
      "65/65 [==============================] - 54s 835ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0504 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0211\n",
      "Epoch 18/180\n",
      "65/65 [==============================] - 49s 758ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0465 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0281\n",
      "Epoch 19/180\n",
      "65/65 [==============================] - 50s 770ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0457 - val_loss: 0.0014 - val_mse: 0.0014 - val_mae: 0.0295\n",
      "Epoch 20/180\n",
      "65/65 [==============================] - 50s 774ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0429 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0248\n",
      "Epoch 21/180\n",
      "65/65 [==============================] - 51s 784ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0421 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0258\n",
      "Epoch 22/180\n",
      "65/65 [==============================] - 51s 779ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0389 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0249\n",
      "Epoch 23/180\n",
      "65/65 [==============================] - 50s 773ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0383 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0243\n",
      "Epoch 24/180\n",
      "65/65 [==============================] - 50s 769ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0364 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0268\n",
      "Epoch 25/180\n",
      "65/65 [==============================] - 49s 755ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0348 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0234\n",
      "Epoch 26/180\n",
      "65/65 [==============================] - 50s 775ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0343 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0238\n",
      "Epoch 27/180\n",
      "65/65 [==============================] - 49s 753ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0329 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0249\n",
      "Epoch 28/180\n",
      "65/65 [==============================] - 52s 793ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0314 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0270\n",
      "Epoch 29/180\n",
      "65/65 [==============================] - 46s 706ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0302 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0273\n",
      "Epoch 30/180\n",
      "65/65 [==============================] - 46s 711ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0300 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0271\n",
      "Epoch 31/180\n",
      "65/65 [==============================] - 46s 715ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0282 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0251\n",
      "Epoch 32/180\n",
      "65/65 [==============================] - 47s 716ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0281 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0264\n",
      "Epoch 33/180\n",
      "65/65 [==============================] - 47s 723ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0272 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0267\n",
      "Epoch 34/180\n",
      "65/65 [==============================] - 45s 688ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0262 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0252\n",
      "Epoch 35/180\n",
      "65/65 [==============================] - 45s 690ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0255 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0225\n",
      "Epoch 36/180\n",
      "65/65 [==============================] - 46s 709ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0254 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0239\n",
      "Epoch 37/180\n",
      "65/65 [==============================] - 45s 687ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0246 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0260\n",
      "Epoch 38/180\n",
      "65/65 [==============================] - 45s 686ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0241 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0237\n",
      "Epoch 39/180\n",
      "65/65 [==============================] - 45s 696ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0235 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0239\n",
      "Epoch 40/180\n",
      "65/65 [==============================] - 45s 687ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0231 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0226\n",
      "Epoch 41/180\n",
      "65/65 [==============================] - 47s 718ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0226 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0240\n",
      "Epoch 42/180\n",
      "65/65 [==============================] - 45s 700ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0222 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0225\n",
      "Epoch 43/180\n",
      "65/65 [==============================] - 46s 710ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0221 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0238\n",
      "Epoch 44/180\n",
      "65/65 [==============================] - 47s 722ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0218 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0240\n",
      "Epoch 45/180\n",
      "65/65 [==============================] - 47s 728ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0216 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0235\n",
      "Epoch 46/180\n",
      "65/65 [==============================] - 47s 726ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0215 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0230\n",
      "Epoch 47/180\n",
      "65/65 [==============================] - 46s 705ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0211 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0226\n",
      "Epoch 48/180\n",
      "65/65 [==============================] - 46s 707ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0211 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0228\n",
      "Epoch 49/180\n",
      "65/65 [==============================] - 47s 726ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0210 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0235\n",
      "Epoch 50/180\n",
      "65/65 [==============================] - 46s 704ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0208 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0229\n",
      "Epoch 51/180\n",
      "65/65 [==============================] - 47s 718ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0204 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0224\n",
      "Epoch 52/180\n",
      "65/65 [==============================] - 46s 708ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0204 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0227\n",
      "Epoch 53/180\n",
      "65/65 [==============================] - 46s 701ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0201 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0221\n",
      "Epoch 54/180\n",
      "65/65 [==============================] - 46s 715ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0202 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0222\n",
      "Epoch 55/180\n",
      "65/65 [==============================] - 46s 704ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0199 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0219\n",
      "Epoch 56/180\n",
      "65/65 [==============================] - 46s 713ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0198 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0221\n",
      "Epoch 57/180\n",
      "65/65 [==============================] - 46s 703ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0197 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0209\n",
      "Epoch 58/180\n",
      "65/65 [==============================] - 47s 725ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0197 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0210\n",
      "Epoch 59/180\n",
      "65/65 [==============================] - 46s 711ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0196 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0214\n",
      "Epoch 60/180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 46s 706ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0195 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0217\n",
      "Epoch 61/180\n",
      "65/65 [==============================] - 45s 699ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0197 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0214\n",
      "Epoch 62/180\n",
      "65/65 [==============================] - 47s 717ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0193 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0216\n",
      "Epoch 63/180\n",
      "65/65 [==============================] - 46s 711ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0191 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0207\n",
      "Epoch 64/180\n",
      "65/65 [==============================] - 47s 716ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0193 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0215\n",
      "Epoch 65/180\n",
      "65/65 [==============================] - 46s 702ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0192 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0209\n",
      "Epoch 66/180\n",
      "65/65 [==============================] - 46s 714ms/step - loss: 9.9583e-04 - mse: 9.9583e-04 - mae: 0.0190 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0217\n",
      "Epoch 67/180\n",
      "65/65 [==============================] - 47s 724ms/step - loss: 9.9125e-04 - mse: 9.9125e-04 - mae: 0.0190 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0208\n",
      "Epoch 68/180\n",
      "65/65 [==============================] - 46s 707ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0191 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0220\n",
      "Epoch 69/180\n",
      "65/65 [==============================] - 46s 715ms/step - loss: 9.8444e-04 - mse: 9.8444e-04 - mae: 0.0188 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0213\n",
      "Epoch 70/180\n",
      "65/65 [==============================] - 46s 707ms/step - loss: 9.8765e-04 - mse: 9.8765e-04 - mae: 0.0189 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0211\n",
      "Epoch 71/180\n",
      "65/65 [==============================] - 49s 751ms/step - loss: 9.8513e-04 - mse: 9.8513e-04 - mae: 0.0189 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0210\n",
      "Epoch 72/180\n",
      "65/65 [==============================] - 51s 783ms/step - loss: 9.7879e-04 - mse: 9.7879e-04 - mae: 0.0186 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0212\n",
      "Epoch 73/180\n",
      "65/65 [==============================] - 46s 703ms/step - loss: 9.9705e-04 - mse: 9.9705e-04 - mae: 0.0190 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0214\n",
      "Epoch 74/180\n",
      "65/65 [==============================] - 46s 713ms/step - loss: 9.7542e-04 - mse: 9.7542e-04 - mae: 0.0187 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0212\n",
      "Epoch 75/180\n",
      "65/65 [==============================] - 46s 709ms/step - loss: 9.6110e-04 - mse: 9.6110e-04 - mae: 0.0185 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0208\n",
      "Epoch 76/180\n",
      "65/65 [==============================] - 46s 703ms/step - loss: 9.7017e-04 - mse: 9.7017e-04 - mae: 0.0185 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0209\n",
      "Epoch 77/180\n",
      "65/65 [==============================] - 46s 715ms/step - loss: 9.6439e-04 - mse: 9.6439e-04 - mae: 0.0185 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0210\n",
      "Epoch 78/180\n",
      "65/65 [==============================] - 46s 713ms/step - loss: 9.6402e-04 - mse: 9.6402e-04 - mae: 0.0185 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0212\n",
      "Epoch 79/180\n",
      "65/65 [==============================] - 46s 714ms/step - loss: 9.6048e-04 - mse: 9.6048e-04 - mae: 0.0184 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0213\n",
      "Epoch 80/180\n",
      "65/65 [==============================] - 46s 707ms/step - loss: 9.5557e-04 - mse: 9.5557e-04 - mae: 0.0183 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0213\n",
      "Epoch 81/180\n",
      "65/65 [==============================] - 46s 710ms/step - loss: 9.6348e-04 - mse: 9.6348e-04 - mae: 0.0183 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0211\n",
      "Epoch 82/180\n",
      "65/65 [==============================] - 47s 727ms/step - loss: 9.5302e-04 - mse: 9.5302e-04 - mae: 0.0183 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0211\n",
      "Epoch 83/180\n",
      "65/65 [==============================] - 48s 736ms/step - loss: 9.5699e-04 - mse: 9.5699e-04 - mae: 0.0183 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0215\n",
      "Epoch 84/180\n",
      "65/65 [==============================] - 47s 729ms/step - loss: 9.5170e-04 - mse: 9.5170e-04 - mae: 0.0183 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0212\n",
      "Epoch 85/180\n",
      "65/65 [==============================] - 46s 711ms/step - loss: 9.4646e-04 - mse: 9.4646e-04 - mae: 0.0181 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0209\n",
      "Epoch 86/180\n",
      "65/65 [==============================] - 46s 710ms/step - loss: 9.3701e-04 - mse: 9.3701e-04 - mae: 0.0180 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0210\n",
      "Epoch 87/180\n",
      "65/65 [==============================] - 47s 716ms/step - loss: 9.4490e-04 - mse: 9.4490e-04 - mae: 0.0181 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0197\n",
      "Epoch 88/180\n",
      "65/65 [==============================] - 46s 704ms/step - loss: 9.4027e-04 - mse: 9.4027e-04 - mae: 0.0180 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0199\n",
      "Epoch 89/180\n",
      "65/65 [==============================] - 46s 709ms/step - loss: 9.3628e-04 - mse: 9.3628e-04 - mae: 0.0180 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0194\n",
      "Epoch 90/180\n",
      "65/65 [==============================] - 46s 715ms/step - loss: 9.3315e-04 - mse: 9.3315e-04 - mae: 0.0179 - val_loss: 9.9642e-04 - val_mse: 9.9642e-04 - val_mae: 0.0186\n",
      "Epoch 91/180\n",
      "65/65 [==============================] - 46s 709ms/step - loss: 9.2451e-04 - mse: 9.2451e-04 - mae: 0.0177 - val_loss: 9.9031e-04 - val_mse: 9.9031e-04 - val_mae: 0.0191\n",
      "Epoch 92/180\n",
      "65/65 [==============================] - 47s 716ms/step - loss: 9.2523e-04 - mse: 9.2523e-04 - mae: 0.0178 - val_loss: 9.8996e-04 - val_mse: 9.8996e-04 - val_mae: 0.0188\n",
      "Epoch 93/180\n",
      "65/65 [==============================] - 46s 702ms/step - loss: 9.2511e-04 - mse: 9.2511e-04 - mae: 0.0178 - val_loss: 9.8524e-04 - val_mse: 9.8524e-04 - val_mae: 0.0185\n",
      "Epoch 94/180\n",
      "65/65 [==============================] - 46s 705ms/step - loss: 9.1441e-04 - mse: 9.1441e-04 - mae: 0.0177 - val_loss: 9.7957e-04 - val_mse: 9.7957e-04 - val_mae: 0.0184\n",
      "Epoch 95/180\n",
      "65/65 [==============================] - 47s 724ms/step - loss: 9.2085e-04 - mse: 9.2085e-04 - mae: 0.0176 - val_loss: 9.7962e-04 - val_mse: 9.7962e-04 - val_mae: 0.0185\n",
      "Epoch 96/180\n",
      "65/65 [==============================] - 48s 736ms/step - loss: 9.1453e-04 - mse: 9.1453e-04 - mae: 0.0176 - val_loss: 9.8085e-04 - val_mse: 9.8085e-04 - val_mae: 0.0189\n",
      "Epoch 97/180\n",
      "65/65 [==============================] - 48s 742ms/step - loss: 9.2209e-04 - mse: 9.2209e-04 - mae: 0.0177 - val_loss: 9.7854e-04 - val_mse: 9.7854e-04 - val_mae: 0.0187\n",
      "Epoch 98/180\n",
      "65/65 [==============================] - 49s 759ms/step - loss: 9.1013e-04 - mse: 9.1013e-04 - mae: 0.0176 - val_loss: 9.6793e-04 - val_mse: 9.6793e-04 - val_mae: 0.0186\n",
      "Epoch 99/180\n",
      "65/65 [==============================] - 46s 713ms/step - loss: 9.0870e-04 - mse: 9.0870e-04 - mae: 0.0175 - val_loss: 9.6622e-04 - val_mse: 9.6622e-04 - val_mae: 0.0186\n",
      "Epoch 100/180\n",
      "65/65 [==============================] - 47s 725ms/step - loss: 9.0985e-04 - mse: 9.0985e-04 - mae: 0.0176 - val_loss: 9.5817e-04 - val_mse: 9.5817e-04 - val_mae: 0.0188\n",
      "Epoch 101/180\n",
      "65/65 [==============================] - 47s 716ms/step - loss: 9.0784e-04 - mse: 9.0784e-04 - mae: 0.0176 - val_loss: 9.5709e-04 - val_mse: 9.5709e-04 - val_mae: 0.0187\n",
      "Epoch 102/180\n",
      "65/65 [==============================] - 47s 716ms/step - loss: 9.0035e-04 - mse: 9.0035e-04 - mae: 0.0175 - val_loss: 9.5097e-04 - val_mse: 9.5097e-04 - val_mae: 0.0188\n",
      "Epoch 103/180\n",
      "65/65 [==============================] - 46s 702ms/step - loss: 8.9637e-04 - mse: 8.9637e-04 - mae: 0.0174 - val_loss: 9.3206e-04 - val_mse: 9.3206e-04 - val_mae: 0.0188\n",
      "Epoch 104/180\n",
      "65/65 [==============================] - 45s 700ms/step - loss: 8.9299e-04 - mse: 8.9299e-04 - mae: 0.0173 - val_loss: 9.3328e-04 - val_mse: 9.3328e-04 - val_mae: 0.0191\n",
      "Epoch 105/180\n",
      "65/65 [==============================] - 48s 732ms/step - loss: 9.0784e-04 - mse: 9.0784e-04 - mae: 0.0176 - val_loss: 9.1231e-04 - val_mse: 9.1231e-04 - val_mae: 0.0180\n",
      "Epoch 106/180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 46s 709ms/step - loss: 9.0750e-04 - mse: 9.0750e-04 - mae: 0.0175 - val_loss: 8.9661e-04 - val_mse: 8.9661e-04 - val_mae: 0.0179\n",
      "Epoch 107/180\n",
      "65/65 [==============================] - 46s 711ms/step - loss: 8.9424e-04 - mse: 8.9424e-04 - mae: 0.0174 - val_loss: 8.9381e-04 - val_mse: 8.9381e-04 - val_mae: 0.0189\n",
      "Epoch 108/180\n",
      "65/65 [==============================] - 46s 706ms/step - loss: 9.0324e-04 - mse: 9.0324e-04 - mae: 0.0175 - val_loss: 8.8857e-04 - val_mse: 8.8857e-04 - val_mae: 0.0187\n",
      "Epoch 109/180\n",
      "65/65 [==============================] - 48s 736ms/step - loss: 8.9037e-04 - mse: 8.9037e-04 - mae: 0.0173 - val_loss: 8.8172e-04 - val_mse: 8.8172e-04 - val_mae: 0.0183\n",
      "Epoch 110/180\n",
      "65/65 [==============================] - 46s 712ms/step - loss: 8.8693e-04 - mse: 8.8693e-04 - mae: 0.0172 - val_loss: 8.9370e-04 - val_mse: 8.9370e-04 - val_mae: 0.0187\n",
      "Epoch 111/180\n",
      "65/65 [==============================] - 45s 699ms/step - loss: 8.8802e-04 - mse: 8.8802e-04 - mae: 0.0173 - val_loss: 8.8068e-04 - val_mse: 8.8068e-04 - val_mae: 0.0186\n",
      "Epoch 112/180\n",
      "65/65 [==============================] - 46s 709ms/step - loss: 8.8418e-04 - mse: 8.8418e-04 - mae: 0.0171 - val_loss: 8.8014e-04 - val_mse: 8.8014e-04 - val_mae: 0.0183\n",
      "Epoch 113/180\n",
      "65/65 [==============================] - 47s 718ms/step - loss: 8.9364e-04 - mse: 8.9364e-04 - mae: 0.0174 - val_loss: 8.7788e-04 - val_mse: 8.7788e-04 - val_mae: 0.0182\n",
      "Epoch 114/180\n",
      "65/65 [==============================] - 46s 713ms/step - loss: 8.7662e-04 - mse: 8.7662e-04 - mae: 0.0171 - val_loss: 8.8666e-04 - val_mse: 8.8666e-04 - val_mae: 0.0182\n",
      "Epoch 115/180\n",
      "65/65 [==============================] - 46s 711ms/step - loss: 8.7749e-04 - mse: 8.7749e-04 - mae: 0.0171 - val_loss: 8.7228e-04 - val_mse: 8.7228e-04 - val_mae: 0.0170\n",
      "Epoch 116/180\n",
      "65/65 [==============================] - 46s 707ms/step - loss: 8.7601e-04 - mse: 8.7601e-04 - mae: 0.0170 - val_loss: 9.1420e-04 - val_mse: 9.1420e-04 - val_mae: 0.0188\n",
      "Epoch 117/180\n",
      "65/65 [==============================] - 46s 707ms/step - loss: 8.9112e-04 - mse: 8.9112e-04 - mae: 0.0172 - val_loss: 8.4785e-04 - val_mse: 8.4785e-04 - val_mae: 0.0168\n",
      "Epoch 118/180\n",
      "65/65 [==============================] - 46s 704ms/step - loss: 8.7702e-04 - mse: 8.7702e-04 - mae: 0.0171 - val_loss: 9.1395e-04 - val_mse: 9.1395e-04 - val_mae: 0.0183\n",
      "Epoch 119/180\n",
      "65/65 [==============================] - 46s 711ms/step - loss: 8.6807e-04 - mse: 8.6807e-04 - mae: 0.0170 - val_loss: 8.7284e-04 - val_mse: 8.7284e-04 - val_mae: 0.0179\n",
      "Epoch 120/180\n",
      "65/65 [==============================] - 47s 728ms/step - loss: 8.7247e-04 - mse: 8.7247e-04 - mae: 0.0171 - val_loss: 9.7447e-04 - val_mse: 9.7447e-04 - val_mae: 0.0197\n",
      "Epoch 121/180\n",
      "65/65 [==============================] - 46s 702ms/step - loss: 8.7873e-04 - mse: 8.7873e-04 - mae: 0.0171 - val_loss: 9.8690e-04 - val_mse: 9.8690e-04 - val_mae: 0.0191\n",
      "Epoch 122/180\n",
      "65/65 [==============================] - 47s 730ms/step - loss: 8.7051e-04 - mse: 8.7051e-04 - mae: 0.0170 - val_loss: 8.8525e-04 - val_mse: 8.8525e-04 - val_mae: 0.0168\n",
      "Epoch 123/180\n",
      "65/65 [==============================] - 46s 712ms/step - loss: 8.7301e-04 - mse: 8.7301e-04 - mae: 0.0170 - val_loss: 9.4038e-04 - val_mse: 9.4038e-04 - val_mae: 0.0192\n",
      "Epoch 124/180\n",
      "65/65 [==============================] - 46s 702ms/step - loss: 8.8422e-04 - mse: 8.8422e-04 - mae: 0.0170 - val_loss: 8.5752e-04 - val_mse: 8.5752e-04 - val_mae: 0.0173\n",
      "Epoch 125/180\n",
      "65/65 [==============================] - 46s 707ms/step - loss: 8.7015e-04 - mse: 8.7015e-04 - mae: 0.0170 - val_loss: 8.8239e-04 - val_mse: 8.8239e-04 - val_mae: 0.0165\n",
      "Epoch 126/180\n",
      "65/65 [==============================] - 46s 705ms/step - loss: 8.6534e-04 - mse: 8.6534e-04 - mae: 0.0170 - val_loss: 9.5704e-04 - val_mse: 9.5704e-04 - val_mae: 0.0177\n",
      "Epoch 127/180\n",
      "65/65 [==============================] - 45s 696ms/step - loss: 8.8577e-04 - mse: 8.8577e-04 - mae: 0.0170 - val_loss: 9.2195e-04 - val_mse: 9.2195e-04 - val_mae: 0.0174\n",
      "Epoch 128/180\n",
      "65/65 [==============================] - 46s 710ms/step - loss: 8.6933e-04 - mse: 8.6933e-04 - mae: 0.0172 - val_loss: 8.8925e-04 - val_mse: 8.8925e-04 - val_mae: 0.0181\n",
      "Epoch 129/180\n",
      "65/65 [==============================] - 45s 695ms/step - loss: 8.7054e-04 - mse: 8.7054e-04 - mae: 0.0169 - val_loss: 8.4354e-04 - val_mse: 8.4354e-04 - val_mae: 0.0171\n",
      "Epoch 130/180\n",
      "65/65 [==============================] - 45s 700ms/step - loss: 8.5769e-04 - mse: 8.5769e-04 - mae: 0.0167 - val_loss: 8.6687e-04 - val_mse: 8.6687e-04 - val_mae: 0.0168\n",
      "Epoch 131/180\n",
      "65/65 [==============================] - 46s 703ms/step - loss: 8.6185e-04 - mse: 8.6185e-04 - mae: 0.0168 - val_loss: 8.5230e-04 - val_mse: 8.5230e-04 - val_mae: 0.0155\n",
      "Epoch 132/180\n",
      "65/65 [==============================] - 45s 696ms/step - loss: 8.5931e-04 - mse: 8.5931e-04 - mae: 0.0169 - val_loss: 9.5369e-04 - val_mse: 9.5369e-04 - val_mae: 0.0184\n",
      "Epoch 133/180\n",
      "65/65 [==============================] - 46s 707ms/step - loss: 8.5591e-04 - mse: 8.5591e-04 - mae: 0.0168 - val_loss: 9.0690e-04 - val_mse: 9.0690e-04 - val_mae: 0.0190\n",
      "Epoch 134/180\n",
      "65/65 [==============================] - 45s 698ms/step - loss: 8.5765e-04 - mse: 8.5765e-04 - mae: 0.0166 - val_loss: 8.7690e-04 - val_mse: 8.7690e-04 - val_mae: 0.0160\n",
      "Epoch 135/180\n",
      "65/65 [==============================] - 58s 900ms/step - loss: 8.7633e-04 - mse: 8.7633e-04 - mae: 0.0172 - val_loss: 8.9772e-04 - val_mse: 8.9772e-04 - val_mae: 0.0173\n",
      "Epoch 136/180\n",
      "65/65 [==============================] - 51s 790ms/step - loss: 8.8536e-04 - mse: 8.8536e-04 - mae: 0.0170 - val_loss: 8.8045e-04 - val_mse: 8.8045e-04 - val_mae: 0.0182\n",
      "Epoch 137/180\n",
      "65/65 [==============================] - 52s 803ms/step - loss: 8.5370e-04 - mse: 8.5370e-04 - mae: 0.0167 - val_loss: 8.4175e-04 - val_mse: 8.4175e-04 - val_mae: 0.0163\n",
      "Epoch 138/180\n",
      "65/65 [==============================] - 55s 842ms/step - loss: 8.5820e-04 - mse: 8.5820e-04 - mae: 0.0167 - val_loss: 8.7700e-04 - val_mse: 8.7700e-04 - val_mae: 0.0162\n",
      "Epoch 139/180\n",
      "65/65 [==============================] - 53s 812ms/step - loss: 8.5647e-04 - mse: 8.5647e-04 - mae: 0.0168 - val_loss: 8.6890e-04 - val_mse: 8.6890e-04 - val_mae: 0.0161\n",
      "Epoch 140/180\n",
      "65/65 [==============================] - 55s 853ms/step - loss: 8.4902e-04 - mse: 8.4902e-04 - mae: 0.0166 - val_loss: 8.9752e-04 - val_mse: 8.9752e-04 - val_mae: 0.0167\n",
      "Epoch 141/180\n",
      "65/65 [==============================] - 57s 879ms/step - loss: 8.4813e-04 - mse: 8.4813e-04 - mae: 0.0166 - val_loss: 9.2016e-04 - val_mse: 9.2016e-04 - val_mae: 0.0170\n",
      "Epoch 142/180\n",
      "65/65 [==============================] - 57s 872ms/step - loss: 8.6090e-04 - mse: 8.6090e-04 - mae: 0.0167 - val_loss: 8.9669e-04 - val_mse: 8.9669e-04 - val_mae: 0.0196\n",
      "Epoch 143/180\n",
      "65/65 [==============================] - 55s 848ms/step - loss: 8.5327e-04 - mse: 8.5327e-04 - mae: 0.0167 - val_loss: 8.4732e-04 - val_mse: 8.4732e-04 - val_mae: 0.0160\n",
      "Epoch 144/180\n",
      "65/65 [==============================] - 58s 885ms/step - loss: 8.5761e-04 - mse: 8.5761e-04 - mae: 0.0169 - val_loss: 9.4668e-04 - val_mse: 9.4668e-04 - val_mae: 0.0182\n",
      "Epoch 145/180\n",
      "65/65 [==============================] - 61s 935ms/step - loss: 8.6380e-04 - mse: 8.6380e-04 - mae: 0.0167 - val_loss: 8.5209e-04 - val_mse: 8.5209e-04 - val_mae: 0.0182\n",
      "Epoch 146/180\n",
      "65/65 [==============================] - 64s 987ms/step - loss: 8.4703e-04 - mse: 8.4703e-04 - mae: 0.0166 - val_loss: 8.2300e-04 - val_mse: 8.2300e-04 - val_mae: 0.0153\n",
      "Epoch 147/180\n",
      "65/65 [==============================] - 66s 1s/step - loss: 8.4804e-04 - mse: 8.4804e-04 - mae: 0.0166 - val_loss: 8.5802e-04 - val_mse: 8.5802e-04 - val_mae: 0.0166\n",
      "Epoch 148/180\n",
      "65/65 [==============================] - 64s 985ms/step - loss: 8.4205e-04 - mse: 8.4205e-04 - mae: 0.0164 - val_loss: 8.3518e-04 - val_mse: 8.3518e-04 - val_mae: 0.0164\n",
      "Epoch 149/180\n",
      "65/65 [==============================] - 63s 967ms/step - loss: 8.3514e-04 - mse: 8.3514e-04 - mae: 0.0165 - val_loss: 8.6668e-04 - val_mse: 8.6668e-04 - val_mae: 0.0158\n",
      "Epoch 150/180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 60s 927ms/step - loss: 8.4337e-04 - mse: 8.4337e-04 - mae: 0.0166 - val_loss: 9.2294e-04 - val_mse: 9.2294e-04 - val_mae: 0.0177\n",
      "Epoch 151/180\n",
      "65/65 [==============================] - 61s 943ms/step - loss: 8.5270e-04 - mse: 8.5270e-04 - mae: 0.0166 - val_loss: 8.4232e-04 - val_mse: 8.4232e-04 - val_mae: 0.0180\n",
      "Epoch 152/180\n",
      "65/65 [==============================] - 61s 937ms/step - loss: 8.4131e-04 - mse: 8.4131e-04 - mae: 0.0164 - val_loss: 8.2860e-04 - val_mse: 8.2860e-04 - val_mae: 0.0160\n",
      "Epoch 153/180\n",
      "65/65 [==============================] - 63s 971ms/step - loss: 8.5336e-04 - mse: 8.5336e-04 - mae: 0.0167 - val_loss: 8.3559e-04 - val_mse: 8.3559e-04 - val_mae: 0.0163\n",
      "Epoch 154/180\n",
      "65/65 [==============================] - 65s 998ms/step - loss: 8.3699e-04 - mse: 8.3699e-04 - mae: 0.0166 - val_loss: 8.4454e-04 - val_mse: 8.4454e-04 - val_mae: 0.0174\n",
      "Epoch 155/180\n",
      "65/65 [==============================] - 63s 977ms/step - loss: 8.3804e-04 - mse: 8.3804e-04 - mae: 0.0163 - val_loss: 8.1627e-04 - val_mse: 8.1627e-04 - val_mae: 0.0162\n",
      "Epoch 156/180\n",
      "65/65 [==============================] - 63s 969ms/step - loss: 8.2884e-04 - mse: 8.2884e-04 - mae: 0.0162 - val_loss: 7.9754e-04 - val_mse: 7.9754e-04 - val_mae: 0.0158\n",
      "Epoch 157/180\n",
      "65/65 [==============================] - 63s 976ms/step - loss: 8.3424e-04 - mse: 8.3424e-04 - mae: 0.0163 - val_loss: 8.1411e-04 - val_mse: 8.1411e-04 - val_mae: 0.0171\n",
      "Epoch 158/180\n",
      "65/65 [==============================] - 59s 904ms/step - loss: 8.3073e-04 - mse: 8.3073e-04 - mae: 0.0161 - val_loss: 7.9243e-04 - val_mse: 7.9243e-04 - val_mae: 0.0158\n",
      "Epoch 159/180\n",
      "65/65 [==============================] - 69s 1s/step - loss: 8.2282e-04 - mse: 8.2282e-04 - mae: 0.0161 - val_loss: 8.0219e-04 - val_mse: 8.0219e-04 - val_mae: 0.0152\n",
      "Epoch 160/180\n",
      "65/65 [==============================] - 61s 942ms/step - loss: 8.3283e-04 - mse: 8.3283e-04 - mae: 0.0163 - val_loss: 7.9024e-04 - val_mse: 7.9024e-04 - val_mae: 0.0167\n",
      "Epoch 161/180\n",
      "65/65 [==============================] - 63s 969ms/step - loss: 8.3307e-04 - mse: 8.3307e-04 - mae: 0.0162 - val_loss: 8.9025e-04 - val_mse: 8.9025e-04 - val_mae: 0.0179\n",
      "Epoch 162/180\n",
      "65/65 [==============================] - 55s 850ms/step - loss: 8.3949e-04 - mse: 8.3949e-04 - mae: 0.0165 - val_loss: 8.3476e-04 - val_mse: 8.3476e-04 - val_mae: 0.0165\n",
      "Epoch 163/180\n",
      "65/65 [==============================] - 62s 948ms/step - loss: 8.5250e-04 - mse: 8.5250e-04 - mae: 0.0166 - val_loss: 8.4331e-04 - val_mse: 8.4331e-04 - val_mae: 0.0181\n",
      "Epoch 164/180\n",
      "65/65 [==============================] - 73s 1s/step - loss: 8.2105e-04 - mse: 8.2105e-04 - mae: 0.0161 - val_loss: 7.9977e-04 - val_mse: 7.9977e-04 - val_mae: 0.0155\n",
      "Epoch 165/180\n",
      "65/65 [==============================] - 62s 959ms/step - loss: 8.1800e-04 - mse: 8.1800e-04 - mae: 0.0160 - val_loss: 8.5193e-04 - val_mse: 8.5193e-04 - val_mae: 0.0157\n",
      "Epoch 166/180\n",
      "65/65 [==============================] - 63s 970ms/step - loss: 8.3381e-04 - mse: 8.3381e-04 - mae: 0.0163 - val_loss: 8.6624e-04 - val_mse: 8.6624e-04 - val_mae: 0.0173\n",
      "Epoch 167/180\n",
      "65/65 [==============================] - 65s 1s/step - loss: 8.2759e-04 - mse: 8.2759e-04 - mae: 0.0161 - val_loss: 8.0731e-04 - val_mse: 8.0731e-04 - val_mae: 0.0160\n",
      "Epoch 168/180\n",
      "65/65 [==============================] - 58s 888ms/step - loss: 8.3863e-04 - mse: 8.3863e-04 - mae: 0.0162 - val_loss: 7.5818e-04 - val_mse: 7.5818e-04 - val_mae: 0.0165\n",
      "Epoch 169/180\n",
      "65/65 [==============================] - 64s 988ms/step - loss: 8.2400e-04 - mse: 8.2400e-04 - mae: 0.0162 - val_loss: 7.7653e-04 - val_mse: 7.7653e-04 - val_mae: 0.0155\n",
      "Epoch 170/180\n",
      "65/65 [==============================] - 60s 920ms/step - loss: 8.2398e-04 - mse: 8.2398e-04 - mae: 0.0161 - val_loss: 7.7132e-04 - val_mse: 7.7132e-04 - val_mae: 0.0161\n",
      "Epoch 171/180\n",
      "65/65 [==============================] - 60s 926ms/step - loss: 8.1677e-04 - mse: 8.1677e-04 - mae: 0.0161 - val_loss: 8.0398e-04 - val_mse: 8.0398e-04 - val_mae: 0.0150\n",
      "Epoch 172/180\n",
      "65/65 [==============================] - 56s 866ms/step - loss: 8.3034e-04 - mse: 8.3034e-04 - mae: 0.0163 - val_loss: 7.8765e-04 - val_mse: 7.8765e-04 - val_mae: 0.0167\n",
      "Epoch 173/180\n",
      "65/65 [==============================] - 55s 842ms/step - loss: 8.2083e-04 - mse: 8.2083e-04 - mae: 0.0159 - val_loss: 8.1070e-04 - val_mse: 8.1070e-04 - val_mae: 0.0165\n",
      "Epoch 174/180\n",
      "65/65 [==============================] - 67s 1s/step - loss: 8.1316e-04 - mse: 8.1316e-04 - mae: 0.0160 - val_loss: 7.8803e-04 - val_mse: 7.8803e-04 - val_mae: 0.0161\n",
      "Epoch 175/180\n",
      "65/65 [==============================] - 58s 897ms/step - loss: 8.0409e-04 - mse: 8.0409e-04 - mae: 0.0158 - val_loss: 7.8647e-04 - val_mse: 7.8647e-04 - val_mae: 0.0162\n",
      "Epoch 176/180\n",
      "65/65 [==============================] - 62s 956ms/step - loss: 8.4069e-04 - mse: 8.4069e-04 - mae: 0.0162 - val_loss: 7.9377e-04 - val_mse: 7.9377e-04 - val_mae: 0.0188\n",
      "Epoch 177/180\n",
      "65/65 [==============================] - 64s 990ms/step - loss: 8.1958e-04 - mse: 8.1958e-04 - mae: 0.0162 - val_loss: 7.6579e-04 - val_mse: 7.6579e-04 - val_mae: 0.0151\n",
      "Epoch 178/180\n",
      "65/65 [==============================] - 76s 1s/step - loss: 8.1239e-04 - mse: 8.1239e-04 - mae: 0.0157 - val_loss: 7.7314e-04 - val_mse: 7.7314e-04 - val_mae: 0.0152\n",
      "Epoch 179/180\n",
      "65/65 [==============================] - 61s 946ms/step - loss: 8.0812e-04 - mse: 8.0812e-04 - mae: 0.0157 - val_loss: 7.7496e-04 - val_mse: 7.7496e-04 - val_mae: 0.0152\n",
      "Epoch 180/180\n",
      "65/65 [==============================] - 83s 1s/step - loss: 8.0079e-04 - mse: 8.0079e-04 - mae: 0.0157 - val_loss: 7.9132e-04 - val_mse: 7.9132e-04 - val_mae: 0.0157\n",
      "Epoch 1/180\n",
      "65/65 [==============================] - 166s 3s/step - loss: 0.2311 - mse: 0.2311 - mae: 0.3642 - val_loss: 0.0020 - val_mse: 0.0020 - val_mae: 0.0313\n",
      "Epoch 2/180\n",
      "65/65 [==============================] - 132s 2s/step - loss: 0.1085 - mse: 0.1085 - mae: 0.2624 - val_loss: 0.0029 - val_mse: 0.0029 - val_mae: 0.0463\n",
      "Epoch 3/180\n",
      "65/65 [==============================] - 88s 1s/step - loss: 0.0860 - mse: 0.0860 - mae: 0.2330 - val_loss: 0.0025 - val_mse: 0.0025 - val_mae: 0.0407\n",
      "Epoch 4/180\n",
      "65/65 [==============================] - 96s 1s/step - loss: 0.0638 - mse: 0.0638 - mae: 0.2010 - val_loss: 0.0026 - val_mse: 0.0026 - val_mae: 0.0430\n",
      "Epoch 5/180\n",
      "65/65 [==============================] - 95s 1s/step - loss: 0.0500 - mse: 0.0500 - mae: 0.1782 - val_loss: 0.0028 - val_mse: 0.0028 - val_mae: 0.0470\n",
      "Epoch 6/180\n",
      "65/65 [==============================] - 92s 1s/step - loss: 0.0391 - mse: 0.0391 - mae: 0.1569 - val_loss: 0.0026 - val_mse: 0.0026 - val_mae: 0.0452\n",
      "Epoch 7/180\n",
      "65/65 [==============================] - 124s 2s/step - loss: 0.0298 - mse: 0.0298 - mae: 0.1364 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0206\n",
      "Epoch 8/180\n",
      "65/65 [==============================] - 88s 1s/step - loss: 0.0252 - mse: 0.0252 - mae: 0.1265 - val_loss: 0.0017 - val_mse: 0.0017 - val_mae: 0.0359\n",
      "Epoch 9/180\n",
      "65/65 [==============================] - 91s 1s/step - loss: 0.0194 - mse: 0.0194 - mae: 0.1098 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0236\n",
      "Epoch 10/180\n",
      "65/65 [==============================] - 86s 1s/step - loss: 0.0159 - mse: 0.0159 - mae: 0.0997 - val_loss: 0.0014 - val_mse: 0.0014 - val_mae: 0.0301\n",
      "Epoch 11/180\n",
      "65/65 [==============================] - 98s 2s/step - loss: 0.0134 - mse: 0.0134 - mae: 0.0906 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0217\n",
      "Epoch 12/180\n",
      "65/65 [==============================] - 88s 1s/step - loss: 0.0112 - mse: 0.0112 - mae: 0.0834 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0202\n",
      "Epoch 13/180\n",
      "65/65 [==============================] - 96s 1s/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0813 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0165\n",
      "Epoch 14/180\n",
      "65/65 [==============================] - 97s 1s/step - loss: 0.0086 - mse: 0.0086 - mae: 0.0731 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0237\n",
      "Epoch 15/180\n",
      "15/65 [=====>........................] - ETA: 59s - loss: 0.0077 - mse: 0.0077 - mae: 0.0692 "
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "steps = 96\n",
    "#n_hidden = 1\n",
    "#units = 100\n",
    "batch_size = 96\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "# no hidden or one hidden layer\n",
    "parameters = {'n_hidden': [1, 2],\n",
    "              'units': [50, 100, 150, 200]}\n",
    "\n",
    "all_param = ParameterGrid(parameters)\n",
    "\n",
    "# function to split data into correct shape for RNN\n",
    "def split_data(X, y, steps):\n",
    "    X_, y_ = list(), list()\n",
    "    for i in range(steps, len(y)):\n",
    "        X_.append(X[i - steps : i, :])\n",
    "        y_.append(y[i]) \n",
    "    return np.array(X_), np.array(y_)\n",
    "\n",
    "# function to cut data set so it can be divisible by the batch_size\n",
    "def cut_data(data, batch_size):\n",
    "     # see if it is divisivel\n",
    "    condition = data.shape[0] % batch_size\n",
    "    if condition == 0:\n",
    "        return data\n",
    "    else:\n",
    "        return data[: -condition]\n",
    "\n",
    "# divide features and labels\n",
    "X_train = data_train[:, 0:15] \n",
    "y_train = data_train[:, -1]\n",
    "X_test = data_test[:, 0:15] \n",
    "y_test = data_test[:, -1] \n",
    "\n",
    "# divide data into train and test \n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "         X_train, y_train, test_size = 0.15, shuffle=False)\n",
    "\n",
    "# put data into correct shape\n",
    "X_train, y_train = split_data(X_train, y_train, steps)\n",
    "X_test, y_test = split_data(X_test, y_test, steps)\n",
    "X_val, y_val = split_data(X_val, y_val, steps)\n",
    "\n",
    "X_train = cut_data(X_train, batch_size)\n",
    "y_train = cut_data(y_train, batch_size)\n",
    "X_test = cut_data(X_test, batch_size)\n",
    "y_test = cut_data(y_test, batch_size)\n",
    "X_val = cut_data(X_val, batch_size)\n",
    "y_val = cut_data(y_val, batch_size)\n",
    "\n",
    "# design the LSTM\n",
    "def regressor_tunning(kernel_initializer = 'he_normal',\n",
    "                      bias_initializer = initializers.Ones()):\n",
    "    model = Sequential()\n",
    "    if n_hidden == 0:\n",
    "        model.add(LSTM(units = units,                    \n",
    "                       batch_input_shape = (batch_size, steps, features_num), \n",
    "                       stateful = True,\n",
    "                       kernel_initializer = kernel_initializer,\n",
    "                       bias_initializer = bias_initializer))\n",
    "        model.add(LeakyReLU(alpha = 0.2))\n",
    "        model.add(Dropout(0.2))\n",
    "    else:\n",
    "        model.add(LSTM(units = units,                    \n",
    "                       batch_input_shape = (batch_size, steps, features_num), \n",
    "                       stateful = True,\n",
    "                       return_sequences = True,\n",
    "                       kernel_initializer = kernel_initializer,\n",
    "                       bias_initializer = bias_initializer))\n",
    "        model.add(LeakyReLU(alpha = 0.2))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(LSTM(units = units, \n",
    "                       batch_input_shape = (batch_size, steps, features_num), \n",
    "                       stateful = True,\n",
    "                       kernel_initializer = kernel_initializer,\n",
    "                       bias_initializer = bias_initializer))\n",
    "        model.add(LeakyReLU(alpha = 0.2))\n",
    "        model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(loss = 'mse', metrics = ['mse', 'mae'], optimizer = 'Adamax')\n",
    "    return model\n",
    "\n",
    "# inverse of test set should not be inside the loop \n",
    "y_test = (y_test * sc_X.data_range_[15]) + (sc_X.data_min_[15])\n",
    "\n",
    "for i in range(len(all_param)):\n",
    "    \n",
    "    units = all_param[i]['units']\n",
    "    n_hidden = all_param[i]['n_hidden']\n",
    "    \n",
    "    model = regressor_tunning()\n",
    "\n",
    "    # fitting the LSTM to the training set\n",
    "    history = model.fit(X_train,\n",
    "                        y_train, \n",
    "                        batch_size = batch_size, \n",
    "                        epochs = 180,\n",
    "                        shuffle = False, \n",
    "                        validation_data = (X_val, y_val))\n",
    "    \n",
    "    model.reset_states()\n",
    "    \n",
    "    # make new predicitons with test set\n",
    "    y_pred = model.predict(X_test, batch_size = batch_size)\n",
    "    \n",
    "    # prices col = 15\n",
    "    y_pred = (y_pred * sc_X.data_range_[15]) + (sc_X.data_min_[15])\n",
    "\n",
    "    y_pred_list.append(y_pred)\n",
    "    \n",
    "    from sklearn.metrics import mean_squared_error as mse\n",
    "    from sklearn.metrics import mean_absolute_error as mae\n",
    "\n",
    "    rmse_error = mse(y_test, y_pred, squared = False)\n",
    "    mae_error = mae(y_test, y_pred)\n",
    "    \n",
    "    rmse_gen.append(rmse_error)\n",
    "    mae_gen.append(mae_error)\n",
    "    \n",
    "    # =============================================================================\n",
    "    # Metrics evaluation on spike regions\n",
    "    # =============================================================================\n",
    "    \n",
    "    y_spike_occ = pd.read_csv('Spike_binary_1std.csv', usecols = [6])\n",
    "    \n",
    "    # create array same size as y_test\n",
    "    y_spike_occ = y_spike_occ.iloc[- len(y_test):]\n",
    "    y_spike_occ = pd.Series(y_spike_occ.iloc[:,0]).values\n",
    "    \n",
    "    # smal adjustment\n",
    "    y_test = pd.Series(y_test)\n",
    "    y_test.replace(0, 0.0001,inplace = True)\n",
    "\n",
    "    # select y_pred and y_test only for regions with spikes\n",
    "    y_test_spike = (y_test.T * y_spike_occ).T\n",
    "    y_pred_spike = (y_pred.T * y_spike_occ).T\n",
    "    y_test_spike = y_test_spike[y_test_spike != 0]\n",
    "    y_pred_spike = y_pred_spike[y_pred_spike != 0]\n",
    "    \n",
    "    # calculate metric\n",
    "    rmse_spike = mse(y_test_spike, y_pred_spike, squared = False)\n",
    "    mae_spike = mae(y_test_spike, y_pred_spike)\n",
    "    \n",
    "    rmse_spi.append(rmse_spike)\n",
    "    mae_spi.append(mae_spike)\n",
    "    \n",
    "    # =============================================================================\n",
    "    # Metric evaluation on normal regions\n",
    "    # =============================================================================\n",
    "    \n",
    "    # inverse y_spike_occ so the only normal occurences are chosen\n",
    "    y_normal_occ = (y_spike_occ - 1) * (-1)\n",
    "    \n",
    "    # sanity check\n",
    "    y_normal_occ.sum() + y_spike_occ.sum() # gives the correct total \n",
    "    \n",
    "    # select y_pred and y_test only for normal regions\n",
    "    y_test_normal = (y_test.T * y_normal_occ).T\n",
    "    y_pred_normal = (y_pred.T * y_normal_occ).T\n",
    "    y_test_normal = y_test_normal[y_test_normal != 0.00]\n",
    "    y_pred_normal = y_pred_normal[y_pred_normal != 0.00]\n",
    "    \n",
    "    # calculate metric\n",
    "    rmse_normal = mse(y_test_normal, y_pred_normal, squared = False)\n",
    "    mae_normal = mae(y_test_normal, y_pred_normal)\n",
    "    \n",
    "    rmse_nor.append(rmse_normal)\n",
    "    mae_nor.append(mae_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({'all_param':all_param,\n",
    "                        \n",
    "                        'rmse_general': rmse_gen, \n",
    "                 \n",
    "                        'mae_general': mae_gen,\n",
    "                        \n",
    "                        'rmse_spike': rmse_spi,\n",
    "                 \n",
    "                        'mae_spike': mae_spi,\n",
    "                        \n",
    "                        'rmse_normal': rmse_nor,\n",
    "                    \n",
    "                        'mae_normal': mae_nor})\n",
    "\n",
    "results.to_csv('Results_LSTM_2_n_neurons_n_hidden.csv')\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({'rmse_general': rmse_gen, \n",
    "                 \n",
    "                        'mae_general': mae_gen,\n",
    "                        \n",
    "                        'rmse_spike': rmse_spi,\n",
    "                 \n",
    "                        'mae_spike': mae_spi,\n",
    "                        \n",
    "                        'rmse_normal': rmse_nor,\n",
    "                    \n",
    "                        'mae_normal': mae_nor})\n",
    "\n",
    "def highlight_min(s):\n",
    "    '''\n",
    "    highlight the maximum in a Series yellow.\n",
    "    '''\n",
    "    is_max = s == s.min()\n",
    "    return ['background-color: yellow' if v else '' for v in is_max]\n",
    "\n",
    "results.style.apply(highlight_min)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
