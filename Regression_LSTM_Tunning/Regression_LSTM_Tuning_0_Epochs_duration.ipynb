{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Parameter Tunning \n",
    "    \n",
    "    Look at epochs duration (6 months of data used)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\maria\\anaconda3\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from pandas) (1.18.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from python-dateutil>=2.6.1->pandas) (1.14.0)\n",
      "Requirement already satisfied: sklearn in c:\\users\\maria\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\maria\\anaconda3\\lib\\site-packages (from sklearn) (0.22.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (0.14.1)\n",
      "Requirement already satisfied: scipy>=0.17.0 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.11.0 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.18.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install sklearn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data; fill nan values; split data intro train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "data = pd.read_csv('Data_set_1_smaller.csv', index_col = 0)\n",
    "\n",
    "# for later use\n",
    "features_num = 15\n",
    "\n",
    "# 2018 data\n",
    "data = data.loc[data.index > 2018070000, :]\n",
    "\n",
    "# reset index\n",
    "data.reset_index(inplace = True)\n",
    "data.drop('index', axis = 1, inplace = True)\n",
    "\n",
    "# fill nan values\n",
    "data.fillna(method = 'ffill', inplace = True)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# divide data into train and test \n",
    "data_train, data_test = train_test_split(\n",
    "         data, test_size = 0.15, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply feature scaling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# data scaling\n",
    "sc_X = MinMaxScaler()\n",
    "data_train = sc_X.fit_transform(data_train)\n",
    "data_test = sc_X.transform(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the Keras libraries and packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LeakyReLU\n",
    "from keras import initializers\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "mae_cv = []\n",
    "mse_cv = []\n",
    "mae_gen = []\n",
    "mse_gen  =[]\n",
    "rmse_gen = []\n",
    "mae_nor = []\n",
    "mae_spi = []\n",
    "mse_nor = []\n",
    "mse_spi = []\n",
    "rmse_nor = []\n",
    "rmse_spi = []\n",
    "hist_list = []\n",
    "y_pred_list = []\n",
    "prediction_list = []\n",
    "time_count = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare of data according to LSTM needs,  create regressor & tune:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "62/62 [==============================] - 9s 144ms/step - loss: 0.1542 - mse: 0.1542 - mae: 0.3126 - val_loss: 0.0065 - val_mse: 0.0065 - val_mae: 0.0663\n",
      "Epoch 2/50\n",
      "62/62 [==============================] - 8s 125ms/step - loss: 0.0856 - mse: 0.0856 - mae: 0.2320 - val_loss: 0.0037 - val_mse: 0.0037 - val_mae: 0.0482\n",
      "Epoch 3/50\n",
      "62/62 [==============================] - 8s 124ms/step - loss: 0.0509 - mse: 0.0509 - mae: 0.1804 - val_loss: 0.0026 - val_mse: 0.0026 - val_mae: 0.0394\n",
      "Epoch 4/50\n",
      "62/62 [==============================] - 8s 122ms/step - loss: 0.0348 - mse: 0.0348 - mae: 0.1482 - val_loss: 0.0023 - val_mse: 0.0023 - val_mae: 0.0379\n",
      "Epoch 5/50\n",
      "62/62 [==============================] - 8s 128ms/step - loss: 0.0251 - mse: 0.0251 - mae: 0.1251 - val_loss: 0.0022 - val_mse: 0.0022 - val_mae: 0.0363\n",
      "Epoch 6/50\n",
      "62/62 [==============================] - 8s 132ms/step - loss: 0.0199 - mse: 0.0199 - mae: 0.1118 - val_loss: 0.0038 - val_mse: 0.0038 - val_mae: 0.0513\n",
      "Epoch 7/50\n",
      "62/62 [==============================] - 8s 123ms/step - loss: 0.0156 - mse: 0.0156 - mae: 0.0987 - val_loss: 0.0031 - val_mse: 0.0031 - val_mae: 0.0458\n",
      "Epoch 8/50\n",
      "62/62 [==============================] - 8s 122ms/step - loss: 0.0126 - mse: 0.0126 - mae: 0.0887 - val_loss: 0.0024 - val_mse: 0.0024 - val_mae: 0.0394\n",
      "Epoch 9/50\n",
      "62/62 [==============================] - 8s 121ms/step - loss: 0.0101 - mse: 0.0101 - mae: 0.0794 - val_loss: 0.0020 - val_mse: 0.0020 - val_mae: 0.0351\n",
      "Epoch 10/50\n",
      "62/62 [==============================] - 9s 142ms/step - loss: 0.0083 - mse: 0.0083 - mae: 0.0715 - val_loss: 0.0028 - val_mse: 0.0028 - val_mae: 0.0441\n",
      "Epoch 11/50\n",
      "62/62 [==============================] - 9s 138ms/step - loss: 0.0069 - mse: 0.0069 - mae: 0.0655 - val_loss: 0.0017 - val_mse: 0.0017 - val_mae: 0.0310\n",
      "Epoch 12/50\n",
      "62/62 [==============================] - 8s 133ms/step - loss: 0.0057 - mse: 0.0057 - mae: 0.0589 - val_loss: 0.0018 - val_mse: 0.0018 - val_mae: 0.0324\n",
      "Epoch 13/50\n",
      "62/62 [==============================] - 8s 129ms/step - loss: 0.0049 - mse: 0.0049 - mae: 0.0548 - val_loss: 0.0015 - val_mse: 0.0015 - val_mae: 0.0295\n",
      "Epoch 14/50\n",
      "62/62 [==============================] - 8s 128ms/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0499 - val_loss: 0.0015 - val_mse: 0.0015 - val_mae: 0.0291\n",
      "Epoch 15/50\n",
      "62/62 [==============================] - 8s 121ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0452 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0252\n",
      "Epoch 16/50\n",
      "62/62 [==============================] - 7s 118ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0422 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0252\n",
      "Epoch 17/50\n",
      "62/62 [==============================] - 7s 118ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0391 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0235\n",
      "Epoch 18/50\n",
      "62/62 [==============================] - 7s 119ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0372 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0243\n",
      "Epoch 19/50\n",
      "62/62 [==============================] - 7s 117ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0344 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0232\n",
      "Epoch 20/50\n",
      "62/62 [==============================] - 7s 119ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0339 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0242\n",
      "Epoch 21/50\n",
      "62/62 [==============================] - 7s 118ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0315 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0244\n",
      "Epoch 22/50\n",
      "62/62 [==============================] - 7s 115ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0310 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0237\n",
      "Epoch 23/50\n",
      "62/62 [==============================] - 7s 117ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0286 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0239\n",
      "Epoch 24/50\n",
      "62/62 [==============================] - 7s 121ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0282 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0222\n",
      "Epoch 25/50\n",
      "62/62 [==============================] - 7s 120ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0265 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0224\n",
      "Epoch 26/50\n",
      "62/62 [==============================] - 8s 130ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0262 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0233\n",
      "Epoch 27/50\n",
      "62/62 [==============================] - 8s 130ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0258 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0233\n",
      "Epoch 28/50\n",
      "62/62 [==============================] - 7s 120ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0253 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0217\n",
      "Epoch 29/50\n",
      "62/62 [==============================] - 7s 120ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0244 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0210\n",
      "Epoch 30/50\n",
      "62/62 [==============================] - 7s 119ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0241 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0222\n",
      "Epoch 31/50\n",
      "62/62 [==============================] - 7s 119ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0232 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0205\n",
      "Epoch 32/50\n",
      "62/62 [==============================] - 7s 119ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0232 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0213\n",
      "Epoch 33/50\n",
      "62/62 [==============================] - 8s 124ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0227 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0198\n",
      "Epoch 34/50\n",
      "62/62 [==============================] - 8s 122ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0223 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0200\n",
      "Epoch 35/50\n",
      "62/62 [==============================] - 7s 121ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0219 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0200\n",
      "Epoch 36/50\n",
      "62/62 [==============================] - 8s 121ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0217 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0194\n",
      "Epoch 37/50\n",
      "62/62 [==============================] - 7s 120ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0215 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0204\n",
      "Epoch 38/50\n",
      "62/62 [==============================] - 7s 118ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0217 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0201\n",
      "Epoch 39/50\n",
      "62/62 [==============================] - 8s 125ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0214 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0200\n",
      "Epoch 40/50\n",
      "62/62 [==============================] - 8s 123ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0210 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0194\n",
      "Epoch 41/50\n",
      "62/62 [==============================] - 9s 140ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0208 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0207\n",
      "Epoch 42/50\n",
      "62/62 [==============================] - 8s 131ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0206 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0195\n",
      "Epoch 43/50\n",
      "62/62 [==============================] - 8s 134ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0203 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0199\n",
      "Epoch 44/50\n",
      "62/62 [==============================] - 9s 144ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0202 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0199\n",
      "Epoch 45/50\n",
      "62/62 [==============================] - 9s 153ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0200 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0191\n",
      "Epoch 46/50\n",
      "62/62 [==============================] - 9s 141ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0201 - val_loss: 9.9616e-04 - val_mse: 9.9616e-04 - val_mae: 0.0195\n",
      "Epoch 47/50\n",
      "62/62 [==============================] - 10s 155ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0199 - val_loss: 9.8657e-04 - val_mse: 9.8657e-04 - val_mae: 0.0193\n",
      "Epoch 48/50\n",
      "62/62 [==============================] - 8s 134ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0199 - val_loss: 9.9902e-04 - val_mse: 9.9902e-04 - val_mae: 0.0196\n",
      "Epoch 49/50\n",
      "62/62 [==============================] - 8s 126ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0199 - val_loss: 9.8527e-04 - val_mse: 9.8527e-04 - val_mae: 0.0195\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 8s 129ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0197 - val_loss: 9.7983e-04 - val_mse: 9.7983e-04 - val_mae: 0.0197\n",
      "Epoch 1/100\n",
      "62/62 [==============================] - 9s 151ms/step - loss: 0.1661 - mse: 0.1661 - mae: 0.3258 - val_loss: 0.0046 - val_mse: 0.0046 - val_mae: 0.0521\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 9s 138ms/step - loss: 0.1062 - mse: 0.1062 - mae: 0.2578 - val_loss: 0.0046 - val_mse: 0.0046 - val_mae: 0.0508\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 8s 129ms/step - loss: 0.0697 - mse: 0.0697 - mae: 0.2097 - val_loss: 0.0044 - val_mse: 0.0044 - val_mae: 0.0492\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 8s 124ms/step - loss: 0.0494 - mse: 0.0494 - mae: 0.1760 - val_loss: 0.0049 - val_mse: 0.0049 - val_mae: 0.0543\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 8s 127ms/step - loss: 0.0376 - mse: 0.0376 - mae: 0.1539 - val_loss: 0.0041 - val_mse: 0.0041 - val_mae: 0.0463\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 8s 136ms/step - loss: 0.0289 - mse: 0.0289 - mae: 0.1340 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0398\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 9s 144ms/step - loss: 0.0226 - mse: 0.0226 - mae: 0.1194 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0383\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 8s 134ms/step - loss: 0.0188 - mse: 0.0188 - mae: 0.1088 - val_loss: 0.0037 - val_mse: 0.0037 - val_mae: 0.0398\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 8s 129ms/step - loss: 0.0151 - mse: 0.0151 - mae: 0.0970 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0406\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 8s 123ms/step - loss: 0.0118 - mse: 0.0118 - mae: 0.0852 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0407\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 7s 121ms/step - loss: 0.0101 - mse: 0.0101 - mae: 0.0793 - val_loss: 0.0029 - val_mse: 0.0029 - val_mae: 0.0356\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 7s 120ms/step - loss: 0.0086 - mse: 0.0086 - mae: 0.0729 - val_loss: 0.0030 - val_mse: 0.0030 - val_mae: 0.0373\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 7s 119ms/step - loss: 0.0072 - mse: 0.0072 - mae: 0.0664 - val_loss: 0.0031 - val_mse: 0.0031 - val_mae: 0.0397\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 8s 125ms/step - loss: 0.0063 - mse: 0.0063 - mae: 0.0614 - val_loss: 0.0028 - val_mse: 0.0028 - val_mae: 0.0362\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 7s 118ms/step - loss: 0.0054 - mse: 0.0054 - mae: 0.0569 - val_loss: 0.0026 - val_mse: 0.0026 - val_mae: 0.0359\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 7s 119ms/step - loss: 0.0047 - mse: 0.0047 - mae: 0.0529 - val_loss: 0.0025 - val_mse: 0.0025 - val_mae: 0.0362\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 7s 119ms/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0500 - val_loss: 0.0024 - val_mse: 0.0024 - val_mae: 0.0339\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 7s 117ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0452 - val_loss: 0.0023 - val_mse: 0.0023 - val_mae: 0.0333\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 7s 119ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0422 - val_loss: 0.0020 - val_mse: 0.0020 - val_mae: 0.0279\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 8s 127ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0401 - val_loss: 0.0021 - val_mse: 0.0021 - val_mae: 0.0296\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 8s 124ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0373 - val_loss: 0.0020 - val_mse: 0.0020 - val_mae: 0.0291\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 7s 115ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0353 - val_loss: 0.0020 - val_mse: 0.0020 - val_mae: 0.0315\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 7s 116ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0343 - val_loss: 0.0018 - val_mse: 0.0018 - val_mae: 0.0296\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 7s 117ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0327 - val_loss: 0.0018 - val_mse: 0.0018 - val_mae: 0.0297\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 8s 121ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0312 - val_loss: 0.0017 - val_mse: 0.0017 - val_mae: 0.0299\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 8s 127ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0298 - val_loss: 0.0016 - val_mse: 0.0016 - val_mae: 0.0275\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 8s 133ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0285 - val_loss: 0.0016 - val_mse: 0.0016 - val_mae: 0.0265\n",
      "Epoch 28/100\n",
      "62/62 [==============================] - 9s 148ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0280 - val_loss: 0.0016 - val_mse: 0.0016 - val_mae: 0.0286\n",
      "Epoch 29/100\n",
      "62/62 [==============================] - 8s 127ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0270 - val_loss: 0.0014 - val_mse: 0.0014 - val_mae: 0.0244\n",
      "Epoch 30/100\n",
      "62/62 [==============================] - 8s 127ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0262 - val_loss: 0.0014 - val_mse: 0.0014 - val_mae: 0.0253\n",
      "Epoch 31/100\n",
      "62/62 [==============================] - 7s 118ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0255 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0240\n",
      "Epoch 32/100\n",
      "62/62 [==============================] - 7s 119ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0251 - val_loss: 0.0015 - val_mse: 0.0015 - val_mae: 0.0283\n",
      "Epoch 33/100\n",
      "62/62 [==============================] - 8s 126ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0253 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0257\n",
      "Epoch 34/100\n",
      "62/62 [==============================] - 9s 142ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0241 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0239\n",
      "Epoch 35/100\n",
      "62/62 [==============================] - 9s 142ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0234 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0259\n",
      "Epoch 36/100\n",
      "62/62 [==============================] - 8s 136ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0229 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0239\n",
      "Epoch 37/100\n",
      "62/62 [==============================] - 8s 128ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0228 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0228\n",
      "Epoch 38/100\n",
      "62/62 [==============================] - 9s 142ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0223 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0228\n",
      "Epoch 39/100\n",
      "62/62 [==============================] - 9s 147ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0218 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0212\n",
      "Epoch 40/100\n",
      "62/62 [==============================] - 8s 127ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0218 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0226\n",
      "Epoch 41/100\n",
      "62/62 [==============================] - 9s 151ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0218 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0229\n",
      "Epoch 42/100\n",
      "62/62 [==============================] - 10s 167ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0213 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0227\n",
      "Epoch 43/100\n",
      "62/62 [==============================] - 11s 174ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0216 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0208\n",
      "Epoch 44/100\n",
      "62/62 [==============================] - 14s 228ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0216 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0220\n",
      "Epoch 45/100\n",
      "62/62 [==============================] - 12s 200ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0209 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.02240.\n",
      "Epoch 46/100\n",
      "62/62 [==============================] - 12s 198ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0209 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0215\n",
      "Epoch 47/100\n",
      "62/62 [==============================] - 12s 186ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0206 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0213\n",
      "Epoch 48/100\n",
      "62/62 [==============================] - 11s 185ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0206 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0207\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 13s 203ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0204 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0214\n",
      "Epoch 50/100\n",
      "62/62 [==============================] - 13s 215ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0202 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0220\n",
      "Epoch 51/100\n",
      "62/62 [==============================] - 13s 206ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0204 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0209\n",
      "Epoch 52/100\n",
      "62/62 [==============================] - 14s 223ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0201 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0218\n",
      "Epoch 53/100\n",
      "62/62 [==============================] - 13s 202ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0197 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0214\n",
      "Epoch 54/100\n",
      "62/62 [==============================] - 12s 190ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0199 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0219\n",
      "Epoch 55/100\n",
      "62/62 [==============================] - 13s 203ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0197 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0205\n",
      "Epoch 56/100\n",
      "62/62 [==============================] - 14s 219ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0197 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0213\n",
      "Epoch 57/100\n",
      "62/62 [==============================] - 12s 195ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0196 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0209\n",
      "Epoch 58/100\n",
      "62/62 [==============================] - 12s 199ms/step - loss: 9.9349e-04 - mse: 9.9349e-04 - mae: 0.0192 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0201\n",
      "Epoch 59/100\n",
      "62/62 [==============================] - 12s 197ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0193 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0199\n",
      "Epoch 60/100\n",
      "62/62 [==============================] - 10s 166ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0193 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0212\n",
      "Epoch 61/100\n",
      "62/62 [==============================] - 10s 157ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0194 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0213\n",
      "Epoch 62/100\n",
      "62/62 [==============================] - 10s 164ms/step - loss: 9.9366e-04 - mse: 9.9366e-04 - mae: 0.0191 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0208\n",
      "Epoch 63/100\n",
      "62/62 [==============================] - 9s 151ms/step - loss: 9.9796e-04 - mse: 9.9796e-04 - mae: 0.0192 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0215\n",
      "Epoch 64/100\n",
      "62/62 [==============================] - 10s 167ms/step - loss: 9.9661e-04 - mse: 9.9661e-04 - mae: 0.0192 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0212\n",
      "Epoch 65/100\n",
      "62/62 [==============================] - 10s 166ms/step - loss: 9.8405e-04 - mse: 9.8405e-04 - mae: 0.0189 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0211\n",
      "Epoch 66/100\n",
      "39/62 [=================>............] - ETA: 3s - loss: 9.5195e-04 - mse: 9.5195e-04 - mae: 0.0187"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "steps = 96\n",
    "# n_hidden = 1\n",
    "units = 100\n",
    "batch_size = 100\n",
    "\n",
    "# function to split data into correct shape for RNN\n",
    "def split_data(X, y, steps):\n",
    "    X_, y_ = list(), list()\n",
    "    for i in range(steps, len(y)):\n",
    "        X_.append(X[i - steps : i, :])\n",
    "        y_.append(y[i]) \n",
    "    return np.array(X_), np.array(y_)\n",
    "\n",
    "# function to cut data set so it can be divisible by the batch_size\n",
    "def cut_data(data, batch_size):\n",
    "     # see if it is divisivel\n",
    "    condition = data.shape[0] % batch_size\n",
    "    if condition == 0:\n",
    "        return data\n",
    "    else:\n",
    "        return data[: -condition]\n",
    "\n",
    "# divide features and labels\n",
    "X_train = data_train[:, 0:15] \n",
    "y_train = data_train[:, -1]\n",
    "X_test = data_test[:, 0:15] \n",
    "y_test = data_test[:, -1] \n",
    "\n",
    "# divide data into train and test \n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train, y_train, test_size = 0.15, shuffle=False)\n",
    "\n",
    "# put data into correct shape\n",
    "X_train, y_train = split_data(X_train, y_train, steps)\n",
    "X_test, y_test = split_data(X_test, y_test, steps)\n",
    "X_val, y_val = split_data(X_val, y_val, steps)\n",
    "\n",
    "X_train = cut_data(X_train, batch_size)\n",
    "y_train = cut_data(y_train, batch_size)\n",
    "X_test = cut_data(X_test, batch_size)\n",
    "y_test = cut_data(y_test, batch_size)\n",
    "X_val = cut_data(X_val, batch_size)\n",
    "y_val = cut_data(y_val, batch_size)\n",
    "\n",
    "epochs_range = [50, 100, 200, 500, 1000, 5000]\n",
    "\n",
    "for i in epochs_range:\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # design the LSTM\n",
    "    def regressor_tunning(kernel_initializer = 'he_normal',\n",
    "                          bias_initializer = initializers.Ones()):\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(units = units,                    \n",
    "                       batch_input_shape = (batch_size, steps, features_num), \n",
    "                       stateful = True,\n",
    "                       kernel_initializer = kernel_initializer,\n",
    "                       bias_initializer = bias_initializer))\n",
    "        model.add(LeakyReLU(alpha = 0.2))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(1, activation='linear'))\n",
    "        model.compile(loss = 'mse', metrics = ['mse', 'mae'], optimizer = 'Adamax')\n",
    "        return model\n",
    "\n",
    "    model = regressor_tunning()\n",
    "\n",
    "    # apply patience callback\n",
    "    # early_stopping = EarlyStopping(monitor='val_mse', patience=10)\n",
    "\n",
    "    # fitting the LSTM to the training set\n",
    "    history = model.fit(X_train,\n",
    "                        y_train, \n",
    "                        batch_size = batch_size, \n",
    "                        epochs = i,\n",
    "                        shuffle = False, \n",
    "                        validation_data = (X_val, y_val))\n",
    "    \n",
    "    # reset states to have suitable predictions\n",
    "    model.reset_states()\n",
    "    \n",
    "    hist_list.append(history.history['mse'])\n",
    "    hist_list.append(history.history['val_mse'])\n",
    "    hist_list.append(history.history['mae'])\n",
    "    hist_list.append(history.history['val_mae'])\n",
    "    \n",
    "    # make new predicitons with test set\n",
    "    y_pred = model.predict(X_test, batch_size = batch_size)\n",
    "\n",
    "    # prices col = 15\n",
    "    y_pred = (y_pred * sc_X.data_range_[15]) + (sc_X.data_min_[15])\n",
    "    y_test = (y_test * sc_X.data_range_[15]) + (sc_X.data_min_[15])\n",
    "    \n",
    "    y_pred_list.append(y_pred)\n",
    "\n",
    "    from sklearn.metrics import mean_squared_error as mse\n",
    "    from sklearn.metrics import mean_absolute_error as mae\n",
    "\n",
    "    rmse_error = mse(y_test, y_pred, squared = False)\n",
    "    mse_error = mse(y_test, y_pred) # 1479.61335\n",
    "    mae_error = mae(y_test, y_pred) # 23.1525\n",
    "\n",
    "    rmse_gen.append(rmse_error)\n",
    "    mse_gen.append(mse_error)\n",
    "    mae_gen.append(mae_error)\n",
    "\n",
    "    # =============================================================================\n",
    "    # Metrics evaluation on spike regions\n",
    "    # =============================================================================\n",
    "\n",
    "    y_spike_occ = pd.read_csv('Spike_binary_1std.csv', usecols = [6])\n",
    "\n",
    "    # create array same size as y_test\n",
    "    y_spike_occ = y_spike_occ.iloc[- len(y_test):]\n",
    "    y_spike_occ = pd.Series(y_spike_occ.iloc[:,0]).values\n",
    "\n",
    "\n",
    "    # smal adjustment\n",
    "    y_test = pd.Series(y_test)\n",
    "    y_test.replace(0, 0.0001,inplace = True)\n",
    "\n",
    "\n",
    "    # select y_pred and y_test only for regions with spikes\n",
    "    y_test_spike = (y_test.T * y_spike_occ).T\n",
    "    y_pred_spike = (y_pred.T * y_spike_occ).T\n",
    "    y_test_spike = y_test_spike[y_test_spike != 0]\n",
    "    y_pred_spike = y_pred_spike[y_pred_spike != 0]\n",
    "\n",
    "    # calculate metric\n",
    "    rmse_spike = mse(y_test_spike, y_pred_spike, squared = False)\n",
    "    mse_spike = mse(y_test_spike, y_pred_spike)\n",
    "    mae_spike = mae(y_test_spike, y_pred_spike)\n",
    "\n",
    "    rmse_spi.append(rmse_spike)\n",
    "    mse_spi.append(mse_spike)\n",
    "    mae_spi.append(mae_spike)\n",
    "\n",
    "    # =============================================================================\n",
    "    # Metric evaluation on normal regions\n",
    "    # =============================================================================\n",
    "\n",
    "    # inverse y_spike_occ so the only normal occurences are chosen\n",
    "    y_normal_occ = (y_spike_occ - 1) * (-1)\n",
    "\n",
    "    # sanity check\n",
    "    y_normal_occ.sum() + y_spike_occ.sum() # gives the correct total \n",
    "\n",
    "    # select y_pred and y_test only for normal regions\n",
    "    y_test_normal = (y_test.T * y_normal_occ).T\n",
    "    y_pred_normal = (y_pred.T * y_normal_occ).T\n",
    "    y_test_normal = y_test_normal[y_test_normal != 0.00]\n",
    "    y_pred_normal = y_pred_normal[y_pred_normal != 0.00]\n",
    "\n",
    "    # calculate metric\n",
    "    rmse_normal = mse(y_test_normal, y_pred_normal, squared = False)\n",
    "    mse_normal = mse(y_test_normal, y_pred_normal)\n",
    "    mae_normal = mae(y_test_normal, y_pred_normal)\n",
    "\n",
    "    rmse_nor.append(rmse_normal)\n",
    "    mse_nor.append(mse_normal)\n",
    "    mae_nor.append(mae_normal)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    time_count.append(elapsed_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions with rmse & mae during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create plots with rmse & mae during training\n",
    "rmse = []\n",
    "val_rmse = []\n",
    "\n",
    "for i in history.history['mse']:\n",
    "    rmse.append(i ** 0.5)\n",
    "    \n",
    "for i in history.history['val_mse']:\n",
    "    val_rmse.append(i ** 0.5)\n",
    "    \n",
    "plt.figure(figsize=(9,4))\n",
    "plt.plot(rmse, label = 'train')\n",
    "plt.plot(val_rmse, label = 'test')\n",
    "plt.legend()\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('RMSE(£/MWh)')\n",
    "plt.tight_layout()\n",
    "plt.minorticks_on()\n",
    "plt.grid(which='major', linestyle='-', linewidth='0.5')\n",
    "plt.grid(which='minor', linestyle=':', linewidth='0.5')\n",
    "plt.title('RMSE during training for an initial LSTM architecture')\n",
    "# plt.savefig('RMSE_1000_epochs_initial_LSTM.png')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(9,4))\n",
    "plt.plot(history.history['mae'], label = 'train')\n",
    "plt.plot(history.history['val_mae'], label = 'test')\n",
    "plt.legend()\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('MAE(£/MWh)')\n",
    "plt.tight_layout()\n",
    "plt.minorticks_on()\n",
    "plt.grid(which='major', linestyle='-', linewidth='0.5')\n",
    "plt.grid(which='minor', linestyle=':', linewidth='0.5')\n",
    "plt.title('MAE during training for an initial LSTM architecture')\n",
    "# plt.savefig('MAE_1000_epochs_initial_LSTM.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save results into a data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "results = pd.DataFrame({'rmse_general': rmse_gen, \n",
    "                 \n",
    "                        'mae_general': mae_gen,\n",
    "                        \n",
    "                        'rmse_spike': rmse_spi,\n",
    "                 \n",
    "                        'mae_spike': mae_spi,\n",
    "                        \n",
    "                        'rmse_normal': rmse_nor,\n",
    "                    \n",
    "                        'mae_normal': mae_nor,\n",
    "                       \n",
    "                        'time': time_count}, index = epochs_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_min(s):\n",
    "    '''\n",
    "    highlight the maximum in a Series yellow.\n",
    "    '''\n",
    "    is_max = s == s.min()\n",
    "    return ['background-color: yellow' if v else '' for v in is_max]\n",
    "\n",
    "results.style.apply(highlight_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_test, label = 'actual values')\n",
    "plt.plot(y_pred, label = 'pred values')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
