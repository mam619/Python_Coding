{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Parameter Tunning \n",
    "    \n",
    "    Look at epochs duration\n",
    "    \n",
    "    (6 months of data used)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\maria\\anaconda3\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from pandas) (1.18.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from python-dateutil>=2.6.1->pandas) (1.14.0)\n",
      "Requirement already satisfied: sklearn in c:\\users\\maria\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\maria\\anaconda3\\lib\\site-packages (from sklearn) (0.22.1)\n",
      "Requirement already satisfied: scipy>=0.17.0 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.11.0 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.18.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (0.14.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install sklearn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data; set X and y; fill nan values and split in test, training and validation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import data\n",
    "data = pd.read_csv('Data_set_1_smaller.csv', index_col = 0)\n",
    "\n",
    "# for later use\n",
    "features_num = 15\n",
    "\n",
    "# 2018 data\n",
    "data = data.loc[data.index > 2018070000, :]\n",
    "\n",
    "# reset index\n",
    "data.reset_index(inplace = True)\n",
    "data.drop('index', axis = 1, inplace = True)\n",
    "\n",
    "# fill nan values\n",
    "data.fillna(method = 'ffill', inplace = True)\n",
    "\n",
    "# divide features and labels\n",
    "X = data.iloc[:, 0:15] .values # turns it into an array\n",
    "y = data.loc[:, 'Offers'].values # turns it into an array\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# divide data into train and test \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "         X, y, test_size = 0.15, shuffle=False)\n",
    "\n",
    "# divide data into train and validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "         X_train, y_train, test_size = 0.3, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply feature scaling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# feature scaling \n",
    "sc_X = MinMaxScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the Keras libraries and packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LeakyReLU\n",
    "from keras import initializers\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import time\n",
    "\n",
    "mae_cv = []\n",
    "mse_cv = []\n",
    "mae_gen = []\n",
    "mse_gen  =[]\n",
    "rmse_gen = []\n",
    "mae_nor = []\n",
    "mae_spi = []\n",
    "mse_nor = []\n",
    "mse_spi = []\n",
    "rmse_nor = []\n",
    "rmse_spi = []\n",
    "time_count = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare of data according to LSTM needs,  create regressor & tune:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "steps = 96\n",
    "n_hidden = 1\n",
    "units = 50\n",
    "batch_size = 96\n",
    "\n",
    "# function to split data into correct shape for RNN\n",
    "def split_data(X, y, steps):\n",
    "    X_, y_ = list(), list()\n",
    "    for i in range(steps, len(y)):\n",
    "        X_.append(X[i - steps : i, :])\n",
    "        y_.append(y[i]) \n",
    "    return np.array(X_), np.array(y_)\n",
    "\n",
    "X_train, y_train = split_data(X_train, y_train, steps)\n",
    "X_test, y_test = split_data(X_test, y_test, steps)\n",
    "X_val, y_val = split_data(X_val, y_val, steps)\n",
    "\n",
    "# function to cut data set so it can be divisible by the batch_size\n",
    "def cut_data(data, batch_size):\n",
    "     # see if it is divisivel\n",
    "    condition = data.shape[0] % batch_size\n",
    "    if condition == 0:\n",
    "        return data\n",
    "    else:\n",
    "        return data[: -condition]\n",
    "\n",
    "# empty list to append metric values\n",
    "mae_cv = []\n",
    "mse_cv = []\n",
    "mae_gen = []\n",
    "mse_gen  =[]\n",
    "rmse_gen = []\n",
    "mae_nor = []\n",
    "mae_spi = []\n",
    "mse_nor = []\n",
    "mse_spi = []\n",
    "rmse_nor = []\n",
    "rmse_spi = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do tunning of epochs to understand how long it takes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "53/53 [==============================] - 14s 266ms/step - loss: 14039.4902 - mse: 14039.4902 - mae: 110.3462 - val_loss: 15014.0674 - val_mse: 15014.0674 - val_mae: 110.8759\n",
      "Epoch 2/50\n",
      "53/53 [==============================] - 13s 251ms/step - loss: 13447.7627 - mse: 13447.7627 - mae: 107.5981 - val_loss: 14652.0381 - val_mse: 14652.0371 - val_mae: 109.2327\n",
      "Epoch 3/50\n",
      "53/53 [==============================] - 12s 224ms/step - loss: 13113.4424 - mse: 13113.4424 - mae: 106.0417 - val_loss: 14344.4912 - val_mse: 14344.4912 - val_mae: 107.8131\n",
      "Epoch 4/50\n",
      "53/53 [==============================] - 11s 214ms/step - loss: 12800.2080 - mse: 12800.2080 - mae: 104.5661 - val_loss: 14060.7285 - val_mse: 14060.7285 - val_mae: 106.4845\n",
      "Epoch 5/50\n",
      "53/53 [==============================] - 11s 211ms/step - loss: 12526.1709 - mse: 12526.1709 - mae: 103.2208 - val_loss: 13797.1738 - val_mse: 13797.1738 - val_mae: 105.2360\n",
      "Epoch 6/50\n",
      "53/53 [==============================] - 12s 225ms/step - loss: 12249.6719 - mse: 12249.6719 - mae: 101.8873 - val_loss: 13540.9023 - val_mse: 13540.9023 - val_mae: 104.0082\n",
      "Epoch 7/50\n",
      "53/53 [==============================] - 11s 215ms/step - loss: 11986.1152 - mse: 11986.1152 - mae: 100.5735 - val_loss: 13286.9561 - val_mse: 13286.9561 - val_mae: 102.7774\n",
      "Epoch 8/50\n",
      "53/53 [==============================] - 12s 219ms/step - loss: 11707.3936 - mse: 11707.3936 - mae: 99.1629 - val_loss: 13038.1953 - val_mse: 13038.1953 - val_mae: 101.5567\n",
      "Epoch 9/50\n",
      "53/53 [==============================] - 12s 220ms/step - loss: 11453.8408 - mse: 11453.8408 - mae: 97.8948 - val_loss: 12795.5176 - val_mse: 12795.5176 - val_mae: 100.3545\n",
      "Epoch 10/50\n",
      "53/53 [==============================] - 12s 218ms/step - loss: 11200.3564 - mse: 11200.3564 - mae: 96.5898 - val_loss: 12561.0176 - val_mse: 12561.0176 - val_mae: 99.1771\n",
      "Epoch 11/50\n",
      "53/53 [==============================] - 11s 212ms/step - loss: 10952.5049 - mse: 10952.5049 - mae: 95.2781 - val_loss: 12330.1602 - val_mse: 12330.1602 - val_mae: 98.0045\n",
      "Epoch 12/50\n",
      "53/53 [==============================] - 11s 215ms/step - loss: 10691.5576 - mse: 10691.5576 - mae: 93.9355 - val_loss: 12103.1475 - val_mse: 12103.1475 - val_mae: 96.8368\n",
      "Epoch 13/50\n",
      "53/53 [==============================] - 12s 231ms/step - loss: 10446.7520 - mse: 10446.7520 - mae: 92.5956 - val_loss: 11878.9316 - val_mse: 11878.9316 - val_mae: 95.6706\n",
      "Epoch 14/50\n",
      "53/53 [==============================] - 15s 292ms/step - loss: 10208.5283 - mse: 10208.5283 - mae: 91.3365 - val_loss: 11659.3496 - val_mse: 11659.3496 - val_mae: 94.5141\n",
      "Epoch 15/50\n",
      "53/53 [==============================] - 13s 242ms/step - loss: 9983.0098 - mse: 9983.0098 - mae: 90.0487 - val_loss: 11443.9004 - val_mse: 11443.9004 - val_mae: 93.3651\n",
      "Epoch 16/50\n",
      "53/53 [==============================] - 11s 212ms/step - loss: 9752.6592 - mse: 9752.6592 - mae: 88.7787 - val_loss: 11230.9395 - val_mse: 11230.9395 - val_mae: 92.2158\n",
      "Epoch 17/50\n",
      "53/53 [==============================] - 11s 212ms/step - loss: 9509.3789 - mse: 9509.3789 - mae: 87.3968 - val_loss: 11021.7188 - val_mse: 11021.7188 - val_mae: 91.0721\n",
      "Epoch 18/50\n",
      "53/53 [==============================] - 11s 210ms/step - loss: 9302.4453 - mse: 9302.4453 - mae: 86.2032 - val_loss: 10817.7197 - val_mse: 10817.7197 - val_mae: 89.9408\n",
      "Epoch 19/50\n",
      "53/53 [==============================] - 11s 205ms/step - loss: 9063.3096 - mse: 9063.3096 - mae: 84.8137 - val_loss: 10615.4971 - val_mse: 10615.4971 - val_mae: 88.8095\n",
      "Epoch 20/50\n",
      "53/53 [==============================] - 11s 210ms/step - loss: 8839.4951 - mse: 8839.4951 - mae: 83.4799 - val_loss: 10414.8564 - val_mse: 10414.8564 - val_mae: 87.6739\n",
      "Epoch 21/50\n",
      "53/53 [==============================] - 11s 211ms/step - loss: 8638.7188 - mse: 8638.7188 - mae: 82.2614 - val_loss: 10218.6738 - val_mse: 10218.6738 - val_mae: 86.5487\n",
      "Epoch 22/50\n",
      "53/53 [==============================] - 12s 219ms/step - loss: 8426.1797 - mse: 8426.1797 - mae: 80.9591 - val_loss: 10027.6191 - val_mse: 10027.6191 - val_mae: 85.4379\n",
      "Epoch 23/50\n",
      "53/53 [==============================] - 11s 209ms/step - loss: 8206.6055 - mse: 8206.6055 - mae: 79.5931 - val_loss: 9840.1055 - val_mse: 9840.1055 - val_mae: 84.3333\n",
      "Epoch 24/50\n",
      "53/53 [==============================] - 12s 217ms/step - loss: 8016.4819 - mse: 8016.4819 - mae: 78.3972 - val_loss: 9654.9219 - val_mse: 9654.9219 - val_mae: 83.2287\n",
      "Epoch 25/50\n",
      "53/53 [==============================] - 11s 211ms/step - loss: 7811.3105 - mse: 7811.3105 - mae: 77.0265 - val_loss: 9471.6953 - val_mse: 9471.6953 - val_mae: 82.1201\n",
      "Epoch 26/50\n",
      "53/53 [==============================] - 11s 209ms/step - loss: 7620.3398 - mse: 7620.3398 - mae: 75.8241 - val_loss: 9293.0342 - val_mse: 9293.0342 - val_mae: 81.0253\n",
      "Epoch 27/50\n",
      "53/53 [==============================] - 11s 213ms/step - loss: 7434.7085 - mse: 7434.7085 - mae: 74.5292 - val_loss: 9118.4512 - val_mse: 9118.4502 - val_mae: 79.9405\n",
      "Epoch 28/50\n",
      "53/53 [==============================] - 11s 212ms/step - loss: 7245.9912 - mse: 7245.9912 - mae: 73.2905 - val_loss: 8947.5225 - val_mse: 8947.5225 - val_mae: 78.8631\n",
      "Epoch 29/50\n",
      "53/53 [==============================] - 11s 209ms/step - loss: 7042.4238 - mse: 7042.4238 - mae: 71.9016 - val_loss: 8778.9258 - val_mse: 8778.9258 - val_mae: 77.7843\n",
      "Epoch 30/50\n",
      "53/53 [==============================] - 11s 205ms/step - loss: 6877.3027 - mse: 6877.3027 - mae: 70.8153 - val_loss: 8614.0186 - val_mse: 8614.0186 - val_mae: 76.7163\n",
      "Epoch 31/50\n",
      "53/53 [==============================] - 11s 213ms/step - loss: 6711.9536 - mse: 6711.9536 - mae: 69.5995 - val_loss: 8450.4648 - val_mse: 8450.4648 - val_mae: 75.6413\n",
      "Epoch 32/50\n",
      "53/53 [==============================] - 11s 212ms/step - loss: 6534.1782 - mse: 6534.1782 - mae: 68.2584 - val_loss: 8285.3701 - val_mse: 8285.3701 - val_mae: 74.5434\n",
      "Epoch 33/50\n",
      "53/53 [==============================] - 12s 223ms/step - loss: 6387.6665 - mse: 6387.6665 - mae: 67.1882 - val_loss: 8128.0977 - val_mse: 8128.0977 - val_mae: 73.4800\n",
      "Epoch 34/50\n",
      "53/53 [==============================] - 11s 216ms/step - loss: 6213.0713 - mse: 6213.0713 - mae: 65.8742 - val_loss: 7974.9263 - val_mse: 7974.9263 - val_mae: 72.4296\n",
      "Epoch 35/50\n",
      "53/53 [==============================] - 11s 212ms/step - loss: 6033.5435 - mse: 6033.5435 - mae: 64.5769 - val_loss: 7825.8799 - val_mse: 7825.8799 - val_mae: 71.3923\n",
      "Epoch 36/50\n",
      "53/53 [==============================] - 11s 213ms/step - loss: 5907.0635 - mse: 5907.0635 - mae: 63.4995 - val_loss: 7679.9014 - val_mse: 7679.9014 - val_mae: 70.3612\n",
      "Epoch 37/50\n",
      "53/53 [==============================] - 11s 207ms/step - loss: 5737.5645 - mse: 5737.5645 - mae: 62.2645 - val_loss: 7536.3779 - val_mse: 7536.3779 - val_mae: 69.3326\n",
      "Epoch 38/50\n",
      "53/53 [==============================] - 11s 205ms/step - loss: 5609.0654 - mse: 5609.0654 - mae: 61.1418 - val_loss: 7395.0454 - val_mse: 7395.0449 - val_mae: 68.3055\n",
      "Epoch 39/50\n",
      "53/53 [==============================] - 11s 209ms/step - loss: 5437.9570 - mse: 5437.9570 - mae: 59.7647 - val_loss: 7256.8896 - val_mse: 7256.8896 - val_mae: 67.2855\n",
      "Epoch 40/50\n",
      "53/53 [==============================] - 11s 214ms/step - loss: 5310.6934 - mse: 5310.6934 - mae: 58.6824 - val_loss: 7123.7217 - val_mse: 7123.7217 - val_mae: 66.2867\n",
      "Epoch 41/50\n",
      "53/53 [==============================] - 11s 208ms/step - loss: 5171.6772 - mse: 5171.6772 - mae: 57.5032 - val_loss: 6993.7349 - val_mse: 6993.7349 - val_mae: 65.3012\n",
      "Epoch 42/50\n",
      "53/53 [==============================] - 11s 212ms/step - loss: 5042.6636 - mse: 5042.6636 - mae: 56.3252 - val_loss: 6877.6934 - val_mse: 6877.6934 - val_mae: 64.4452\n",
      "Epoch 43/50\n",
      "53/53 [==============================] - 11s 214ms/step - loss: 4917.9756 - mse: 4917.9756 - mae: 55.2821 - val_loss: 6755.3813 - val_mse: 6755.3813 - val_mae: 63.4875\n",
      "Epoch 44/50\n",
      "53/53 [==============================] - 11s 212ms/step - loss: 4781.8540 - mse: 4781.8540 - mae: 54.0067 - val_loss: 6631.7017 - val_mse: 6631.7017 - val_mae: 62.5051\n",
      "Epoch 45/50\n",
      "53/53 [==============================] - 11s 207ms/step - loss: 4675.1016 - mse: 4675.1016 - mae: 53.0406 - val_loss: 6510.8257 - val_mse: 6510.8257 - val_mae: 61.5302\n",
      "Epoch 46/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 11s 204ms/step - loss: 4548.2227 - mse: 4548.2227 - mae: 51.7799 - val_loss: 6394.0713 - val_mse: 6394.0713 - val_mae: 60.5734\n",
      "Epoch 47/50\n",
      "53/53 [==============================] - 11s 208ms/step - loss: 4446.4536 - mse: 4446.4536 - mae: 50.7424 - val_loss: 6279.9536 - val_mse: 6279.9536 - val_mae: 59.6232\n",
      "Epoch 48/50\n",
      "53/53 [==============================] - 11s 207ms/step - loss: 4334.7729 - mse: 4334.7729 - mae: 49.8467 - val_loss: 6168.7852 - val_mse: 6168.7852 - val_mae: 58.6838\n",
      "Epoch 49/50\n",
      "53/53 [==============================] - 11s 203ms/step - loss: 4220.5308 - mse: 4220.5308 - mae: 48.5890 - val_loss: 6061.3169 - val_mse: 6061.3169 - val_mae: 57.7612\n",
      "Epoch 50/50\n",
      "53/53 [==============================] - 11s 207ms/step - loss: 4098.2803 - mse: 4098.2803 - mae: 47.4804 - val_loss: 5955.7329 - val_mse: 5955.7329 - val_mae: 56.8402\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File Spike_binary_1std.csv does not exist: 'Spike_binary_1std.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-65982bbd4205>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[1;31m# =============================================================================\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m     \u001b[0my_spike_occ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Spike_binary_1std.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0musecols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[1;31m# create array same size as y_test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1891\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File Spike_binary_1std.csv does not exist: 'Spike_binary_1std.csv'"
     ]
    }
   ],
   "source": [
    "epochs_range = [50, 75, 100, 125, 150, 200, 400]\n",
    "\n",
    "for i in epochs_range:\n",
    "    start_time = time.time()\n",
    "    # design the LSTM\n",
    "    def regressor_tunning(kernel_initializer = 'he_normal',\n",
    "                          bias_initializer = initializers.Ones()):\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(units = units,                    \n",
    "                       batch_input_shape = (batch_size, steps, features_num), \n",
    "                       stateful = True,\n",
    "                       return_sequences = True,\n",
    "                       kernel_initializer = kernel_initializer,\n",
    "                       bias_initializer = bias_initializer))\n",
    "        model.add(LeakyReLU(alpha = 0.2))\n",
    "        model.add(Dropout(0.2))\n",
    "        for layer in list(reversed(range(n_hidden))):\n",
    "            if layer == 0:\n",
    "                model.add(LSTM(units = units, \n",
    "                               kernel_initializer = kernel_initializer,\n",
    "                               bias_initializer = bias_initializer))\n",
    "                model.add(LeakyReLU(alpha = 0.2))\n",
    "                model.add(Dropout(0.2))\n",
    "            else:\n",
    "                model.add(LSTM(units = units, \n",
    "                               batch_input_shape = (batch_size, steps, features_num), \n",
    "                               stateful = True,\n",
    "                               return_sequences = True,\n",
    "                               kernel_initializer = kernel_initializer,\n",
    "                               bias_initializer = bias_initializer))\n",
    "                model.add(LeakyReLU(alpha = 0.2))\n",
    "                model.add(Dropout(0.2))\n",
    "        model.add(Dense(1, activation='linear'))\n",
    "        model.compile(loss = 'mse', metrics = ['mse', 'mae'], optimizer = 'Adamax')\n",
    "        return model\n",
    "\n",
    "    model = regressor_tunning()\n",
    "\n",
    "    # apply patience callback\n",
    "    early_stopping = EarlyStopping(monitor='mse', patience=10)\n",
    "\n",
    "    # fitting the LSTM to the training set\n",
    "    history = model.fit(cut_data(X_train, batch_size),\n",
    "                        cut_data(y_train, batch_size), \n",
    "                        batch_size = batch_size, \n",
    "                        epochs = i,\n",
    "                        shuffle = False, \n",
    "                        validation_data = (cut_data(X_val, batch_size), cut_data(y_val, batch_size)),\n",
    "                        callbacks = early_stopping)\n",
    "\n",
    "    X_test = cut_data(X_test, batch_size)\n",
    "    y_test = cut_data(y_test, batch_size)\n",
    "\n",
    "    # make new predicitons with test set\n",
    "    y_pred = model.predict(cut_data(X_test, batch_size), batch_size = batch_size)\n",
    "\n",
    "    # plot the training progression\n",
    "    #plt.plot(history.history['val_loss'], label = 'train')\n",
    "    #plt.plot(history.history['val_loss'], label = 'test')\n",
    "    #plt.legend()\n",
    "    #plt.show()\n",
    "\n",
    "    from sklearn.metrics import mean_squared_error as mse\n",
    "    from sklearn.metrics import mean_absolute_error as mae\n",
    "\n",
    "    rmse_error = mse(y_test, y_pred, squared = False)\n",
    "    mse_error = mse(y_test, y_pred) # 1479.61335\n",
    "    mae_error = mae(y_test, y_pred) # 23.1525\n",
    "\n",
    "    rmse_gen.append(rmse_error)\n",
    "    mse_gen.append(mse_error)\n",
    "    mae_gen.append(mae_error)\n",
    "\n",
    "    # =============================================================================\n",
    "    # Metrics evaluation on spike regions\n",
    "    # =============================================================================\n",
    "\n",
    "    y_spike_occ = pd.read_csv('Spike_binary_1std.csv', usecols = [6])\n",
    "\n",
    "    # create array same size as y_test\n",
    "    y_spike_occ = y_spike_occ.iloc[- len(y_test):]\n",
    "    y_spike_occ = pd.Series(y_spike_occ.iloc[:,0]).values\n",
    "\n",
    "\n",
    "    # smal adjustment\n",
    "    y_test = pd.Series(y_test)\n",
    "    y_test.replace(0, 0.0001,inplace = True)\n",
    "\n",
    "\n",
    "    # select y_pred and y_test only for regions with spikes\n",
    "    y_test_spike = (y_test.T * y_spike_occ).T\n",
    "    y_pred_spike = (y_pred.T * y_spike_occ).T\n",
    "    y_test_spike = y_test_spike[y_test_spike != 0]\n",
    "    y_pred_spike = y_pred_spike[y_pred_spike != 0]\n",
    "\n",
    "    # calculate metric\n",
    "    rmse_spike = mse(y_test_spike, y_pred_spike, squared = False)\n",
    "    mse_spike = mse(y_test_spike, y_pred_spike)\n",
    "    mae_spike = mae(y_test_spike, y_pred_spike)\n",
    "\n",
    "    rmse_spi.append(rmse_spike)\n",
    "    mse_spi.append(mse_spike)\n",
    "    mae_spi.append(mae_spike)\n",
    "\n",
    "    # =============================================================================\n",
    "    # Metric evaluation on normal regions\n",
    "    # =============================================================================\n",
    "\n",
    "    # inverse y_spike_occ so the only normal occurences are chosen\n",
    "    y_normal_occ = (y_spike_occ - 1) * (-1)\n",
    "\n",
    "    # sanity check\n",
    "    y_normal_occ.sum() + y_spike_occ.sum() # gives the correct total \n",
    "\n",
    "    # select y_pred and y_test only for normal regions\n",
    "    y_test_normal = (y_test.T * y_normal_occ).T\n",
    "    y_pred_normal = (y_pred.T * y_normal_occ).T\n",
    "    y_test_normal = y_test_normal[y_test_normal != 0.00]\n",
    "    y_pred_normal = y_pred_normal[y_pred_normal != 0.00]\n",
    "\n",
    "    # calculate metric\n",
    "    rmse_normal = mse(y_test_normal, y_pred_normal, squared = False)\n",
    "    mse_normal = mse(y_test_normal, y_pred_normal)\n",
    "    mae_normal = mae(y_test_normal, y_pred_normal)\n",
    "\n",
    "    rmse_nor.append(rmse_normal)\n",
    "    mse_nor.append(mse_normal)\n",
    "    mae_nor.append(mae_normal)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    time_count.append(elapsed_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save results into a data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "results = pd.DataFrame({'rmse_general': rmse_gen, \n",
    "                 \n",
    "                        'mae_general': mae_gen,\n",
    "                        \n",
    "                        'rmse_spike': rmse_spi,\n",
    "                 \n",
    "                        'mae_spike': mae_spi,\n",
    "                        \n",
    "                        'rmse_normal': rmse_nor,\n",
    "                    \n",
    "                        'mae_normal': mae_nor,\n",
    "                       \n",
    "                        'time': time_count}, index = epochs_range)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
