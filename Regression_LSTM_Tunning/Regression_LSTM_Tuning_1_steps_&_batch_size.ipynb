{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Parameter Tunning \n",
    "    \n",
    "    Look at different steps & batch sizes \n",
    "    (6 months of data used)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\maria\\anaconda3\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from pandas) (1.18.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from python-dateutil>=2.6.1->pandas) (1.14.0)\n",
      "Requirement already satisfied: sklearn in c:\\users\\maria\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\maria\\anaconda3\\lib\\site-packages (from sklearn) (0.22.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (0.14.1)\n",
      "Requirement already satisfied: scipy>=0.17.0 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.11.0 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.18.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install sklearn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data; fill nan values; split data intro train and test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "data = pd.read_csv('Data_set_1_smaller.csv', index_col = 0)\n",
    "\n",
    "# for later use\n",
    "features_num = 15\n",
    "\n",
    "# 2018 data\n",
    "data = data.loc[data.index > 2018070000, :]\n",
    "\n",
    "# reset index\n",
    "data.reset_index(inplace = True)\n",
    "data.drop('index', axis = 1, inplace = True)\n",
    "\n",
    "# fill nan values\n",
    "data.fillna(method = 'ffill', inplace = True)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# divide data into train and test \n",
    "data_train, data_test = train_test_split(\n",
    "         data, test_size = 0.15, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply feature scaling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# data scaling\n",
    "sc_X = MinMaxScaler()\n",
    "data_train = sc_X.fit_transform(data_train)\n",
    "data_test = sc_X.transform(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the Keras libraries and packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LeakyReLU\n",
    "from keras import initializers\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "mae_cv = []\n",
    "mse_cv = []\n",
    "mae_gen = []\n",
    "mse_gen  =[]\n",
    "rmse_gen = []\n",
    "mae_nor = []\n",
    "mae_spi = []\n",
    "mse_nor = []\n",
    "mse_spi = []\n",
    "rmse_nor = []\n",
    "rmse_spi = []\n",
    "hist_list = []\n",
    "y_pred_list = []\n",
    "prediction_list = []\n",
    "time_count = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare of data according to LSTM needs,  create regressor & tune:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "63/63 [==============================] - 9s 144ms/step - loss: 0.1495 - mse: 0.1495 - mae: 0.3068 - val_loss: 0.0105 - val_mse: 0.0105 - val_mae: 0.0771\n",
      "Epoch 2/200\n",
      "63/63 [==============================] - 6s 103ms/step - loss: 0.1023 - mse: 0.1023 - mae: 0.2525 - val_loss: 0.0081 - val_mse: 0.0081 - val_mae: 0.0661\n",
      "Epoch 3/200\n",
      "63/63 [==============================] - 7s 119ms/step - loss: 0.0678 - mse: 0.0678 - mae: 0.2063 - val_loss: 0.0066 - val_mse: 0.0066 - val_mae: 0.0543\n",
      "Epoch 4/200\n",
      "63/63 [==============================] - 7s 116ms/step - loss: 0.0480 - mse: 0.0480 - mae: 0.1734 - val_loss: 0.0089 - val_mse: 0.0089 - val_mae: 0.0657\n",
      "Epoch 5/200\n",
      "63/63 [==============================] - 7s 104ms/step - loss: 0.0340 - mse: 0.0340 - mae: 0.1465 - val_loss: 0.0082 - val_mse: 0.0082 - val_mae: 0.0605\n",
      "Epoch 6/200\n",
      "63/63 [==============================] - 7s 105ms/step - loss: 0.0276 - mse: 0.0276 - mae: 0.1316 - val_loss: 0.0066 - val_mse: 0.0066 - val_mae: 0.0563\n",
      "Epoch 7/200\n",
      "63/63 [==============================] - 7s 103ms/step - loss: 0.0219 - mse: 0.0219 - mae: 0.1177 - val_loss: 0.0057 - val_mse: 0.0057 - val_mae: 0.0501\n",
      "Epoch 8/200\n",
      "63/63 [==============================] - 6s 101ms/step - loss: 0.0165 - mse: 0.0165 - mae: 0.1017 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0435\n",
      "Epoch 9/200\n",
      "63/63 [==============================] - 6s 101ms/step - loss: 0.0141 - mse: 0.0141 - mae: 0.0936 - val_loss: 0.0030 - val_mse: 0.0030 - val_mae: 0.0404\n",
      "Epoch 10/200\n",
      "63/63 [==============================] - 6s 94ms/step - loss: 0.0116 - mse: 0.0116 - mae: 0.0847 - val_loss: 0.0025 - val_mse: 0.0025 - val_mae: 0.0388\n",
      "Epoch 11/200\n",
      "63/63 [==============================] - 6s 94ms/step - loss: 0.0098 - mse: 0.0098 - mae: 0.0778 - val_loss: 0.0024 - val_mse: 0.0024 - val_mae: 0.0379\n",
      "Epoch 12/200\n",
      "63/63 [==============================] - 6s 96ms/step - loss: 0.0085 - mse: 0.0085 - mae: 0.0723 - val_loss: 0.0020 - val_mse: 0.0020 - val_mae: 0.0341\n",
      "Epoch 13/200\n",
      "63/63 [==============================] - 6s 102ms/step - loss: 0.0069 - mse: 0.0069 - mae: 0.0648 - val_loss: 0.0017 - val_mse: 0.0017 - val_mae: 0.0305loss: 0.0069 - mse\n",
      "Epoch 14/200\n",
      "63/63 [==============================] - 7s 112ms/step - loss: 0.0058 - mse: 0.0058 - mae: 0.0590 - val_loss: 0.0016 - val_mse: 0.0016 - val_mae: 0.0269\n",
      "Epoch 15/200\n",
      "63/63 [==============================] - 7s 110ms/step - loss: 0.0053 - mse: 0.0053 - mae: 0.0571 - val_loss: 0.0016 - val_mse: 0.0016 - val_mae: 0.0296\n",
      "Epoch 16/200\n",
      "63/63 [==============================] - 7s 109ms/step - loss: 0.0046 - mse: 0.0046 - mae: 0.0522 - val_loss: 0.0016 - val_mse: 0.0016 - val_mae: 0.0305\n",
      "Epoch 17/200\n",
      "63/63 [==============================] - 7s 104ms/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0495 - val_loss: 0.0014 - val_mse: 0.0014 - val_mae: 0.0261\n",
      "Epoch 18/200\n",
      "63/63 [==============================] - 7s 118ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0457 - val_loss: 0.0014 - val_mse: 0.0014 - val_mae: 0.0285\n",
      "Epoch 19/200\n",
      "63/63 [==============================] - 7s 117ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0436 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0266\n",
      "Epoch 20/200\n",
      "63/63 [==============================] - 7s 114ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0411 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0251\n",
      "Epoch 21/200\n",
      "63/63 [==============================] - 6s 101ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0388 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0259\n",
      "Epoch 22/200\n",
      "63/63 [==============================] - 6s 100ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0370 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0247\n",
      "Epoch 23/200\n",
      "63/63 [==============================] - 6s 98ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0356 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0238\n",
      "Epoch 24/200\n",
      "63/63 [==============================] - 6s 98ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0337 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0252\n",
      "Epoch 25/200\n",
      "63/63 [==============================] - 8s 121ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0326 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0209\n",
      "Epoch 26/200\n",
      "63/63 [==============================] - 8s 121ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0312 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0231\n",
      "Epoch 27/200\n",
      "63/63 [==============================] - 7s 106ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0298 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0203\n",
      "Epoch 28/200\n",
      "63/63 [==============================] - 6s 96ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0292 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0230\n",
      "Epoch 29/200\n",
      "63/63 [==============================] - 6s 89ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0283 - val_loss: 9.7515e-04 - val_mse: 9.7515e-04 - val_mae: 0.0194\n",
      "Epoch 30/200\n",
      "63/63 [==============================] - 7s 105ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0271 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0224\n",
      "Epoch 31/200\n",
      "63/63 [==============================] - 7s 103ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0266 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0209\n",
      "Epoch 32/200\n",
      "63/63 [==============================] - 7s 108ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0260 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0212\n",
      "Epoch 33/200\n",
      "63/63 [==============================] - 6s 89ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0255 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0213\n",
      "Epoch 34/200\n",
      "63/63 [==============================] - 6s 88ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0246 - val_loss: 9.8719e-04 - val_mse: 9.8719e-04 - val_mae: 0.0201\n",
      "Epoch 35/200\n",
      "63/63 [==============================] - 5s 84ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0242 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0213\n",
      "Epoch 36/200\n",
      "63/63 [==============================] - 5s 80ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0244 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0251\n",
      "Epoch 37/200\n",
      "63/63 [==============================] - 5s 82ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0233 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0219\n",
      "Epoch 38/200\n",
      "63/63 [==============================] - 5s 86ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0229 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0240\n",
      "Epoch 39/200\n",
      "63/63 [==============================] - 5s 82ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0229 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0207\n",
      "Epoch 40/200\n",
      "63/63 [==============================] - 5s 77ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0220 - val_loss: 9.7632e-04 - val_mse: 9.7632e-04 - val_mae: 0.0200\n",
      "Epoch 41/200\n",
      "63/63 [==============================] - 5s 83ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0219 - val_loss: 9.8663e-04 - val_mse: 9.8663e-04 - val_mae: 0.0206\n",
      "Epoch 42/200\n",
      "63/63 [==============================] - 6s 90ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0221 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0220\n",
      "Epoch 43/200\n",
      "63/63 [==============================] - 5s 87ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0216 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0214\n",
      "Epoch 44/200\n",
      "63/63 [==============================] - 6s 87ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0215 - val_loss: 9.9874e-04 - val_mse: 9.9874e-04 - val_mae: 0.0212\n",
      "Epoch 45/200\n",
      "30/63 [=============>................] - ETA: 2s - loss: 8.2845e-04 - mse: 8.2845e-04 - mae: 0.0206"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "# steps = 96\n",
    "# n_hidden = 1 - NO HIDDEN LAYERS HERE\n",
    "units = 100\n",
    "# batch_size = 96\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "parameters = {'steps': [48, 96, 336],\n",
    "              'batch_size': [100, 200, 300, 400]}\n",
    "\n",
    "all_param = ParameterGrid(parameters)\n",
    "\n",
    "# function to split data into correct shape for RNN\n",
    "def split_data(X, y, steps):\n",
    "    X_, y_ = list(), list()\n",
    "    for i in range(steps, len(y)):\n",
    "        X_.append(X[i - steps : i, :])\n",
    "        y_.append(y[i]) \n",
    "    return np.array(X_), np.array(y_)\n",
    "\n",
    "# function to cut data set so it can be divisible by the batch_size\n",
    "def cut_data(data, batch_size):\n",
    "     # see if it is divisivel\n",
    "    condition = data.shape[0] % batch_size\n",
    "    if condition == 0:\n",
    "        return data\n",
    "    else:\n",
    "        return data[: -condition]\n",
    "\n",
    "# divide features and labels\n",
    "X_train = data_train[:, 0:15] \n",
    "y_train = data_train[:, -1]\n",
    "X_test = data_test[:, 0:15] \n",
    "y_test = data_test[:, -1] \n",
    "\n",
    "# divide data into train and test \n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "         X_train, y_train, test_size = 0.15, shuffle=False)\n",
    "\n",
    "for i in range(len(all_param)):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # set parameters right\n",
    "    steps = all_param[i]['steps']\n",
    "    batch_size = all_param[i]['batch_size']\n",
    "    \n",
    "    # put data into correct shape\n",
    "    X_train, y_train = split_data(X_train, y_train, steps)\n",
    "    X_test, y_test = split_data(X_test, y_test, steps)\n",
    "    X_val, y_val = split_data(X_val, y_val, steps)\n",
    "\n",
    "    X_train = cut_data(X_train, batch_size)\n",
    "    y_train = cut_data(y_train, batch_size)\n",
    "    X_test = cut_data(X_test, batch_size)\n",
    "    y_test = cut_data(y_test, batch_size)\n",
    "    X_val = cut_data(X_val, batch_size)\n",
    "    y_val = cut_data(y_val, batch_size)\n",
    "    \n",
    "    # design the LSTM\n",
    "    def regressor_tunning(kernel_initializer = 'he_normal',\n",
    "                          bias_initializer = initializers.Ones()):\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(units = units,                    \n",
    "                       batch_input_shape = (batch_size, steps, features_num), \n",
    "                       stateful = True,\n",
    "                       kernel_initializer = kernel_initializer,\n",
    "                       bias_initializer = bias_initializer))\n",
    "        model.add(LeakyReLU(alpha = 0.2))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(1, activation='linear'))\n",
    "        model.compile(loss = 'mse', metrics = ['mse', 'mae'], optimizer = 'Adamax')\n",
    "        return model\n",
    "\n",
    "    model = regressor_tunning()\n",
    "\n",
    "    # apply patience callback\n",
    "    early_stopping = EarlyStopping(monitor = 'val_mse', patience= 25)\n",
    "\n",
    "    # fitting the LSTM to the training set\n",
    "    history = model.fit(X_train,\n",
    "                        y_train, \n",
    "                        batch_size = batch_size, \n",
    "                        epochs = 200,\n",
    "                        shuffle = False, \n",
    "                        validation_data = (X_val, y_val),\n",
    "                        callbacks = early_stopping)\n",
    "    \n",
    "    hist_list.append(history.history['mse'])\n",
    "    hist_list.append(history.history['val_mse'])\n",
    "    hist_list.append(history.history['mae'])\n",
    "    hist_list.append(history.history['val_mae'])\n",
    "\n",
    "    # make new predicitons with test set\n",
    "    y_pred = model.predict(X_test, batch_size = batch_size)\n",
    "\n",
    "    y_pred_list.append(y_pred)\n",
    "    \n",
    "    # prices col = 15\n",
    "    y_pred = (y_pred * sc_X.data_range_[15]) + (sc_X.data_min_[15])\n",
    "    y_test = (y_test * sc_X.data_range_[15]) + (sc_X.data_min_[15])\n",
    "\n",
    "    from sklearn.metrics import mean_squared_error as mse\n",
    "    from sklearn.metrics import mean_absolute_error as mae\n",
    "\n",
    "    rmse_error = mse(y_test, y_pred, squared = False)\n",
    "    mse_error = mse(y_test, y_pred) # 1479.61335\n",
    "    mae_error = mae(y_test, y_pred) # 23.1525\n",
    "\n",
    "    rmse_gen.append(rmse_error)\n",
    "    mse_gen.append(mse_error)\n",
    "    mae_gen.append(mae_error)\n",
    "\n",
    "    # =============================================================================\n",
    "    # Metrics evaluation on spike regions\n",
    "    # =============================================================================\n",
    "\n",
    "    y_spike_occ = pd.read_csv('Spike_binary_1std.csv', usecols = [6])\n",
    "\n",
    "    # create array same size as y_test\n",
    "    y_spike_occ = y_spike_occ.iloc[- len(y_test):]\n",
    "    y_spike_occ = pd.Series(y_spike_occ.iloc[:,0]).values\n",
    "\n",
    "\n",
    "    # smal adjustment\n",
    "    y_test = pd.Series(y_test)\n",
    "    y_test.replace(0, 0.0001,inplace = True)\n",
    "\n",
    "\n",
    "    # select y_pred and y_test only for regions with spikes\n",
    "    y_test_spike = (y_test.T * y_spike_occ).T\n",
    "    y_pred_spike = (y_pred.T * y_spike_occ).T\n",
    "    y_test_spike = y_test_spike[y_test_spike != 0]\n",
    "    y_pred_spike = y_pred_spike[y_pred_spike != 0]\n",
    "\n",
    "    # calculate metric\n",
    "    rmse_spike = mse(y_test_spike, y_pred_spike, squared = False)\n",
    "    mse_spike = mse(y_test_spike, y_pred_spike)\n",
    "    mae_spike = mae(y_test_spike, y_pred_spike)\n",
    "\n",
    "    rmse_spi.append(rmse_spike)\n",
    "    mse_spi.append(mse_spike)\n",
    "    mae_spi.append(mae_spike)\n",
    "\n",
    "    # =============================================================================\n",
    "    # Metric evaluation on normal regions\n",
    "    # =============================================================================\n",
    "\n",
    "    # inverse y_spike_occ so the only normal occurences are chosen\n",
    "    y_normal_occ = (y_spike_occ - 1) * (-1)\n",
    "\n",
    "    # sanity check\n",
    "    y_normal_occ.sum() + y_spike_occ.sum() # gives the correct total \n",
    "\n",
    "    # select y_pred and y_test only for normal regions\n",
    "    y_test_normal = (y_test.T * y_normal_occ).T\n",
    "    y_pred_normal = (y_pred.T * y_normal_occ).T\n",
    "    y_test_normal = y_test_normal[y_test_normal != 0.00]\n",
    "    y_pred_normal = y_pred_normal[y_pred_normal != 0.00]\n",
    "\n",
    "    # calculate metric\n",
    "    rmse_normal = mse(y_test_normal, y_pred_normal, squared = False)\n",
    "    mse_normal = mse(y_test_normal, y_pred_normal)\n",
    "    mae_normal = mae(y_test_normal, y_pred_normal)\n",
    "\n",
    "    rmse_nor.append(rmse_normal)\n",
    "    mse_nor.append(mse_normal)\n",
    "    mae_nor.append(mae_normal)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    time_count.append(elapsed_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save results into a data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "results = pd.DataFrame({'rmse_general': rmse_gen, \n",
    "                 \n",
    "                        'mae_general': mae_gen,\n",
    "                        \n",
    "                        'rmse_spike': rmse_spi,\n",
    "                 \n",
    "                        'mae_spike': mae_spi,\n",
    "                        \n",
    "                        'rmse_normal': rmse_nor,\n",
    "                    \n",
    "                        'mae_normal': mae_nor,\n",
    "                       \n",
    "                        'time': time_count})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_min(s):\n",
    "    '''\n",
    "    highlight the maximum in a Series yellow.\n",
    "    '''\n",
    "    is_max = s == s.min()\n",
    "    return ['background-color: yellow' if v else '' for v in is_max]\n",
    "\n",
    "results.style.apply(highlight_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "results = pd.DataFrame({'rmse_general': rmse_gen, \n",
    "                 \n",
    "                        'mae_general': mae_gen,\n",
    "                        \n",
    "                        'rmse_spike': rmse_spi,\n",
    "                 \n",
    "                        'mae_spike': mae_spi,\n",
    "                        \n",
    "                        'rmse_normal': rmse_nor,\n",
    "                    \n",
    "                        'mae_normal': mae_nor,\n",
    "                       \n",
    "                        'time': time_count}, index = all_param)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_pred, label = 'predicted value')\n",
    "plt.plot(y_test, label = 'actual value')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
