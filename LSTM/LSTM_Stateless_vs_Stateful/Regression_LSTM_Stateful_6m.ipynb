{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in c:\\users\\maria\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\maria\\anaconda3\\lib\\site-packages (from sklearn) (0.22.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (0.14.1)\n",
      "Requirement already satisfied: scipy>=0.17.0 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.11.0 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.18.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\maria\\anaconda3\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from pandas) (1.18.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from python-dateutil>=2.6.1->pandas) (1.14.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\maria\\anaconda3\\lib\\site-packages (3.1.3)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from matplotlib) (2.4.6)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.11 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from matplotlib) (1.18.1)\n",
      "Requirement already satisfied: six in c:\\users\\maria\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib) (1.14.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\maria\\anaconda3\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib) (45.2.0.post20200210)\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn\n",
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# empty list to append metric values\n",
    "mae_gen = []\n",
    "mae_nor = []\n",
    "mae_spi = []\n",
    "rmse_gen = []\n",
    "rmse_nor = []\n",
    "rmse_spi = []\n",
    "\n",
    "# parameters\n",
    "steps = 96\n",
    "n_hidden = 1\n",
    "units = 150\n",
    "batch_size = 96\n",
    "epochs = 100\n",
    "\n",
    "# months to evaluate model on\n",
    "date = 2018070000\n",
    "\n",
    "# for later use\n",
    "features_num = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Data_set_1_smaller_(1).csv', index_col = 0)\n",
    "\n",
    "# set predictive window according with tuning best results\n",
    "data = data.loc[data.index > date, :]\n",
    "\n",
    "# reset index\n",
    "data.reset_index(inplace = True)\n",
    "data.drop('index', axis = 1, inplace = True)\n",
    "\n",
    "# fill nan values in the whole data set\n",
    "data.fillna(data.mean(), inplace = True)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# divide data into train and test \n",
    "data_train, data_test = train_test_split(\n",
    "         data, test_size = 0.15, shuffle=False)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# data scaling  (including offer (y))\n",
    "sc_X = MinMaxScaler()\n",
    "data_train = sc_X.fit_transform(data_train)\n",
    "data_test = sc_X.transform(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Required functions to put data into required shape for LSTM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to split data into correct shape for RNN\n",
    "def split_data(X, y, steps):\n",
    "    X_, y_ = list(), list()\n",
    "    for i in range(steps, len(y)):\n",
    "        X_.append(X[i - steps : i, :])\n",
    "        y_.append(y[i]) \n",
    "    return np.array(X_), np.array(y_)\n",
    "\n",
    "# function to cut data set so it can be divisible by the batch_size\n",
    "def cut_data(data, batch_size):\n",
    "     # see if it is divisivel\n",
    "    condition = data.shape[0] % batch_size\n",
    "    if condition == 0:\n",
    "        return data\n",
    "    else:\n",
    "        return data[: -condition]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up X and y for train, test and val into correct shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide features and labels\n",
    "X_train = data_train[:, 0:14] \n",
    "y_train = data_train[:, -1]\n",
    "X_test = data_test[:, 0:14]\n",
    "y_test = data_test[:, -1] \n",
    "\n",
    "# divide data into validation and normal test \n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train, y_train, test_size = 0.15, shuffle=False)\n",
    "\n",
    "# put data into correct shape\n",
    "X_train, y_train = split_data(X_train, y_train, steps)\n",
    "X_test, y_test = split_data(X_test, y_test, steps)\n",
    "X_val, y_val = split_data(X_val, y_val, steps)\n",
    "\n",
    "# cut data\n",
    "X_train = cut_data(X_train, batch_size)\n",
    "y_train = cut_data(y_train, batch_size)\n",
    "X_test = cut_data(X_test, batch_size)\n",
    "y_test = cut_data(y_test, batch_size)\n",
    "X_val = cut_data(X_val, batch_size)\n",
    "y_val = cut_data(y_val, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LeakyReLU\n",
    "from keras import initializers\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Design LSTM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regressor_tunning(kernel_initializer = 'he_uniform',\n",
    "                      bias_initializer = initializers.Ones()):\n",
    "    model = Sequential()\n",
    "    if n_hidden == 0:\n",
    "        model.add(LSTM(units = units,                    \n",
    "                       batch_input_shape = (batch_size, steps, features_num), \n",
    "                       stateful = True,\n",
    "                       kernel_initializer = kernel_initializer,\n",
    "                       bias_initializer = bias_initializer))\n",
    "        model.add(LeakyReLU(alpha = 0.2))\n",
    "        model.add(Dropout(0.2))\n",
    "    else:\n",
    "        model.add(LSTM(units = units,                    \n",
    "                       batch_input_shape = (batch_size, steps, features_num), \n",
    "                       stateful = True,\n",
    "                       return_sequences = True,\n",
    "                       kernel_initializer = kernel_initializer,\n",
    "                       bias_initializer = bias_initializer))\n",
    "        model.add(LeakyReLU(alpha = 0.2))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(LSTM(units = units, \n",
    "                       batch_input_shape = (batch_size, steps, features_num), \n",
    "                       stateful = True,\n",
    "                       kernel_initializer = kernel_initializer,\n",
    "                       bias_initializer = bias_initializer))\n",
    "        model.add(LeakyReLU(alpha = 0.2))\n",
    "        model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    optimizer = optimizers.RMSprop()\n",
    "    model.compile(loss = 'mse', metrics = ['mse', 'mae'], optimizer = optimizer)\n",
    "    return model\n",
    "\n",
    "model = regressor_tunning()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "65/65 [==============================] - 50s 774ms/step - loss: 0.3067 - mse: 0.3067 - mae: 0.3756 - val_loss: 0.0058 - val_mse: 0.0058 - val_mae: 0.0556\n",
      "Epoch 2/100\n",
      "65/65 [==============================] - 39s 606ms/step - loss: 0.0811 - mse: 0.0811 - mae: 0.2261 - val_loss: 0.0293 - val_mse: 0.0293 - val_mae: 0.1689\n",
      "Epoch 3/100\n",
      "65/65 [==============================] - 40s 615ms/step - loss: 0.0289 - mse: 0.0289 - mae: 0.1339 - val_loss: 0.0023 - val_mse: 0.0023 - val_mae: 0.0423\n",
      "Epoch 4/100\n",
      "65/65 [==============================] - 41s 631ms/step - loss: 0.0106 - mse: 0.0106 - mae: 0.0806 - val_loss: 0.0018 - val_mse: 0.0018 - val_mae: 0.0274\n",
      "Epoch 5/100\n",
      "65/65 [==============================] - 45s 699ms/step - loss: 0.0049 - mse: 0.0049 - mae: 0.0543 - val_loss: 0.0014 - val_mse: 0.0014 - val_mae: 0.0195\n",
      "Epoch 6/100\n",
      "65/65 [==============================] - 51s 792ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0382 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0176\n",
      "Epoch 7/100\n",
      "65/65 [==============================] - 52s 793ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0300 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0167\n",
      "Epoch 8/100\n",
      "65/65 [==============================] - 44s 678ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0243 - val_loss: 0.0014 - val_mse: 0.0014 - val_mae: 0.0199\n",
      "Epoch 9/100\n",
      "65/65 [==============================] - 52s 802ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0212 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0166\n",
      "Epoch 10/100\n",
      "65/65 [==============================] - 58s 893ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0198 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0161\n",
      "Epoch 11/100\n",
      "65/65 [==============================] - 44s 681ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0190 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0160\n",
      "Epoch 12/100\n",
      "65/65 [==============================] - 50s 770ms/step - loss: 9.6618e-04 - mse: 9.6618e-04 - mae: 0.0185 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0161\n",
      "Epoch 13/100\n",
      "65/65 [==============================] - 41s 629ms/step - loss: 9.4448e-04 - mse: 9.4448e-04 - mae: 0.0182 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0162\n",
      "Epoch 14/100\n",
      "65/65 [==============================] - 39s 601ms/step - loss: 9.3467e-04 - mse: 9.3467e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0163\n",
      "Epoch 15/100\n",
      "65/65 [==============================] - 39s 600ms/step - loss: 9.2144e-04 - mse: 9.2144e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0164\n",
      "Epoch 16/100\n",
      "65/65 [==============================] - 53s 815ms/step - loss: 9.0707e-04 - mse: 9.0707e-04 - mae: 0.0174 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0158\n",
      "Epoch 17/100\n",
      "65/65 [==============================] - 47s 723ms/step - loss: 8.9524e-04 - mse: 8.9524e-04 - mae: 0.0173 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0159\n",
      "Epoch 18/100\n",
      "65/65 [==============================] - 45s 685ms/step - loss: 8.8623e-04 - mse: 8.8623e-04 - mae: 0.0171 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0158\n",
      "Epoch 19/100\n",
      "65/65 [==============================] - 46s 707ms/step - loss: 8.8002e-04 - mse: 8.8002e-04 - mae: 0.0170 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0157\n",
      "Epoch 20/100\n",
      "65/65 [==============================] - 45s 687ms/step - loss: 8.6252e-04 - mse: 8.6252e-04 - mae: 0.0166 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0160\n",
      "Epoch 21/100\n",
      "65/65 [==============================] - 45s 698ms/step - loss: 8.5286e-04 - mse: 8.5286e-04 - mae: 0.0164 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0157\n",
      "Epoch 22/100\n",
      "65/65 [==============================] - 49s 748ms/step - loss: 8.2891e-04 - mse: 8.2891e-04 - mae: 0.0160 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0154\n",
      "Epoch 23/100\n",
      "65/65 [==============================] - 42s 648ms/step - loss: 8.1498e-04 - mse: 8.1498e-04 - mae: 0.0157 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0153\n",
      "Epoch 24/100\n",
      "65/65 [==============================] - 50s 766ms/step - loss: 8.0568e-04 - mse: 8.0568e-04 - mae: 0.0156 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0150\n",
      "Epoch 25/100\n",
      "65/65 [==============================] - 51s 791ms/step - loss: 8.0412e-04 - mse: 8.0412e-04 - mae: 0.0155 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0150\n",
      "Epoch 26/100\n",
      "65/65 [==============================] - 42s 650ms/step - loss: 7.8473e-04 - mse: 7.8473e-04 - mae: 0.0153 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0150\n",
      "Epoch 27/100\n",
      "65/65 [==============================] - 47s 724ms/step - loss: 7.8235e-04 - mse: 7.8235e-04 - mae: 0.0152 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0150\n",
      "Epoch 28/100\n",
      "65/65 [==============================] - 49s 746ms/step - loss: 7.7980e-04 - mse: 7.7980e-04 - mae: 0.0151 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0150\n",
      "Epoch 29/100\n",
      "65/65 [==============================] - 49s 759ms/step - loss: 7.7925e-04 - mse: 7.7925e-04 - mae: 0.0150 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0150\n",
      "Epoch 30/100\n",
      "65/65 [==============================] - 57s 877ms/step - loss: 7.7737e-04 - mse: 7.7737e-04 - mae: 0.0150 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0150\n",
      "Epoch 31/100\n",
      "65/65 [==============================] - 54s 828ms/step - loss: 7.6429e-04 - mse: 7.6429e-04 - mae: 0.0148 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0151\n",
      "Epoch 32/100\n",
      "65/65 [==============================] - 54s 833ms/step - loss: 7.6928e-04 - mse: 7.6928e-04 - mae: 0.0148 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0152\n",
      "Epoch 33/100\n",
      "65/65 [==============================] - 63s 968ms/step - loss: 7.6501e-04 - mse: 7.6501e-04 - mae: 0.0147 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0150\n",
      "Epoch 34/100\n",
      "65/65 [==============================] - 53s 823ms/step - loss: 7.5863e-04 - mse: 7.5863e-04 - mae: 0.0148 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0152\n",
      "Epoch 35/100\n",
      "65/65 [==============================] - 52s 805ms/step - loss: 7.6060e-04 - mse: 7.6060e-04 - mae: 0.0146 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0150\n",
      "Epoch 36/100\n",
      "65/65 [==============================] - 54s 835ms/step - loss: 7.5992e-04 - mse: 7.5992e-04 - mae: 0.0146 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0152\n",
      "Epoch 37/100\n",
      "65/65 [==============================] - 53s 820ms/step - loss: 7.5726e-04 - mse: 7.5726e-04 - mae: 0.0145 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0147\n",
      "Epoch 38/100\n",
      "65/65 [==============================] - 54s 825ms/step - loss: 7.5120e-04 - mse: 7.5120e-04 - mae: 0.0145 - val_loss: 9.9207e-04 - val_mse: 9.9207e-04 - val_mae: 0.0150\n",
      "Epoch 39/100\n",
      "65/65 [==============================] - 57s 882ms/step - loss: 7.6253e-04 - mse: 7.6253e-04 - mae: 0.0146 - val_loss: 9.8592e-04 - val_mse: 9.8592e-04 - val_mae: 0.0153\n",
      "Epoch 40/100\n",
      "65/65 [==============================] - 51s 788ms/step - loss: 7.4874e-04 - mse: 7.4874e-04 - mae: 0.0145 - val_loss: 9.9518e-04 - val_mse: 9.9518e-04 - val_mae: 0.0148\n",
      "Epoch 41/100\n",
      "65/65 [==============================] - 55s 848ms/step - loss: 7.4417e-04 - mse: 7.4417e-04 - mae: 0.0143 - val_loss: 9.9580e-04 - val_mse: 9.9580e-04 - val_mae: 0.0146\n",
      "Epoch 42/100\n",
      "65/65 [==============================] - 56s 858ms/step - loss: 7.4753e-04 - mse: 7.4753e-04 - mae: 0.0144 - val_loss: 9.7486e-04 - val_mse: 9.7486e-04 - val_mae: 0.0148\n",
      "Epoch 43/100\n",
      "65/65 [==============================] - 50s 773ms/step - loss: 7.4446e-04 - mse: 7.4446e-04 - mae: 0.0144 - val_loss: 9.7232e-04 - val_mse: 9.7232e-04 - val_mae: 0.0146\n",
      "Epoch 44/100\n",
      "65/65 [==============================] - 53s 812ms/step - loss: 7.4252e-04 - mse: 7.4252e-04 - mae: 0.0143 - val_loss: 9.6558e-04 - val_mse: 9.6558e-04 - val_mae: 0.0146\n",
      "Epoch 45/100\n",
      "65/65 [==============================] - 48s 736ms/step - loss: 7.5648e-04 - mse: 7.5648e-04 - mae: 0.0146 - val_loss: 9.8334e-04 - val_mse: 9.8334e-04 - val_mae: 0.0150\n",
      "Epoch 46/100\n",
      "65/65 [==============================] - 49s 758ms/step - loss: 7.4233e-04 - mse: 7.4233e-04 - mae: 0.0143 - val_loss: 9.5233e-04 - val_mse: 9.5233e-04 - val_mae: 0.0146\n",
      "Epoch 47/100\n",
      "65/65 [==============================] - 52s 803ms/step - loss: 7.4360e-04 - mse: 7.4360e-04 - mae: 0.0143 - val_loss: 9.8976e-04 - val_mse: 9.8976e-04 - val_mae: 0.0150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/100\n",
      "65/65 [==============================] - 59s 903ms/step - loss: 7.4017e-04 - mse: 7.4017e-04 - mae: 0.0143 - val_loss: 9.7035e-04 - val_mse: 9.7035e-04 - val_mae: 0.0145\n",
      "Epoch 49/100\n",
      "65/65 [==============================] - 57s 870ms/step - loss: 7.3133e-04 - mse: 7.3133e-04 - mae: 0.0141 - val_loss: 9.4491e-04 - val_mse: 9.4491e-04 - val_mae: 0.0145\n",
      "Epoch 50/100\n",
      "65/65 [==============================] - 50s 767ms/step - loss: 7.3105e-04 - mse: 7.3105e-04 - mae: 0.0141 - val_loss: 9.4495e-04 - val_mse: 9.4495e-04 - val_mae: 0.0146\n",
      "Epoch 51/100\n",
      "65/65 [==============================] - 50s 766ms/step - loss: 7.2916e-04 - mse: 7.2916e-04 - mae: 0.0140 - val_loss: 9.4975e-04 - val_mse: 9.4975e-04 - val_mae: 0.0145\n",
      "Epoch 52/100\n",
      "65/65 [==============================] - 49s 759ms/step - loss: 7.2943e-04 - mse: 7.2943e-04 - mae: 0.0140 - val_loss: 9.1885e-04 - val_mse: 9.1885e-04 - val_mae: 0.0147\n",
      "Epoch 53/100\n",
      "65/65 [==============================] - 53s 814ms/step - loss: 7.2923e-04 - mse: 7.2923e-04 - mae: 0.0140 - val_loss: 9.3437e-04 - val_mse: 9.3437e-04 - val_mae: 0.0142\n",
      "Epoch 54/100\n",
      "65/65 [==============================] - 50s 772ms/step - loss: 7.2948e-04 - mse: 7.2948e-04 - mae: 0.0140 - val_loss: 9.2688e-04 - val_mse: 9.2688e-04 - val_mae: 0.0145\n",
      "Epoch 55/100\n",
      "65/65 [==============================] - 50s 773ms/step - loss: 7.2589e-04 - mse: 7.2589e-04 - mae: 0.0139 - val_loss: 9.2361e-04 - val_mse: 9.2361e-04 - val_mae: 0.0142\n",
      "Epoch 56/100\n",
      "65/65 [==============================] - 46s 702ms/step - loss: 7.2263e-04 - mse: 7.2263e-04 - mae: 0.0139 - val_loss: 9.4753e-04 - val_mse: 9.4753e-04 - val_mae: 0.0147\n",
      "Epoch 57/100\n",
      "65/65 [==============================] - 48s 733ms/step - loss: 7.2254e-04 - mse: 7.2254e-04 - mae: 0.0139 - val_loss: 9.0924e-04 - val_mse: 9.0924e-04 - val_mae: 0.0145\n",
      "Epoch 58/100\n",
      "65/65 [==============================] - 45s 693ms/step - loss: 7.1393e-04 - mse: 7.1393e-04 - mae: 0.0138 - val_loss: 9.5412e-04 - val_mse: 9.5412e-04 - val_mae: 0.0143\n",
      "Epoch 59/100\n",
      "65/65 [==============================] - 46s 701ms/step - loss: 7.2324e-04 - mse: 7.2324e-04 - mae: 0.0139 - val_loss: 9.2917e-04 - val_mse: 9.2917e-04 - val_mae: 0.0144\n",
      "Epoch 60/100\n",
      "65/65 [==============================] - 46s 706ms/step - loss: 7.1629e-04 - mse: 7.1629e-04 - mae: 0.0138 - val_loss: 9.4150e-04 - val_mse: 9.4150e-04 - val_mae: 0.0144\n",
      "Epoch 61/100\n",
      "65/65 [==============================] - 46s 709ms/step - loss: 7.1812e-04 - mse: 7.1812e-04 - mae: 0.0137 - val_loss: 8.8138e-04 - val_mse: 8.8138e-04 - val_mae: 0.0144\n",
      "Epoch 62/100\n",
      "65/65 [==============================] - 46s 709ms/step - loss: 7.1490e-04 - mse: 7.1490e-04 - mae: 0.0139 - val_loss: 8.8876e-04 - val_mse: 8.8876e-04 - val_mae: 0.0143\n",
      "Epoch 63/100\n",
      "65/65 [==============================] - 44s 677ms/step - loss: 7.1237e-04 - mse: 7.1237e-04 - mae: 0.0137 - val_loss: 9.3059e-04 - val_mse: 9.3059e-04 - val_mae: 0.0143\n",
      "Epoch 64/100\n",
      "65/65 [==============================] - 45s 696ms/step - loss: 7.1005e-04 - mse: 7.1005e-04 - mae: 0.0137 - val_loss: 9.2172e-04 - val_mse: 9.2172e-04 - val_mae: 0.0145\n",
      "Epoch 65/100\n",
      "65/65 [==============================] - 44s 670ms/step - loss: 7.0944e-04 - mse: 7.0944e-04 - mae: 0.0137 - val_loss: 9.6053e-04 - val_mse: 9.6053e-04 - val_mae: 0.0141\n",
      "Epoch 66/100\n",
      "65/65 [==============================] - 44s 684ms/step - loss: 7.1070e-04 - mse: 7.1070e-04 - mae: 0.0137 - val_loss: 9.5788e-04 - val_mse: 9.5788e-04 - val_mae: 0.0147\n",
      "Epoch 67/100\n",
      "65/65 [==============================] - 46s 703ms/step - loss: 6.9731e-04 - mse: 6.9731e-04 - mae: 0.0136 - val_loss: 9.3182e-04 - val_mse: 9.3182e-04 - val_mae: 0.0143\n",
      "Epoch 68/100\n",
      "65/65 [==============================] - 44s 671ms/step - loss: 6.9581e-04 - mse: 6.9581e-04 - mae: 0.0135 - val_loss: 8.8184e-04 - val_mse: 8.8184e-04 - val_mae: 0.0143\n",
      "Epoch 69/100\n",
      "65/65 [==============================] - 45s 700ms/step - loss: 6.9334e-04 - mse: 6.9334e-04 - mae: 0.0134 - val_loss: 9.2907e-04 - val_mse: 9.2907e-04 - val_mae: 0.0142\n",
      "Epoch 70/100\n",
      "65/65 [==============================] - 44s 684ms/step - loss: 6.9867e-04 - mse: 6.9867e-04 - mae: 0.0135 - val_loss: 9.2866e-04 - val_mse: 9.2866e-04 - val_mae: 0.0143\n",
      "Epoch 71/100\n",
      "65/65 [==============================] - 44s 679ms/step - loss: 6.9466e-04 - mse: 6.9466e-04 - mae: 0.0136 - val_loss: 9.2836e-04 - val_mse: 9.2836e-04 - val_mae: 0.0142\n",
      "Epoch 72/100\n",
      "65/65 [==============================] - 47s 718ms/step - loss: 6.9429e-04 - mse: 6.9429e-04 - mae: 0.0135 - val_loss: 8.7112e-04 - val_mse: 8.7112e-04 - val_mae: 0.0140\n",
      "Epoch 73/100\n",
      "65/65 [==============================] - 44s 672ms/step - loss: 7.0092e-04 - mse: 7.0092e-04 - mae: 0.0135 - val_loss: 8.6755e-04 - val_mse: 8.6755e-04 - val_mae: 0.0141\n",
      "Epoch 74/100\n",
      "65/65 [==============================] - 44s 683ms/step - loss: 7.0070e-04 - mse: 7.0070e-04 - mae: 0.0136 - val_loss: 9.3262e-04 - val_mse: 9.3262e-04 - val_mae: 0.0146\n",
      "Epoch 75/100\n",
      "65/65 [==============================] - 45s 689ms/step - loss: 6.9547e-04 - mse: 6.9547e-04 - mae: 0.0136 - val_loss: 9.7415e-04 - val_mse: 9.7415e-04 - val_mae: 0.0144\n",
      "Epoch 76/100\n",
      "65/65 [==============================] - 44s 670ms/step - loss: 6.9522e-04 - mse: 6.9522e-04 - mae: 0.0136 - val_loss: 8.8544e-04 - val_mse: 8.8544e-04 - val_mae: 0.0141\n",
      "Epoch 77/100\n",
      "65/65 [==============================] - 45s 690ms/step - loss: 6.9696e-04 - mse: 6.9696e-04 - mae: 0.0136 - val_loss: 9.2748e-04 - val_mse: 9.2748e-04 - val_mae: 0.0146\n",
      "Epoch 78/100\n",
      "65/65 [==============================] - 43s 668ms/step - loss: 6.8344e-04 - mse: 6.8344e-04 - mae: 0.0133 - val_loss: 8.5369e-04 - val_mse: 8.5369e-04 - val_mae: 0.0140\n",
      "Epoch 79/100\n",
      "65/65 [==============================] - 48s 744ms/step - loss: 6.8626e-04 - mse: 6.8626e-04 - mae: 0.0134 - val_loss: 9.1100e-04 - val_mse: 9.1100e-04 - val_mae: 0.0140\n",
      "Epoch 80/100\n",
      "65/65 [==============================] - 46s 706ms/step - loss: 6.8656e-04 - mse: 6.8656e-04 - mae: 0.0134 - val_loss: 9.1202e-04 - val_mse: 9.1202e-04 - val_mae: 0.0143\n",
      "Epoch 81/100\n",
      "65/65 [==============================] - 44s 680ms/step - loss: 6.7834e-04 - mse: 6.7834e-04 - mae: 0.0133 - val_loss: 9.5826e-04 - val_mse: 9.5826e-04 - val_mae: 0.0140\n",
      "Epoch 82/100\n",
      "65/65 [==============================] - 46s 703ms/step - loss: 6.7984e-04 - mse: 6.7984e-04 - mae: 0.0133 - val_loss: 9.1182e-04 - val_mse: 9.1182e-04 - val_mae: 0.0140\n",
      "Epoch 83/100\n",
      "65/65 [==============================] - 48s 738ms/step - loss: 6.7124e-04 - mse: 6.7124e-04 - mae: 0.0132 - val_loss: 9.5639e-04 - val_mse: 9.5639e-04 - val_mae: 0.0142\n",
      "Epoch 84/100\n",
      "65/65 [==============================] - 46s 710ms/step - loss: 6.7620e-04 - mse: 6.7620e-04 - mae: 0.0132 - val_loss: 9.3347e-04 - val_mse: 9.3347e-04 - val_mae: 0.0141\n",
      "Epoch 85/100\n",
      "65/65 [==============================] - 47s 719ms/step - loss: 6.6301e-04 - mse: 6.6301e-04 - mae: 0.0131 - val_loss: 9.4322e-04 - val_mse: 9.4322e-04 - val_mae: 0.0138\n",
      "Epoch 86/100\n",
      "65/65 [==============================] - 44s 683ms/step - loss: 6.6829e-04 - mse: 6.6829e-04 - mae: 0.0131 - val_loss: 8.4103e-04 - val_mse: 8.4103e-04 - val_mae: 0.0139\n",
      "Epoch 87/100\n",
      "65/65 [==============================] - 45s 688ms/step - loss: 6.6503e-04 - mse: 6.6503e-04 - mae: 0.0131 - val_loss: 8.8506e-04 - val_mse: 8.8506e-04 - val_mae: 0.0138\n",
      "Epoch 88/100\n",
      "65/65 [==============================] - 45s 696ms/step - loss: 6.7198e-04 - mse: 6.7198e-04 - mae: 0.0132 - val_loss: 9.0155e-04 - val_mse: 9.0155e-04 - val_mae: 0.0150\n",
      "Epoch 89/100\n",
      "65/65 [==============================] - 43s 654ms/step - loss: 6.7656e-04 - mse: 6.7656e-04 - mae: 0.0133 - val_loss: 9.0306e-04 - val_mse: 9.0306e-04 - val_mae: 0.0139\n",
      "Epoch 90/100\n",
      "65/65 [==============================] - 44s 676ms/step - loss: 6.7315e-04 - mse: 6.7315e-04 - mae: 0.0132 - val_loss: 8.9964e-04 - val_mse: 8.9964e-04 - val_mae: 0.0144\n",
      "Epoch 91/100\n",
      "65/65 [==============================] - 44s 685ms/step - loss: 6.7045e-04 - mse: 6.7045e-04 - mae: 0.0132 - val_loss: 9.2686e-04 - val_mse: 9.2686e-04 - val_mae: 0.0142\n",
      "Epoch 92/100\n",
      "65/65 [==============================] - 43s 667ms/step - loss: 6.6429e-04 - mse: 6.6429e-04 - mae: 0.0131 - val_loss: 8.9911e-04 - val_mse: 8.9911e-04 - val_mae: 0.0142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/100\n",
      "65/65 [==============================] - 45s 692ms/step - loss: 6.5494e-04 - mse: 6.5494e-04 - mae: 0.0130 - val_loss: 9.8416e-04 - val_mse: 9.8416e-04 - val_mae: 0.0143\n",
      "Epoch 94/100\n",
      "65/65 [==============================] - 43s 664ms/step - loss: 6.5852e-04 - mse: 6.5852e-04 - mae: 0.0131 - val_loss: 9.1539e-04 - val_mse: 9.1539e-04 - val_mae: 0.0140\n",
      "Epoch 95/100\n",
      "65/65 [==============================] - 44s 675ms/step - loss: 6.5859e-04 - mse: 6.5859e-04 - mae: 0.0130 - val_loss: 8.8259e-04 - val_mse: 8.8259e-04 - val_mae: 0.0143\n",
      "Epoch 96/100\n",
      "65/65 [==============================] - 47s 722ms/step - loss: 6.5728e-04 - mse: 6.5728e-04 - mae: 0.0130 - val_loss: 9.0433e-04 - val_mse: 9.0433e-04 - val_mae: 0.0144\n",
      "Epoch 97/100\n",
      "65/65 [==============================] - 42s 651ms/step - loss: 6.5721e-04 - mse: 6.5721e-04 - mae: 0.0130 - val_loss: 9.5625e-04 - val_mse: 9.5625e-04 - val_mae: 0.0147\n",
      "Epoch 98/100\n",
      "65/65 [==============================] - 35s 536ms/step - loss: 6.4362e-04 - mse: 6.4362e-04 - mae: 0.0128 - val_loss: 9.5466e-04 - val_mse: 9.5466e-04 - val_mae: 0.0143\n",
      "Epoch 99/100\n",
      "65/65 [==============================] - 27s 416ms/step - loss: 6.5040e-04 - mse: 6.5040e-04 - mae: 0.0129 - val_loss: 9.3049e-04 - val_mse: 9.3049e-04 - val_mae: 0.0145\n",
      "Epoch 100/100\n",
      "65/65 [==============================] - 28s 428ms/step - loss: 6.4464e-04 - mse: 6.4464e-04 - mae: 0.0129 - val_loss: 8.2682e-04 - val_mse: 8.2682e-04 - val_mae: 0.0142\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,\n",
    "                    y_train, \n",
    "                    batch_size = batch_size, \n",
    "                    epochs = epochs,\n",
    "                    shuffle = False, \n",
    "                    validation_data = (X_val, y_val))\n",
    "    \n",
    "# required before predicitons\n",
    "model.reset_states()\n",
    "    \n",
    "y_pred = model.predict(X_test, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cannot use inverse function; prices col = 14\n",
    "y_pred = (y_pred * sc_X.data_range_[14]) + (sc_X.data_min_[14])\n",
    "y_test = (y_test * sc_X.data_range_[14]) + (sc_X.data_min_[14])\n",
    "\n",
    "# Reshaping\n",
    "y_pred = np.reshape(y_pred, (y_pred.shape[0]))\n",
    "\n",
    "# =============================================================================\n",
    "# METRICS EVALUATION (1) for the whole test set\n",
    "# =============================================================================\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "\n",
    "# calculate metrics\n",
    "rmse_error = mse(y_test, y_pred, squared = False)\n",
    "mae_error = mae(y_test, y_pred)\n",
    "\n",
    "# append to list\n",
    "rmse_gen.append(rmse_error)\n",
    "mae_gen.append(mae_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Need to process data with spike occurences in the same way as features and offers:\n",
    "(Required to evaluate predictions in both normal regions and spike regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data for shaded area\n",
    "data = pd.read_csv('Spike_binary_1std.csv', index_col = 0)\n",
    "\n",
    "# set predictive window according with tuning best results\n",
    "data = data.loc[data.index > date, :]\n",
    "\n",
    "# make sure shaded area will correspond to values outputed by LSTM\n",
    "data.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# fill_nan is already made - so lets split data into test and train\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# divide data into train and test \n",
    "shade_train, shade_test = train_test_split(\n",
    "         data, test_size = 0.15, shuffle = False)\n",
    "\n",
    "# reset index of testing data\n",
    "shade_test.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# function to split data into correct shape for RNN\n",
    "def split_data(shade_test, steps):\n",
    "    y_spike_occ = list()\n",
    "    upper_lim = list()\n",
    "    lower_lim = list()\n",
    "    for i in range(steps, len(shade_test.index)):\n",
    "        y_spike_occ.append(shade_test['spike_occurance'][i])\n",
    "        upper_lim.append(shade_test['spike_upperlim'][i])\n",
    "        lower_lim.append(shade_test['spike_lowerlim'][i])\n",
    "    return np.array(y_spike_occ), np.array(upper_lim), np.array(lower_lim)\n",
    "\n",
    "# function to cut data set so it can be divisible by the batch_size\n",
    "def cut_data(data, batch_size):\n",
    "     # see if it is divisivel\n",
    "    condition = data.shape[0] % batch_size\n",
    "    if condition == 0:\n",
    "        return data\n",
    "    else:\n",
    "        return data[: -condition]\n",
    "\n",
    "y_spike_occ, spike_upperlim, spike_lowerlim = split_data(shade_test, steps)\n",
    "y_spike_occ = cut_data(y_spike_occ, batch_size)\n",
    "spike_upperlim = cut_data(spike_upperlim, batch_size)\n",
    "spike_lowerlim = cut_data(spike_lowerlim, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate on spike and normal regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# METRICS EVALUATION (2) on spike regions\n",
    "# =============================================================================\n",
    "\n",
    "# smal adjustment\n",
    "#y_test.replace(0, 0.0001,inplace = True)\n",
    "\n",
    "# select y_pred and y_test only for regions with spikes\n",
    "y_test_spike = (y_test.T * y_spike_occ).T\n",
    "y_pred_spike = (y_pred.T * y_spike_occ).T\n",
    "y_test_spike = y_test_spike[y_test_spike != 0]\n",
    "y_pred_spike = y_pred_spike[y_pred_spike != 0]\n",
    "\n",
    "# calculate metric\n",
    "rmse_spike = mse(y_test_spike, y_pred_spike, squared = False)\n",
    "mae_spike = mae(y_test_spike, y_pred_spike)\n",
    "\n",
    "# append ot lists\n",
    "rmse_spi.append(rmse_spike)\n",
    "mae_spi.append(mae_spike)\n",
    "\n",
    "# =============================================================================\n",
    "# METRIC EVALUATION (3) on normal regions\n",
    "# =============================================================================\n",
    "\n",
    "# inverse y_spike_occ so the only normal occurences are chosen\n",
    "y_normal_occ = (y_spike_occ - 1) * (-1)\n",
    "\n",
    "# sanity check\n",
    "y_normal_occ.sum() + y_spike_occ.sum() # gives the correct total \n",
    "\n",
    "# select y_pred and y_test only for normal regions\n",
    "y_test_normal = (y_test.T * y_normal_occ).T\n",
    "y_pred_normal = (y_pred.T * y_normal_occ).T\n",
    "y_test_normal = y_test_normal[y_test_normal != 0.00]\n",
    "y_pred_normal = y_pred_normal[y_pred_normal != 0.00]\n",
    "\n",
    "# calculate metric\n",
    "rmse_normal = mse(y_test_normal, y_pred_normal, squared = False)\n",
    "mae_normal = mae(y_test_normal, y_pred_normal)\n",
    "\n",
    "# append to list\n",
    "rmse_nor.append(rmse_normal)\n",
    "mae_nor.append(mae_normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now evaluate predictions on Spike & Normal regions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({'rmse_general': rmse_gen, \n",
    "                 \n",
    "                        'mae_general': mae_gen,\n",
    "                        \n",
    "                        'rmse_spike': rmse_spi,\n",
    "                 \n",
    "                        'mae_spike': mae_spi,\n",
    "                        \n",
    "                        'rmse_normal': rmse_nor,\n",
    "                    \n",
    "                        'mae_normal': mae_nor})\n",
    "\n",
    "# Save y_pred & spike limits to plot with Stateless LSTM\n",
    "datasave = pd.DataFrame({'y_pred': y_pred,\n",
    "                         'y_test':y_test,\n",
    "                         'spike_upperlim':spike_upperlim,\n",
    "                         'spike_lowerlim':spike_lowerlim})\n",
    "\n",
    "datasave.to_csv('LSTM_plot_Stateful_6m.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse_general</th>\n",
       "      <th>mae_general</th>\n",
       "      <th>rmse_spike</th>\n",
       "      <th>mae_spike</th>\n",
       "      <th>rmse_normal</th>\n",
       "      <th>mae_normal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29.129889</td>\n",
       "      <td>17.739845</td>\n",
       "      <td>58.859746</td>\n",
       "      <td>44.155569</td>\n",
       "      <td>21.092452</td>\n",
       "      <td>13.663671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rmse_general  mae_general  rmse_spike  mae_spike  rmse_normal  mae_normal\n",
       "0     29.129889    17.739845   58.859746  44.155569    21.092452   13.663671"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
