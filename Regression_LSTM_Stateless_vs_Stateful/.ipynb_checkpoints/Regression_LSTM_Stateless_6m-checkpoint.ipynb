{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in c:\\users\\maria\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\maria\\anaconda3\\lib\\site-packages (from sklearn) (0.22.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (0.14.1)\n",
      "Requirement already satisfied: numpy>=1.11.0 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.18.1)\n",
      "Requirement already satisfied: scipy>=0.17.0 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.4.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\maria\\anaconda3\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from pandas) (1.18.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from python-dateutil>=2.6.1->pandas) (1.14.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\maria\\anaconda3\\lib\\site-packages (3.1.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from matplotlib) (2.4.6)\n",
      "Requirement already satisfied: numpy>=1.11 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from matplotlib) (1.18.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\maria\\anaconda3\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib) (45.2.0.post20200210)\n",
      "Requirement already satisfied: six in c:\\users\\maria\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib) (1.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn\n",
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# empty list to append metric values\n",
    "mae_gen = []\n",
    "mae_nor = []\n",
    "mae_spi = []\n",
    "rmse_gen = []\n",
    "rmse_nor = []\n",
    "rmse_spi = []\n",
    "\n",
    "# parameters\n",
    "steps = 96\n",
    "n_hidden = 1\n",
    "units = 150\n",
    "batch_size = 96\n",
    "epochs = 100\n",
    "\n",
    "# months to evaluate model on\n",
    "date = 2018090000\n",
    "\n",
    "# for later use\n",
    "features_num = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Data_set_1_smaller_(1).csv', index_col = 0)\n",
    "\n",
    "# set predictive window according with tuning best results\n",
    "data = data.loc[data.index > date, :]\n",
    "\n",
    "# reset index\n",
    "data.reset_index(inplace = True)\n",
    "data.drop('index', axis = 1, inplace = True)\n",
    "\n",
    "# fill nan values in the whole data set\n",
    "data.fillna(data.mean(), inplace = True)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# divide data into train and test \n",
    "data_train, data_test = train_test_split(\n",
    "         data, test_size = 0.15, shuffle=False)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# data scaling  (including offer (y))\n",
    "sc_X = MinMaxScaler()\n",
    "data_train = sc_X.fit_transform(data_train)\n",
    "data_test = sc_X.transform(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Required functions to put data into required shape for LSTM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to split data into correct shape for RNN\n",
    "def split_data(X, y, steps):\n",
    "    X_, y_ = list(), list()\n",
    "    for i in range(steps, len(y)):\n",
    "        X_.append(X[i - steps : i, :])\n",
    "        y_.append(y[i]) \n",
    "    return np.array(X_), np.array(y_)\n",
    "\n",
    "# function to cut data set so it can be divisible by the batch_size\n",
    "def cut_data(data, batch_size):\n",
    "     # see if it is divisivel\n",
    "    condition = data.shape[0] % batch_size\n",
    "    if condition == 0:\n",
    "        return data\n",
    "    else:\n",
    "        return data[: -condition]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up X and y for train, test and val into correct shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide features and labels\n",
    "X_train = data_train[:, 0:14] \n",
    "y_train = data_train[:, -1]\n",
    "X_test = data_test[:, 0:14]\n",
    "y_test = data_test[:, -1] \n",
    "\n",
    "# divide data into validation and normal test \n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train, y_train, test_size = 0.15, shuffle=False)\n",
    "\n",
    "# put data into correct shape\n",
    "X_train, y_train = split_data(X_train, y_train, steps)\n",
    "X_test, y_test = split_data(X_test, y_test, steps)\n",
    "X_val, y_val = split_data(X_val, y_val, steps)\n",
    "\n",
    "# cut data\n",
    "X_train = cut_data(X_train, batch_size)\n",
    "y_train = cut_data(y_train, batch_size)\n",
    "X_test = cut_data(X_test, batch_size)\n",
    "y_test = cut_data(y_test, batch_size)\n",
    "X_val = cut_data(X_val, batch_size)\n",
    "y_val = cut_data(y_val, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LeakyReLU\n",
    "from keras import initializers\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Design LSTM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regressor_tunning(kernel_initializer = 'he_uniform',\n",
    "                      bias_initializer = initializers.Ones()):\n",
    "    model = Sequential()\n",
    "    if n_hidden == 0:\n",
    "        model.add(LSTM(units = units,                    \n",
    "                       input_shape = (steps, features_num), \n",
    "                       kernel_initializer = kernel_initializer,\n",
    "                       bias_initializer = bias_initializer))\n",
    "        model.add(LeakyReLU(alpha = 0.2))\n",
    "        model.add(Dropout(0.2))\n",
    "    else:\n",
    "        model.add(LSTM(units = units,                    \n",
    "                       input_shape = (steps, features_num), \n",
    "                       return_sequences = True,\n",
    "                       kernel_initializer = kernel_initializer,\n",
    "                       bias_initializer = bias_initializer))\n",
    "        model.add(LeakyReLU(alpha = 0.2))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(LSTM(units = units, \n",
    "                       input_shape = (steps, features_num), \n",
    "                       kernel_initializer = kernel_initializer,\n",
    "                       bias_initializer = bias_initializer))\n",
    "        model.add(LeakyReLU(alpha = 0.2))\n",
    "        model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    optimizer = optimizers.RMSprop()\n",
    "    model.compile(loss = 'mse', metrics = ['mse', 'mae'], optimizer = optimizer)\n",
    "    return model\n",
    "\n",
    "model = regressor_tunning()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "43/43 [==============================] - 22s 504ms/step - loss: 0.4112 - mse: 0.4112 - mae: 0.4256 - val_loss: 0.0731 - val_mse: 0.0731 - val_mae: 0.2683\n",
      "Epoch 2/100\n",
      "43/43 [==============================] - 15s 359ms/step - loss: 0.1103 - mse: 0.1103 - mae: 0.2646 - val_loss: 0.0195 - val_mse: 0.0195 - val_mae: 0.1375\n",
      "Epoch 3/100\n",
      "43/43 [==============================] - 17s 393ms/step - loss: 0.0546 - mse: 0.0546 - mae: 0.1871 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0329\n",
      "Epoch 4/100\n",
      "43/43 [==============================] - 17s 387ms/step - loss: 0.0251 - mse: 0.0251 - mae: 0.1257 - val_loss: 4.6027e-04 - val_mse: 4.6027e-04 - val_mae: 0.0146\n",
      "Epoch 5/100\n",
      "43/43 [==============================] - 17s 394ms/step - loss: 0.0140 - mse: 0.0140 - mae: 0.0917 - val_loss: 0.0050 - val_mse: 0.0050 - val_mae: 0.0674\n",
      "Epoch 6/100\n",
      "43/43 [==============================] - 19s 448ms/step - loss: 0.0079 - mse: 0.0079 - mae: 0.0694 - val_loss: 0.0052 - val_mse: 0.0052 - val_mae: 0.0696\n",
      "Epoch 7/100\n",
      "43/43 [==============================] - 19s 452ms/step - loss: 0.0052 - mse: 0.0052 - mae: 0.0547 - val_loss: 0.0015 - val_mse: 0.0015 - val_mae: 0.0370\n",
      "Epoch 8/100\n",
      "43/43 [==============================] - 19s 444ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0441 - val_loss: 0.0014 - val_mse: 0.0014 - val_mae: 0.0346\n",
      "Epoch 9/100\n",
      "43/43 [==============================] - 19s 436ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0351 - val_loss: 6.6261e-04 - val_mse: 6.6261e-04 - val_mae: 0.0226\n",
      "Epoch 10/100\n",
      "43/43 [==============================] - 18s 413ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0275 - val_loss: 4.9019e-04 - val_mse: 4.9019e-04 - val_mae: 0.0136\n",
      "Epoch 11/100\n",
      "43/43 [==============================] - 19s 436ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0255 - val_loss: 4.8671e-04 - val_mse: 4.8671e-04 - val_mae: 0.0146\n",
      "Epoch 12/100\n",
      "43/43 [==============================] - 19s 439ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0229 - val_loss: 4.9158e-04 - val_mse: 4.9158e-04 - val_mae: 0.0136\n",
      "Epoch 13/100\n",
      "43/43 [==============================] - 18s 425ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0217 - val_loss: 4.9583e-04 - val_mse: 4.9583e-04 - val_mae: 0.0133\n",
      "Epoch 14/100\n",
      "43/43 [==============================] - 22s 500ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0212 - val_loss: 5.0036e-04 - val_mse: 5.0036e-04 - val_mae: 0.0130\n",
      "Epoch 15/100\n",
      "43/43 [==============================] - 27s 635ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0206 - val_loss: 4.9845e-04 - val_mse: 4.9845e-04 - val_mae: 0.0129\n",
      "Epoch 16/100\n",
      "43/43 [==============================] - 26s 612ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0202 - val_loss: 4.8619e-04 - val_mse: 4.8619e-04 - val_mae: 0.0136\n",
      "Epoch 17/100\n",
      "43/43 [==============================] - 27s 634ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0198 - val_loss: 4.8794e-04 - val_mse: 4.8794e-04 - val_mae: 0.0132\n",
      "Epoch 18/100\n",
      "43/43 [==============================] - 26s 612ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0197 - val_loss: 4.9035e-04 - val_mse: 4.9035e-04 - val_mae: 0.0130\n",
      "Epoch 19/100\n",
      "43/43 [==============================] - 26s 593ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0193 - val_loss: 4.7559e-04 - val_mse: 4.7559e-04 - val_mae: 0.0137\n",
      "Epoch 20/100\n",
      "43/43 [==============================] - 26s 605ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0190 - val_loss: 4.7472e-04 - val_mse: 4.7472e-04 - val_mae: 0.0131\n",
      "Epoch 21/100\n",
      "43/43 [==============================] - 26s 609ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0190 - val_loss: 4.6887e-04 - val_mse: 4.6887e-04 - val_mae: 0.0135\n",
      "Epoch 22/100\n",
      "43/43 [==============================] - 26s 602ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0186 - val_loss: 4.6669e-04 - val_mse: 4.6669e-04 - val_mae: 0.0135\n",
      "Epoch 23/100\n",
      "43/43 [==============================] - 25s 570ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0186 - val_loss: 4.5897e-04 - val_mse: 4.5897e-04 - val_mae: 0.0132\n",
      "Epoch 24/100\n",
      "43/43 [==============================] - 25s 583ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0184 - val_loss: 4.5801e-04 - val_mse: 4.5801e-04 - val_mae: 0.0128\n",
      "Epoch 25/100\n",
      "43/43 [==============================] - 26s 597ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0182 - val_loss: 4.4257e-04 - val_mse: 4.4257e-04 - val_mae: 0.0126\n",
      "Epoch 26/100\n",
      "43/43 [==============================] - 26s 611ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0179 - val_loss: 4.3120e-04 - val_mse: 4.3120e-04 - val_mae: 0.0128\n",
      "Epoch 27/100\n",
      "43/43 [==============================] - 27s 628ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0180 - val_loss: 4.2176e-04 - val_mse: 4.2176e-04 - val_mae: 0.0131\n",
      "Epoch 28/100\n",
      "43/43 [==============================] - 25s 591ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0175 - val_loss: 4.1424e-04 - val_mse: 4.1424e-04 - val_mae: 0.0126\n",
      "Epoch 29/100\n",
      "43/43 [==============================] - 27s 631ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0174 - val_loss: 4.0835e-04 - val_mse: 4.0835e-04 - val_mae: 0.0121\n",
      "Epoch 30/100\n",
      "43/43 [==============================] - 30s 699ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0172 - val_loss: 3.9314e-04 - val_mse: 3.9314e-04 - val_mae: 0.0123\n",
      "Epoch 31/100\n",
      "43/43 [==============================] - 27s 636ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0170 - val_loss: 3.8408e-04 - val_mse: 3.8408e-04 - val_mae: 0.0118\n",
      "Epoch 32/100\n",
      "43/43 [==============================] - 26s 605ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0167 - val_loss: 3.7137e-04 - val_mse: 3.7137e-04 - val_mae: 0.0122\n",
      "Epoch 33/100\n",
      "43/43 [==============================] - 27s 628ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0165 - val_loss: 3.6496e-04 - val_mse: 3.6496e-04 - val_mae: 0.0115\n",
      "Epoch 34/100\n",
      "43/43 [==============================] - 27s 635ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0163 - val_loss: 3.6086e-04 - val_mse: 3.6086e-04 - val_mae: 0.0115\n",
      "Epoch 35/100\n",
      "43/43 [==============================] - 28s 653ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0162 - val_loss: 3.4701e-04 - val_mse: 3.4701e-04 - val_mae: 0.0109\n",
      "Epoch 36/100\n",
      "43/43 [==============================] - 28s 645ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0161 - val_loss: 3.3798e-04 - val_mse: 3.3798e-04 - val_mae: 0.0112\n",
      "Epoch 37/100\n",
      "43/43 [==============================] - 27s 632ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0159 - val_loss: 3.4053e-04 - val_mse: 3.4053e-04 - val_mae: 0.0108\n",
      "Epoch 38/100\n",
      "43/43 [==============================] - 32s 752ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0158 - val_loss: 3.5012e-04 - val_mse: 3.5012e-04 - val_mae: 0.0109\n",
      "Epoch 39/100\n",
      "43/43 [==============================] - 32s 744ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0157 - val_loss: 3.3950e-04 - val_mse: 3.3950e-04 - val_mae: 0.0106\n",
      "Epoch 40/100\n",
      "43/43 [==============================] - 33s 762ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0156 - val_loss: 3.2273e-04 - val_mse: 3.2273e-04 - val_mae: 0.0111\n",
      "Epoch 41/100\n",
      "43/43 [==============================] - 29s 685ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0156 - val_loss: 3.3034e-04 - val_mse: 3.3034e-04 - val_mae: 0.0106\n",
      "Epoch 42/100\n",
      "43/43 [==============================] - 30s 705ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0155 - val_loss: 3.2029e-04 - val_mse: 3.2029e-04 - val_mae: 0.0110\n",
      "Epoch 43/100\n",
      "43/43 [==============================] - 31s 713ms/step - loss: 9.9344e-04 - mse: 9.9344e-04 - mae: 0.0154 - val_loss: 3.4397e-04 - val_mse: 3.4397e-04 - val_mae: 0.0104\n",
      "Epoch 44/100\n",
      "43/43 [==============================] - 31s 727ms/step - loss: 9.8942e-04 - mse: 9.8942e-04 - mae: 0.0154 - val_loss: 3.2426e-04 - val_mse: 3.2426e-04 - val_mae: 0.0105\n",
      "Epoch 45/100\n",
      "43/43 [==============================] - 33s 769ms/step - loss: 9.8851e-04 - mse: 9.8851e-04 - mae: 0.0152 - val_loss: 3.2322e-04 - val_mse: 3.2322e-04 - val_mae: 0.0106\n",
      "Epoch 46/100\n",
      "43/43 [==============================] - 31s 710ms/step - loss: 9.9502e-04 - mse: 9.9502e-04 - mae: 0.0153 - val_loss: 3.0443e-04 - val_mse: 3.0443e-04 - val_mae: 0.0103\n",
      "Epoch 47/100\n",
      "43/43 [==============================] - 29s 677ms/step - loss: 9.8378e-04 - mse: 9.8378e-04 - mae: 0.0152 - val_loss: 3.0870e-04 - val_mse: 3.0870e-04 - val_mae: 0.0104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/100\n",
      "43/43 [==============================] - 28s 662ms/step - loss: 9.7839e-04 - mse: 9.7839e-04 - mae: 0.0151 - val_loss: 3.2044e-04 - val_mse: 3.2044e-04 - val_mae: 0.0104\n",
      "Epoch 49/100\n",
      "43/43 [==============================] - 28s 656ms/step - loss: 9.7894e-04 - mse: 9.7894e-04 - mae: 0.0151 - val_loss: 2.8796e-04 - val_mse: 2.8796e-04 - val_mae: 0.0100\n",
      "Epoch 50/100\n",
      "43/43 [==============================] - 28s 654ms/step - loss: 9.5358e-04 - mse: 9.5358e-04 - mae: 0.0148 - val_loss: 3.0199e-04 - val_mse: 3.0199e-04 - val_mae: 0.0103\n",
      "Epoch 51/100\n",
      "43/43 [==============================] - 29s 668ms/step - loss: 9.3421e-04 - mse: 9.3421e-04 - mae: 0.0147 - val_loss: 2.9095e-04 - val_mse: 2.9095e-04 - val_mae: 0.0103\n",
      "Epoch 52/100\n",
      "43/43 [==============================] - 29s 680ms/step - loss: 9.1889e-04 - mse: 9.1889e-04 - mae: 0.0146 - val_loss: 3.7221e-04 - val_mse: 3.7221e-04 - val_mae: 0.0105\n",
      "Epoch 53/100\n",
      "43/43 [==============================] - 29s 682ms/step - loss: 9.9209e-04 - mse: 9.9209e-04 - mae: 0.0153 - val_loss: 2.8821e-04 - val_mse: 2.8821e-04 - val_mae: 0.0109\n",
      "Epoch 54/100\n",
      "43/43 [==============================] - 29s 677ms/step - loss: 9.7254e-04 - mse: 9.7254e-04 - mae: 0.0150 - val_loss: 3.2484e-04 - val_mse: 3.2484e-04 - val_mae: 0.0099\n",
      "Epoch 55/100\n",
      "43/43 [==============================] - 30s 687ms/step - loss: 9.4926e-04 - mse: 9.4926e-04 - mae: 0.0148 - val_loss: 2.8460e-04 - val_mse: 2.8460e-04 - val_mae: 0.0103\n",
      "Epoch 56/100\n",
      "43/43 [==============================] - 28s 660ms/step - loss: 9.2820e-04 - mse: 9.2820e-04 - mae: 0.0146 - val_loss: 2.7446e-04 - val_mse: 2.7446e-04 - val_mae: 0.0100\n",
      "Epoch 57/100\n",
      "43/43 [==============================] - 28s 647ms/step - loss: 9.2014e-04 - mse: 9.2014e-04 - mae: 0.0145 - val_loss: 2.7216e-04 - val_mse: 2.7216e-04 - val_mae: 0.0098\n",
      "Epoch 58/100\n",
      "43/43 [==============================] - 30s 693ms/step - loss: 9.3607e-04 - mse: 9.3607e-04 - mae: 0.0147 - val_loss: 2.9243e-04 - val_mse: 2.9243e-04 - val_mae: 0.0100\n",
      "Epoch 59/100\n",
      "43/43 [==============================] - 31s 718ms/step - loss: 8.7613e-04 - mse: 8.7613e-04 - mae: 0.0142 - val_loss: 3.3089e-04 - val_mse: 3.3089e-04 - val_mae: 0.0102\n",
      "Epoch 60/100\n",
      "43/43 [==============================] - 28s 656ms/step - loss: 9.1971e-04 - mse: 9.1971e-04 - mae: 0.0144 - val_loss: 2.8153e-04 - val_mse: 2.8153e-04 - val_mae: 0.0108\n",
      "Epoch 61/100\n",
      "43/43 [==============================] - 29s 664ms/step - loss: 9.1829e-04 - mse: 9.1829e-04 - mae: 0.0146 - val_loss: 3.0414e-04 - val_mse: 3.0414e-04 - val_mae: 0.0097\n",
      "Epoch 62/100\n",
      "43/43 [==============================] - 29s 681ms/step - loss: 8.9343e-04 - mse: 8.9343e-04 - mae: 0.0142 - val_loss: 2.9526e-04 - val_mse: 2.9526e-04 - val_mae: 0.0095\n",
      "Epoch 63/100\n",
      "43/43 [==============================] - 28s 662ms/step - loss: 9.1970e-04 - mse: 9.1970e-04 - mae: 0.0144 - val_loss: 2.9964e-04 - val_mse: 2.9964e-04 - val_mae: 0.0097\n",
      "Epoch 64/100\n",
      "43/43 [==============================] - 28s 647ms/step - loss: 9.0886e-04 - mse: 9.0886e-04 - mae: 0.0141 - val_loss: 2.8456e-04 - val_mse: 2.8456e-04 - val_mae: 0.0112\n",
      "Epoch 65/100\n",
      "43/43 [==============================] - 28s 656ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0148 - val_loss: 3.8132e-04 - val_mse: 3.8132e-04 - val_mae: 0.0117\n",
      "Epoch 66/100\n",
      "43/43 [==============================] - 27s 640ms/step - loss: 9.2645e-04 - mse: 9.2645e-04 - mae: 0.0147 - val_loss: 3.0081e-04 - val_mse: 3.0081e-04 - val_mae: 0.0102\n",
      "Epoch 67/100\n",
      "43/43 [==============================] - 28s 657ms/step - loss: 8.6691e-04 - mse: 8.6691e-04 - mae: 0.0140 - val_loss: 3.2660e-04 - val_mse: 3.2660e-04 - val_mae: 0.0105\n",
      "Epoch 68/100\n",
      "43/43 [==============================] - 28s 644ms/step - loss: 9.8255e-04 - mse: 9.8255e-04 - mae: 0.0146 - val_loss: 2.9359e-04 - val_mse: 2.9359e-04 - val_mae: 0.0113\n",
      "Epoch 69/100\n",
      "43/43 [==============================] - 28s 651ms/step - loss: 9.5230e-04 - mse: 9.5230e-04 - mae: 0.0146 - val_loss: 3.1741e-04 - val_mse: 3.1741e-04 - val_mae: 0.0107\n",
      "Epoch 70/100\n",
      "43/43 [==============================] - 28s 661ms/step - loss: 9.3180e-04 - mse: 9.3180e-04 - mae: 0.0148 - val_loss: 2.9159e-04 - val_mse: 2.9159e-04 - val_mae: 0.0096\n",
      "Epoch 71/100\n",
      "43/43 [==============================] - 29s 674ms/step - loss: 8.9013e-04 - mse: 8.9013e-04 - mae: 0.0142 - val_loss: 2.6650e-04 - val_mse: 2.6650e-04 - val_mae: 0.0097\n",
      "Epoch 72/100\n",
      "43/43 [==============================] - 28s 660ms/step - loss: 9.3904e-04 - mse: 9.3904e-04 - mae: 0.0143 - val_loss: 3.0209e-04 - val_mse: 3.0209e-04 - val_mae: 0.0105\n",
      "Epoch 73/100\n",
      "43/43 [==============================] - 28s 658ms/step - loss: 9.1513e-04 - mse: 9.1513e-04 - mae: 0.0141 - val_loss: 2.8189e-04 - val_mse: 2.8189e-04 - val_mae: 0.0104\n",
      "Epoch 74/100\n",
      "43/43 [==============================] - 28s 652ms/step - loss: 8.7742e-04 - mse: 8.7742e-04 - mae: 0.0140 - val_loss: 3.1703e-04 - val_mse: 3.1703e-04 - val_mae: 0.0102\n",
      "Epoch 75/100\n",
      "43/43 [==============================] - 29s 675ms/step - loss: 9.0099e-04 - mse: 9.0099e-04 - mae: 0.0142 - val_loss: 3.4224e-04 - val_mse: 3.4224e-04 - val_mae: 0.0103\n",
      "Epoch 76/100\n",
      "43/43 [==============================] - 28s 656ms/step - loss: 8.9952e-04 - mse: 8.9952e-04 - mae: 0.0140 - val_loss: 3.0606e-04 - val_mse: 3.0606e-04 - val_mae: 0.0124\n",
      "Epoch 77/100\n",
      "43/43 [==============================] - 28s 646ms/step - loss: 9.3369e-04 - mse: 9.3369e-04 - mae: 0.0142 - val_loss: 3.0415e-04 - val_mse: 3.0415e-04 - val_mae: 0.0103\n",
      "Epoch 78/100\n",
      "43/43 [==============================] - 28s 641ms/step - loss: 8.6957e-04 - mse: 8.6957e-04 - mae: 0.0138 - val_loss: 3.0262e-04 - val_mse: 3.0262e-04 - val_mae: 0.0099\n",
      "Epoch 79/100\n",
      "43/43 [==============================] - 28s 651ms/step - loss: 8.9251e-04 - mse: 8.9251e-04 - mae: 0.0138 - val_loss: 2.7595e-04 - val_mse: 2.7595e-04 - val_mae: 0.0102\n",
      "Epoch 80/100\n",
      "43/43 [==============================] - 27s 636ms/step - loss: 8.6858e-04 - mse: 8.6858e-04 - mae: 0.0139 - val_loss: 2.6563e-04 - val_mse: 2.6563e-04 - val_mae: 0.0092\n",
      "Epoch 81/100\n",
      "43/43 [==============================] - 28s 661ms/step - loss: 8.4447e-04 - mse: 8.4447e-04 - mae: 0.0136 - val_loss: 2.8074e-04 - val_mse: 2.8074e-04 - val_mae: 0.0104\n",
      "Epoch 82/100\n",
      "43/43 [==============================] - 30s 699ms/step - loss: 8.8250e-04 - mse: 8.8250e-04 - mae: 0.0140 - val_loss: 2.7705e-04 - val_mse: 2.7705e-04 - val_mae: 0.0108\n",
      "Epoch 83/100\n",
      "43/43 [==============================] - 29s 677ms/step - loss: 9.2753e-04 - mse: 9.2753e-04 - mae: 0.0142 - val_loss: 3.0503e-04 - val_mse: 3.0503e-04 - val_mae: 0.0104\n",
      "Epoch 84/100\n",
      "43/43 [==============================] - 29s 680ms/step - loss: 8.3953e-04 - mse: 8.3953e-04 - mae: 0.0135 - val_loss: 3.0146e-04 - val_mse: 3.0146e-04 - val_mae: 0.0112\n",
      "Epoch 85/100\n",
      "43/43 [==============================] - 28s 661ms/step - loss: 9.0110e-04 - mse: 9.0110e-04 - mae: 0.0140 - val_loss: 2.7648e-04 - val_mse: 2.7648e-04 - val_mae: 0.0104\n",
      "Epoch 86/100\n",
      "43/43 [==============================] - 28s 657ms/step - loss: 8.9361e-04 - mse: 8.9361e-04 - mae: 0.0140 - val_loss: 2.6176e-04 - val_mse: 2.6176e-04 - val_mae: 0.0100\n",
      "Epoch 87/100\n",
      "43/43 [==============================] - 29s 679ms/step - loss: 8.6025e-04 - mse: 8.6025e-04 - mae: 0.0136 - val_loss: 2.7809e-04 - val_mse: 2.7809e-04 - val_mae: 0.0100\n",
      "Epoch 88/100\n",
      "43/43 [==============================] - 29s 686ms/step - loss: 8.6553e-04 - mse: 8.6553e-04 - mae: 0.0137 - val_loss: 2.5576e-04 - val_mse: 2.5576e-04 - val_mae: 0.0098\n",
      "Epoch 89/100\n",
      "43/43 [==============================] - 29s 672ms/step - loss: 8.4865e-04 - mse: 8.4865e-04 - mae: 0.0134 - val_loss: 2.6659e-04 - val_mse: 2.6659e-04 - val_mae: 0.0101\n",
      "Epoch 90/100\n",
      "43/43 [==============================] - 28s 653ms/step - loss: 8.6406e-04 - mse: 8.6406e-04 - mae: 0.0136 - val_loss: 2.6773e-04 - val_mse: 2.6773e-04 - val_mae: 0.0097\n",
      "Epoch 91/100\n",
      "43/43 [==============================] - 29s 667ms/step - loss: 8.8067e-04 - mse: 8.8067e-04 - mae: 0.0137 - val_loss: 3.1934e-04 - val_mse: 3.1934e-04 - val_mae: 0.0105\n",
      "Epoch 92/100\n",
      "43/43 [==============================] - 29s 673ms/step - loss: 8.4204e-04 - mse: 8.4204e-04 - mae: 0.0135 - val_loss: 3.0665e-04 - val_mse: 3.0665e-04 - val_mae: 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/100\n",
      "43/43 [==============================] - 28s 662ms/step - loss: 8.4006e-04 - mse: 8.4006e-04 - mae: 0.0136 - val_loss: 2.7850e-04 - val_mse: 2.7850e-04 - val_mae: 0.0112\n",
      "Epoch 94/100\n",
      "43/43 [==============================] - 29s 677ms/step - loss: 9.3717e-04 - mse: 9.3717e-04 - mae: 0.0138 - val_loss: 2.7489e-04 - val_mse: 2.7489e-04 - val_mae: 0.0105\n",
      "Epoch 95/100\n",
      "43/43 [==============================] - 28s 656ms/step - loss: 8.6969e-04 - mse: 8.6969e-04 - mae: 0.0138 - val_loss: 3.0359e-04 - val_mse: 3.0359e-04 - val_mae: 0.0097\n",
      "Epoch 96/100\n",
      "43/43 [==============================] - 27s 629ms/step - loss: 8.3867e-04 - mse: 8.3867e-04 - mae: 0.0135 - val_loss: 2.9363e-04 - val_mse: 2.9363e-04 - val_mae: 0.0104\n",
      "Epoch 97/100\n",
      "43/43 [==============================] - 27s 619ms/step - loss: 8.3938e-04 - mse: 8.3938e-04 - mae: 0.0134 - val_loss: 2.7774e-04 - val_mse: 2.7774e-04 - val_mae: 0.0101\n",
      "Epoch 98/100\n",
      "43/43 [==============================] - 27s 639ms/step - loss: 8.0989e-04 - mse: 8.0989e-04 - mae: 0.0130 - val_loss: 2.8192e-04 - val_mse: 2.8192e-04 - val_mae: 0.0109\n",
      "Epoch 99/100\n",
      "43/43 [==============================] - 28s 647ms/step - loss: 8.7142e-04 - mse: 8.7142e-04 - mae: 0.0136 - val_loss: 2.6329e-04 - val_mse: 2.6329e-04 - val_mae: 0.0097\n",
      "Epoch 100/100\n",
      "43/43 [==============================] - 29s 682ms/step - loss: 8.5237e-04 - mse: 8.5237e-04 - mae: 0.0133 - val_loss: 2.7608e-04 - val_mse: 2.7608e-04 - val_mae: 0.0109\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,\n",
    "                    y_train, \n",
    "                    batch_size = batch_size, \n",
    "                    epochs = epochs,\n",
    "                    shuffle = False, \n",
    "                    validation_data = (X_val, y_val))\n",
    "    \n",
    "# required before predicitons\n",
    "model.reset_states()\n",
    "    \n",
    "y_pred = model.predict(X_test, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cannot use inverse function; prices col = 14\n",
    "y_pred = (y_pred * sc_X.data_range_[14]) + (sc_X.data_min_[14])\n",
    "y_test = (y_test * sc_X.data_range_[14]) + (sc_X.data_min_[14])\n",
    "\n",
    "# Reshaping\n",
    "y_pred = np.reshape(y_pred, (y_pred.shape[0]))\n",
    "\n",
    "# =============================================================================\n",
    "# METRICS EVALUATION (1) for the whole test set\n",
    "# =============================================================================\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "\n",
    "# calculate metrics\n",
    "rmse_error = mse(y_test, y_pred, squared = False)\n",
    "mae_error = mae(y_test, y_pred)\n",
    "\n",
    "# append to list\n",
    "rmse_gen.append(rmse_error)\n",
    "mae_gen.append(mae_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Need to process data with spike occurences in the same way as features and offers:\n",
    "(Required to evaluate predictions in both normal regions and spike regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data for shaded area\n",
    "data = pd.read_csv('Spike_binary_1std.csv', index_col = 0)\n",
    "\n",
    "# set predictive window according with tuning best results\n",
    "data = data.loc[data.index > date, :]\n",
    "\n",
    "# make sure shaded area will correspond to values outputed by LSTM\n",
    "data.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# fill_nan is already made - so lets split data into test and train\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# divide data into train and test \n",
    "shade_train, shade_test = train_test_split(\n",
    "         data, test_size = 0.15, shuffle = False)\n",
    "\n",
    "# reset index of testing data\n",
    "shade_test.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# function to split data into correct shape for RNN\n",
    "def split_data(shade_test, steps):\n",
    "    y_spike_occ = list()\n",
    "    upper_lim = list()\n",
    "    lower_lim = list()\n",
    "    for i in range(steps, len(shade_test.index)):\n",
    "        y_spike_occ.append(shade_test['spike_occurance'][i])\n",
    "        upper_lim.append(shade_test['spike_upperlim'][i])\n",
    "        lower_lim.append(shade_test['spike_lowerlim'][i])\n",
    "    return np.array(y_spike_occ), np.array(upper_lim), np.array(lower_lim)\n",
    "\n",
    "# function to cut data set so it can be divisible by the batch_size\n",
    "def cut_data(data, batch_size):\n",
    "     # see if it is divisivel\n",
    "    condition = data.shape[0] % batch_size\n",
    "    if condition == 0:\n",
    "        return data\n",
    "    else:\n",
    "        return data[: -condition]\n",
    "\n",
    "y_spike_occ, spike_upperlim, spike_lowerlim = split_data(shade_test, steps)\n",
    "y_spike_occ = cut_data(y_spike_occ, batch_size)\n",
    "spike_upperlim = cut_data(spike_upperlim, batch_size)\n",
    "spike_lowerlim = cut_data(spike_lowerlim, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate on spike and normal regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# METRICS EVALUATION (2) on spike regions\n",
    "# =============================================================================\n",
    "\n",
    "# smal adjustment\n",
    "#y_test.replace(0, 0.0001,inplace = True)\n",
    "\n",
    "# select y_pred and y_test only for regions with spikes\n",
    "y_test_spike = (y_test.T * y_spike_occ).T\n",
    "y_pred_spike = (y_pred.T * y_spike_occ).T\n",
    "y_test_spike = y_test_spike[y_test_spike != 0]\n",
    "y_pred_spike = y_pred_spike[y_pred_spike != 0]\n",
    "\n",
    "# calculate metric\n",
    "rmse_spike = mse(y_test_spike, y_pred_spike, squared = False)\n",
    "mae_spike = mae(y_test_spike, y_pred_spike)\n",
    "\n",
    "# append ot lists\n",
    "rmse_spi.append(rmse_spike)\n",
    "mae_spi.append(mae_spike)\n",
    "\n",
    "# =============================================================================\n",
    "# METRIC EVALUATION (3) on normal regions\n",
    "# =============================================================================\n",
    "\n",
    "# inverse y_spike_occ so the only normal occurences are chosen\n",
    "y_normal_occ = (y_spike_occ - 1) * (-1)\n",
    "\n",
    "# sanity check\n",
    "y_normal_occ.sum() + y_spike_occ.sum() # gives the correct total \n",
    "\n",
    "# select y_pred and y_test only for normal regions\n",
    "y_test_normal = (y_test.T * y_normal_occ).T\n",
    "y_pred_normal = (y_pred.T * y_normal_occ).T\n",
    "y_test_normal = y_test_normal[y_test_normal != 0.00]\n",
    "y_pred_normal = y_pred_normal[y_pred_normal != 0.00]\n",
    "\n",
    "# calculate metric\n",
    "rmse_normal = mse(y_test_normal, y_pred_normal, squared = False)\n",
    "mae_normal = mae(y_test_normal, y_pred_normal)\n",
    "\n",
    "# append to list\n",
    "rmse_nor.append(rmse_normal)\n",
    "mae_nor.append(mae_normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now evaluate predictions on Spike & Normal regions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save y_pred & spike limits to plot with Stateless LSTM\n",
    "datasave = pd.DataFrame({'y_pred': y_pred,\n",
    "                         'y_test':y_test,\n",
    "                         'spike_upperlim':spike_upperlim,\n",
    "                         'spike_lowerlim':spike_lowerlim})\n",
    "\n",
    "data_to_save.to_csv('LSTM_plot_Stateless_4m.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse_general</th>\n",
       "      <th>mae_general</th>\n",
       "      <th>rmse_spike</th>\n",
       "      <th>mae_spike</th>\n",
       "      <th>rmse_normal</th>\n",
       "      <th>mae_normal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27.453873</td>\n",
       "      <td>16.655973</td>\n",
       "      <td>48.038634</td>\n",
       "      <td>36.04465</td>\n",
       "      <td>22.64997</td>\n",
       "      <td>13.652915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rmse_general  mae_general  rmse_spike  mae_spike  rmse_normal  mae_normal\n",
       "0     27.453873    16.655973   48.038634   36.04465     22.64997   13.652915"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({'rmse_general': rmse_gen, \n",
    "                 \n",
    "                        'mae_general': mae_gen,\n",
    "                        \n",
    "                        'rmse_spike': rmse_spi,\n",
    "                 \n",
    "                        'mae_spike': mae_spi,\n",
    "                        \n",
    "                        'rmse_normal': rmse_nor,\n",
    "                    \n",
    "                        'mae_normal': mae_nor})\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
