{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in c:\\users\\maria\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\maria\\anaconda3\\lib\\site-packages (from sklearn) (0.22.1)\n",
      "Requirement already satisfied: numpy>=1.11.0 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.18.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (0.14.1)\n",
      "Requirement already satisfied: scipy>=0.17.0 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.4.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\maria\\anaconda3\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from pandas) (1.18.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from python-dateutil>=2.6.1->pandas) (1.14.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\maria\\anaconda3\\lib\\site-packages (3.1.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.11 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from matplotlib) (1.18.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from matplotlib) (2.4.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\maria\\anaconda3\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib) (45.2.0.post20200210)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from python-dateutil>=2.1->matplotlib) (1.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn\n",
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# empty list to append metric values\n",
    "mae_gen = []\n",
    "mae_nor = []\n",
    "mae_spi = []\n",
    "rmse_gen = []\n",
    "rmse_nor = []\n",
    "rmse_spi = []\n",
    "\n",
    "# parameters\n",
    "steps = 96\n",
    "n_hidden = 1\n",
    "units = 150\n",
    "batch_size = 96\n",
    "epochs = 100\n",
    "\n",
    "# months to evaluate model on\n",
    "date = 2018070000\n",
    "\n",
    "# for later use\n",
    "features_num = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Data_set_1_smaller_(1).csv', index_col = 0)\n",
    "\n",
    "# set predictive window according with tuning best results\n",
    "data = data.loc[data.index > date, :]\n",
    "\n",
    "# reset index\n",
    "data.reset_index(inplace = True)\n",
    "data.drop('index', axis = 1, inplace = True)\n",
    "\n",
    "# fill nan values in the whole data set\n",
    "data.fillna(data.mean(), inplace = True)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# divide data into train and test \n",
    "data_train, data_test = train_test_split(\n",
    "         data, test_size = 0.15, shuffle=False)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# data scaling  (including offer (y))\n",
    "sc_X = MinMaxScaler()\n",
    "data_train = sc_X.fit_transform(data_train)\n",
    "data_test = sc_X.transform(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Required functions to put data into required shape for LSTM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to split data into correct shape for RNN\n",
    "def split_data(X, y, steps):\n",
    "    X_, y_ = list(), list()\n",
    "    for i in range(steps, len(y)):\n",
    "        X_.append(X[i - steps : i, :])\n",
    "        y_.append(y[i]) \n",
    "    return np.array(X_), np.array(y_)\n",
    "\n",
    "# function to cut data set so it can be divisible by the batch_size\n",
    "def cut_data(data, batch_size):\n",
    "     # see if it is divisivel\n",
    "    condition = data.shape[0] % batch_size\n",
    "    if condition == 0:\n",
    "        return data\n",
    "    else:\n",
    "        return data[: -condition]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up X and y for train, test and val into correct shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide features and labels\n",
    "X_train = data_train[:, 0:14] \n",
    "y_train = data_train[:, -1]\n",
    "X_test = data_test[:, 0:14]\n",
    "y_test = data_test[:, -1] \n",
    "\n",
    "# divide data into validation and normal test \n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train, y_train, test_size = 0.15, shuffle=False)\n",
    "\n",
    "# put data into correct shape\n",
    "X_train, y_train = split_data(X_train, y_train, steps)\n",
    "X_test, y_test = split_data(X_test, y_test, steps)\n",
    "X_val, y_val = split_data(X_val, y_val, steps)\n",
    "\n",
    "# cut data\n",
    "X_train = cut_data(X_train, batch_size)\n",
    "y_train = cut_data(y_train, batch_size)\n",
    "X_test = cut_data(X_test, batch_size)\n",
    "y_test = cut_data(y_test, batch_size)\n",
    "X_val = cut_data(X_val, batch_size)\n",
    "y_val = cut_data(y_val, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LeakyReLU\n",
    "from keras import initializers\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Design LSTM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regressor_tunning(kernel_initializer = 'he_uniform',\n",
    "                      bias_initializer = initializers.Ones()):\n",
    "    model = Sequential()\n",
    "    if n_hidden == 0:\n",
    "        model.add(LSTM(units = units,                    \n",
    "                       input_shape = (steps, features_num), \n",
    "                       kernel_initializer = kernel_initializer,\n",
    "                       bias_initializer = bias_initializer))\n",
    "        model.add(LeakyReLU(alpha = 0.2))\n",
    "        model.add(Dropout(0.2))\n",
    "    else:\n",
    "        model.add(LSTM(units = units,                    \n",
    "                       input_shape = (steps, features_num), \n",
    "                       return_sequences = True,\n",
    "                       kernel_initializer = kernel_initializer,\n",
    "                       bias_initializer = bias_initializer))\n",
    "        model.add(LeakyReLU(alpha = 0.2))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(LSTM(units = units, \n",
    "                       input_shape = (steps, features_num), \n",
    "                       kernel_initializer = kernel_initializer,\n",
    "                       bias_initializer = bias_initializer))\n",
    "        model.add(LeakyReLU(alpha = 0.2))\n",
    "        model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    optimizer = optimizers.RMSprop()\n",
    "    model.compile(loss = 'mse', metrics = ['mse', 'mae'], optimizer = optimizer)\n",
    "    return model\n",
    "\n",
    "model = regressor_tunning()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "65/65 [==============================] - 35s 541ms/step - loss: 0.3081 - mse: 0.3081 - mae: 0.3708 - val_loss: 0.0015 - val_mse: 0.0015 - val_mae: 0.0262\n",
      "Epoch 2/100\n",
      "65/65 [==============================] - 32s 497ms/step - loss: 0.0633 - mse: 0.0633 - mae: 0.1968 - val_loss: 0.0106 - val_mse: 0.0106 - val_mae: 0.0999\n",
      "Epoch 3/100\n",
      "65/65 [==============================] - 44s 672ms/step - loss: 0.0220 - mse: 0.0220 - mae: 0.1167 - val_loss: 0.0045 - val_mse: 0.0045 - val_mae: 0.0631\n",
      "Epoch 4/100\n",
      "65/65 [==============================] - 42s 639ms/step - loss: 0.0088 - mse: 0.0088 - mae: 0.0717 - val_loss: 0.0014 - val_mse: 0.0014 - val_mae: 0.0289\n",
      "Epoch 5/100\n",
      "65/65 [==============================] - 35s 540ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0459 - val_loss: 0.0017 - val_mse: 0.0017 - val_mae: 0.0250\n",
      "Epoch 6/100\n",
      "65/65 [==============================] - 41s 625ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0323 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0167\n",
      "Epoch 7/100\n",
      "65/65 [==============================] - 45s 696ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0250 - val_loss: 0.0014 - val_mse: 0.0014 - val_mae: 0.0183\n",
      "Epoch 8/100\n",
      "65/65 [==============================] - 47s 730ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0220 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0167\n",
      "Epoch 9/100\n",
      "65/65 [==============================] - 52s 799ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0203 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0166\n",
      "Epoch 10/100\n",
      "65/65 [==============================] - 48s 738ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0194 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0162\n",
      "Epoch 11/100\n",
      "65/65 [==============================] - 45s 691ms/step - loss: 9.9415e-04 - mse: 9.9415e-04 - mae: 0.0190 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0161\n",
      "Epoch 12/100\n",
      "65/65 [==============================] - 51s 791ms/step - loss: 9.7174e-04 - mse: 9.7174e-04 - mae: 0.0186 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0161\n",
      "Epoch 13/100\n",
      "65/65 [==============================] - 50s 775ms/step - loss: 9.5711e-04 - mse: 9.5711e-04 - mae: 0.0183 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0162\n",
      "Epoch 14/100\n",
      "65/65 [==============================] - 47s 721ms/step - loss: 9.3170e-04 - mse: 9.3170e-04 - mae: 0.0179 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0162\n",
      "Epoch 15/100\n",
      "65/65 [==============================] - 46s 712ms/step - loss: 9.2348e-04 - mse: 9.2348e-04 - mae: 0.0177 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 16/100\n",
      "65/65 [==============================] - 38s 587ms/step - loss: 9.0760e-04 - mse: 9.0760e-04 - mae: 0.0175 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0161\n",
      "Epoch 17/100\n",
      "65/65 [==============================] - 38s 582ms/step - loss: 9.0213e-04 - mse: 9.0213e-04 - mae: 0.0174 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0161\n",
      "Epoch 18/100\n",
      "65/65 [==============================] - 43s 660ms/step - loss: 8.9646e-04 - mse: 8.9646e-04 - mae: 0.0172 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0165\n",
      "Epoch 19/100\n",
      "65/65 [==============================] - 49s 761ms/step - loss: 8.8651e-04 - mse: 8.8651e-04 - mae: 0.0171 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0164\n",
      "Epoch 20/100\n",
      "65/65 [==============================] - 43s 665ms/step - loss: 8.6665e-04 - mse: 8.6665e-04 - mae: 0.0169 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0163\n",
      "Epoch 21/100\n",
      "65/65 [==============================] - 45s 690ms/step - loss: 8.6371e-04 - mse: 8.6371e-04 - mae: 0.0167 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0162\n",
      "Epoch 22/100\n",
      "65/65 [==============================] - 46s 704ms/step - loss: 8.5519e-04 - mse: 8.5519e-04 - mae: 0.0166 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0159\n",
      "Epoch 23/100\n",
      "65/65 [==============================] - 42s 645ms/step - loss: 8.5150e-04 - mse: 8.5150e-04 - mae: 0.0164 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0159\n",
      "Epoch 24/100\n",
      "65/65 [==============================] - 45s 687ms/step - loss: 8.3733e-04 - mse: 8.3733e-04 - mae: 0.0162 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0159\n",
      "Epoch 25/100\n",
      "65/65 [==============================] - 47s 726ms/step - loss: 8.2373e-04 - mse: 8.2373e-04 - mae: 0.0159 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0158\n",
      "Epoch 26/100\n",
      "65/65 [==============================] - 40s 621ms/step - loss: 8.1399e-04 - mse: 8.1399e-04 - mae: 0.0158 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0156\n",
      "Epoch 27/100\n",
      "65/65 [==============================] - 50s 762ms/step - loss: 8.0276e-04 - mse: 8.0276e-04 - mae: 0.0156 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0155\n",
      "Epoch 28/100\n",
      "65/65 [==============================] - 49s 757ms/step - loss: 7.9759e-04 - mse: 7.9759e-04 - mae: 0.0154 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0154\n",
      "Epoch 29/100\n",
      "65/65 [==============================] - 42s 639ms/step - loss: 7.9345e-04 - mse: 7.9345e-04 - mae: 0.0154 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0157\n",
      "Epoch 30/100\n",
      "65/65 [==============================] - 46s 713ms/step - loss: 7.8997e-04 - mse: 7.8997e-04 - mae: 0.0154 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0155\n",
      "Epoch 31/100\n",
      "65/65 [==============================] - 47s 730ms/step - loss: 7.8429e-04 - mse: 7.8429e-04 - mae: 0.0152 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0152\n",
      "Epoch 32/100\n",
      "65/65 [==============================] - 49s 752ms/step - loss: 7.8109e-04 - mse: 7.8109e-04 - mae: 0.0151 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0153\n",
      "Epoch 33/100\n",
      "65/65 [==============================] - 57s 878ms/step - loss: 7.7160e-04 - mse: 7.7160e-04 - mae: 0.0149 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0154\n",
      "Epoch 34/100\n",
      "65/65 [==============================] - 53s 811ms/step - loss: 7.7526e-04 - mse: 7.7526e-04 - mae: 0.0149 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0155\n",
      "Epoch 35/100\n",
      "65/65 [==============================] - 54s 837ms/step - loss: 7.7187e-04 - mse: 7.7187e-04 - mae: 0.0150 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0154\n",
      "Epoch 36/100\n",
      "65/65 [==============================] - 63s 965ms/step - loss: 7.7137e-04 - mse: 7.7137e-04 - mae: 0.0149 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0151\n",
      "Epoch 37/100\n",
      "65/65 [==============================] - 54s 824ms/step - loss: 7.6565e-04 - mse: 7.6565e-04 - mae: 0.0148 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0153\n",
      "Epoch 38/100\n",
      "65/65 [==============================] - 52s 798ms/step - loss: 7.6799e-04 - mse: 7.6799e-04 - mae: 0.0148 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0152\n",
      "Epoch 39/100\n",
      "65/65 [==============================] - 54s 831ms/step - loss: 7.6776e-04 - mse: 7.6776e-04 - mae: 0.0148 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0157\n",
      "Epoch 40/100\n",
      "65/65 [==============================] - 53s 822ms/step - loss: 7.6519e-04 - mse: 7.6519e-04 - mae: 0.0147 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0152\n",
      "Epoch 41/100\n",
      "65/65 [==============================] - 53s 822ms/step - loss: 7.6409e-04 - mse: 7.6409e-04 - mae: 0.0148 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0154\n",
      "Epoch 42/100\n",
      "65/65 [==============================] - 58s 890ms/step - loss: 7.5955e-04 - mse: 7.5955e-04 - mae: 0.0147 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0149\n",
      "Epoch 43/100\n",
      "65/65 [==============================] - 51s 783ms/step - loss: 7.5948e-04 - mse: 7.5948e-04 - mae: 0.0147 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0154\n",
      "Epoch 44/100\n",
      "65/65 [==============================] - 54s 835ms/step - loss: 7.5985e-04 - mse: 7.5985e-04 - mae: 0.0146 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0154\n",
      "Epoch 45/100\n",
      "65/65 [==============================] - 57s 873ms/step - loss: 7.5688e-04 - mse: 7.5688e-04 - mae: 0.0146 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0154\n",
      "Epoch 46/100\n",
      "65/65 [==============================] - 49s 754ms/step - loss: 7.4958e-04 - mse: 7.4958e-04 - mae: 0.0146 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0150\n",
      "Epoch 47/100\n",
      "65/65 [==============================] - 53s 812ms/step - loss: 7.5758e-04 - mse: 7.5758e-04 - mae: 0.0146 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0153\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 47s 729ms/step - loss: 7.4871e-04 - mse: 7.4871e-04 - mae: 0.0145 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0153\n",
      "Epoch 49/100\n",
      "65/65 [==============================] - 48s 736ms/step - loss: 7.4648e-04 - mse: 7.4648e-04 - mae: 0.0144 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0148\n",
      "Epoch 50/100\n",
      "65/65 [==============================] - 51s 788ms/step - loss: 7.4601e-04 - mse: 7.4601e-04 - mae: 0.0144 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0150\n",
      "Epoch 51/100\n",
      "65/65 [==============================] - 56s 864ms/step - loss: 7.4970e-04 - mse: 7.4970e-04 - mae: 0.0144 - val_loss: 9.9914e-04 - val_mse: 9.9914e-04 - val_mae: 0.0154\n",
      "Epoch 52/100\n",
      "65/65 [==============================] - 57s 880ms/step - loss: 7.4583e-04 - mse: 7.4583e-04 - mae: 0.0144 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0150\n",
      "Epoch 53/100\n",
      "65/65 [==============================] - 51s 781ms/step - loss: 7.4167e-04 - mse: 7.4167e-04 - mae: 0.0143 - val_loss: 9.9699e-04 - val_mse: 9.9699e-04 - val_mae: 0.0150\n",
      "Epoch 54/100\n",
      "65/65 [==============================] - 51s 777ms/step - loss: 7.4151e-04 - mse: 7.4151e-04 - mae: 0.0143 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0149\n",
      "Epoch 55/100\n",
      "65/65 [==============================] - 51s 781ms/step - loss: 7.4567e-04 - mse: 7.4567e-04 - mae: 0.0143 - val_loss: 9.8559e-04 - val_mse: 9.8559e-04 - val_mae: 0.0148\n",
      "Epoch 56/100\n",
      "65/65 [==============================] - 51s 790ms/step - loss: 7.4288e-04 - mse: 7.4288e-04 - mae: 0.0144 - val_loss: 9.8844e-04 - val_mse: 9.8844e-04 - val_mae: 0.0149\n",
      "Epoch 57/100\n",
      "65/65 [==============================] - 49s 761ms/step - loss: 7.3534e-04 - mse: 7.3534e-04 - mae: 0.0143 - val_loss: 9.8183e-04 - val_mse: 9.8183e-04 - val_mae: 0.0154\n",
      "Epoch 58/100\n",
      "65/65 [==============================] - 52s 797ms/step - loss: 7.3809e-04 - mse: 7.3809e-04 - mae: 0.0142 - val_loss: 9.8616e-04 - val_mse: 9.8616e-04 - val_mae: 0.0146\n",
      "Epoch 59/100\n",
      "65/65 [==============================] - 45s 695ms/step - loss: 7.3194e-04 - mse: 7.3194e-04 - mae: 0.0142 - val_loss: 9.7066e-04 - val_mse: 9.7066e-04 - val_mae: 0.0146\n",
      "Epoch 60/100\n",
      "65/65 [==============================] - 47s 729ms/step - loss: 7.3730e-04 - mse: 7.3730e-04 - mae: 0.0142 - val_loss: 9.7960e-04 - val_mse: 9.7960e-04 - val_mae: 0.0146\n",
      "Epoch 61/100\n",
      "65/65 [==============================] - 44s 679ms/step - loss: 7.3396e-04 - mse: 7.3396e-04 - mae: 0.0142 - val_loss: 9.6438e-04 - val_mse: 9.6438e-04 - val_mae: 0.0146\n",
      "Epoch 62/100\n",
      "65/65 [==============================] - 46s 706ms/step - loss: 7.3281e-04 - mse: 7.3281e-04 - mae: 0.0141 - val_loss: 9.5979e-04 - val_mse: 9.5979e-04 - val_mae: 0.0145\n",
      "Epoch 63/100\n",
      "65/65 [==============================] - 45s 693ms/step - loss: 7.3369e-04 - mse: 7.3369e-04 - mae: 0.0141 - val_loss: 9.5850e-04 - val_mse: 9.5850e-04 - val_mae: 0.0145\n",
      "Epoch 64/100\n",
      "65/65 [==============================] - 46s 714ms/step - loss: 7.3140e-04 - mse: 7.3140e-04 - mae: 0.0141 - val_loss: 9.5296e-04 - val_mse: 9.5296e-04 - val_mae: 0.0145\n",
      "Epoch 65/100\n",
      "65/65 [==============================] - 46s 711ms/step - loss: 7.3058e-04 - mse: 7.3058e-04 - mae: 0.0140 - val_loss: 9.5280e-04 - val_mse: 9.5280e-04 - val_mae: 0.0145\n",
      "Epoch 66/100\n",
      "65/65 [==============================] - 43s 667ms/step - loss: 7.2626e-04 - mse: 7.2626e-04 - mae: 0.0141 - val_loss: 9.5811e-04 - val_mse: 9.5811e-04 - val_mae: 0.0145\n",
      "Epoch 67/100\n",
      "65/65 [==============================] - 45s 690ms/step - loss: 7.2092e-04 - mse: 7.2092e-04 - mae: 0.0139 - val_loss: 9.9421e-04 - val_mse: 9.9421e-04 - val_mae: 0.0145\n",
      "Epoch 68/100\n",
      "65/65 [==============================] - 43s 664ms/step - loss: 7.2324e-04 - mse: 7.2324e-04 - mae: 0.0139 - val_loss: 9.6335e-04 - val_mse: 9.6335e-04 - val_mae: 0.0146\n",
      "Epoch 69/100\n",
      "65/65 [==============================] - 43s 662ms/step - loss: 7.2240e-04 - mse: 7.2240e-04 - mae: 0.0140 - val_loss: 9.4965e-04 - val_mse: 9.4965e-04 - val_mae: 0.0147\n",
      "Epoch 70/100\n",
      "65/65 [==============================] - 45s 686ms/step - loss: 7.3050e-04 - mse: 7.3050e-04 - mae: 0.0140 - val_loss: 9.2307e-04 - val_mse: 9.2307e-04 - val_mae: 0.0145\n",
      "Epoch 71/100\n",
      "65/65 [==============================] - 42s 654ms/step - loss: 7.2431e-04 - mse: 7.2431e-04 - mae: 0.0140 - val_loss: 9.2532e-04 - val_mse: 9.2532e-04 - val_mae: 0.0144\n",
      "Epoch 72/100\n",
      "65/65 [==============================] - 45s 699ms/step - loss: 7.2050e-04 - mse: 7.2050e-04 - mae: 0.0138 - val_loss: 9.1956e-04 - val_mse: 9.1956e-04 - val_mae: 0.0143\n",
      "Epoch 73/100\n",
      "65/65 [==============================] - 45s 690ms/step - loss: 7.1326e-04 - mse: 7.1326e-04 - mae: 0.0138 - val_loss: 9.2173e-04 - val_mse: 9.2173e-04 - val_mae: 0.0147\n",
      "Epoch 74/100\n",
      "65/65 [==============================] - 43s 665ms/step - loss: 7.1554e-04 - mse: 7.1554e-04 - mae: 0.0138 - val_loss: 9.2619e-04 - val_mse: 9.2619e-04 - val_mae: 0.0145\n",
      "Epoch 75/100\n",
      "65/65 [==============================] - 46s 713ms/step - loss: 7.1269e-04 - mse: 7.1269e-04 - mae: 0.0138 - val_loss: 9.2289e-04 - val_mse: 9.2289e-04 - val_mae: 0.0140\n",
      "Epoch 76/100\n",
      "65/65 [==============================] - 44s 683ms/step - loss: 7.0742e-04 - mse: 7.0742e-04 - mae: 0.0137 - val_loss: 9.1817e-04 - val_mse: 9.1817e-04 - val_mae: 0.0141\n",
      "Epoch 77/100\n",
      "65/65 [==============================] - 43s 663ms/step - loss: 7.0771e-04 - mse: 7.0771e-04 - mae: 0.0137 - val_loss: 9.2256e-04 - val_mse: 9.2256e-04 - val_mae: 0.0142\n",
      "Epoch 78/100\n",
      "65/65 [==============================] - 45s 695ms/step - loss: 7.0966e-04 - mse: 7.0966e-04 - mae: 0.0137 - val_loss: 9.1361e-04 - val_mse: 9.1361e-04 - val_mae: 0.0144\n",
      "Epoch 79/100\n",
      "65/65 [==============================] - 44s 674ms/step - loss: 7.0053e-04 - mse: 7.0053e-04 - mae: 0.0135 - val_loss: 9.0659e-04 - val_mse: 9.0659e-04 - val_mae: 0.0141\n",
      "Epoch 80/100\n",
      "65/65 [==============================] - 44s 672ms/step - loss: 7.0712e-04 - mse: 7.0712e-04 - mae: 0.0136 - val_loss: 9.1216e-04 - val_mse: 9.1216e-04 - val_mae: 0.0142\n",
      "Epoch 81/100\n",
      "65/65 [==============================] - 44s 678ms/step - loss: 7.0214e-04 - mse: 7.0214e-04 - mae: 0.0136 - val_loss: 9.2844e-04 - val_mse: 9.2844e-04 - val_mae: 0.0141\n",
      "Epoch 82/100\n",
      "65/65 [==============================] - 46s 711ms/step - loss: 7.0223e-04 - mse: 7.0223e-04 - mae: 0.0137 - val_loss: 8.6678e-04 - val_mse: 8.6678e-04 - val_mae: 0.0140\n",
      "Epoch 83/100\n",
      "65/65 [==============================] - 47s 725ms/step - loss: 6.9856e-04 - mse: 6.9856e-04 - mae: 0.0135 - val_loss: 9.0456e-04 - val_mse: 9.0456e-04 - val_mae: 0.0141\n",
      "Epoch 84/100\n",
      "65/65 [==============================] - 45s 692ms/step - loss: 6.9961e-04 - mse: 6.9961e-04 - mae: 0.0135 - val_loss: 9.3050e-04 - val_mse: 9.3050e-04 - val_mae: 0.0140\n",
      "Epoch 85/100\n",
      "65/65 [==============================] - 46s 701ms/step - loss: 6.9622e-04 - mse: 6.9622e-04 - mae: 0.0135 - val_loss: 8.8142e-04 - val_mse: 8.8142e-04 - val_mae: 0.0141\n",
      "Epoch 86/100\n",
      "65/65 [==============================] - 48s 739ms/step - loss: 6.9762e-04 - mse: 6.9762e-04 - mae: 0.0135 - val_loss: 8.6143e-04 - val_mse: 8.6143e-04 - val_mae: 0.0139\n",
      "Epoch 87/100\n",
      "65/65 [==============================] - 46s 711ms/step - loss: 6.9480e-04 - mse: 6.9480e-04 - mae: 0.0133 - val_loss: 8.9247e-04 - val_mse: 8.9247e-04 - val_mae: 0.0140\n",
      "Epoch 88/100\n",
      "65/65 [==============================] - 46s 707ms/step - loss: 6.9342e-04 - mse: 6.9342e-04 - mae: 0.0134 - val_loss: 8.7458e-04 - val_mse: 8.7458e-04 - val_mae: 0.0137\n",
      "Epoch 89/100\n",
      "65/65 [==============================] - 45s 693ms/step - loss: 6.9297e-04 - mse: 6.9297e-04 - mae: 0.0134 - val_loss: 8.7457e-04 - val_mse: 8.7457e-04 - val_mae: 0.0139\n",
      "Epoch 90/100\n",
      "65/65 [==============================] - 44s 683ms/step - loss: 6.8687e-04 - mse: 6.8687e-04 - mae: 0.0133 - val_loss: 8.7237e-04 - val_mse: 8.7237e-04 - val_mae: 0.0136\n",
      "Epoch 91/100\n",
      "65/65 [==============================] - 45s 699ms/step - loss: 6.8869e-04 - mse: 6.8869e-04 - mae: 0.0133 - val_loss: 8.6190e-04 - val_mse: 8.6190e-04 - val_mae: 0.0138\n",
      "Epoch 92/100\n",
      "65/65 [==============================] - 44s 670ms/step - loss: 6.8284e-04 - mse: 6.8284e-04 - mae: 0.0133 - val_loss: 8.8725e-04 - val_mse: 8.8725e-04 - val_mae: 0.0141\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 45s 685ms/step - loss: 6.8773e-04 - mse: 6.8773e-04 - mae: 0.0134 - val_loss: 8.8298e-04 - val_mse: 8.8298e-04 - val_mae: 0.0140\n",
      "Epoch 94/100\n",
      "65/65 [==============================] - 45s 688ms/step - loss: 6.8580e-04 - mse: 6.8580e-04 - mae: 0.0133 - val_loss: 8.9950e-04 - val_mse: 8.9950e-04 - val_mae: 0.0140\n",
      "Epoch 95/100\n",
      "65/65 [==============================] - 44s 669ms/step - loss: 6.8115e-04 - mse: 6.8115e-04 - mae: 0.0133 - val_loss: 8.6875e-04 - val_mse: 8.6875e-04 - val_mae: 0.0140\n",
      "Epoch 96/100\n",
      "65/65 [==============================] - 45s 693ms/step - loss: 6.7563e-04 - mse: 6.7563e-04 - mae: 0.0132 - val_loss: 8.7497e-04 - val_mse: 8.7497e-04 - val_mae: 0.0140\n",
      "Epoch 97/100\n",
      "65/65 [==============================] - 44s 679ms/step - loss: 6.7819e-04 - mse: 6.7819e-04 - mae: 0.0132 - val_loss: 8.6331e-04 - val_mse: 8.6331e-04 - val_mae: 0.0139\n",
      "Epoch 98/100\n",
      "65/65 [==============================] - 45s 685ms/step - loss: 6.7210e-04 - mse: 6.7210e-04 - mae: 0.0131 - val_loss: 8.8845e-04 - val_mse: 8.8845e-04 - val_mae: 0.0139\n",
      "Epoch 99/100\n",
      "65/65 [==============================] - 46s 713ms/step - loss: 6.6611e-04 - mse: 6.6611e-04 - mae: 0.0131 - val_loss: 9.0367e-04 - val_mse: 9.0367e-04 - val_mae: 0.0136\n",
      "Epoch 100/100\n",
      "65/65 [==============================] - 46s 711ms/step - loss: 6.7216e-04 - mse: 6.7216e-04 - mae: 0.0132 - val_loss: 8.5209e-04 - val_mse: 8.5209e-04 - val_mae: 0.0137\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,\n",
    "                    y_train, \n",
    "                    batch_size = batch_size, \n",
    "                    epochs = epochs,\n",
    "                    shuffle = False, \n",
    "                    validation_data = (X_val, y_val))\n",
    "    \n",
    "# required before predicitons\n",
    "model.reset_states()\n",
    "    \n",
    "y_pred = model.predict(X_test, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cannot use inverse function; prices col = 14\n",
    "y_pred = (y_pred * sc_X.data_range_[14]) + (sc_X.data_min_[14])\n",
    "y_test = (y_test * sc_X.data_range_[14]) + (sc_X.data_min_[14])\n",
    "\n",
    "# Reshaping\n",
    "y_pred = np.reshape(y_pred, (y_pred.shape[0]))\n",
    "\n",
    "# =============================================================================\n",
    "# METRICS EVALUATION (1) for the whole test set\n",
    "# =============================================================================\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "\n",
    "# calculate metrics\n",
    "rmse_error = mse(y_test, y_pred, squared = False)\n",
    "mae_error = mae(y_test, y_pred)\n",
    "\n",
    "# append to list\n",
    "rmse_gen.append(rmse_error)\n",
    "mae_gen.append(mae_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Need to process data with spike occurences in the same way as features and offers:\n",
    "(Required to evaluate predictions in both normal regions and spike regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data for shaded area\n",
    "data = pd.read_csv('Spike_binary_1std.csv', index_col = 0)\n",
    "\n",
    "# set predictive window according with tuning best results\n",
    "data = data.loc[data.index > date, :]\n",
    "\n",
    "# make sure shaded area will correspond to values outputed by LSTM\n",
    "data.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# fill_nan is already made - so lets split data into test and train\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# divide data into train and test \n",
    "shade_train, shade_test = train_test_split(\n",
    "         data, test_size = 0.15, shuffle = False)\n",
    "\n",
    "# reset index of testing data\n",
    "shade_test.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# function to split data into correct shape for RNN\n",
    "def split_data(shade_test, steps):\n",
    "    y_spike_occ = list()\n",
    "    upper_lim = list()\n",
    "    lower_lim = list()\n",
    "    for i in range(steps, len(shade_test.index)):\n",
    "        y_spike_occ.append(shade_test['spike_occurance'][i])\n",
    "        upper_lim.append(shade_test['spike_upperlim'][i])\n",
    "        lower_lim.append(shade_test['spike_lowerlim'][i])\n",
    "    return np.array(y_spike_occ), np.array(upper_lim), np.array(lower_lim)\n",
    "\n",
    "# function to cut data set so it can be divisible by the batch_size\n",
    "def cut_data(data, batch_size):\n",
    "     # see if it is divisivel\n",
    "    condition = data.shape[0] % batch_size\n",
    "    if condition == 0:\n",
    "        return data\n",
    "    else:\n",
    "        return data[: -condition]\n",
    "\n",
    "y_spike_occ, spike_upperlim, spike_lowerlim = split_data(shade_test, steps)\n",
    "y_spike_occ = cut_data(y_spike_occ, batch_size)\n",
    "spike_upperlim = cut_data(spike_upperlim, batch_size)\n",
    "spike_lowerlim = cut_data(spike_lowerlim, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate on spike and normal regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# METRICS EVALUATION (2) on spike regions\n",
    "# =============================================================================\n",
    "\n",
    "# smal adjustment\n",
    "#y_test.replace(0, 0.0001,inplace = True)\n",
    "\n",
    "# select y_pred and y_test only for regions with spikes\n",
    "y_test_spike = (y_test.T * y_spike_occ).T\n",
    "y_pred_spike = (y_pred.T * y_spike_occ).T\n",
    "y_test_spike = y_test_spike[y_test_spike != 0]\n",
    "y_pred_spike = y_pred_spike[y_pred_spike != 0]\n",
    "\n",
    "# calculate metric\n",
    "rmse_spike = mse(y_test_spike, y_pred_spike, squared = False)\n",
    "mae_spike = mae(y_test_spike, y_pred_spike)\n",
    "\n",
    "# append ot lists\n",
    "rmse_spi.append(rmse_spike)\n",
    "mae_spi.append(mae_spike)\n",
    "\n",
    "# =============================================================================\n",
    "# METRIC EVALUATION (3) on normal regions\n",
    "# =============================================================================\n",
    "\n",
    "# inverse y_spike_occ so the only normal occurences are chosen\n",
    "y_normal_occ = (y_spike_occ - 1) * (-1)\n",
    "\n",
    "# sanity check\n",
    "y_normal_occ.sum() + y_spike_occ.sum() # gives the correct total \n",
    "\n",
    "# select y_pred and y_test only for normal regions\n",
    "y_test_normal = (y_test.T * y_normal_occ).T\n",
    "y_pred_normal = (y_pred.T * y_normal_occ).T\n",
    "y_test_normal = y_test_normal[y_test_normal != 0.00]\n",
    "y_pred_normal = y_pred_normal[y_pred_normal != 0.00]\n",
    "\n",
    "# calculate metric\n",
    "rmse_normal = mse(y_test_normal, y_pred_normal, squared = False)\n",
    "mae_normal = mae(y_test_normal, y_pred_normal)\n",
    "\n",
    "# append to list\n",
    "rmse_nor.append(rmse_normal)\n",
    "mae_nor.append(mae_normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now evaluate predictions on Spike & Normal regions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save y_pred & spike limits to plot with Stateless LSTM\n",
    "datasave = pd.DataFrame({'y_pred': y_pred,\n",
    "                         'y_test':y_test,\n",
    "                         'spike_upperlim':spike_upperlim,\n",
    "                         'spike_lowerlim':spike_lowerlim})\n",
    "\n",
    "datasave.to_csv('LSTM_plot_Stateless_6m.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse_general</th>\n",
       "      <th>mae_general</th>\n",
       "      <th>rmse_spike</th>\n",
       "      <th>mae_spike</th>\n",
       "      <th>rmse_normal</th>\n",
       "      <th>mae_normal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29.507019</td>\n",
       "      <td>16.921611</td>\n",
       "      <td>61.626203</td>\n",
       "      <td>46.699398</td>\n",
       "      <td>20.469089</td>\n",
       "      <td>12.326642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rmse_general  mae_general  rmse_spike  mae_spike  rmse_normal  mae_normal\n",
       "0     29.507019    16.921611   61.626203  46.699398    20.469089   12.326642"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({'rmse_general': rmse_gen, \n",
    "                 \n",
    "                        'mae_general': mae_gen,\n",
    "                        \n",
    "                        'rmse_spike': rmse_spi,\n",
    "                 \n",
    "                        'mae_spike': mae_spi,\n",
    "                        \n",
    "                        'rmse_normal': rmse_nor,\n",
    "                    \n",
    "                        'mae_normal': mae_nor})\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
