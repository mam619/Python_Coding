{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in c:\\users\\maria\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\maria\\anaconda3\\lib\\site-packages (from sklearn) (0.22.1)\n",
      "Requirement already satisfied: scipy>=0.17.0 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.11.0 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.18.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (0.14.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\maria\\anaconda3\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from pandas) (1.18.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from python-dateutil>=2.6.1->pandas) (1.14.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\maria\\anaconda3\\lib\\site-packages (3.1.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from matplotlib) (2.4.6)\n",
      "Requirement already satisfied: numpy>=1.11 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from matplotlib) (1.18.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: six in c:\\users\\maria\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib) (1.14.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\maria\\anaconda3\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib) (45.2.0.post20200210)\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn\n",
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# empty list to append metric values\n",
    "mae_gen = []\n",
    "mae_nor = []\n",
    "mae_spi = []\n",
    "rmse_gen = []\n",
    "rmse_nor = []\n",
    "rmse_spi = []\n",
    "\n",
    "# parameters\n",
    "steps = 96\n",
    "n_hidden = 1\n",
    "units = 150\n",
    "batch_size = 96\n",
    "epochs = 100\n",
    "\n",
    "# months to evaluate model on\n",
    "date = 2018090000\n",
    "\n",
    "# for later use\n",
    "features_num = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Data_set_1_smaller_(1).csv', index_col = 0)\n",
    "\n",
    "# set predictive window according with tuning best results\n",
    "data = data.loc[data.index > date, :]\n",
    "\n",
    "# reset index\n",
    "data.reset_index(inplace = True)\n",
    "data.drop('index', axis = 1, inplace = True)\n",
    "\n",
    "# fill nan values in the whole data set\n",
    "data.fillna(data.mean(), inplace = True)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# divide data into train and test \n",
    "data_train, data_test = train_test_split(\n",
    "         data, test_size = 0.15, shuffle=False)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# data scaling  (including offer (y))\n",
    "sc_X = MinMaxScaler()\n",
    "data_train = sc_X.fit_transform(data_train)\n",
    "data_test = sc_X.transform(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Required functions to put data into required shape for LSTM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to split data into correct shape for RNN\n",
    "def split_data(X, y, steps):\n",
    "    X_, y_ = list(), list()\n",
    "    for i in range(steps, len(y)):\n",
    "        X_.append(X[i - steps : i, :])\n",
    "        y_.append(y[i]) \n",
    "    return np.array(X_), np.array(y_)\n",
    "\n",
    "# function to cut data set so it can be divisible by the batch_size\n",
    "def cut_data(data, batch_size):\n",
    "     # see if it is divisivel\n",
    "    condition = data.shape[0] % batch_size\n",
    "    if condition == 0:\n",
    "        return data\n",
    "    else:\n",
    "        return data[: -condition]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up X and y for train, test and val into correct shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide features and labels\n",
    "X_train = data_train[:, 0:14] \n",
    "y_train = data_train[:, -1]\n",
    "X_test = data_test[:, 0:14]\n",
    "y_test = data_test[:, -1] \n",
    "\n",
    "# divide data into validation and normal test \n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train, y_train, test_size = 0.15, shuffle=False)\n",
    "\n",
    "# put data into correct shape\n",
    "X_train, y_train = split_data(X_train, y_train, steps)\n",
    "X_test, y_test = split_data(X_test, y_test, steps)\n",
    "X_val, y_val = split_data(X_val, y_val, steps)\n",
    "\n",
    "# cut data\n",
    "X_train = cut_data(X_train, batch_size)\n",
    "y_train = cut_data(y_train, batch_size)\n",
    "X_test = cut_data(X_test, batch_size)\n",
    "y_test = cut_data(y_test, batch_size)\n",
    "X_val = cut_data(X_val, batch_size)\n",
    "y_val = cut_data(y_val, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LeakyReLU\n",
    "from keras import initializers\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Design LSTM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regressor_tunning(kernel_initializer = 'he_uniform',\n",
    "                      bias_initializer = initializers.Ones()):\n",
    "    model = Sequential()\n",
    "    if n_hidden == 1:\n",
    "        model.add(LSTM(units = units,                    \n",
    "                       batch_input_shape = (batch_size, steps, features_num), \n",
    "                       stateful = True,\n",
    "                       kernel_initializer = kernel_initializer,\n",
    "                       bias_initializer = bias_initializer))\n",
    "        model.add(LeakyReLU(alpha = 0.2))\n",
    "        model.add(Dropout(0.2))\n",
    "    else:\n",
    "        model.add(LSTM(units = units,                    \n",
    "                       batch_input_shape = (batch_size, steps, features_num), \n",
    "                       stateful = True,\n",
    "                       return_sequences = True,\n",
    "                       kernel_initializer = kernel_initializer,\n",
    "                       bias_initializer = bias_initializer))\n",
    "        model.add(LeakyReLU(alpha = 0.2))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(LSTM(units = units, \n",
    "                       batch_input_shape = (batch_size, steps, features_num), \n",
    "                       stateful = True,\n",
    "                       kernel_initializer = kernel_initializer,\n",
    "                       bias_initializer = bias_initializer))\n",
    "        model.add(LeakyReLU(alpha = 0.2))\n",
    "        model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    optimizer = optimizers.RMSprop()\n",
    "    model.compile(loss = 'mse', metrics = ['mse', 'mae'], optimizer = optimizer)\n",
    "    return model\n",
    "\n",
    "model = regressor_tunning()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "43/43 [==============================] - 32s 750ms/step - loss: 0.3126 - mse: 0.3126 - mae: 0.3781 - val_loss: 0.0182 - val_mse: 0.0182 - val_mae: 0.1333\n",
      "Epoch 2/100\n",
      "43/43 [==============================] - 28s 656ms/step - loss: 0.1080 - mse: 0.1080 - mae: 0.2620 - val_loss: 0.0101 - val_mse: 0.0101 - val_mae: 0.0979\n",
      "Epoch 3/100\n",
      "43/43 [==============================] - 26s 613ms/step - loss: 0.0587 - mse: 0.0587 - mae: 0.1914 - val_loss: 5.3386e-04 - val_mse: 5.3386e-04 - val_mae: 0.0134\n",
      "Epoch 4/100\n",
      "43/43 [==============================] - 27s 618ms/step - loss: 0.0318 - mse: 0.0318 - mae: 0.1418 - val_loss: 6.2931e-04 - val_mse: 6.2931e-04 - val_mae: 0.0219\n",
      "Epoch 5/100\n",
      "43/43 [==============================] - 26s 601ms/step - loss: 0.0185 - mse: 0.0185 - mae: 0.1078 - val_loss: 0.0016 - val_mse: 0.0016 - val_mae: 0.0345\n",
      "Epoch 6/100\n",
      "43/43 [==============================] - 26s 606ms/step - loss: 0.0093 - mse: 0.0093 - mae: 0.0746 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0558\n",
      "Epoch 7/100\n",
      "43/43 [==============================] - 26s 603ms/step - loss: 0.0061 - mse: 0.0061 - mae: 0.0602 - val_loss: 5.5633e-04 - val_mse: 5.5633e-04 - val_mae: 0.0124\n",
      "Epoch 8/100\n",
      "43/43 [==============================] - 26s 599ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0457 - val_loss: 0.0021 - val_mse: 0.0021 - val_mae: 0.0443\n",
      "Epoch 9/100\n",
      "43/43 [==============================] - 25s 580ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0382 - val_loss: 5.3568e-04 - val_mse: 5.3568e-04 - val_mae: 0.0188\n",
      "Epoch 10/100\n",
      "43/43 [==============================] - 26s 598ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0294 - val_loss: 4.8356e-04 - val_mse: 4.8356e-04 - val_mae: 0.0148\n",
      "Epoch 11/100\n",
      "43/43 [==============================] - 26s 607ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0260 - val_loss: 4.8607e-04 - val_mse: 4.8607e-04 - val_mae: 0.0156\n",
      "Epoch 12/100\n",
      "43/43 [==============================] - 27s 637ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0234 - val_loss: 4.8086e-04 - val_mse: 4.8086e-04 - val_mae: 0.0148\n",
      "Epoch 13/100\n",
      "43/43 [==============================] - 26s 605ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0221 - val_loss: 4.8285e-04 - val_mse: 4.8285e-04 - val_mae: 0.0133\n",
      "Epoch 14/100\n",
      "43/43 [==============================] - 26s 613ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0211 - val_loss: 4.7674e-04 - val_mse: 4.7674e-04 - val_mae: 0.0133\n",
      "Epoch 15/100\n",
      "43/43 [==============================] - 29s 671ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0203 - val_loss: 4.6935e-04 - val_mse: 4.6935e-04 - val_mae: 0.0135\n",
      "Epoch 16/100\n",
      "43/43 [==============================] - 29s 670ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0199 - val_loss: 4.6908e-04 - val_mse: 4.6908e-04 - val_mae: 0.0128\n",
      "Epoch 17/100\n",
      "43/43 [==============================] - 27s 627ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0194 - val_loss: 4.6375e-04 - val_mse: 4.6375e-04 - val_mae: 0.0125\n",
      "Epoch 18/100\n",
      "43/43 [==============================] - 27s 631ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0190 - val_loss: 4.5413e-04 - val_mse: 4.5413e-04 - val_mae: 0.0126\n",
      "Epoch 19/100\n",
      "43/43 [==============================] - 28s 643ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0191 - val_loss: 4.4845e-04 - val_mse: 4.4845e-04 - val_mae: 0.0123\n",
      "Epoch 20/100\n",
      "43/43 [==============================] - 29s 668ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0184 - val_loss: 4.3903e-04 - val_mse: 4.3903e-04 - val_mae: 0.0124\n",
      "Epoch 21/100\n",
      "43/43 [==============================] - 29s 667ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0182 - val_loss: 4.3601e-04 - val_mse: 4.3601e-04 - val_mae: 0.0120\n",
      "Epoch 22/100\n",
      "43/43 [==============================] - 28s 652ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0181 - val_loss: 4.2902e-04 - val_mse: 4.2902e-04 - val_mae: 0.0118\n",
      "Epoch 23/100\n",
      "43/43 [==============================] - 33s 760ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0178 - val_loss: 4.1011e-04 - val_mse: 4.1011e-04 - val_mae: 0.0121\n",
      "Epoch 24/100\n",
      "43/43 [==============================] - 32s 733ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0178 - val_loss: 4.0707e-04 - val_mse: 4.0707e-04 - val_mae: 0.0117\n",
      "Epoch 25/100\n",
      "43/43 [==============================] - 34s 799ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0174 - val_loss: 3.9755e-04 - val_mse: 3.9755e-04 - val_mae: 0.0115\n",
      "Epoch 26/100\n",
      "43/43 [==============================] - 30s 706ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0172 - val_loss: 3.8312e-04 - val_mse: 3.8312e-04 - val_mae: 0.0118\n",
      "Epoch 27/100\n",
      "43/43 [==============================] - 30s 690ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0171 - val_loss: 3.8134e-04 - val_mse: 3.8134e-04 - val_mae: 0.0118\n",
      "Epoch 28/100\n",
      "43/43 [==============================] - 30s 693ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0169 - val_loss: 3.7992e-04 - val_mse: 3.7992e-04 - val_mae: 0.0113\n",
      "Epoch 29/100\n",
      "43/43 [==============================] - 32s 749ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0169 - val_loss: 3.6676e-04 - val_mse: 3.6676e-04 - val_mae: 0.0113\n",
      "Epoch 30/100\n",
      "43/43 [==============================] - 33s 767ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0165 - val_loss: 3.5924e-04 - val_mse: 3.5924e-04 - val_mae: 0.0114\n",
      "Epoch 31/100\n",
      "43/43 [==============================] - 31s 724ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0165 - val_loss: 3.5840e-04 - val_mse: 3.5840e-04 - val_mae: 0.0108\n",
      "Epoch 32/100\n",
      "43/43 [==============================] - 29s 684ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0162 - val_loss: 3.6433e-04 - val_mse: 3.6433e-04 - val_mae: 0.0107\n",
      "Epoch 33/100\n",
      "43/43 [==============================] - 29s 671ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0164 - val_loss: 3.4250e-04 - val_mse: 3.4250e-04 - val_mae: 0.0106\n",
      "Epoch 34/100\n",
      "43/43 [==============================] - 29s 676ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0160 - val_loss: 3.5008e-04 - val_mse: 3.5008e-04 - val_mae: 0.0109\n",
      "Epoch 35/100\n",
      "43/43 [==============================] - 28s 658ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0159 - val_loss: 3.5420e-04 - val_mse: 3.5420e-04 - val_mae: 0.0108\n",
      "Epoch 36/100\n",
      "43/43 [==============================] - 30s 686ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0160 - val_loss: 3.4653e-04 - val_mse: 3.4653e-04 - val_mae: 0.0107\n",
      "Epoch 37/100\n",
      "43/43 [==============================] - 29s 669ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0159 - val_loss: 3.2893e-04 - val_mse: 3.2893e-04 - val_mae: 0.0103\n",
      "Epoch 38/100\n",
      "43/43 [==============================] - 29s 664ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0158 - val_loss: 3.3457e-04 - val_mse: 3.3457e-04 - val_mae: 0.0108\n",
      "Epoch 39/100\n",
      "43/43 [==============================] - 28s 654ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0155 - val_loss: 3.3178e-04 - val_mse: 3.3178e-04 - val_mae: 0.0102\n",
      "Epoch 40/100\n",
      "43/43 [==============================] - 29s 675ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0158 - val_loss: 3.1874e-04 - val_mse: 3.1874e-04 - val_mae: 0.0101\n",
      "Epoch 41/100\n",
      "43/43 [==============================] - 29s 666ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0154 - val_loss: 3.1568e-04 - val_mse: 3.1568e-04 - val_mae: 0.0101\n",
      "Epoch 42/100\n",
      "43/43 [==============================] - 27s 639ms/step - loss: 9.9484e-04 - mse: 9.9484e-04 - mae: 0.0153 - val_loss: 3.2830e-04 - val_mse: 3.2830e-04 - val_mae: 0.0104\n",
      "Epoch 43/100\n",
      "43/43 [==============================] - 29s 677ms/step - loss: 9.9310e-04 - mse: 9.9310e-04 - mae: 0.0152 - val_loss: 3.3360e-04 - val_mse: 3.3360e-04 - val_mae: 0.0103\n",
      "Epoch 44/100\n",
      "43/43 [==============================] - 31s 721ms/step - loss: 9.9763e-04 - mse: 9.9763e-04 - mae: 0.0154 - val_loss: 3.2834e-04 - val_mse: 3.2834e-04 - val_mae: 0.0105\n",
      "Epoch 45/100\n",
      "43/43 [==============================] - 28s 653ms/step - loss: 9.7938e-04 - mse: 9.7938e-04 - mae: 0.0151 - val_loss: 3.1323e-04 - val_mse: 3.1323e-04 - val_mae: 0.0103\n",
      "Epoch 46/100\n",
      "43/43 [==============================] - 28s 656ms/step - loss: 9.9655e-04 - mse: 9.9655e-04 - mae: 0.0153 - val_loss: 3.2566e-04 - val_mse: 3.2566e-04 - val_mae: 0.0102\n",
      "Epoch 47/100\n",
      "43/43 [==============================] - 29s 681ms/step - loss: 9.8807e-04 - mse: 9.8807e-04 - mae: 0.0151 - val_loss: 3.1543e-04 - val_mse: 3.1543e-04 - val_mae: 0.0102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/100\n",
      "43/43 [==============================] - 29s 677ms/step - loss: 9.7664e-04 - mse: 9.7664e-04 - mae: 0.0150 - val_loss: 3.1054e-04 - val_mse: 3.1054e-04 - val_mae: 0.0099\n",
      "Epoch 49/100\n",
      "43/43 [==============================] - 28s 652ms/step - loss: 9.6723e-04 - mse: 9.6723e-04 - mae: 0.0148 - val_loss: 2.9835e-04 - val_mse: 2.9835e-04 - val_mae: 0.0104\n",
      "Epoch 50/100\n",
      "43/43 [==============================] - 28s 660ms/step - loss: 9.5443e-04 - mse: 9.5443e-04 - mae: 0.0147 - val_loss: 2.9671e-04 - val_mse: 2.9671e-04 - val_mae: 0.0111\n",
      "Epoch 51/100\n",
      "43/43 [==============================] - 28s 652ms/step - loss: 9.4457e-04 - mse: 9.4457e-04 - mae: 0.0145 - val_loss: 3.0626e-04 - val_mse: 3.0626e-04 - val_mae: 0.0103\n",
      "Epoch 52/100\n",
      "43/43 [==============================] - 28s 658ms/step - loss: 9.5139e-04 - mse: 9.5139e-04 - mae: 0.0147 - val_loss: 2.8798e-04 - val_mse: 2.8798e-04 - val_mae: 0.0098\n",
      "Epoch 53/100\n",
      "43/43 [==============================] - 28s 648ms/step - loss: 9.2179e-04 - mse: 9.2179e-04 - mae: 0.0144 - val_loss: 2.8558e-04 - val_mse: 2.8558e-04 - val_mae: 0.0103\n",
      "Epoch 54/100\n",
      "43/43 [==============================] - 28s 657ms/step - loss: 9.6963e-04 - mse: 9.6963e-04 - mae: 0.0150 - val_loss: 3.0961e-04 - val_mse: 3.0961e-04 - val_mae: 0.0102\n",
      "Epoch 55/100\n",
      "43/43 [==============================] - 29s 668ms/step - loss: 9.4327e-04 - mse: 9.4327e-04 - mae: 0.0145 - val_loss: 3.3156e-04 - val_mse: 3.3156e-04 - val_mae: 0.0101\n",
      "Epoch 56/100\n",
      "43/43 [==============================] - 29s 675ms/step - loss: 9.4077e-04 - mse: 9.4077e-04 - mae: 0.0145 - val_loss: 2.7953e-04 - val_mse: 2.7953e-04 - val_mae: 0.0099\n",
      "Epoch 57/100\n",
      "43/43 [==============================] - 29s 669ms/step - loss: 8.9401e-04 - mse: 8.9401e-04 - mae: 0.0141 - val_loss: 3.2556e-04 - val_mse: 3.2556e-04 - val_mae: 0.0101\n",
      "Epoch 58/100\n",
      "43/43 [==============================] - 29s 669ms/step - loss: 9.0425e-04 - mse: 9.0425e-04 - mae: 0.0143 - val_loss: 2.8657e-04 - val_mse: 2.8657e-04 - val_mae: 0.0106\n",
      "Epoch 59/100\n",
      "43/43 [==============================] - 28s 657ms/step - loss: 9.1686e-04 - mse: 9.1686e-04 - mae: 0.0145 - val_loss: 3.6122e-04 - val_mse: 3.6122e-04 - val_mae: 0.0100\n",
      "Epoch 60/100\n",
      "43/43 [==============================] - 29s 674ms/step - loss: 9.5090e-04 - mse: 9.5090e-04 - mae: 0.0146 - val_loss: 3.0305e-04 - val_mse: 3.0305e-04 - val_mae: 0.0108\n",
      "Epoch 61/100\n",
      "43/43 [==============================] - 29s 674ms/step - loss: 8.7311e-04 - mse: 8.7311e-04 - mae: 0.0139 - val_loss: 3.1892e-04 - val_mse: 3.1892e-04 - val_mae: 0.0105\n",
      "Epoch 62/100\n",
      "43/43 [==============================] - 28s 663ms/step - loss: 9.2057e-04 - mse: 9.2057e-04 - mae: 0.0144 - val_loss: 3.1950e-04 - val_mse: 3.1950e-04 - val_mae: 0.0107\n",
      "Epoch 63/100\n",
      "43/43 [==============================] - 28s 661ms/step - loss: 9.2898e-04 - mse: 9.2898e-04 - mae: 0.0143 - val_loss: 4.6689e-04 - val_mse: 4.6689e-04 - val_mae: 0.0113\n",
      "Epoch 64/100\n",
      "43/43 [==============================] - 28s 663ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0152 - val_loss: 3.1790e-04 - val_mse: 3.1790e-04 - val_mae: 0.0112\n",
      "Epoch 65/100\n",
      "43/43 [==============================] - 28s 650ms/step - loss: 9.2233e-04 - mse: 9.2233e-04 - mae: 0.0147 - val_loss: 2.9660e-04 - val_mse: 2.9660e-04 - val_mae: 0.0100\n",
      "Epoch 66/100\n",
      "43/43 [==============================] - 29s 665ms/step - loss: 8.9266e-04 - mse: 8.9266e-04 - mae: 0.0141 - val_loss: 2.8787e-04 - val_mse: 2.8787e-04 - val_mae: 0.0098\n",
      "Epoch 67/100\n",
      "43/43 [==============================] - 28s 650ms/step - loss: 9.4867e-04 - mse: 9.4867e-04 - mae: 0.0144 - val_loss: 3.4327e-04 - val_mse: 3.4327e-04 - val_mae: 0.0103\n",
      "Epoch 68/100\n",
      "43/43 [==============================] - 28s 658ms/step - loss: 8.8624e-04 - mse: 8.8624e-04 - mae: 0.0141 - val_loss: 2.9551e-04 - val_mse: 2.9551e-04 - val_mae: 0.0113\n",
      "Epoch 69/100\n",
      "43/43 [==============================] - 29s 664ms/step - loss: 9.2981e-04 - mse: 9.2981e-04 - mae: 0.0143 - val_loss: 2.8950e-04 - val_mse: 2.8950e-04 - val_mae: 0.0103\n",
      "Epoch 70/100\n",
      "43/43 [==============================] - 28s 645ms/step - loss: 8.7036e-04 - mse: 8.7036e-04 - mae: 0.0136 - val_loss: 2.8132e-04 - val_mse: 2.8132e-04 - val_mae: 0.0102\n",
      "Epoch 71/100\n",
      "43/43 [==============================] - 28s 643ms/step - loss: 8.6957e-04 - mse: 8.6957e-04 - mae: 0.0139 - val_loss: 4.6835e-04 - val_mse: 4.6835e-04 - val_mae: 0.0115\n",
      "Epoch 72/100\n",
      "43/43 [==============================] - 28s 660ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0153 - val_loss: 3.0805e-04 - val_mse: 3.0805e-04 - val_mae: 0.0115\n",
      "Epoch 73/100\n",
      "43/43 [==============================] - 29s 683ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0154 - val_loss: 2.9012e-04 - val_mse: 2.9012e-04 - val_mae: 0.0098\n",
      "Epoch 74/100\n",
      "43/43 [==============================] - 28s 662ms/step - loss: 9.2016e-04 - mse: 9.2016e-04 - mae: 0.0144 - val_loss: 2.8057e-04 - val_mse: 2.8057e-04 - val_mae: 0.0097\n",
      "Epoch 75/100\n",
      "43/43 [==============================] - 28s 661ms/step - loss: 9.1399e-04 - mse: 9.1399e-04 - mae: 0.0142 - val_loss: 2.7557e-04 - val_mse: 2.7557e-04 - val_mae: 0.0097\n",
      "Epoch 76/100\n",
      "43/43 [==============================] - 28s 651ms/step - loss: 8.8756e-04 - mse: 8.8756e-04 - mae: 0.0140 - val_loss: 3.8445e-04 - val_mse: 3.8445e-04 - val_mae: 0.0105\n",
      "Epoch 77/100\n",
      "43/43 [==============================] - 29s 669ms/step - loss: 9.4075e-04 - mse: 9.4075e-04 - mae: 0.0145 - val_loss: 3.0632e-04 - val_mse: 3.0632e-04 - val_mae: 0.0107\n",
      "Epoch 78/100\n",
      "43/43 [==============================] - 28s 655ms/step - loss: 8.9822e-04 - mse: 8.9822e-04 - mae: 0.0142 - val_loss: 3.8649e-04 - val_mse: 3.8649e-04 - val_mae: 0.0109\n",
      "Epoch 79/100\n",
      "43/43 [==============================] - 28s 655ms/step - loss: 9.3228e-04 - mse: 9.3228e-04 - mae: 0.0143 - val_loss: 2.8632e-04 - val_mse: 2.8632e-04 - val_mae: 0.0109\n",
      "Epoch 80/100\n",
      "43/43 [==============================] - 28s 643ms/step - loss: 8.8678e-04 - mse: 8.8678e-04 - mae: 0.0142 - val_loss: 3.1518e-04 - val_mse: 3.1518e-04 - val_mae: 0.0096\n",
      "Epoch 81/100\n",
      "43/43 [==============================] - 28s 655ms/step - loss: 8.7152e-04 - mse: 8.7152e-04 - mae: 0.0139 - val_loss: 2.8625e-04 - val_mse: 2.8625e-04 - val_mae: 0.0102\n",
      "Epoch 82/100\n",
      "43/43 [==============================] - 27s 618ms/step - loss: 8.9569e-04 - mse: 8.9569e-04 - mae: 0.0138 - val_loss: 3.0440e-04 - val_mse: 3.0440e-04 - val_mae: 0.0107\n",
      "Epoch 83/100\n",
      "43/43 [==============================] - 27s 624ms/step - loss: 8.9101e-04 - mse: 8.9101e-04 - mae: 0.0139 - val_loss: 3.3944e-04 - val_mse: 3.3944e-04 - val_mae: 0.0102\n",
      "Epoch 84/100\n",
      "43/43 [==============================] - 27s 631ms/step - loss: 9.6535e-04 - mse: 9.6535e-04 - mae: 0.0143 - val_loss: 3.0084e-04 - val_mse: 3.0084e-04 - val_mae: 0.0101\n",
      "Epoch 85/100\n",
      "43/43 [==============================] - 29s 664ms/step - loss: 8.6291e-04 - mse: 8.6291e-04 - mae: 0.0137 - val_loss: 3.3238e-04 - val_mse: 3.3238e-04 - val_mae: 0.0110\n",
      "Epoch 86/100\n",
      "43/43 [==============================] - 23s 529ms/step - loss: 9.5014e-04 - mse: 9.5014e-04 - mae: 0.0140 - val_loss: 3.3807e-04 - val_mse: 3.3807e-04 - val_mae: 0.0110\n",
      "Epoch 87/100\n",
      "43/43 [==============================] - 17s 406ms/step - loss: 9.9961e-04 - mse: 9.9961e-04 - mae: 0.0150 - val_loss: 3.0008e-04 - val_mse: 3.0008e-04 - val_mae: 0.0117\n",
      "Epoch 88/100\n",
      "43/43 [==============================] - 18s 410ms/step - loss: 9.5428e-04 - mse: 9.5428e-04 - mae: 0.0146 - val_loss: 2.8452e-04 - val_mse: 2.8452e-04 - val_mae: 0.0103\n",
      "Epoch 89/100\n",
      "43/43 [==============================] - 17s 398ms/step - loss: 8.9645e-04 - mse: 8.9645e-04 - mae: 0.0142 - val_loss: 2.7922e-04 - val_mse: 2.7922e-04 - val_mae: 0.0105\n",
      "Epoch 90/100\n",
      "43/43 [==============================] - 17s 390ms/step - loss: 8.8609e-04 - mse: 8.8609e-04 - mae: 0.0140 - val_loss: 3.0093e-04 - val_mse: 3.0093e-04 - val_mae: 0.0108\n",
      "Epoch 91/100\n",
      "43/43 [==============================] - 16s 378ms/step - loss: 9.0100e-04 - mse: 9.0100e-04 - mae: 0.0140 - val_loss: 3.0189e-04 - val_mse: 3.0189e-04 - val_mae: 0.0111\n",
      "Epoch 92/100\n",
      "43/43 [==============================] - 16s 368ms/step - loss: 8.9975e-04 - mse: 8.9975e-04 - mae: 0.0142 - val_loss: 3.3271e-04 - val_mse: 3.3271e-04 - val_mae: 0.0099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/100\n",
      "43/43 [==============================] - 16s 363ms/step - loss: 8.9820e-04 - mse: 8.9820e-04 - mae: 0.0140 - val_loss: 2.7447e-04 - val_mse: 2.7447e-04 - val_mae: 0.0102\n",
      "Epoch 94/100\n",
      "43/43 [==============================] - 16s 371ms/step - loss: 8.2752e-04 - mse: 8.2752e-04 - mae: 0.0132 - val_loss: 2.8839e-04 - val_mse: 2.8839e-04 - val_mae: 0.0097\n",
      "Epoch 95/100\n",
      "43/43 [==============================] - 17s 387ms/step - loss: 8.6802e-04 - mse: 8.6802e-04 - mae: 0.0138 - val_loss: 2.8375e-04 - val_mse: 2.8375e-04 - val_mae: 0.0106\n",
      "Epoch 96/100\n",
      "43/43 [==============================] - 17s 404ms/step - loss: 9.1804e-04 - mse: 9.1804e-04 - mae: 0.0139 - val_loss: 2.8741e-04 - val_mse: 2.8741e-04 - val_mae: 0.0107\n",
      "Epoch 97/100\n",
      "43/43 [==============================] - 16s 377ms/step - loss: 8.5496e-04 - mse: 8.5496e-04 - mae: 0.0135 - val_loss: 3.7830e-04 - val_mse: 3.7830e-04 - val_mae: 0.0108\n",
      "Epoch 98/100\n",
      "43/43 [==============================] - 17s 395ms/step - loss: 8.8089e-04 - mse: 8.8089e-04 - mae: 0.0137 - val_loss: 3.4340e-04 - val_mse: 3.4340e-04 - val_mae: 0.0101\n",
      "Epoch 99/100\n",
      "43/43 [==============================] - 15s 360ms/step - loss: 8.4352e-04 - mse: 8.4352e-04 - mae: 0.0132 - val_loss: 2.9181e-04 - val_mse: 2.9181e-04 - val_mae: 0.0108\n",
      "Epoch 100/100\n",
      "43/43 [==============================] - 15s 350ms/step - loss: 8.4467e-04 - mse: 8.4467e-04 - mae: 0.0135 - val_loss: 3.5272e-04 - val_mse: 3.5272e-04 - val_mae: 0.0106\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,\n",
    "                    y_train, \n",
    "                    batch_size = batch_size, \n",
    "                    epochs = epochs,\n",
    "                    shuffle = False, \n",
    "                    validation_data = (X_val, y_val))\n",
    "    \n",
    "# required before predicitons\n",
    "model.reset_states()\n",
    "    \n",
    "y_pred = model.predict(X_test, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cannot use inverse function; prices col = 14\n",
    "y_pred = (y_pred * sc_X.data_range_[14]) + (sc_X.data_min_[14])\n",
    "y_test = (y_test * sc_X.data_range_[14]) + (sc_X.data_min_[14])\n",
    "\n",
    "# Reshaping\n",
    "y_pred = np.reshape(y_pred, (y_pred.shape[0]))\n",
    "\n",
    "# =============================================================================\n",
    "# METRICS EVALUATION (1) for the whole test set\n",
    "# =============================================================================\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "\n",
    "# calculate metrics\n",
    "rmse_error = mse(y_test, y_pred, squared = False)\n",
    "mae_error = mae(y_test, y_pred)\n",
    "\n",
    "# append to list\n",
    "rmse_gen.append(rmse_error)\n",
    "mae_gen.append(mae_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Need to process data with spike occurences in the same way as features and offers:\n",
    "(Required to evaluate predictions in both normal regions and spike regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data for shaded area\n",
    "data = pd.read_csv('Spike_binary_1std.csv', index_col = 0)\n",
    "\n",
    "# set predictive window according with tuning best results\n",
    "data = data.loc[data.index > date, :]\n",
    "\n",
    "# make sure shaded area will correspond to values outputed by LSTM\n",
    "data.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# fill_nan is already made - so lets split data into test and train\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# divide data into train and test \n",
    "shade_train, shade_test = train_test_split(\n",
    "         data, test_size = 0.15, shuffle = False)\n",
    "\n",
    "# reset index of testing data\n",
    "shade_test.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# function to split data into correct shape for RNN\n",
    "def split_data(shade_test, steps):\n",
    "    y_spike_occ = list()\n",
    "    upper_lim = list()\n",
    "    lower_lim = list()\n",
    "    for i in range(steps, len(shade_test.index)):\n",
    "        y_spike_occ.append(shade_test['spike_occurance'][i])\n",
    "        upper_lim.append(shade_test['spike_upperlim'][i])\n",
    "        lower_lim.append(shade_test['spike_lowerlim'][i])\n",
    "    return np.array(y_spike_occ), np.array(upper_lim), np.array(lower_lim)\n",
    "\n",
    "# function to cut data set so it can be divisible by the batch_size\n",
    "def cut_data(data, batch_size):\n",
    "     # see if it is divisivel\n",
    "    condition = data.shape[0] % batch_size\n",
    "    if condition == 0:\n",
    "        return data\n",
    "    else:\n",
    "        return data[: -condition]\n",
    "\n",
    "y_spike_occ, spike_upperlim, spike_lowerlim = split_data(shade_test, steps)\n",
    "y_spike_occ = cut_data(y_spike_occ, batch_size)\n",
    "spike_upperlim = cut_data(spike_upperlim, batch_size)\n",
    "spike_lowerlim = cut_data(spike_lowerlim, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate on spike and normal regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# METRICS EVALUATION (2) on spike regions\n",
    "# =============================================================================\n",
    "\n",
    "# smal adjustment\n",
    "#y_test.replace(0, 0.0001,inplace = True)\n",
    "\n",
    "# select y_pred and y_test only for regions with spikes\n",
    "y_test_spike = (y_test.T * y_spike_occ).T\n",
    "y_pred_spike = (y_pred.T * y_spike_occ).T\n",
    "y_test_spike = y_test_spike[y_test_spike != 0]\n",
    "y_pred_spike = y_pred_spike[y_pred_spike != 0]\n",
    "\n",
    "# calculate metric\n",
    "rmse_spike = mse(y_test_spike, y_pred_spike, squared = False)\n",
    "mae_spike = mae(y_test_spike, y_pred_spike)\n",
    "\n",
    "# append ot lists\n",
    "rmse_spi.append(rmse_spike)\n",
    "mae_spi.append(mae_spike)\n",
    "\n",
    "# =============================================================================\n",
    "# METRIC EVALUATION (3) on normal regions\n",
    "# =============================================================================\n",
    "\n",
    "# inverse y_spike_occ so the only normal occurences are chosen\n",
    "y_normal_occ = (y_spike_occ - 1) * (-1)\n",
    "\n",
    "# sanity check\n",
    "y_normal_occ.sum() + y_spike_occ.sum() # gives the correct total \n",
    "\n",
    "# select y_pred and y_test only for normal regions\n",
    "y_test_normal = (y_test.T * y_normal_occ).T\n",
    "y_pred_normal = (y_pred.T * y_normal_occ).T\n",
    "y_test_normal = y_test_normal[y_test_normal != 0.00]\n",
    "y_pred_normal = y_pred_normal[y_pred_normal != 0.00]\n",
    "\n",
    "# calculate metric\n",
    "rmse_normal = mse(y_test_normal, y_pred_normal, squared = False)\n",
    "mae_normal = mae(y_test_normal, y_pred_normal)\n",
    "\n",
    "# append to list\n",
    "rmse_nor.append(rmse_normal)\n",
    "mae_nor.append(mae_normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now evaluate predictions on Spike & Normal regions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({'rmse_general': rmse_gen, \n",
    "                 \n",
    "                        'mae_general': mae_gen,\n",
    "                        \n",
    "                        'rmse_spike': rmse_spi,\n",
    "                 \n",
    "                        'mae_spike': mae_spi,\n",
    "                        \n",
    "                        'rmse_normal': rmse_nor,\n",
    "                    \n",
    "                        'mae_normal': mae_nor})\n",
    "\n",
    "# Save y_pred & spike limits to plot with Stateless LSTM\n",
    "datasave = pd.DataFrame({'y_pred': y_pred,\n",
    "                         'y_test':y_test,\n",
    "                         'spike_upperlim':spike_upperlim,\n",
    "                         'spike_lowerlim':spike_lowerlim})\n",
    "\n",
    "datasave.to_csv('LSTM_plot_Stateful_4m.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse_general</th>\n",
       "      <th>mae_general</th>\n",
       "      <th>rmse_spike</th>\n",
       "      <th>mae_spike</th>\n",
       "      <th>rmse_normal</th>\n",
       "      <th>mae_normal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.538148</td>\n",
       "      <td>13.986985</td>\n",
       "      <td>61.526372</td>\n",
       "      <td>48.157042</td>\n",
       "      <td>12.918564</td>\n",
       "      <td>8.69448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rmse_general  mae_general  rmse_spike  mae_spike  rmse_normal  mae_normal\n",
       "0     25.538148    13.986985   61.526372  48.157042    12.918564     8.69448"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
