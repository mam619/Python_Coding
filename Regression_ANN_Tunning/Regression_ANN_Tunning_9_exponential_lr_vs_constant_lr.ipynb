{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression ANN with best parameters\n",
    "    find the best approach for learning rate (exponential schedueling - or not)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd;\n",
    "import numpy as np;\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split, cross_validate, cross_val_predict;\n",
    "from sklearn.preprocessing import MinMaxScaler;\n",
    "from sklearn import metrics;\n",
    "from sklearn.model_selection import TimeSeriesSplit;\n",
    "\n",
    "mae_cv = []\n",
    "mse_cv = []\n",
    "mae_gen = []\n",
    "mse_gen  =[]\n",
    "rmse_gen = []\n",
    "mae_nor = []\n",
    "mae_spi = []\n",
    "mse_nor = []\n",
    "mse_spi = []\n",
    "rmse_nor = []\n",
    "rmse_spi = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results for lr = 0.001:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/pandas/core/generic.py:6245: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 17723.4456 - mse: 17723.4434 - mae: 114.6029\n",
      "Epoch 2/80\n",
      "591/591 [==============================] - 0s 198us/step - loss: 17339.0107 - mse: 17339.0078 - mae: 112.9127\n",
      "Epoch 3/80\n",
      "591/591 [==============================] - 0s 158us/step - loss: 16649.5569 - mse: 16649.5547 - mae: 109.8538\n",
      "Epoch 4/80\n",
      "591/591 [==============================] - 0s 137us/step - loss: 15506.8899 - mse: 15506.8896 - mae: 104.4732\n",
      "Epoch 5/80\n",
      "591/591 [==============================] - 0s 145us/step - loss: 13343.1175 - mse: 13343.1172 - mae: 93.6944\n",
      "Epoch 6/80\n",
      "591/591 [==============================] - 0s 128us/step - loss: 10941.8065 - mse: 10941.8057 - mae: 79.6697\n",
      "Epoch 7/80\n",
      "591/591 [==============================] - 0s 129us/step - loss: 8627.3079 - mse: 8627.3066 - mae: 63.4058\n",
      "Epoch 8/80\n",
      "591/591 [==============================] - 0s 135us/step - loss: 6722.2319 - mse: 6722.2314 - mae: 45.4122\n",
      "Epoch 9/80\n",
      "591/591 [==============================] - 0s 127us/step - loss: 5574.3508 - mse: 5574.3516 - mae: 33.5033\n",
      "Epoch 10/80\n",
      "591/591 [==============================] - 0s 156us/step - loss: 4970.1065 - mse: 4970.1060 - mae: 28.2641\n",
      "Epoch 11/80\n",
      "591/591 [==============================] - 0s 193us/step - loss: 4810.5135 - mse: 4810.5122 - mae: 27.9700\n",
      "Epoch 12/80\n",
      "591/591 [==============================] - 0s 197us/step - loss: 4847.8636 - mse: 4847.8638 - mae: 28.0173\n",
      "Epoch 13/80\n",
      "591/591 [==============================] - 0s 195us/step - loss: 4840.1719 - mse: 4840.1729 - mae: 29.1210\n",
      "Epoch 14/80\n",
      "591/591 [==============================] - 0s 193us/step - loss: 4858.3940 - mse: 4858.3940 - mae: 29.0367\n",
      "Epoch 15/80\n",
      "591/591 [==============================] - 0s 194us/step - loss: 4726.5123 - mse: 4726.5122 - mae: 29.0689\n",
      "Epoch 16/80\n",
      "591/591 [==============================] - 0s 174us/step - loss: 4780.2287 - mse: 4780.2290 - mae: 28.6120\n",
      "Epoch 17/80\n",
      "591/591 [==============================] - 0s 210us/step - loss: 4821.8271 - mse: 4821.8262 - mae: 28.3318\n",
      "Epoch 18/80\n",
      "591/591 [==============================] - 0s 160us/step - loss: 4703.3751 - mse: 4703.3755 - mae: 28.2076\n",
      "Epoch 19/80\n",
      "591/591 [==============================] - 0s 161us/step - loss: 4912.3703 - mse: 4912.3701 - mae: 29.3397\n",
      "Epoch 20/80\n",
      "591/591 [==============================] - 0s 161us/step - loss: 4727.6542 - mse: 4727.6548 - mae: 28.4009\n",
      "Epoch 21/80\n",
      "591/591 [==============================] - 0s 173us/step - loss: 4880.0609 - mse: 4880.0605 - mae: 28.3533\n",
      "Epoch 22/80\n",
      "591/591 [==============================] - 0s 175us/step - loss: 4665.9294 - mse: 4665.9297 - mae: 27.2181\n",
      "Epoch 23/80\n",
      "591/591 [==============================] - 0s 162us/step - loss: 4744.8573 - mse: 4744.8569 - mae: 27.6559\n",
      "Epoch 24/80\n",
      "591/591 [==============================] - 0s 162us/step - loss: 4742.4468 - mse: 4742.4468 - mae: 28.9923\n",
      "Epoch 25/80\n",
      "591/591 [==============================] - 0s 164us/step - loss: 4700.2025 - mse: 4700.2021 - mae: 28.9771\n",
      "Epoch 26/80\n",
      "591/591 [==============================] - 0s 160us/step - loss: 4764.3766 - mse: 4764.3765 - mae: 27.9205\n",
      "Epoch 27/80\n",
      "591/591 [==============================] - 0s 162us/step - loss: 4755.2113 - mse: 4755.2114 - mae: 28.5903\n",
      "Epoch 28/80\n",
      "591/591 [==============================] - 0s 161us/step - loss: 4757.7027 - mse: 4757.7026 - mae: 28.3239\n",
      "Epoch 29/80\n",
      "591/591 [==============================] - 0s 163us/step - loss: 4664.4031 - mse: 4664.4033 - mae: 28.3217\n",
      "Epoch 30/80\n",
      "591/591 [==============================] - 0s 198us/step - loss: 4623.5680 - mse: 4623.5679 - mae: 28.5100\n",
      "Epoch 31/80\n",
      "591/591 [==============================] - 0s 162us/step - loss: 4704.3251 - mse: 4704.3247 - mae: 27.8730\n",
      "Epoch 32/80\n",
      "591/591 [==============================] - 0s 160us/step - loss: 4710.2414 - mse: 4710.2422 - mae: 28.7435\n",
      "Epoch 33/80\n",
      "591/591 [==============================] - 0s 165us/step - loss: 4769.7428 - mse: 4769.7427 - mae: 29.0000\n",
      "Epoch 34/80\n",
      "591/591 [==============================] - 0s 188us/step - loss: 4606.0434 - mse: 4606.0430 - mae: 28.0707\n",
      "Epoch 35/80\n",
      "591/591 [==============================] - 0s 206us/step - loss: 4617.0847 - mse: 4617.0845 - mae: 27.0043\n",
      "Epoch 36/80\n",
      "591/591 [==============================] - 0s 159us/step - loss: 4807.3620 - mse: 4807.3623 - mae: 28.7770\n",
      "Epoch 37/80\n",
      "591/591 [==============================] - 0s 161us/step - loss: 4788.0248 - mse: 4788.0244 - mae: 28.3220\n",
      "Epoch 38/80\n",
      "591/591 [==============================] - 0s 195us/step - loss: 4823.3801 - mse: 4823.3799 - mae: 28.2318\n",
      "Epoch 39/80\n",
      "591/591 [==============================] - 0s 166us/step - loss: 4771.1904 - mse: 4771.1904 - mae: 27.6041\n",
      "Epoch 40/80\n",
      "591/591 [==============================] - 0s 163us/step - loss: 4784.1376 - mse: 4784.1377 - mae: 27.3042\n",
      "Epoch 41/80\n",
      "591/591 [==============================] - 0s 163us/step - loss: 4913.4103 - mse: 4913.4097 - mae: 28.6594\n",
      "Epoch 42/80\n",
      "591/591 [==============================] - 0s 165us/step - loss: 4735.0165 - mse: 4735.0166 - mae: 28.0703\n",
      "Epoch 43/80\n",
      "591/591 [==============================] - 0s 167us/step - loss: 4740.4674 - mse: 4740.4668 - mae: 28.4839\n",
      "Epoch 44/80\n",
      "591/591 [==============================] - 0s 164us/step - loss: 4731.7632 - mse: 4731.7632 - mae: 28.8552\n",
      "Epoch 45/80\n",
      "591/591 [==============================] - 0s 163us/step - loss: 4838.8786 - mse: 4838.8779 - mae: 29.2652\n",
      "Epoch 46/80\n",
      "591/591 [==============================] - 0s 177us/step - loss: 4776.4844 - mse: 4776.4839 - mae: 28.3564\n",
      "Epoch 47/80\n",
      "591/591 [==============================] - 0s 224us/step - loss: 4738.3684 - mse: 4738.3687 - mae: 28.2561\n",
      "Epoch 48/80\n",
      "591/591 [==============================] - 0s 213us/step - loss: 4866.1817 - mse: 4866.1821 - mae: 28.1131\n",
      "Epoch 49/80\n",
      "591/591 [==============================] - 0s 157us/step - loss: 4825.6252 - mse: 4825.6245 - mae: 27.7485\n",
      "Epoch 50/80\n",
      "591/591 [==============================] - 0s 166us/step - loss: 4723.4160 - mse: 4723.4155 - mae: 28.8415\n",
      "Epoch 51/80\n",
      "591/591 [==============================] - 0s 162us/step - loss: 4724.7019 - mse: 4724.7017 - mae: 26.8610\n",
      "Epoch 52/80\n",
      "591/591 [==============================] - 0s 152us/step - loss: 4997.4107 - mse: 4997.4116 - mae: 28.6714\n",
      "Epoch 53/80\n",
      "591/591 [==============================] - 0s 163us/step - loss: 4725.6845 - mse: 4725.6851 - mae: 28.5740\n",
      "Epoch 54/80\n",
      "591/591 [==============================] - 0s 157us/step - loss: 4731.3487 - mse: 4731.3481 - mae: 28.8184\n",
      "Epoch 55/80\n",
      "591/591 [==============================] - 0s 154us/step - loss: 4684.4057 - mse: 4684.4058 - mae: 27.2652\n",
      "Epoch 56/80\n",
      "591/591 [==============================] - 0s 161us/step - loss: 4811.3364 - mse: 4811.3364 - mae: 28.4482\n",
      "Epoch 57/80\n",
      "591/591 [==============================] - 0s 169us/step - loss: 4842.7017 - mse: 4842.7012 - mae: 28.9138\n",
      "Epoch 58/80\n",
      "591/591 [==============================] - 0s 142us/step - loss: 4607.4392 - mse: 4607.4390 - mae: 27.4237\n",
      "Epoch 59/80\n",
      "591/591 [==============================] - 0s 148us/step - loss: 4837.0689 - mse: 4837.0684 - mae: 28.8170\n",
      "Epoch 60/80\n",
      "591/591 [==============================] - 0s 166us/step - loss: 4707.0495 - mse: 4707.0493 - mae: 27.5623\n",
      "Epoch 61/80\n",
      "591/591 [==============================] - 0s 142us/step - loss: 4719.4686 - mse: 4719.4688 - mae: 27.9257\n",
      "Epoch 62/80\n",
      "591/591 [==============================] - 0s 148us/step - loss: 4744.0181 - mse: 4744.0186 - mae: 28.1839\n",
      "Epoch 63/80\n",
      "591/591 [==============================] - 0s 169us/step - loss: 4575.1757 - mse: 4575.1748 - mae: 27.8090\n",
      "Epoch 64/80\n",
      "591/591 [==============================] - 0s 153us/step - loss: 4797.0275 - mse: 4797.0278 - mae: 28.4817\n",
      "Epoch 65/80\n",
      "591/591 [==============================] - 0s 167us/step - loss: 4728.9890 - mse: 4728.9907 - mae: 28.4223\n",
      "Epoch 66/80\n",
      "591/591 [==============================] - 0s 154us/step - loss: 4660.2813 - mse: 4660.2808 - mae: 27.9256\n",
      "Epoch 67/80\n",
      "591/591 [==============================] - 0s 137us/step - loss: 4655.6328 - mse: 4655.6328 - mae: 27.8838\n",
      "Epoch 68/80\n",
      "591/591 [==============================] - 0s 166us/step - loss: 4803.1562 - mse: 4803.1562 - mae: 29.2807\n",
      "Epoch 69/80\n",
      "591/591 [==============================] - 0s 142us/step - loss: 4685.9820 - mse: 4685.9810 - mae: 27.9348\n",
      "Epoch 70/80\n",
      "591/591 [==============================] - 0s 149us/step - loss: 4869.0654 - mse: 4869.0649 - mae: 28.1485\n",
      "Epoch 71/80\n",
      "591/591 [==============================] - 0s 160us/step - loss: 4701.9615 - mse: 4701.9609 - mae: 28.3121\n",
      "Epoch 72/80\n",
      "591/591 [==============================] - 0s 135us/step - loss: 4648.1250 - mse: 4648.1250 - mae: 27.9989\n",
      "Epoch 73/80\n",
      "591/591 [==============================] - 0s 144us/step - loss: 4892.3634 - mse: 4892.3633 - mae: 28.1002\n",
      "Epoch 74/80\n",
      "591/591 [==============================] - 0s 167us/step - loss: 4635.8361 - mse: 4635.8364 - mae: 27.6086\n",
      "Epoch 75/80\n",
      "591/591 [==============================] - 0s 159us/step - loss: 4703.7209 - mse: 4703.7207 - mae: 27.5881\n",
      "Epoch 76/80\n",
      "591/591 [==============================] - 0s 182us/step - loss: 4696.6841 - mse: 4696.6841 - mae: 28.1933\n",
      "Epoch 77/80\n",
      "591/591 [==============================] - 0s 132us/step - loss: 4691.4451 - mse: 4691.4453 - mae: 28.5238\n",
      "Epoch 78/80\n",
      "591/591 [==============================] - 0s 147us/step - loss: 4831.1233 - mse: 4831.1230 - mae: 28.6770\n",
      "Epoch 79/80\n",
      "591/591 [==============================] - 0s 133us/step - loss: 4734.5439 - mse: 4734.5439 - mae: 28.4084\n",
      "Epoch 80/80\n",
      "591/591 [==============================] - 0s 158us/step - loss: 4747.1791 - mse: 4747.1792 - mae: 27.4457\n",
      "1\n",
      "Epoch 1/80\n",
      "1176/1176 [==============================] - 0s 177us/step - loss: 3492.9894 - mse: 3492.9893 - mae: 31.1723\n",
      "Epoch 2/80\n",
      "1176/1176 [==============================] - 0s 158us/step - loss: 3448.8684 - mse: 3448.8689 - mae: 30.8529\n",
      "Epoch 3/80\n",
      "1176/1176 [==============================] - 0s 159us/step - loss: 3644.9074 - mse: 3644.9082 - mae: 31.1391\n",
      "Epoch 4/80\n",
      "1176/1176 [==============================] - 0s 165us/step - loss: 3481.3072 - mse: 3481.3071 - mae: 30.4876\n",
      "Epoch 5/80\n",
      "1176/1176 [==============================] - 0s 158us/step - loss: 3448.0910 - mse: 3448.0898 - mae: 31.1790\n",
      "Epoch 6/80\n",
      "1176/1176 [==============================] - 0s 153us/step - loss: 3598.0101 - mse: 3598.0103 - mae: 31.5503\n",
      "Epoch 7/80\n",
      "1176/1176 [==============================] - 0s 162us/step - loss: 3540.2979 - mse: 3540.2986 - mae: 30.9914\n",
      "Epoch 8/80\n",
      "1176/1176 [==============================] - 0s 140us/step - loss: 3429.4592 - mse: 3429.4592 - mae: 30.5830\n",
      "Epoch 9/80\n",
      "1176/1176 [==============================] - 0s 159us/step - loss: 3463.7437 - mse: 3463.7439 - mae: 30.8409\n",
      "Epoch 10/80\n",
      "1176/1176 [==============================] - 0s 159us/step - loss: 3496.3809 - mse: 3496.3799 - mae: 31.0469\n",
      "Epoch 11/80\n",
      "1176/1176 [==============================] - 0s 154us/step - loss: 3499.7570 - mse: 3499.7568 - mae: 30.9972\n",
      "Epoch 12/80\n",
      "1176/1176 [==============================] - 0s 172us/step - loss: 3503.5632 - mse: 3503.5632 - mae: 31.2017\n",
      "Epoch 13/80\n",
      "1176/1176 [==============================] - 0s 158us/step - loss: 3477.0913 - mse: 3477.0908 - mae: 30.9337\n",
      "Epoch 14/80\n",
      "1176/1176 [==============================] - 0s 150us/step - loss: 3387.7781 - mse: 3387.7781 - mae: 30.1846\n",
      "Epoch 15/80\n",
      "1176/1176 [==============================] - 0s 159us/step - loss: 3554.9069 - mse: 3554.9065 - mae: 30.7337\n",
      "Epoch 16/80\n",
      "1176/1176 [==============================] - 0s 152us/step - loss: 3507.1859 - mse: 3507.1853 - mae: 30.7036\n",
      "Epoch 17/80\n",
      "1176/1176 [==============================] - 0s 151us/step - loss: 3494.4568 - mse: 3494.4573 - mae: 30.9995\n",
      "Epoch 18/80\n",
      "1176/1176 [==============================] - 0s 161us/step - loss: 3591.0651 - mse: 3591.0649 - mae: 30.7909\n",
      "Epoch 19/80\n",
      "1176/1176 [==============================] - 0s 158us/step - loss: 3508.7529 - mse: 3508.7527 - mae: 30.8531\n",
      "Epoch 20/80\n",
      "1176/1176 [==============================] - 0s 162us/step - loss: 3539.4627 - mse: 3539.4629 - mae: 30.9200\n",
      "Epoch 21/80\n",
      "1176/1176 [==============================] - 0s 157us/step - loss: 3508.1778 - mse: 3508.1775 - mae: 30.3358\n",
      "Epoch 22/80\n",
      "1176/1176 [==============================] - 0s 163us/step - loss: 3562.0842 - mse: 3562.0847 - mae: 31.2179\n",
      "Epoch 23/80\n",
      "1176/1176 [==============================] - 0s 165us/step - loss: 3375.8196 - mse: 3375.8198 - mae: 30.4882\n",
      "Epoch 24/80\n",
      "1176/1176 [==============================] - 0s 158us/step - loss: 3518.6050 - mse: 3518.6055 - mae: 31.6575\n",
      "Epoch 25/80\n",
      "1176/1176 [==============================] - 0s 170us/step - loss: 3441.7020 - mse: 3441.7031 - mae: 30.4114\n",
      "Epoch 26/80\n",
      "1176/1176 [==============================] - 0s 154us/step - loss: 3430.6688 - mse: 3430.6689 - mae: 30.2653\n",
      "Epoch 27/80\n",
      "1176/1176 [==============================] - 0s 148us/step - loss: 3353.8930 - mse: 3353.8926 - mae: 30.0844\n",
      "Epoch 28/80\n",
      "1176/1176 [==============================] - 0s 152us/step - loss: 3448.6084 - mse: 3448.6079 - mae: 30.2223\n",
      "Epoch 29/80\n",
      "1176/1176 [==============================] - 0s 157us/step - loss: 3511.8263 - mse: 3511.8259 - mae: 30.8162\n",
      "Epoch 30/80\n",
      "1176/1176 [==============================] - 0s 152us/step - loss: 3489.2073 - mse: 3489.2078 - mae: 31.2297\n",
      "Epoch 31/80\n",
      "1176/1176 [==============================] - 0s 163us/step - loss: 3473.5505 - mse: 3473.5498 - mae: 30.8402\n",
      "Epoch 32/80\n",
      "1176/1176 [==============================] - 0s 155us/step - loss: 3475.4728 - mse: 3475.4729 - mae: 30.8145\n",
      "Epoch 33/80\n",
      "1176/1176 [==============================] - 0s 157us/step - loss: 3428.3942 - mse: 3428.3950 - mae: 30.4798\n",
      "Epoch 34/80\n",
      "1176/1176 [==============================] - 0s 154us/step - loss: 3536.0830 - mse: 3536.0825 - mae: 30.4004\n",
      "Epoch 35/80\n",
      "1176/1176 [==============================] - 0s 157us/step - loss: 3508.9666 - mse: 3508.9666 - mae: 31.0350\n",
      "Epoch 36/80\n",
      "1176/1176 [==============================] - 0s 150us/step - loss: 3527.4653 - mse: 3527.4656 - mae: 30.8352\n",
      "Epoch 37/80\n",
      "1176/1176 [==============================] - 0s 139us/step - loss: 3422.5868 - mse: 3422.5859 - mae: 30.1551\n",
      "Epoch 38/80\n",
      "1176/1176 [==============================] - 0s 156us/step - loss: 3505.0114 - mse: 3505.0112 - mae: 30.0063\n",
      "Epoch 39/80\n",
      "1176/1176 [==============================] - 0s 151us/step - loss: 3440.0313 - mse: 3440.0312 - mae: 30.3433\n",
      "Epoch 40/80\n",
      "1176/1176 [==============================] - 0s 156us/step - loss: 3443.9316 - mse: 3443.9319 - mae: 30.1714\n",
      "Epoch 41/80\n",
      "1176/1176 [==============================] - 0s 150us/step - loss: 3565.1445 - mse: 3565.1443 - mae: 31.4850\n",
      "Epoch 42/80\n",
      "1176/1176 [==============================] - 0s 158us/step - loss: 3457.3704 - mse: 3457.3706 - mae: 30.2784\n",
      "Epoch 43/80\n",
      "1176/1176 [==============================] - 0s 162us/step - loss: 3411.3705 - mse: 3411.3701 - mae: 30.7685\n",
      "Epoch 44/80\n",
      "1176/1176 [==============================] - 0s 164us/step - loss: 3504.0358 - mse: 3504.0361 - mae: 30.1869\n",
      "Epoch 45/80\n",
      "1176/1176 [==============================] - 0s 157us/step - loss: 3372.8261 - mse: 3372.8254 - mae: 29.6710\n",
      "Epoch 46/80\n",
      "1176/1176 [==============================] - 0s 164us/step - loss: 3385.7922 - mse: 3385.7922 - mae: 30.7043\n",
      "Epoch 47/80\n",
      "1176/1176 [==============================] - 0s 167us/step - loss: 3458.1147 - mse: 3458.1145 - mae: 30.7401\n",
      "Epoch 48/80\n",
      "1176/1176 [==============================] - 0s 164us/step - loss: 3430.0101 - mse: 3430.0098 - mae: 30.2741\n",
      "Epoch 49/80\n",
      "1176/1176 [==============================] - 0s 160us/step - loss: 3350.9099 - mse: 3350.9102 - mae: 29.5578\n",
      "Epoch 50/80\n",
      "1176/1176 [==============================] - 0s 165us/step - loss: 3481.5356 - mse: 3481.5359 - mae: 31.1494\n",
      "Epoch 51/80\n",
      "1176/1176 [==============================] - 0s 158us/step - loss: 3533.1266 - mse: 3533.1274 - mae: 30.4535\n",
      "Epoch 52/80\n",
      "1176/1176 [==============================] - 0s 167us/step - loss: 3479.9078 - mse: 3479.9080 - mae: 30.6130\n",
      "Epoch 53/80\n",
      "1176/1176 [==============================] - 0s 163us/step - loss: 3477.2671 - mse: 3477.2666 - mae: 30.8638\n",
      "Epoch 54/80\n",
      "1176/1176 [==============================] - 0s 162us/step - loss: 3422.2505 - mse: 3422.2495 - mae: 29.9226\n",
      "Epoch 55/80\n",
      "1176/1176 [==============================] - 0s 161us/step - loss: 3409.5069 - mse: 3409.5073 - mae: 30.1181\n",
      "Epoch 56/80\n",
      "1176/1176 [==============================] - 0s 166us/step - loss: 3390.4875 - mse: 3390.4873 - mae: 29.6066\n",
      "Epoch 57/80\n",
      "1176/1176 [==============================] - 0s 157us/step - loss: 3442.7923 - mse: 3442.7922 - mae: 29.9712\n",
      "Epoch 58/80\n",
      "1176/1176 [==============================] - 0s 163us/step - loss: 3466.9939 - mse: 3466.9934 - mae: 30.3746\n",
      "Epoch 59/80\n",
      "1176/1176 [==============================] - 0s 159us/step - loss: 3416.2877 - mse: 3416.2878 - mae: 30.3968\n",
      "Epoch 60/80\n",
      "1176/1176 [==============================] - 0s 157us/step - loss: 3475.6730 - mse: 3475.6731 - mae: 30.5902\n",
      "Epoch 61/80\n",
      "1176/1176 [==============================] - 0s 160us/step - loss: 3486.1613 - mse: 3486.1611 - mae: 30.1296\n",
      "Epoch 62/80\n",
      "1176/1176 [==============================] - 0s 159us/step - loss: 3476.9871 - mse: 3476.9875 - mae: 30.3186\n",
      "Epoch 63/80\n",
      "1176/1176 [==============================] - 0s 161us/step - loss: 3377.2486 - mse: 3377.2485 - mae: 30.3019\n",
      "Epoch 64/80\n",
      "1176/1176 [==============================] - 0s 165us/step - loss: 3426.9558 - mse: 3426.9561 - mae: 30.2309\n",
      "Epoch 65/80\n",
      "1176/1176 [==============================] - 0s 161us/step - loss: 3447.1753 - mse: 3447.1750 - mae: 30.0198\n",
      "Epoch 66/80\n",
      "1176/1176 [==============================] - 0s 156us/step - loss: 3435.1376 - mse: 3435.1372 - mae: 30.4610\n",
      "Epoch 67/80\n",
      "1176/1176 [==============================] - 0s 152us/step - loss: 3362.3414 - mse: 3362.3418 - mae: 30.1242\n",
      "Epoch 68/80\n",
      "1176/1176 [==============================] - 0s 172us/step - loss: 3297.0895 - mse: 3297.0889 - mae: 29.7591\n",
      "Epoch 69/80\n",
      "1176/1176 [==============================] - 0s 192us/step - loss: 3372.1314 - mse: 3372.1313 - mae: 29.8199\n",
      "Epoch 70/80\n",
      "1176/1176 [==============================] - 0s 193us/step - loss: 3387.8273 - mse: 3387.8276 - mae: 30.2951\n",
      "Epoch 71/80\n",
      "1176/1176 [==============================] - 0s 147us/step - loss: 3435.7096 - mse: 3435.7097 - mae: 30.7673\n",
      "Epoch 72/80\n",
      "1176/1176 [==============================] - 0s 192us/step - loss: 3503.6590 - mse: 3503.6589 - mae: 30.3861\n",
      "Epoch 73/80\n",
      "1176/1176 [==============================] - 0s 193us/step - loss: 3421.4015 - mse: 3421.4014 - mae: 30.5437\n",
      "Epoch 74/80\n",
      "1176/1176 [==============================] - 0s 193us/step - loss: 3412.1054 - mse: 3412.1062 - mae: 29.7790\n",
      "Epoch 75/80\n",
      "1176/1176 [==============================] - 0s 141us/step - loss: 3335.5727 - mse: 3335.5728 - mae: 30.0926\n",
      "Epoch 76/80\n",
      "1176/1176 [==============================] - 0s 132us/step - loss: 3420.4576 - mse: 3420.4575 - mae: 29.7403\n",
      "Epoch 77/80\n",
      "1176/1176 [==============================] - 0s 169us/step - loss: 3388.0810 - mse: 3388.0820 - mae: 30.0053\n",
      "Epoch 78/80\n",
      "1176/1176 [==============================] - 0s 138us/step - loss: 3422.0982 - mse: 3422.0979 - mae: 30.6430\n",
      "Epoch 79/80\n",
      "1176/1176 [==============================] - 0s 159us/step - loss: 3415.7909 - mse: 3415.7910 - mae: 30.5867\n",
      "Epoch 80/80\n",
      "1176/1176 [==============================] - 0s 157us/step - loss: 3430.3897 - mse: 3430.3896 - mae: 30.4315\n",
      "2\n",
      "Epoch 1/80\n",
      "1761/1761 [==============================] - 0s 145us/step - loss: 2692.7021 - mse: 2692.7031 - mae: 28.4834\n",
      "Epoch 2/80\n",
      "1761/1761 [==============================] - 0s 157us/step - loss: 2698.5741 - mse: 2698.5747 - mae: 28.4650\n",
      "Epoch 3/80\n",
      "1761/1761 [==============================] - 0s 158us/step - loss: 2781.9005 - mse: 2781.9009 - mae: 28.8641\n",
      "Epoch 4/80\n",
      "1761/1761 [==============================] - 0s 161us/step - loss: 2725.8943 - mse: 2725.8948 - mae: 28.2186\n",
      "Epoch 5/80\n",
      "1761/1761 [==============================] - 0s 149us/step - loss: 2739.8190 - mse: 2739.8184 - mae: 28.0665\n",
      "Epoch 6/80\n",
      "1761/1761 [==============================] - 0s 158us/step - loss: 2703.3831 - mse: 2703.3826 - mae: 28.4444\n",
      "Epoch 7/80\n",
      "1761/1761 [==============================] - 0s 165us/step - loss: 2652.0695 - mse: 2652.0698 - mae: 27.7823\n",
      "Epoch 8/80\n",
      "1761/1761 [==============================] - 0s 157us/step - loss: 2727.5605 - mse: 2727.5605 - mae: 28.7577\n",
      "Epoch 9/80\n",
      "1761/1761 [==============================] - 0s 160us/step - loss: 2698.6452 - mse: 2698.6453 - mae: 28.0783\n",
      "Epoch 10/80\n",
      "1761/1761 [==============================] - 0s 158us/step - loss: 2736.0534 - mse: 2736.0530 - mae: 28.3429\n",
      "Epoch 11/80\n",
      "1761/1761 [==============================] - 0s 160us/step - loss: 2729.9263 - mse: 2729.9255 - mae: 28.7873\n",
      "Epoch 12/80\n",
      "1761/1761 [==============================] - 0s 162us/step - loss: 2672.2420 - mse: 2672.2427 - mae: 28.0314\n",
      "Epoch 13/80\n",
      "1761/1761 [==============================] - 0s 161us/step - loss: 2681.4436 - mse: 2681.4441 - mae: 27.9545\n",
      "Epoch 14/80\n",
      "1761/1761 [==============================] - 0s 153us/step - loss: 2696.8768 - mse: 2696.8765 - mae: 28.5017\n",
      "Epoch 15/80\n",
      "1761/1761 [==============================] - 0s 160us/step - loss: 2730.7402 - mse: 2730.7410 - mae: 28.3891\n",
      "Epoch 16/80\n",
      "1761/1761 [==============================] - 0s 163us/step - loss: 2668.6885 - mse: 2668.6882 - mae: 28.0601\n",
      "Epoch 17/80\n",
      "1761/1761 [==============================] - 0s 162us/step - loss: 2676.1883 - mse: 2676.1887 - mae: 28.2341\n",
      "Epoch 18/80\n",
      "1761/1761 [==============================] - 0s 158us/step - loss: 2683.2866 - mse: 2683.2869 - mae: 28.3625\n",
      "Epoch 19/80\n",
      "1761/1761 [==============================] - 0s 157us/step - loss: 2743.5818 - mse: 2743.5818 - mae: 28.6848\n",
      "Epoch 20/80\n",
      "1761/1761 [==============================] - 0s 157us/step - loss: 2673.3864 - mse: 2673.3872 - mae: 27.6567\n",
      "Epoch 21/80\n",
      "1761/1761 [==============================] - 0s 160us/step - loss: 2673.2870 - mse: 2673.2869 - mae: 27.9808\n",
      "Epoch 22/80\n",
      "1761/1761 [==============================] - 0s 155us/step - loss: 2650.6730 - mse: 2650.6729 - mae: 28.2154\n",
      "Epoch 23/80\n",
      "1761/1761 [==============================] - 0s 161us/step - loss: 2708.3505 - mse: 2708.3503 - mae: 28.4911\n",
      "Epoch 24/80\n",
      "1761/1761 [==============================] - 0s 157us/step - loss: 2678.6352 - mse: 2678.6343 - mae: 27.8518\n",
      "Epoch 25/80\n",
      "1761/1761 [==============================] - 0s 152us/step - loss: 2677.7826 - mse: 2677.7830 - mae: 27.6085\n",
      "Epoch 26/80\n",
      "1761/1761 [==============================] - 0s 161us/step - loss: 2721.7322 - mse: 2721.7329 - mae: 28.2139\n",
      "Epoch 27/80\n",
      "1761/1761 [==============================] - 0s 164us/step - loss: 2731.1116 - mse: 2731.1118 - mae: 28.3914\n",
      "Epoch 28/80\n",
      "1761/1761 [==============================] - 0s 161us/step - loss: 2697.9206 - mse: 2697.9214 - mae: 28.0158\n",
      "Epoch 29/80\n",
      "1761/1761 [==============================] - 0s 149us/step - loss: 2687.7109 - mse: 2687.7107 - mae: 28.1242\n",
      "Epoch 30/80\n",
      "1761/1761 [==============================] - 0s 147us/step - loss: 2704.9305 - mse: 2704.9299 - mae: 28.1485\n",
      "Epoch 31/80\n",
      "1761/1761 [==============================] - 0s 153us/step - loss: 2690.8159 - mse: 2690.8154 - mae: 28.3572\n",
      "Epoch 32/80\n",
      "1761/1761 [==============================] - 0s 150us/step - loss: 2703.8786 - mse: 2703.8787 - mae: 28.6027\n",
      "Epoch 33/80\n",
      "1761/1761 [==============================] - 0s 154us/step - loss: 2658.9193 - mse: 2658.9202 - mae: 27.8375\n",
      "Epoch 34/80\n",
      "1761/1761 [==============================] - 0s 163us/step - loss: 2682.9780 - mse: 2682.9780 - mae: 27.9176\n",
      "Epoch 35/80\n",
      "1761/1761 [==============================] - 0s 157us/step - loss: 2729.1676 - mse: 2729.1685 - mae: 28.5758\n",
      "Epoch 36/80\n",
      "1761/1761 [==============================] - 0s 155us/step - loss: 2715.4664 - mse: 2715.4668 - mae: 27.7589\n",
      "Epoch 37/80\n",
      "1761/1761 [==============================] - 0s 148us/step - loss: 2701.0677 - mse: 2701.0684 - mae: 28.3027\n",
      "Epoch 38/80\n",
      "1761/1761 [==============================] - 0s 155us/step - loss: 2692.8345 - mse: 2692.8352 - mae: 27.8390\n",
      "Epoch 39/80\n",
      "1761/1761 [==============================] - 0s 161us/step - loss: 2678.2485 - mse: 2678.2488 - mae: 27.9103\n",
      "Epoch 40/80\n",
      "1761/1761 [==============================] - 0s 161us/step - loss: 2690.2259 - mse: 2690.2263 - mae: 27.9062\n",
      "Epoch 41/80\n",
      "1761/1761 [==============================] - 0s 164us/step - loss: 2705.7625 - mse: 2705.7620 - mae: 27.9954\n",
      "Epoch 42/80\n",
      "1761/1761 [==============================] - 0s 162us/step - loss: 2671.9415 - mse: 2671.9409 - mae: 28.2257\n",
      "Epoch 43/80\n",
      "1761/1761 [==============================] - 0s 159us/step - loss: 2668.5019 - mse: 2668.5012 - mae: 27.5891\n",
      "Epoch 44/80\n",
      "1761/1761 [==============================] - 0s 160us/step - loss: 2680.6678 - mse: 2680.6672 - mae: 28.0500\n",
      "Epoch 45/80\n",
      "1761/1761 [==============================] - 0s 163us/step - loss: 2637.3130 - mse: 2637.3135 - mae: 27.9030\n",
      "Epoch 46/80\n",
      "1761/1761 [==============================] - 0s 163us/step - loss: 2680.3264 - mse: 2680.3264 - mae: 28.0451\n",
      "Epoch 47/80\n",
      "1761/1761 [==============================] - 0s 161us/step - loss: 2646.0871 - mse: 2646.0867 - mae: 27.9324\n",
      "Epoch 48/80\n",
      "1761/1761 [==============================] - 0s 161us/step - loss: 2655.8789 - mse: 2655.8794 - mae: 28.2500\n",
      "Epoch 49/80\n",
      "1761/1761 [==============================] - 0s 160us/step - loss: 2753.5427 - mse: 2753.5430 - mae: 28.3190\n",
      "Epoch 50/80\n",
      "1761/1761 [==============================] - 0s 146us/step - loss: 2702.3640 - mse: 2702.3645 - mae: 28.8120\n",
      "Epoch 51/80\n",
      "1761/1761 [==============================] - 0s 148us/step - loss: 2712.7551 - mse: 2712.7559 - mae: 27.8748\n",
      "Epoch 52/80\n",
      "1761/1761 [==============================] - 0s 146us/step - loss: 2715.5137 - mse: 2715.5137 - mae: 28.1214\n",
      "Epoch 53/80\n",
      "1761/1761 [==============================] - 0s 150us/step - loss: 2654.7466 - mse: 2654.7458 - mae: 27.7310\n",
      "Epoch 54/80\n",
      "1761/1761 [==============================] - 0s 144us/step - loss: 2650.9552 - mse: 2650.9558 - mae: 27.7360\n",
      "Epoch 55/80\n",
      "1761/1761 [==============================] - 0s 155us/step - loss: 2616.6138 - mse: 2616.6143 - mae: 28.1956\n",
      "Epoch 56/80\n",
      "1761/1761 [==============================] - 0s 149us/step - loss: 2706.7819 - mse: 2706.7822 - mae: 28.2610\n",
      "Epoch 57/80\n",
      "1761/1761 [==============================] - 0s 153us/step - loss: 2729.6961 - mse: 2729.6963 - mae: 28.1939\n",
      "Epoch 58/80\n",
      "1761/1761 [==============================] - 0s 154us/step - loss: 2705.4398 - mse: 2705.4395 - mae: 27.6928\n",
      "Epoch 59/80\n",
      "1761/1761 [==============================] - 0s 158us/step - loss: 2694.0516 - mse: 2694.0510 - mae: 27.8654\n",
      "Epoch 60/80\n",
      "1761/1761 [==============================] - 0s 161us/step - loss: 2655.8293 - mse: 2655.8289 - mae: 27.7955\n",
      "Epoch 61/80\n",
      "1761/1761 [==============================] - 0s 157us/step - loss: 2709.6245 - mse: 2709.6255 - mae: 28.4039\n",
      "Epoch 62/80\n",
      "1761/1761 [==============================] - 0s 144us/step - loss: 2699.4438 - mse: 2699.4436 - mae: 27.3333\n",
      "Epoch 63/80\n",
      "1761/1761 [==============================] - 0s 159us/step - loss: 2613.3296 - mse: 2613.3291 - mae: 27.3643\n",
      "Epoch 64/80\n",
      "1761/1761 [==============================] - 0s 152us/step - loss: 2648.8473 - mse: 2648.8479 - mae: 27.8028\n",
      "Epoch 65/80\n",
      "1761/1761 [==============================] - 0s 154us/step - loss: 2686.7745 - mse: 2686.7749 - mae: 28.1260\n",
      "Epoch 66/80\n",
      "1761/1761 [==============================] - 0s 155us/step - loss: 2676.7360 - mse: 2676.7366 - mae: 27.6791\n",
      "Epoch 67/80\n",
      "1761/1761 [==============================] - 0s 157us/step - loss: 2695.6370 - mse: 2695.6377 - mae: 28.1925\n",
      "Epoch 68/80\n",
      "1761/1761 [==============================] - 0s 156us/step - loss: 2652.2391 - mse: 2652.2385 - mae: 28.0324\n",
      "Epoch 69/80\n",
      "1761/1761 [==============================] - 0s 162us/step - loss: 2660.0847 - mse: 2660.0847 - mae: 27.9787\n",
      "Epoch 70/80\n",
      "1761/1761 [==============================] - 0s 156us/step - loss: 2624.6515 - mse: 2624.6511 - mae: 27.5823\n",
      "Epoch 71/80\n",
      "1761/1761 [==============================] - 0s 156us/step - loss: 2685.1421 - mse: 2685.1414 - mae: 28.0936\n",
      "Epoch 72/80\n",
      "1761/1761 [==============================] - 0s 158us/step - loss: 2658.2661 - mse: 2658.2664 - mae: 28.2561\n",
      "Epoch 73/80\n",
      "1761/1761 [==============================] - 0s 152us/step - loss: 2685.2922 - mse: 2685.2925 - mae: 27.8819\n",
      "Epoch 74/80\n",
      "1761/1761 [==============================] - 0s 164us/step - loss: 2667.0808 - mse: 2667.0818 - mae: 28.2352\n",
      "Epoch 75/80\n",
      "1761/1761 [==============================] - 0s 193us/step - loss: 2687.7126 - mse: 2687.7122 - mae: 28.3309\n",
      "Epoch 76/80\n",
      "1761/1761 [==============================] - 0s 210us/step - loss: 2657.6551 - mse: 2657.6555 - mae: 28.1780\n",
      "Epoch 77/80\n",
      "1761/1761 [==============================] - 0s 137us/step - loss: 2675.1472 - mse: 2675.1470 - mae: 28.0101\n",
      "Epoch 78/80\n",
      "1761/1761 [==============================] - 0s 173us/step - loss: 2712.1835 - mse: 2712.1831 - mae: 28.0657\n",
      "Epoch 79/80\n",
      "1761/1761 [==============================] - 0s 192us/step - loss: 2663.0093 - mse: 2663.0100 - mae: 27.9649\n",
      "Epoch 80/80\n",
      "1761/1761 [==============================] - 0s 163us/step - loss: 2673.2175 - mse: 2673.2170 - mae: 27.5722\n",
      "3\n",
      "Epoch 1/80\n",
      "2346/2346 [==============================] - 0s 168us/step - loss: 2351.2915 - mse: 2351.2920 - mae: 28.0380\n",
      "Epoch 2/80\n",
      "2346/2346 [==============================] - 0s 158us/step - loss: 2379.3125 - mse: 2379.3130 - mae: 27.8526\n",
      "Epoch 3/80\n",
      "2346/2346 [==============================] - 0s 152us/step - loss: 2371.9311 - mse: 2371.9309 - mae: 27.6351\n",
      "Epoch 4/80\n",
      "2346/2346 [==============================] - 0s 149us/step - loss: 2336.8479 - mse: 2336.8477 - mae: 27.8834\n",
      "Epoch 5/80\n",
      "2346/2346 [==============================] - 0s 158us/step - loss: 2370.9156 - mse: 2370.9153 - mae: 27.9725\n",
      "Epoch 6/80\n",
      "2346/2346 [==============================] - 0s 165us/step - loss: 2417.4278 - mse: 2417.4277 - mae: 28.0884\n",
      "Epoch 7/80\n",
      "2346/2346 [==============================] - 0s 161us/step - loss: 2353.8600 - mse: 2353.8601 - mae: 27.9404\n",
      "Epoch 8/80\n",
      "2346/2346 [==============================] - 0s 149us/step - loss: 2320.3365 - mse: 2320.3367 - mae: 27.3812\n",
      "Epoch 9/80\n",
      "2346/2346 [==============================] - 0s 156us/step - loss: 2360.1167 - mse: 2360.1172 - mae: 28.2846\n",
      "Epoch 10/80\n",
      "2346/2346 [==============================] - 0s 162us/step - loss: 2363.1947 - mse: 2363.1938 - mae: 27.8874\n",
      "Epoch 11/80\n",
      "2346/2346 [==============================] - 0s 152us/step - loss: 2319.9301 - mse: 2319.9290 - mae: 27.6058\n",
      "Epoch 12/80\n",
      "2346/2346 [==============================] - 0s 148us/step - loss: 2421.9328 - mse: 2421.9324 - mae: 27.9509\n",
      "Epoch 13/80\n",
      "2346/2346 [==============================] - 0s 143us/step - loss: 2390.0296 - mse: 2390.0293 - mae: 28.0579\n",
      "Epoch 14/80\n",
      "2346/2346 [==============================] - 0s 143us/step - loss: 2368.7406 - mse: 2368.7410 - mae: 28.1571\n",
      "Epoch 15/80\n",
      "2346/2346 [==============================] - 0s 151us/step - loss: 2412.8062 - mse: 2412.8062 - mae: 27.7460\n",
      "Epoch 16/80\n",
      "2346/2346 [==============================] - 0s 142us/step - loss: 2374.5870 - mse: 2374.5869 - mae: 27.9164\n",
      "Epoch 17/80\n",
      "2346/2346 [==============================] - 0s 158us/step - loss: 2391.7244 - mse: 2391.7241 - mae: 28.1467\n",
      "Epoch 18/80\n",
      "2346/2346 [==============================] - 0s 165us/step - loss: 2425.2230 - mse: 2425.2239 - mae: 28.5224\n",
      "Epoch 19/80\n",
      "2346/2346 [==============================] - 0s 158us/step - loss: 2427.7325 - mse: 2427.7324 - mae: 27.9069\n",
      "Epoch 20/80\n",
      "2346/2346 [==============================] - 0s 154us/step - loss: 2365.6444 - mse: 2365.6443 - mae: 27.5584\n",
      "Epoch 21/80\n",
      "2346/2346 [==============================] - 0s 163us/step - loss: 2379.9440 - mse: 2379.9441 - mae: 28.1427\n",
      "Epoch 22/80\n",
      "2346/2346 [==============================] - 0s 161us/step - loss: 2337.3808 - mse: 2337.3811 - mae: 27.6877\n",
      "Epoch 23/80\n",
      "2346/2346 [==============================] - 0s 159us/step - loss: 2368.3078 - mse: 2368.3079 - mae: 27.9657\n",
      "Epoch 24/80\n",
      "2346/2346 [==============================] - 0s 161us/step - loss: 2345.1336 - mse: 2345.1345 - mae: 27.7974\n",
      "Epoch 25/80\n",
      "2346/2346 [==============================] - 0s 148us/step - loss: 2378.5353 - mse: 2378.5359 - mae: 27.6821\n",
      "Epoch 26/80\n",
      "2346/2346 [==============================] - 0s 157us/step - loss: 2355.7515 - mse: 2355.7512 - mae: 27.7743\n",
      "Epoch 27/80\n",
      "2346/2346 [==============================] - 0s 143us/step - loss: 2316.8463 - mse: 2316.8462 - mae: 27.2184\n",
      "Epoch 28/80\n",
      "2346/2346 [==============================] - 0s 156us/step - loss: 2373.1940 - mse: 2373.1929 - mae: 27.7671\n",
      "Epoch 29/80\n",
      "2346/2346 [==============================] - 0s 160us/step - loss: 2346.4374 - mse: 2346.4375 - mae: 27.9237\n",
      "Epoch 30/80\n",
      "2346/2346 [==============================] - 0s 157us/step - loss: 2385.7729 - mse: 2385.7734 - mae: 27.9950\n",
      "Epoch 31/80\n",
      "2346/2346 [==============================] - 0s 155us/step - loss: 2398.2983 - mse: 2398.2983 - mae: 27.7777\n",
      "Epoch 32/80\n",
      "2346/2346 [==============================] - 0s 153us/step - loss: 2332.3317 - mse: 2332.3303 - mae: 27.5159\n",
      "Epoch 33/80\n",
      "2346/2346 [==============================] - 0s 186us/step - loss: 2355.2792 - mse: 2355.2783 - mae: 27.6403\n",
      "Epoch 34/80\n",
      "2346/2346 [==============================] - 0s 193us/step - loss: 2321.2382 - mse: 2321.2383 - mae: 27.5078\n",
      "Epoch 35/80\n",
      "2346/2346 [==============================] - 0s 160us/step - loss: 2363.2169 - mse: 2363.2170 - mae: 27.6407\n",
      "Epoch 36/80\n",
      "2346/2346 [==============================] - 0s 189us/step - loss: 2343.2566 - mse: 2343.2566 - mae: 27.8976\n",
      "Epoch 37/80\n",
      "2346/2346 [==============================] - 0s 173us/step - loss: 2384.7418 - mse: 2384.7417 - mae: 27.8861\n",
      "Epoch 38/80\n",
      "2346/2346 [==============================] - 0s 181us/step - loss: 2385.4183 - mse: 2385.4180 - mae: 27.6824\n",
      "Epoch 39/80\n",
      "2346/2346 [==============================] - 0s 163us/step - loss: 2358.9986 - mse: 2358.9983 - mae: 27.5363\n",
      "Epoch 40/80\n",
      "2346/2346 [==============================] - 0s 203us/step - loss: 2370.5769 - mse: 2370.5767 - mae: 27.6198\n",
      "Epoch 41/80\n",
      "2346/2346 [==============================] - 0s 164us/step - loss: 2374.2006 - mse: 2374.2004 - mae: 27.7179\n",
      "Epoch 42/80\n",
      "2346/2346 [==============================] - 0s 173us/step - loss: 2327.8243 - mse: 2327.8240 - mae: 27.1011\n",
      "Epoch 43/80\n",
      "2346/2346 [==============================] - 0s 187us/step - loss: 2398.6367 - mse: 2398.6370 - mae: 27.9304\n",
      "Epoch 44/80\n",
      "2346/2346 [==============================] - 0s 147us/step - loss: 2289.0072 - mse: 2289.0071 - mae: 27.4502\n",
      "Epoch 45/80\n",
      "2346/2346 [==============================] - 0s 169us/step - loss: 2361.4934 - mse: 2361.4929 - mae: 27.6737\n",
      "Epoch 46/80\n",
      "2346/2346 [==============================] - 0s 146us/step - loss: 2343.2868 - mse: 2343.2881 - mae: 27.7810\n",
      "Epoch 47/80\n",
      "2346/2346 [==============================] - 0s 147us/step - loss: 2339.6612 - mse: 2339.6606 - mae: 27.5226\n",
      "Epoch 48/80\n",
      "2346/2346 [==============================] - 0s 158us/step - loss: 2399.4585 - mse: 2399.4590 - mae: 27.3334\n",
      "Epoch 49/80\n",
      "2346/2346 [==============================] - 0s 163us/step - loss: 2355.9125 - mse: 2355.9116 - mae: 27.9190\n",
      "Epoch 50/80\n",
      "2346/2346 [==============================] - 0s 157us/step - loss: 2365.6090 - mse: 2365.6086 - mae: 27.8349\n",
      "Epoch 51/80\n",
      "2346/2346 [==============================] - 0s 155us/step - loss: 2336.0635 - mse: 2336.0637 - mae: 27.3811\n",
      "Epoch 52/80\n",
      "2346/2346 [==============================] - 0s 155us/step - loss: 2375.5474 - mse: 2375.5479 - mae: 27.7375\n",
      "Epoch 53/80\n",
      "2346/2346 [==============================] - 0s 159us/step - loss: 2362.9389 - mse: 2362.9387 - mae: 28.0316\n",
      "Epoch 54/80\n",
      "2346/2346 [==============================] - 0s 164us/step - loss: 2331.3622 - mse: 2331.3618 - mae: 27.5223\n",
      "Epoch 55/80\n",
      "2346/2346 [==============================] - 0s 163us/step - loss: 2316.8948 - mse: 2316.8948 - mae: 27.5860\n",
      "Epoch 56/80\n",
      "2346/2346 [==============================] - 0s 164us/step - loss: 2357.7180 - mse: 2357.7170 - mae: 27.8816\n",
      "Epoch 57/80\n",
      "2346/2346 [==============================] - 0s 163us/step - loss: 2345.8596 - mse: 2345.8599 - mae: 27.7468\n",
      "Epoch 58/80\n",
      "2346/2346 [==============================] - 0s 163us/step - loss: 2378.6327 - mse: 2378.6328 - mae: 27.8880\n",
      "Epoch 59/80\n",
      "2346/2346 [==============================] - 0s 146us/step - loss: 2392.7218 - mse: 2392.7212 - mae: 27.8371\n",
      "Epoch 60/80\n",
      "2346/2346 [==============================] - 0s 151us/step - loss: 2365.0604 - mse: 2365.0615 - mae: 27.8354\n",
      "Epoch 61/80\n",
      "2346/2346 [==============================] - 0s 156us/step - loss: 2294.7352 - mse: 2294.7354 - mae: 27.2600\n",
      "Epoch 62/80\n",
      "2346/2346 [==============================] - 0s 149us/step - loss: 2391.7985 - mse: 2391.7988 - mae: 28.0527\n",
      "Epoch 63/80\n",
      "2346/2346 [==============================] - 0s 186us/step - loss: 2331.2943 - mse: 2331.2939 - mae: 27.6512\n",
      "Epoch 64/80\n",
      "2346/2346 [==============================] - 0s 191us/step - loss: 2346.4002 - mse: 2346.3997 - mae: 27.0674\n",
      "Epoch 65/80\n",
      "2346/2346 [==============================] - 0s 197us/step - loss: 2366.0108 - mse: 2366.0103 - mae: 27.7387\n",
      "Epoch 66/80\n",
      "2346/2346 [==============================] - 0s 181us/step - loss: 2360.3367 - mse: 2360.3374 - mae: 27.7654\n",
      "Epoch 67/80\n",
      "2346/2346 [==============================] - 0s 157us/step - loss: 2366.5034 - mse: 2366.5032 - mae: 27.9841\n",
      "Epoch 68/80\n",
      "2346/2346 [==============================] - 0s 159us/step - loss: 2366.4396 - mse: 2366.4397 - mae: 27.5634\n",
      "Epoch 69/80\n",
      "2346/2346 [==============================] - 0s 150us/step - loss: 2310.1642 - mse: 2310.1641 - mae: 27.3253\n",
      "Epoch 70/80\n",
      "2346/2346 [==============================] - 0s 147us/step - loss: 2327.1730 - mse: 2327.1724 - mae: 27.4547\n",
      "Epoch 71/80\n",
      "2346/2346 [==============================] - 0s 149us/step - loss: 2319.3712 - mse: 2319.3721 - mae: 27.6834\n",
      "Epoch 72/80\n",
      "2346/2346 [==============================] - 0s 150us/step - loss: 2345.0346 - mse: 2345.0342 - mae: 27.9466\n",
      "Epoch 73/80\n",
      "2346/2346 [==============================] - 0s 161us/step - loss: 2356.9273 - mse: 2356.9272 - mae: 27.5903\n",
      "Epoch 74/80\n",
      "2346/2346 [==============================] - 0s 155us/step - loss: 2363.0847 - mse: 2363.0847 - mae: 27.4454\n",
      "Epoch 75/80\n",
      "2346/2346 [==============================] - 0s 154us/step - loss: 2375.9623 - mse: 2375.9622 - mae: 27.6859\n",
      "Epoch 76/80\n",
      "2346/2346 [==============================] - 0s 153us/step - loss: 2328.3172 - mse: 2328.3169 - mae: 27.9315\n",
      "Epoch 77/80\n",
      "2346/2346 [==============================] - 0s 148us/step - loss: 2334.3787 - mse: 2334.3789 - mae: 27.3897\n",
      "Epoch 78/80\n",
      "2346/2346 [==============================] - 0s 141us/step - loss: 2354.4646 - mse: 2354.4639 - mae: 28.1608\n",
      "Epoch 79/80\n",
      "2346/2346 [==============================] - 0s 151us/step - loss: 2357.1008 - mse: 2357.1008 - mae: 27.2294\n",
      "Epoch 80/80\n",
      "2346/2346 [==============================] - 0s 162us/step - loss: 2340.8284 - mse: 2340.8279 - mae: 27.9452\n",
      "4\n",
      "Epoch 1/80\n",
      "2931/2931 [==============================] - 0s 146us/step - loss: 2136.2606 - mse: 2136.2617 - mae: 27.3847\n",
      "Epoch 2/80\n",
      "2931/2931 [==============================] - 0s 156us/step - loss: 2150.3487 - mse: 2150.3479 - mae: 27.4624\n",
      "Epoch 3/80\n",
      "2931/2931 [==============================] - 0s 161us/step - loss: 2140.1882 - mse: 2140.1880 - mae: 27.2906\n",
      "Epoch 4/80\n",
      "2931/2931 [==============================] - 0s 150us/step - loss: 2157.7077 - mse: 2157.7075 - mae: 27.2356\n",
      "Epoch 5/80\n",
      "2931/2931 [==============================] - 0s 149us/step - loss: 2170.0476 - mse: 2170.0474 - mae: 27.5886\n",
      "Epoch 6/80\n",
      "2931/2931 [==============================] - 0s 134us/step - loss: 2128.8111 - mse: 2128.8108 - mae: 27.5617\n",
      "Epoch 7/80\n",
      "2931/2931 [==============================] - 0s 147us/step - loss: 2128.6832 - mse: 2128.6833 - mae: 27.2749\n",
      "Epoch 8/80\n",
      "2931/2931 [==============================] - 0s 139us/step - loss: 2143.5731 - mse: 2143.5723 - mae: 27.3548\n",
      "Epoch 9/80\n",
      "2931/2931 [==============================] - 0s 151us/step - loss: 2193.5896 - mse: 2193.5896 - mae: 27.8034\n",
      "Epoch 10/80\n",
      "2931/2931 [==============================] - 0s 149us/step - loss: 2126.9651 - mse: 2126.9658 - mae: 27.2102\n",
      "Epoch 11/80\n",
      "2931/2931 [==============================] - 0s 159us/step - loss: 2158.1795 - mse: 2158.1802 - mae: 27.2313\n",
      "Epoch 12/80\n",
      "2931/2931 [==============================] - 0s 149us/step - loss: 2150.9506 - mse: 2150.9509 - mae: 27.1247\n",
      "Epoch 13/80\n",
      "2931/2931 [==============================] - 0s 156us/step - loss: 2122.7129 - mse: 2122.7129 - mae: 27.1313\n",
      "Epoch 14/80\n",
      "2931/2931 [==============================] - 0s 147us/step - loss: 2121.0254 - mse: 2121.0254 - mae: 27.2858\n",
      "Epoch 15/80\n",
      "2931/2931 [==============================] - 0s 154us/step - loss: 2135.6542 - mse: 2135.6538 - mae: 27.2243\n",
      "Epoch 16/80\n",
      "2931/2931 [==============================] - 0s 156us/step - loss: 2160.6087 - mse: 2160.6084 - mae: 27.2277\n",
      "Epoch 17/80\n",
      "2931/2931 [==============================] - 0s 140us/step - loss: 2105.1325 - mse: 2105.1326 - mae: 27.0312\n",
      "Epoch 18/80\n",
      "2931/2931 [==============================] - 0s 144us/step - loss: 2119.8995 - mse: 2119.8987 - mae: 27.5385\n",
      "Epoch 19/80\n",
      "2931/2931 [==============================] - 0s 156us/step - loss: 2131.6367 - mse: 2131.6362 - mae: 27.2910\n",
      "Epoch 20/80\n",
      "2931/2931 [==============================] - 0s 146us/step - loss: 2146.3353 - mse: 2146.3352 - mae: 27.6846\n",
      "Epoch 21/80\n",
      "2931/2931 [==============================] - 0s 144us/step - loss: 2155.8297 - mse: 2155.8301 - mae: 27.4370\n",
      "Epoch 22/80\n",
      "2931/2931 [==============================] - 0s 148us/step - loss: 2118.0326 - mse: 2118.0325 - mae: 27.2332\n",
      "Epoch 23/80\n",
      "2931/2931 [==============================] - 0s 151us/step - loss: 2117.7687 - mse: 2117.7678 - mae: 27.3464\n",
      "Epoch 24/80\n",
      "2931/2931 [==============================] - 0s 143us/step - loss: 2154.9145 - mse: 2154.9148 - mae: 27.2431\n",
      "Epoch 25/80\n",
      "2931/2931 [==============================] - 0s 152us/step - loss: 2175.0884 - mse: 2175.0881 - mae: 27.6244\n",
      "Epoch 26/80\n",
      "2931/2931 [==============================] - 0s 144us/step - loss: 2126.3146 - mse: 2126.3152 - mae: 27.1847\n",
      "Epoch 27/80\n",
      "2931/2931 [==============================] - 0s 154us/step - loss: 2146.2826 - mse: 2146.2820 - mae: 27.6316\n",
      "Epoch 28/80\n",
      "2931/2931 [==============================] - 0s 153us/step - loss: 2169.3996 - mse: 2169.4001 - mae: 27.1387\n",
      "Epoch 29/80\n",
      "2931/2931 [==============================] - 0s 144us/step - loss: 2129.7248 - mse: 2129.7244 - mae: 27.1559\n",
      "Epoch 30/80\n",
      "2931/2931 [==============================] - 0s 146us/step - loss: 2125.0446 - mse: 2125.0444 - mae: 27.1643\n",
      "Epoch 31/80\n",
      "2931/2931 [==============================] - 0s 149us/step - loss: 2108.8375 - mse: 2108.8374 - mae: 27.3497\n",
      "Epoch 32/80\n",
      "2931/2931 [==============================] - 0s 150us/step - loss: 2097.2188 - mse: 2097.2188 - mae: 26.9289\n",
      "Epoch 33/80\n",
      "2931/2931 [==============================] - 0s 152us/step - loss: 2131.4860 - mse: 2131.4858 - mae: 27.2274\n",
      "Epoch 34/80\n",
      "2931/2931 [==============================] - 0s 140us/step - loss: 2089.3555 - mse: 2089.3560 - mae: 27.1934\n",
      "Epoch 35/80\n",
      "2931/2931 [==============================] - 0s 144us/step - loss: 2109.7193 - mse: 2109.7192 - mae: 26.8947\n",
      "Epoch 36/80\n",
      "2931/2931 [==============================] - 0s 153us/step - loss: 2144.4636 - mse: 2144.4634 - mae: 27.4612\n",
      "Epoch 37/80\n",
      "2931/2931 [==============================] - 0s 148us/step - loss: 2096.3703 - mse: 2096.3706 - mae: 26.8492\n",
      "Epoch 38/80\n",
      "2931/2931 [==============================] - 0s 148us/step - loss: 2113.2989 - mse: 2113.2986 - mae: 27.0417\n",
      "Epoch 39/80\n",
      "2931/2931 [==============================] - 0s 158us/step - loss: 2102.6952 - mse: 2102.6946 - mae: 27.2893\n",
      "Epoch 40/80\n",
      "2931/2931 [==============================] - 0s 149us/step - loss: 2106.4040 - mse: 2106.4045 - mae: 26.9267\n",
      "Epoch 41/80\n",
      "2931/2931 [==============================] - 0s 150us/step - loss: 2121.5105 - mse: 2121.5103 - mae: 27.2551\n",
      "Epoch 42/80\n",
      "2931/2931 [==============================] - 0s 150us/step - loss: 2155.3124 - mse: 2155.3127 - mae: 27.4646\n",
      "Epoch 43/80\n",
      "2931/2931 [==============================] - 0s 144us/step - loss: 2136.5861 - mse: 2136.5859 - mae: 27.0723\n",
      "Epoch 44/80\n",
      "2931/2931 [==============================] - 0s 157us/step - loss: 2132.4134 - mse: 2132.4136 - mae: 27.2746\n",
      "Epoch 45/80\n",
      "2931/2931 [==============================] - 0s 140us/step - loss: 2148.6814 - mse: 2148.6809 - mae: 27.0028\n",
      "Epoch 46/80\n",
      "2931/2931 [==============================] - 0s 160us/step - loss: 2130.0179 - mse: 2130.0181 - mae: 27.4273\n",
      "Epoch 47/80\n",
      "2931/2931 [==============================] - 0s 152us/step - loss: 2115.5216 - mse: 2115.5215 - mae: 27.1804\n",
      "Epoch 48/80\n",
      "2931/2931 [==============================] - 0s 142us/step - loss: 2137.3354 - mse: 2137.3357 - mae: 27.2662\n",
      "Epoch 49/80\n",
      "2931/2931 [==============================] - 0s 137us/step - loss: 2147.8884 - mse: 2147.8879 - mae: 27.4288\n",
      "Epoch 50/80\n",
      "2931/2931 [==============================] - 0s 148us/step - loss: 2105.6044 - mse: 2105.6040 - mae: 27.0159\n",
      "Epoch 51/80\n",
      "2931/2931 [==============================] - 0s 154us/step - loss: 2122.8693 - mse: 2122.8696 - mae: 27.3341\n",
      "Epoch 52/80\n",
      "2931/2931 [==============================] - 0s 139us/step - loss: 2150.8159 - mse: 2150.8169 - mae: 27.4025\n",
      "Epoch 53/80\n",
      "2931/2931 [==============================] - 0s 153us/step - loss: 2122.8205 - mse: 2122.8208 - mae: 27.0023\n",
      "Epoch 54/80\n",
      "2931/2931 [==============================] - 0s 145us/step - loss: 2162.8587 - mse: 2162.8586 - mae: 27.2902\n",
      "Epoch 55/80\n",
      "2931/2931 [==============================] - 0s 150us/step - loss: 2106.8152 - mse: 2106.8154 - mae: 27.0634\n",
      "Epoch 56/80\n",
      "2931/2931 [==============================] - 0s 149us/step - loss: 2116.1846 - mse: 2116.1848 - mae: 27.2480\n",
      "Epoch 57/80\n",
      "2931/2931 [==============================] - 0s 144us/step - loss: 2094.3355 - mse: 2094.3354 - mae: 27.0419\n",
      "Epoch 58/80\n",
      "2931/2931 [==============================] - 0s 149us/step - loss: 2143.4952 - mse: 2143.4958 - mae: 27.4887\n",
      "Epoch 59/80\n",
      "2931/2931 [==============================] - 0s 150us/step - loss: 2125.9481 - mse: 2125.9490 - mae: 27.3844\n",
      "Epoch 60/80\n",
      "2931/2931 [==============================] - 0s 143us/step - loss: 2110.6089 - mse: 2110.6086 - mae: 27.1840\n",
      "Epoch 61/80\n",
      "2931/2931 [==============================] - 0s 165us/step - loss: 2150.8404 - mse: 2150.8401 - mae: 27.2951\n",
      "Epoch 62/80\n",
      "2931/2931 [==============================] - 0s 153us/step - loss: 2119.2181 - mse: 2119.2183 - mae: 26.8614\n",
      "Epoch 63/80\n",
      "2931/2931 [==============================] - 0s 170us/step - loss: 2119.3140 - mse: 2119.3130 - mae: 26.9383\n",
      "Epoch 64/80\n",
      "2931/2931 [==============================] - 1s 172us/step - loss: 2104.7197 - mse: 2104.7202 - mae: 27.0019\n",
      "Epoch 65/80\n",
      "2931/2931 [==============================] - 0s 162us/step - loss: 2118.2736 - mse: 2118.2732 - mae: 26.8843\n",
      "Epoch 66/80\n",
      "2931/2931 [==============================] - 0s 161us/step - loss: 2101.6896 - mse: 2101.6895 - mae: 26.9171\n",
      "Epoch 67/80\n",
      "2931/2931 [==============================] - 1s 176us/step - loss: 2119.0883 - mse: 2119.0884 - mae: 27.2853\n",
      "Epoch 68/80\n",
      "2931/2931 [==============================] - 0s 133us/step - loss: 2099.1073 - mse: 2099.1072 - mae: 26.8851\n",
      "Epoch 69/80\n",
      "2931/2931 [==============================] - 0s 136us/step - loss: 2135.0650 - mse: 2135.0652 - mae: 27.3798\n",
      "Epoch 70/80\n",
      "2931/2931 [==============================] - 0s 136us/step - loss: 2111.4660 - mse: 2111.4658 - mae: 27.1270\n",
      "Epoch 71/80\n",
      "2931/2931 [==============================] - 0s 137us/step - loss: 2098.7332 - mse: 2098.7319 - mae: 26.99620s - loss: 1641.2196 - mse: 1641.2194 - \n",
      "Epoch 72/80\n",
      "2931/2931 [==============================] - 0s 166us/step - loss: 2122.7462 - mse: 2122.7458 - mae: 26.9986\n",
      "Epoch 73/80\n",
      "2931/2931 [==============================] - 1s 175us/step - loss: 2102.5469 - mse: 2102.5464 - mae: 26.8589\n",
      "Epoch 74/80\n",
      "2931/2931 [==============================] - 0s 152us/step - loss: 2071.0565 - mse: 2071.0562 - mae: 26.8530\n",
      "Epoch 75/80\n",
      "2931/2931 [==============================] - 1s 177us/step - loss: 2075.6868 - mse: 2075.6875 - mae: 26.7987\n",
      "Epoch 76/80\n",
      "2931/2931 [==============================] - 0s 166us/step - loss: 2135.9364 - mse: 2135.9358 - mae: 27.3100\n",
      "Epoch 77/80\n",
      "2931/2931 [==============================] - 0s 170us/step - loss: 2134.5569 - mse: 2134.5571 - mae: 26.9422\n",
      "Epoch 78/80\n",
      "2931/2931 [==============================] - 0s 162us/step - loss: 2109.6320 - mse: 2109.6321 - mae: 27.0152\n",
      "Epoch 79/80\n",
      "2931/2931 [==============================] - 0s 162us/step - loss: 2146.7361 - mse: 2146.7354 - mae: 27.2772\n",
      "Epoch 80/80\n",
      "2931/2931 [==============================] - 0s 144us/step - loss: 2141.9739 - mse: 2141.9756 - mae: 27.1481\n",
      "5\n",
      "Epoch 1/80\n",
      "3516/3516 [==============================] - 1s 154us/step - loss: 2559.9558 - mse: 2559.9556 - mae: 27.0995\n",
      "Epoch 2/80\n",
      "3516/3516 [==============================] - 1s 151us/step - loss: 2523.9018 - mse: 2523.9014 - mae: 26.9401\n",
      "Epoch 3/80\n",
      "3516/3516 [==============================] - 1s 157us/step - loss: 2543.9449 - mse: 2543.9453 - mae: 27.1994\n",
      "Epoch 4/80\n",
      "3516/3516 [==============================] - 1s 153us/step - loss: 2529.8765 - mse: 2529.8774 - mae: 27.2130\n",
      "Epoch 5/80\n",
      "3516/3516 [==============================] - 1s 157us/step - loss: 2540.3623 - mse: 2540.3611 - mae: 27.1360\n",
      "Epoch 6/80\n",
      "3516/3516 [==============================] - 1s 157us/step - loss: 2540.5518 - mse: 2540.5520 - mae: 27.0618\n",
      "Epoch 7/80\n",
      "3516/3516 [==============================] - 1s 163us/step - loss: 2526.1816 - mse: 2526.1807 - mae: 27.2562\n",
      "Epoch 8/80\n",
      "3516/3516 [==============================] - 1s 151us/step - loss: 2545.5150 - mse: 2545.5156 - mae: 27.0305\n",
      "Epoch 9/80\n",
      "3516/3516 [==============================] - 1s 148us/step - loss: 2544.1604 - mse: 2544.1597 - mae: 27.2294\n",
      "Epoch 10/80\n",
      "3516/3516 [==============================] - 1s 151us/step - loss: 2548.6992 - mse: 2548.7002 - mae: 27.1073\n",
      "Epoch 11/80\n",
      "3516/3516 [==============================] - 1s 156us/step - loss: 2520.7231 - mse: 2520.7229 - mae: 26.7905\n",
      "Epoch 12/80\n",
      "3516/3516 [==============================] - 1s 146us/step - loss: 2546.3426 - mse: 2546.3428 - mae: 26.9502\n",
      "Epoch 13/80\n",
      "3516/3516 [==============================] - 1s 158us/step - loss: 2543.9926 - mse: 2543.9915 - mae: 27.1829\n",
      "Epoch 14/80\n",
      "3516/3516 [==============================] - 1s 169us/step - loss: 2592.0087 - mse: 2592.0085 - mae: 27.2347\n",
      "Epoch 15/80\n",
      "3516/3516 [==============================] - 1s 158us/step - loss: 2507.6547 - mse: 2507.6548 - mae: 27.0106\n",
      "Epoch 16/80\n",
      "3516/3516 [==============================] - 1s 159us/step - loss: 2559.6098 - mse: 2559.6106 - mae: 27.1588\n",
      "Epoch 17/80\n",
      "3516/3516 [==============================] - 1s 160us/step - loss: 2517.0062 - mse: 2517.0059 - mae: 26.8760\n",
      "Epoch 18/80\n",
      "3516/3516 [==============================] - 1s 157us/step - loss: 2578.3805 - mse: 2578.3806 - mae: 27.2209\n",
      "Epoch 19/80\n",
      "3516/3516 [==============================] - 1s 158us/step - loss: 2524.6615 - mse: 2524.6609 - mae: 27.0203\n",
      "Epoch 20/80\n",
      "3516/3516 [==============================] - 1s 168us/step - loss: 2551.6823 - mse: 2551.6816 - mae: 27.1114\n",
      "Epoch 21/80\n",
      "3516/3516 [==============================] - 1s 158us/step - loss: 2544.9213 - mse: 2544.9207 - mae: 27.2413\n",
      "Epoch 22/80\n",
      "3516/3516 [==============================] - 1s 159us/step - loss: 2536.4989 - mse: 2536.4998 - mae: 27.0472\n",
      "Epoch 23/80\n",
      "3516/3516 [==============================] - 1s 162us/step - loss: 2514.2709 - mse: 2514.2727 - mae: 26.8558\n",
      "Epoch 24/80\n",
      "3516/3516 [==============================] - 1s 160us/step - loss: 2525.1347 - mse: 2525.1343 - mae: 26.8527\n",
      "Epoch 25/80\n",
      "3516/3516 [==============================] - 1s 158us/step - loss: 2520.5262 - mse: 2520.5271 - mae: 27.0925\n",
      "Epoch 26/80\n",
      "3516/3516 [==============================] - 1s 158us/step - loss: 2524.4392 - mse: 2524.4397 - mae: 26.9029\n",
      "Epoch 27/80\n",
      "3516/3516 [==============================] - 1s 153us/step - loss: 2497.5775 - mse: 2497.5779 - mae: 27.1315\n",
      "Epoch 28/80\n",
      "3516/3516 [==============================] - 1s 159us/step - loss: 2531.9894 - mse: 2531.9907 - mae: 26.8490\n",
      "Epoch 29/80\n",
      "3516/3516 [==============================] - 1s 162us/step - loss: 2528.0389 - mse: 2528.0378 - mae: 27.1528\n",
      "Epoch 30/80\n",
      "3516/3516 [==============================] - 1s 160us/step - loss: 2529.7706 - mse: 2529.7703 - mae: 27.0109\n",
      "Epoch 31/80\n",
      "3516/3516 [==============================] - 1s 161us/step - loss: 2550.6139 - mse: 2550.6140 - mae: 27.1874\n",
      "Epoch 32/80\n",
      "3516/3516 [==============================] - 1s 158us/step - loss: 2526.7394 - mse: 2526.7393 - mae: 26.9151\n",
      "Epoch 33/80\n",
      "3516/3516 [==============================] - 1s 161us/step - loss: 2545.9763 - mse: 2545.9766 - mae: 26.8899\n",
      "Epoch 34/80\n",
      "3516/3516 [==============================] - 1s 161us/step - loss: 2529.0267 - mse: 2529.0261 - mae: 27.1332\n",
      "Epoch 35/80\n",
      "3516/3516 [==============================] - 1s 160us/step - loss: 2532.5312 - mse: 2532.5308 - mae: 27.2345\n",
      "Epoch 36/80\n",
      "3516/3516 [==============================] - 1s 160us/step - loss: 2551.8159 - mse: 2551.8162 - mae: 27.1371\n",
      "Epoch 37/80\n",
      "3516/3516 [==============================] - 1s 159us/step - loss: 2521.2274 - mse: 2521.2288 - mae: 26.9651\n",
      "Epoch 38/80\n",
      "3516/3516 [==============================] - 1s 161us/step - loss: 2543.7493 - mse: 2543.7485 - mae: 27.2602\n",
      "Epoch 39/80\n",
      "3516/3516 [==============================] - 1s 157us/step - loss: 2530.5036 - mse: 2530.5034 - mae: 27.0970\n",
      "Epoch 40/80\n",
      "3516/3516 [==============================] - 1s 160us/step - loss: 2515.5613 - mse: 2515.5608 - mae: 27.2679\n",
      "Epoch 41/80\n",
      "3516/3516 [==============================] - 1s 162us/step - loss: 2519.6637 - mse: 2519.6638 - mae: 26.9321\n",
      "Epoch 42/80\n",
      "3516/3516 [==============================] - 1s 161us/step - loss: 2515.1549 - mse: 2515.1548 - mae: 27.0263\n",
      "Epoch 43/80\n",
      "3516/3516 [==============================] - 1s 158us/step - loss: 2515.7266 - mse: 2515.7263 - mae: 27.1184\n",
      "Epoch 44/80\n",
      "3516/3516 [==============================] - 1s 160us/step - loss: 2519.3035 - mse: 2519.3027 - mae: 26.9945\n",
      "Epoch 45/80\n",
      "3516/3516 [==============================] - 1s 158us/step - loss: 2544.2567 - mse: 2544.2583 - mae: 27.0483\n",
      "Epoch 46/80\n",
      "3516/3516 [==============================] - 1s 157us/step - loss: 2536.4856 - mse: 2536.4856 - mae: 26.8902\n",
      "Epoch 47/80\n",
      "3516/3516 [==============================] - 1s 163us/step - loss: 2526.3246 - mse: 2526.3252 - mae: 27.1009\n",
      "Epoch 48/80\n",
      "3516/3516 [==============================] - 1s 166us/step - loss: 2511.9591 - mse: 2511.9587 - mae: 26.8792\n",
      "Epoch 49/80\n",
      "3516/3516 [==============================] - 1s 173us/step - loss: 2545.2181 - mse: 2545.2188 - mae: 27.2375\n",
      "Epoch 50/80\n",
      "3516/3516 [==============================] - 1s 203us/step - loss: 2554.4192 - mse: 2554.4197 - mae: 26.8573\n",
      "Epoch 51/80\n",
      "3516/3516 [==============================] - 1s 219us/step - loss: 2481.1995 - mse: 2481.1995 - mae: 26.5810\n",
      "Epoch 52/80\n",
      "3516/3516 [==============================] - 1s 157us/step - loss: 2534.8174 - mse: 2534.8174 - mae: 26.9488\n",
      "Epoch 53/80\n",
      "3516/3516 [==============================] - 1s 155us/step - loss: 2521.0143 - mse: 2521.0154 - mae: 26.7721\n",
      "Epoch 54/80\n",
      "3516/3516 [==============================] - 1s 159us/step - loss: 2504.8762 - mse: 2504.8765 - mae: 27.0028\n",
      "Epoch 55/80\n",
      "3516/3516 [==============================] - 1s 159us/step - loss: 2523.5732 - mse: 2523.5728 - mae: 26.7383\n",
      "Epoch 56/80\n",
      "3516/3516 [==============================] - 1s 160us/step - loss: 2530.7938 - mse: 2530.7932 - mae: 27.2368\n",
      "Epoch 57/80\n",
      "3516/3516 [==============================] - 1s 163us/step - loss: 2549.5699 - mse: 2549.5703 - mae: 27.1661\n",
      "Epoch 58/80\n",
      "3516/3516 [==============================] - 1s 159us/step - loss: 2520.9614 - mse: 2520.9617 - mae: 27.0107\n",
      "Epoch 59/80\n",
      "3516/3516 [==============================] - 1s 162us/step - loss: 2484.6839 - mse: 2484.6833 - mae: 26.5114\n",
      "Epoch 60/80\n",
      "3516/3516 [==============================] - 1s 163us/step - loss: 2528.8934 - mse: 2528.8936 - mae: 26.8060\n",
      "Epoch 61/80\n",
      "3516/3516 [==============================] - 1s 160us/step - loss: 2534.7608 - mse: 2534.7605 - mae: 27.2621\n",
      "Epoch 62/80\n",
      "3516/3516 [==============================] - 1s 162us/step - loss: 2520.2789 - mse: 2520.2788 - mae: 27.2302\n",
      "Epoch 63/80\n",
      "3516/3516 [==============================] - 1s 157us/step - loss: 2513.1859 - mse: 2513.1858 - mae: 27.1716\n",
      "Epoch 64/80\n",
      "3516/3516 [==============================] - 1s 157us/step - loss: 2512.4046 - mse: 2512.4045 - mae: 26.8341\n",
      "Epoch 65/80\n",
      "3516/3516 [==============================] - 1s 160us/step - loss: 2570.0351 - mse: 2570.0352 - mae: 27.2487\n",
      "Epoch 66/80\n",
      "3516/3516 [==============================] - 1s 159us/step - loss: 2543.1973 - mse: 2543.1978 - mae: 27.0669\n",
      "Epoch 67/80\n",
      "3516/3516 [==============================] - 1s 161us/step - loss: 2541.9318 - mse: 2541.9307 - mae: 27.1060\n",
      "Epoch 68/80\n",
      "3516/3516 [==============================] - 1s 163us/step - loss: 2503.1772 - mse: 2503.1772 - mae: 27.2757\n",
      "Epoch 69/80\n",
      "3516/3516 [==============================] - 1s 162us/step - loss: 2527.7041 - mse: 2527.7041 - mae: 26.9107\n",
      "Epoch 70/80\n",
      "3516/3516 [==============================] - 1s 163us/step - loss: 2549.8330 - mse: 2549.8333 - mae: 27.0447\n",
      "Epoch 71/80\n",
      "3516/3516 [==============================] - 1s 161us/step - loss: 2497.3012 - mse: 2497.3018 - mae: 26.8801\n",
      "Epoch 72/80\n",
      "3516/3516 [==============================] - 1s 160us/step - loss: 2539.7177 - mse: 2539.7178 - mae: 27.0395\n",
      "Epoch 73/80\n",
      "3516/3516 [==============================] - 1s 162us/step - loss: 2532.7166 - mse: 2532.7168 - mae: 27.1239\n",
      "Epoch 74/80\n",
      "3516/3516 [==============================] - 1s 161us/step - loss: 2528.8918 - mse: 2528.8921 - mae: 26.9369\n",
      "Epoch 75/80\n",
      "3516/3516 [==============================] - 1s 159us/step - loss: 2541.9547 - mse: 2541.9539 - mae: 26.9134\n",
      "Epoch 76/80\n",
      "3516/3516 [==============================] - 1s 164us/step - loss: 2528.8961 - mse: 2528.8967 - mae: 26.9929\n",
      "Epoch 77/80\n",
      "3516/3516 [==============================] - 1s 158us/step - loss: 2518.3747 - mse: 2518.3740 - mae: 27.1258\n",
      "Epoch 78/80\n",
      "3516/3516 [==============================] - 1s 162us/step - loss: 2549.1144 - mse: 2549.1152 - mae: 26.7739\n",
      "Epoch 79/80\n",
      "3516/3516 [==============================] - 1s 162us/step - loss: 2502.7517 - mse: 2502.7512 - mae: 26.8544\n",
      "Epoch 80/80\n",
      "3516/3516 [==============================] - 1s 163us/step - loss: 2495.6584 - mse: 2495.6575 - mae: 26.8683\n",
      "6\n",
      "Epoch 1/80\n",
      "4101/4101 [==============================] - 1s 163us/step - loss: 2621.2737 - mse: 2621.2744 - mae: 27.7615\n",
      "Epoch 2/80\n",
      "4101/4101 [==============================] - 1s 154us/step - loss: 2620.4011 - mse: 2620.4014 - mae: 27.7830\n",
      "Epoch 3/80\n",
      "4101/4101 [==============================] - 1s 145us/step - loss: 2617.7929 - mse: 2617.7932 - mae: 27.8137\n",
      "Epoch 4/80\n",
      "4101/4101 [==============================] - 1s 156us/step - loss: 2616.1095 - mse: 2616.1089 - mae: 27.7158\n",
      "Epoch 5/80\n",
      "4101/4101 [==============================] - 1s 154us/step - loss: 2574.1460 - mse: 2574.1455 - mae: 27.6088\n",
      "Epoch 6/80\n",
      "4101/4101 [==============================] - 1s 153us/step - loss: 2579.0346 - mse: 2579.0356 - mae: 27.6945\n",
      "Epoch 7/80\n",
      "4101/4101 [==============================] - 1s 148us/step - loss: 2615.0695 - mse: 2615.0696 - mae: 27.8411\n",
      "Epoch 8/80\n",
      "4101/4101 [==============================] - 1s 149us/step - loss: 2581.1281 - mse: 2581.1279 - mae: 27.3496\n",
      "Epoch 9/80\n",
      "4101/4101 [==============================] - 1s 161us/step - loss: 2650.1374 - mse: 2650.1372 - mae: 28.1314\n",
      "Epoch 10/80\n",
      "4101/4101 [==============================] - 1s 153us/step - loss: 2584.7303 - mse: 2584.7300 - mae: 27.7464\n",
      "Epoch 11/80\n",
      "4101/4101 [==============================] - 1s 182us/step - loss: 2573.3436 - mse: 2573.3440 - mae: 27.5241\n",
      "Epoch 12/80\n",
      "4101/4101 [==============================] - 1s 161us/step - loss: 2581.5897 - mse: 2581.5898 - mae: 27.6377\n",
      "Epoch 13/80\n",
      "4101/4101 [==============================] - 1s 159us/step - loss: 2591.1076 - mse: 2591.1082 - mae: 27.7345\n",
      "Epoch 14/80\n",
      "4101/4101 [==============================] - 1s 159us/step - loss: 2579.2286 - mse: 2579.2292 - mae: 27.8154\n",
      "Epoch 15/80\n",
      "4101/4101 [==============================] - 1s 157us/step - loss: 2616.6710 - mse: 2616.6704 - mae: 27.8085\n",
      "Epoch 16/80\n",
      "4101/4101 [==============================] - 1s 160us/step - loss: 2622.4014 - mse: 2622.4019 - mae: 27.9120\n",
      "Epoch 17/80\n",
      "4101/4101 [==============================] - 1s 163us/step - loss: 2616.2466 - mse: 2616.2466 - mae: 27.9270\n",
      "Epoch 18/80\n",
      "4101/4101 [==============================] - 1s 175us/step - loss: 2631.1651 - mse: 2631.1660 - mae: 27.9329\n",
      "Epoch 19/80\n",
      "4101/4101 [==============================] - 1s 160us/step - loss: 2612.6873 - mse: 2612.6870 - mae: 27.9089\n",
      "Epoch 20/80\n",
      "4101/4101 [==============================] - 1s 152us/step - loss: 2620.5212 - mse: 2620.5222 - mae: 27.6832\n",
      "Epoch 21/80\n",
      "4101/4101 [==============================] - 1s 159us/step - loss: 2579.3428 - mse: 2579.3433 - mae: 27.7297\n",
      "Epoch 22/80\n",
      "4101/4101 [==============================] - 1s 157us/step - loss: 2599.3384 - mse: 2599.3391 - mae: 27.6590\n",
      "Epoch 23/80\n",
      "4101/4101 [==============================] - 1s 154us/step - loss: 2602.8201 - mse: 2602.8196 - mae: 27.6670\n",
      "Epoch 24/80\n",
      "4101/4101 [==============================] - 1s 161us/step - loss: 2602.0184 - mse: 2602.0188 - mae: 27.6181\n",
      "Epoch 25/80\n",
      "4101/4101 [==============================] - 1s 159us/step - loss: 2584.2578 - mse: 2584.2583 - mae: 27.5825\n",
      "Epoch 26/80\n",
      "4101/4101 [==============================] - 1s 153us/step - loss: 2559.1847 - mse: 2559.1838 - mae: 27.5283\n",
      "Epoch 27/80\n",
      "4101/4101 [==============================] - 1s 152us/step - loss: 2591.6892 - mse: 2591.6885 - mae: 27.5996\n",
      "Epoch 28/80\n",
      "4101/4101 [==============================] - 1s 158us/step - loss: 2586.8402 - mse: 2586.8413 - mae: 27.6597\n",
      "Epoch 29/80\n",
      "4101/4101 [==============================] - 1s 156us/step - loss: 2634.2397 - mse: 2634.2397 - mae: 27.5471\n",
      "Epoch 30/80\n",
      "4101/4101 [==============================] - 1s 152us/step - loss: 2569.7008 - mse: 2569.7000 - mae: 27.5719\n",
      "Epoch 31/80\n",
      "4101/4101 [==============================] - 1s 156us/step - loss: 2596.5293 - mse: 2596.5300 - mae: 27.6524\n",
      "Epoch 32/80\n",
      "4101/4101 [==============================] - 1s 159us/step - loss: 2622.2496 - mse: 2622.2495 - mae: 27.9942\n",
      "Epoch 33/80\n",
      "4101/4101 [==============================] - 1s 158us/step - loss: 2575.3065 - mse: 2575.3074 - mae: 27.4361\n",
      "Epoch 34/80\n",
      "4101/4101 [==============================] - 1s 159us/step - loss: 2604.9432 - mse: 2604.9429 - mae: 27.9388\n",
      "Epoch 35/80\n",
      "4101/4101 [==============================] - 1s 161us/step - loss: 2582.4766 - mse: 2582.4771 - mae: 27.5951\n",
      "Epoch 36/80\n",
      "4101/4101 [==============================] - 1s 159us/step - loss: 2615.3228 - mse: 2615.3225 - mae: 27.8948\n",
      "Epoch 37/80\n",
      "4101/4101 [==============================] - 1s 156us/step - loss: 2606.4946 - mse: 2606.4934 - mae: 27.7675\n",
      "Epoch 38/80\n",
      "4101/4101 [==============================] - 1s 163us/step - loss: 2589.7869 - mse: 2589.7856 - mae: 27.5676\n",
      "Epoch 39/80\n",
      "4101/4101 [==============================] - 1s 153us/step - loss: 2620.7900 - mse: 2620.7896 - mae: 27.6956\n",
      "Epoch 40/80\n",
      "4101/4101 [==============================] - 1s 166us/step - loss: 2589.2023 - mse: 2589.2026 - mae: 27.7181\n",
      "Epoch 41/80\n",
      "4101/4101 [==============================] - 1s 160us/step - loss: 2626.9978 - mse: 2626.9985 - mae: 27.9505\n",
      "Epoch 42/80\n",
      "4101/4101 [==============================] - 1s 159us/step - loss: 2589.6028 - mse: 2589.6025 - mae: 27.6018\n",
      "Epoch 43/80\n",
      "4101/4101 [==============================] - 1s 159us/step - loss: 2573.3274 - mse: 2573.3279 - mae: 27.5155\n",
      "Epoch 44/80\n",
      "4101/4101 [==============================] - 1s 158us/step - loss: 2587.5253 - mse: 2587.5242 - mae: 27.5902\n",
      "Epoch 45/80\n",
      "4101/4101 [==============================] - 1s 159us/step - loss: 2589.7152 - mse: 2589.7131 - mae: 27.8890\n",
      "Epoch 46/80\n",
      "4101/4101 [==============================] - 1s 161us/step - loss: 2603.0631 - mse: 2603.0640 - mae: 27.6606\n",
      "Epoch 47/80\n",
      "4101/4101 [==============================] - 1s 158us/step - loss: 2599.3843 - mse: 2599.3845 - mae: 27.8081\n",
      "Epoch 48/80\n",
      "4101/4101 [==============================] - 1s 155us/step - loss: 2604.5190 - mse: 2604.5181 - mae: 27.4101\n",
      "Epoch 49/80\n",
      "4101/4101 [==============================] - 1s 161us/step - loss: 2575.6111 - mse: 2575.6106 - mae: 27.7158\n",
      "Epoch 50/80\n",
      "4101/4101 [==============================] - 1s 160us/step - loss: 2601.3367 - mse: 2601.3359 - mae: 27.7593\n",
      "Epoch 51/80\n",
      "4101/4101 [==============================] - 1s 161us/step - loss: 2599.6918 - mse: 2599.6919 - mae: 27.6240\n",
      "Epoch 52/80\n",
      "4101/4101 [==============================] - 1s 156us/step - loss: 2565.6012 - mse: 2565.6003 - mae: 27.5581\n",
      "Epoch 53/80\n",
      "4101/4101 [==============================] - 1s 146us/step - loss: 2561.7277 - mse: 2561.7268 - mae: 27.5884\n",
      "Epoch 54/80\n",
      "4101/4101 [==============================] - 1s 160us/step - loss: 2590.3385 - mse: 2590.3379 - mae: 27.4861\n",
      "Epoch 55/80\n",
      "4101/4101 [==============================] - 1s 162us/step - loss: 2600.9404 - mse: 2600.9402 - mae: 27.7253\n",
      "Epoch 56/80\n",
      "4101/4101 [==============================] - 1s 153us/step - loss: 2617.5281 - mse: 2617.5283 - mae: 27.6745\n",
      "Epoch 57/80\n",
      "4101/4101 [==============================] - 1s 156us/step - loss: 2611.0863 - mse: 2611.0872 - mae: 28.1176\n",
      "Epoch 58/80\n",
      "4101/4101 [==============================] - 1s 163us/step - loss: 2601.6360 - mse: 2601.6353 - mae: 27.5895\n",
      "Epoch 59/80\n",
      "4101/4101 [==============================] - 1s 156us/step - loss: 2577.7060 - mse: 2577.7058 - mae: 27.6306\n",
      "Epoch 60/80\n",
      "4101/4101 [==============================] - 1s 159us/step - loss: 2585.3850 - mse: 2585.3845 - mae: 27.5961\n",
      "Epoch 61/80\n",
      "4101/4101 [==============================] - 1s 156us/step - loss: 2553.9100 - mse: 2553.9102 - mae: 27.6404\n",
      "Epoch 62/80\n",
      "4101/4101 [==============================] - 1s 160us/step - loss: 2568.9756 - mse: 2568.9753 - mae: 27.3755\n",
      "Epoch 63/80\n",
      "4101/4101 [==============================] - 1s 160us/step - loss: 2617.9793 - mse: 2617.9797 - mae: 27.7739\n",
      "Epoch 64/80\n",
      "4101/4101 [==============================] - 1s 161us/step - loss: 2601.5517 - mse: 2601.5510 - mae: 27.7240\n",
      "Epoch 65/80\n",
      "4101/4101 [==============================] - 1s 159us/step - loss: 2592.0011 - mse: 2592.0017 - mae: 27.2833\n",
      "Epoch 66/80\n",
      "4101/4101 [==============================] - 1s 161us/step - loss: 2573.9238 - mse: 2573.9236 - mae: 27.4145\n",
      "Epoch 67/80\n",
      "4101/4101 [==============================] - 1s 160us/step - loss: 2593.8546 - mse: 2593.8547 - mae: 27.9906\n",
      "Epoch 68/80\n",
      "4101/4101 [==============================] - 1s 161us/step - loss: 2578.0642 - mse: 2578.0647 - mae: 27.3476\n",
      "Epoch 69/80\n",
      "4101/4101 [==============================] - 1s 153us/step - loss: 2594.2169 - mse: 2594.2173 - mae: 27.9495\n",
      "Epoch 70/80\n",
      "4101/4101 [==============================] - 1s 152us/step - loss: 2583.6928 - mse: 2583.6926 - mae: 27.6606\n",
      "Epoch 71/80\n",
      "4101/4101 [==============================] - 1s 157us/step - loss: 2588.8293 - mse: 2588.8286 - mae: 27.9656\n",
      "Epoch 72/80\n",
      "4101/4101 [==============================] - 1s 166us/step - loss: 2589.5832 - mse: 2589.5833 - mae: 27.8624\n",
      "Epoch 73/80\n",
      "4101/4101 [==============================] - 1s 153us/step - loss: 2595.7410 - mse: 2595.7397 - mae: 27.7136\n",
      "Epoch 74/80\n",
      "4101/4101 [==============================] - 1s 155us/step - loss: 2573.6073 - mse: 2573.6074 - mae: 27.5943\n",
      "Epoch 75/80\n",
      "4101/4101 [==============================] - 1s 161us/step - loss: 2572.3201 - mse: 2572.3210 - mae: 27.7217\n",
      "Epoch 76/80\n",
      "4101/4101 [==============================] - 1s 163us/step - loss: 2605.2319 - mse: 2605.2327 - mae: 27.5092\n",
      "Epoch 77/80\n",
      "4101/4101 [==============================] - 1s 160us/step - loss: 2584.6927 - mse: 2584.6926 - mae: 27.7788\n",
      "Epoch 78/80\n",
      "4101/4101 [==============================] - 1s 160us/step - loss: 2595.5256 - mse: 2595.5266 - mae: 27.6011\n",
      "Epoch 79/80\n",
      "4101/4101 [==============================] - 1s 157us/step - loss: 2584.3579 - mse: 2584.3577 - mae: 27.7142\n",
      "Epoch 80/80\n",
      "4101/4101 [==============================] - 1s 162us/step - loss: 2571.6852 - mse: 2571.6858 - mae: 27.7489\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "# data\n",
    "data = pd.read_csv('Data_set_1_smaller.csv', index_col = 0)\n",
    "\n",
    "# COMPLETE\n",
    "data = data.loc[data.index > 2018090000, :]\n",
    "    \n",
    "# reset index\n",
    "data.reset_index(inplace = True)\n",
    "data.drop('index', axis = 1, inplace = True)\n",
    "    \n",
    "# Divide features and labels\n",
    "X = data.iloc[:, 0:15]\n",
    "y = data.loc[:, 'Offers']\n",
    "\n",
    "X.fillna(X.mean(), inplace = True)\n",
    "y.fillna(y.mean(), inplace = True)\n",
    "    \n",
    "X = X.astype('float64')\n",
    "X = X.round(20)\n",
    "    \n",
    "# divide data into train and test with 20% test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "             X, y, test_size=0.2, shuffle=False)\n",
    "    \n",
    "# feature scaling\n",
    "sc_X = MinMaxScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)\n",
    "    \n",
    "import keras\n",
    "from keras.models import Sequential # to initialise the NN\n",
    "from keras.layers import Dense # to create layers\n",
    "from keras.layers import Dropout\n",
    "from keras import initializers\n",
    "from keras import optimizers\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "    \n",
    "# possible debug\n",
    "X_train = np.nan_to_num(X_train)\n",
    "X_test = np.nan_to_num(X_test)\n",
    "    \n",
    "def regressor_tunning(n_hidden = 2, \n",
    "                      n_neurons = 30,  \n",
    "                      kernel_initializer = \"he_normal\",\n",
    "                      bias_initializer = initializers.Ones()):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = n_neurons, input_dim = 15))        \n",
    "    model.add(keras.layers.LeakyReLU(alpha = 0.2))\n",
    "    model.add(Dropout(rate = 0.1))        \n",
    "    for layer in range(n_hidden):\n",
    "        model.add(Dense(n_neurons))\n",
    "        model.add(keras.layers.LeakyReLU(alpha = 0.2))\n",
    "        model.add(Dropout(rate = 0.1))\n",
    "    model.add(Dense(units = 1, activation = 'linear'))\n",
    "    optimizer = optimizers.Adamax(lr = 0.001)\n",
    "    model.compile(loss = 'mse', optimizer = optimizer, metrics = ['mse', 'mae'])\n",
    "    return model\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits = 7)\n",
    "\n",
    "hist_list = pd.DataFrame()\n",
    "count = 1\n",
    "    \n",
    "regressor = regressor_tunning()\n",
    "    \n",
    "for train_index, test_index in tscv.split(X_train):\n",
    "    X_train_split, X_test_split = X_train[train_index], X_train[test_index]\n",
    "    y_train_split, y_test_split = y_train[train_index], y_train[test_index]\n",
    "    hist = regressor.fit(X_train_split, y_train_split, batch_size = 15, epochs = 80)\n",
    "    hist_list = hist_list.append(hist.history, ignore_index = True)\n",
    "    print(count)\n",
    "    count = count + 1\n",
    "\n",
    "a = []\n",
    "b = []\n",
    "\n",
    "for i in range(len(hist_list.mse)):\n",
    "    a.append(np.mean(hist_list.mse[i]))\n",
    "    b.append(np.mean(hist_list.mae[i]))\n",
    "\n",
    "mse_cv.append(np.mean(a))\n",
    "mae_cv.append(np.mean(b))\n",
    "\n",
    "# predict for X_test  \n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "\n",
    "rmse_error = mse(y_test, y_pred, squared = False)\n",
    "mse_error = mse(y_test, y_pred) # 1479.61335\n",
    "mae_error = mae(y_test, y_pred) # 23.1525\n",
    "\n",
    "rmse_gen.append(rmse_error)\n",
    "mse_gen.append(mse_error)\n",
    "mae_gen.append(mae_error)\n",
    "\n",
    "# =============================================================================\n",
    "# Metrics evaluation on spike regions\n",
    "# =============================================================================\n",
    "\n",
    "y_spike_occ = pd.read_csv('Spike_binary_1std.csv', usecols = [6])\n",
    "\n",
    "# create array same size as y_test\n",
    "y_spike_occ = y_spike_occ.iloc[- len(y_test):]\n",
    "y_spike_occ = pd.Series(y_spike_occ.iloc[:,0]).values\n",
    "\n",
    "\n",
    "# smal adjustment\n",
    "y_test.replace(0, 0.0001,inplace = True)\n",
    "\n",
    "\n",
    "# select y_pred and y_test only for regions with spikes\n",
    "y_test_spike = (y_test.T * y_spike_occ).T\n",
    "y_pred_spike = (y_pred.T * y_spike_occ).T\n",
    "y_test_spike = y_test_spike[y_test_spike != 0]\n",
    "y_pred_spike = y_pred_spike[y_pred_spike != 0]\n",
    "\n",
    "# calculate metric\n",
    "rmse_spike = mse(y_test_spike, y_pred_spike, squared = False)\n",
    "mse_spike = mse(y_test_spike, y_pred_spike)\n",
    "mae_spike = mae(y_test_spike, y_pred_spike)\n",
    "\n",
    "rmse_spi.append(rmse_spike)\n",
    "mse_spi.append(mse_spike)\n",
    "mae_spi.append(mae_spike)\n",
    "\n",
    "# =============================================================================\n",
    "# Metric evaluation on normal regions\n",
    "# =============================================================================\n",
    "\n",
    "# inverse y_spike_occ so the only normal occurences are chosen\n",
    "y_normal_occ = (y_spike_occ - 1) * (-1)\n",
    "\n",
    "# sanity check\n",
    "y_normal_occ.sum() + y_spike_occ.sum() # gives the correct total \n",
    "\n",
    "# select y_pred and y_test only for normal regions\n",
    "y_test_normal = (y_test.T * y_normal_occ).T\n",
    "y_pred_normal = (y_pred.T * y_normal_occ).T\n",
    "y_test_normal = y_test_normal[y_test_normal != 0.00]\n",
    "y_pred_normal = y_pred_normal[y_pred_normal != 0.00]\n",
    "\n",
    "# calculate metric\n",
    "rmse_normal = mse(y_test_normal, y_pred_normal, squared = False)\n",
    "mse_normal = mse(y_test_normal, y_pred_normal)\n",
    "mae_normal = mae(y_test_normal, y_pred_normal)\n",
    "\n",
    "rmse_nor.append(rmse_normal)\n",
    "mse_nor.append(mse_normal)\n",
    "mae_nor.append(mae_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse_cv</th>\n",
       "      <th>mae_cv</th>\n",
       "      <th>rmse_general</th>\n",
       "      <th>mae_general</th>\n",
       "      <th>rmse_spike</th>\n",
       "      <th>mae_spike</th>\n",
       "      <th>rmse_normal</th>\n",
       "      <th>mae_normal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55.276041</td>\n",
       "      <td>28.98105</td>\n",
       "      <td>33.480437</td>\n",
       "      <td>25.72624</td>\n",
       "      <td>70.280266</td>\n",
       "      <td>57.429934</td>\n",
       "      <td>23.855083</td>\n",
       "      <td>21.144065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     rmse_cv    mae_cv  rmse_general  mae_general  rmse_spike  mae_spike  \\\n",
       "0  55.276041  28.98105     33.480437     25.72624   70.280266  57.429934   \n",
       "\n",
       "   rmse_normal  mae_normal  \n",
       "0    23.855083   21.144065  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_cv = []\n",
    "for i in mse_cv:\n",
    "    rmse_cv.append(i ** 0.5)\n",
    "    \n",
    "results = pd.DataFrame({'rmse_cv':rmse_cv,\n",
    "              \n",
    "                        'mae_cv': mae_cv,\n",
    "                        \n",
    "                        'rmse_general': rmse_gen, \n",
    "                 \n",
    "                        'mae_general': mae_gen,\n",
    "                        \n",
    "                        'rmse_spike': rmse_spi,\n",
    "                 \n",
    "                        'mae_spike': mae_spi,\n",
    "                        \n",
    "                        'rmse_normal': rmse_nor,\n",
    "                    \n",
    "                        'mae_normal': mae_nor})\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results for exponential schedueling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/pandas/core/generic.py:6245: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 17809.8309 - mse: 17809.8301 - mae: 114.9894\n",
      "Epoch 2/80\n",
      "591/591 [==============================] - 0s 147us/step - loss: 17643.1505 - mse: 17643.1543 - mae: 114.2578\n",
      "Epoch 3/80\n",
      "591/591 [==============================] - 0s 174us/step - loss: 17340.5621 - mse: 17340.5625 - mae: 112.9505\n",
      "Epoch 4/80\n",
      "591/591 [==============================] - 0s 198us/step - loss: 16972.6350 - mse: 16972.6367 - mae: 111.2634\n",
      "Epoch 5/80\n",
      "591/591 [==============================] - 0s 194us/step - loss: 16607.2175 - mse: 16607.2188 - mae: 109.6209\n",
      "Epoch 6/80\n",
      "591/591 [==============================] - 0s 157us/step - loss: 16082.2955 - mse: 16082.2979 - mae: 107.2934\n",
      "Epoch 7/80\n",
      "591/591 [==============================] - 0s 168us/step - loss: 15493.6103 - mse: 15493.6123 - mae: 104.4968\n",
      "Epoch 8/80\n",
      "591/591 [==============================] - 0s 170us/step - loss: 14807.4340 - mse: 14807.4336 - mae: 101.1935\n",
      "Epoch 9/80\n",
      "591/591 [==============================] - 0s 167us/step - loss: 14130.6506 - mse: 14130.6494 - mae: 97.7188\n",
      "Epoch 10/80\n",
      "591/591 [==============================] - 0s 196us/step - loss: 13523.0623 - mse: 13523.0625 - mae: 94.5377\n",
      "Epoch 11/80\n",
      "591/591 [==============================] - 0s 190us/step - loss: 12956.8412 - mse: 12956.8389 - mae: 91.4667\n",
      "Epoch 12/80\n",
      "591/591 [==============================] - 0s 175us/step - loss: 12572.1822 - mse: 12572.1816 - mae: 89.4465\n",
      "Epoch 13/80\n",
      "591/591 [==============================] - 0s 133us/step - loss: 12213.3570 - mse: 12213.3574 - mae: 87.5561\n",
      "Epoch 14/80\n",
      "591/591 [==============================] - 0s 188us/step - loss: 11917.5377 - mse: 11917.5371 - mae: 85.7766\n",
      "Epoch 15/80\n",
      "591/591 [==============================] - 0s 193us/step - loss: 11681.0651 - mse: 11681.0645 - mae: 84.0901\n",
      "Epoch 16/80\n",
      "591/591 [==============================] - 0s 188us/step - loss: 11389.5378 - mse: 11389.5371 - mae: 82.4406\n",
      "Epoch 17/80\n",
      "591/591 [==============================] - 0s 176us/step - loss: 11073.7541 - mse: 11073.7549 - mae: 80.6127\n",
      "Epoch 18/80\n",
      "591/591 [==============================] - 0s 175us/step - loss: 10848.1298 - mse: 10848.1309 - mae: 78.9819\n",
      "Epoch 19/80\n",
      "591/591 [==============================] - 0s 179us/step - loss: 10538.3661 - mse: 10538.3652 - mae: 77.4800\n",
      "Epoch 20/80\n",
      "591/591 [==============================] - 0s 177us/step - loss: 10472.1879 - mse: 10472.1885 - mae: 76.3632\n",
      "Epoch 21/80\n",
      "591/591 [==============================] - 0s 177us/step - loss: 10161.2641 - mse: 10161.2627 - mae: 74.7400\n",
      "Epoch 22/80\n",
      "591/591 [==============================] - 0s 177us/step - loss: 10055.7355 - mse: 10055.7373 - mae: 73.8220\n",
      "Epoch 23/80\n",
      "591/591 [==============================] - 0s 179us/step - loss: 9860.6086 - mse: 9860.6084 - mae: 72.6982\n",
      "Epoch 24/80\n",
      "591/591 [==============================] - 0s 264us/step - loss: 9837.3333 - mse: 9837.3340 - mae: 71.8996\n",
      "Epoch 25/80\n",
      "591/591 [==============================] - 0s 196us/step - loss: 9615.1929 - mse: 9615.1934 - mae: 70.8096\n",
      "Epoch 26/80\n",
      "591/591 [==============================] - 0s 179us/step - loss: 9563.1221 - mse: 9563.1211 - mae: 70.6135\n",
      "Epoch 27/80\n",
      "591/591 [==============================] - 0s 224us/step - loss: 9453.3879 - mse: 9453.3867 - mae: 69.7502\n",
      "Epoch 28/80\n",
      "591/591 [==============================] - 0s 204us/step - loss: 9357.6151 - mse: 9357.6143 - mae: 69.1820\n",
      "Epoch 29/80\n",
      "591/591 [==============================] - 0s 271us/step - loss: 9355.7410 - mse: 9355.7432 - mae: 68.6481\n",
      "Epoch 30/80\n",
      "591/591 [==============================] - 0s 216us/step - loss: 9237.8471 - mse: 9237.8467 - mae: 68.4964\n",
      "Epoch 31/80\n",
      "591/591 [==============================] - 0s 220us/step - loss: 9137.7558 - mse: 9137.7559 - mae: 67.3633\n",
      "Epoch 32/80\n",
      "591/591 [==============================] - 0s 173us/step - loss: 9152.1703 - mse: 9152.1709 - mae: 67.1863\n",
      "Epoch 33/80\n",
      "591/591 [==============================] - 0s 160us/step - loss: 9052.7464 - mse: 9052.7461 - mae: 66.4441\n",
      "Epoch 34/80\n",
      "591/591 [==============================] - 0s 160us/step - loss: 9061.3270 - mse: 9061.3271 - mae: 66.7491\n",
      "Epoch 35/80\n",
      "591/591 [==============================] - 0s 162us/step - loss: 9068.9562 - mse: 9068.9570 - mae: 66.5226\n",
      "Epoch 36/80\n",
      "591/591 [==============================] - 0s 202us/step - loss: 9019.4281 - mse: 9019.4268 - mae: 66.4311\n",
      "Epoch 37/80\n",
      "591/591 [==============================] - 0s 198us/step - loss: 8943.2561 - mse: 8943.2559 - mae: 66.1742\n",
      "Epoch 38/80\n",
      "591/591 [==============================] - 0s 159us/step - loss: 8954.8254 - mse: 8954.8262 - mae: 65.6354\n",
      "Epoch 39/80\n",
      "591/591 [==============================] - 0s 158us/step - loss: 8883.1880 - mse: 8883.1885 - mae: 65.4149\n",
      "Epoch 40/80\n",
      "591/591 [==============================] - 0s 159us/step - loss: 8953.4278 - mse: 8953.4287 - mae: 65.5000\n",
      "Epoch 41/80\n",
      "591/591 [==============================] - 0s 159us/step - loss: 8833.9314 - mse: 8833.9316 - mae: 65.1812\n",
      "Epoch 42/80\n",
      "591/591 [==============================] - 0s 163us/step - loss: 8913.6999 - mse: 8913.6992 - mae: 65.4638\n",
      "Epoch 43/80\n",
      "591/591 [==============================] - 0s 222us/step - loss: 8772.5549 - mse: 8772.5557 - mae: 64.9982\n",
      "Epoch 44/80\n",
      "591/591 [==============================] - 0s 212us/step - loss: 8833.9947 - mse: 8833.9971 - mae: 65.3005\n",
      "Epoch 45/80\n",
      "591/591 [==============================] - 0s 168us/step - loss: 8793.4216 - mse: 8793.4209 - mae: 64.5841\n",
      "Epoch 46/80\n",
      "591/591 [==============================] - 0s 163us/step - loss: 8783.7446 - mse: 8783.7451 - mae: 65.1743\n",
      "Epoch 47/80\n",
      "591/591 [==============================] - 0s 161us/step - loss: 8748.1179 - mse: 8748.1162 - mae: 64.5545\n",
      "Epoch 48/80\n",
      "591/591 [==============================] - 0s 164us/step - loss: 8711.9435 - mse: 8711.9424 - mae: 64.7605\n",
      "Epoch 49/80\n",
      "591/591 [==============================] - 0s 199us/step - loss: 8786.2733 - mse: 8786.2734 - mae: 64.5828\n",
      "Epoch 50/80\n",
      "591/591 [==============================] - 0s 214us/step - loss: 8815.7151 - mse: 8815.7158 - mae: 64.3006\n",
      "Epoch 51/80\n",
      "591/591 [==============================] - 0s 176us/step - loss: 8733.7863 - mse: 8733.7852 - mae: 64.5471\n",
      "Epoch 52/80\n",
      "591/591 [==============================] - 0s 161us/step - loss: 8818.5837 - mse: 8818.5840 - mae: 64.4374\n",
      "Epoch 53/80\n",
      "591/591 [==============================] - 0s 149us/step - loss: 8763.3515 - mse: 8763.3516 - mae: 63.9042\n",
      "Epoch 54/80\n",
      "591/591 [==============================] - 0s 150us/step - loss: 8708.6602 - mse: 8708.6602 - mae: 64.5408\n",
      "Epoch 55/80\n",
      "591/591 [==============================] - 0s 167us/step - loss: 8761.1061 - mse: 8761.1064 - mae: 64.1314\n",
      "Epoch 56/80\n",
      "591/591 [==============================] - 0s 162us/step - loss: 8718.7511 - mse: 8718.7500 - mae: 64.3492\n",
      "Epoch 57/80\n",
      "591/591 [==============================] - 0s 144us/step - loss: 8585.2629 - mse: 8585.2637 - mae: 63.9786\n",
      "Epoch 58/80\n",
      "591/591 [==============================] - 0s 142us/step - loss: 8711.6501 - mse: 8711.6504 - mae: 64.4958\n",
      "Epoch 59/80\n",
      "591/591 [==============================] - 0s 163us/step - loss: 8641.2635 - mse: 8641.2646 - mae: 64.0504\n",
      "Epoch 60/80\n",
      "591/591 [==============================] - 0s 164us/step - loss: 8663.1755 - mse: 8663.1758 - mae: 64.0608\n",
      "Epoch 61/80\n",
      "591/591 [==============================] - 0s 148us/step - loss: 8677.3721 - mse: 8677.3711 - mae: 64.0715\n",
      "Epoch 62/80\n",
      "591/591 [==============================] - 0s 147us/step - loss: 8730.9300 - mse: 8730.9307 - mae: 64.3864\n",
      "Epoch 63/80\n",
      "591/591 [==============================] - 0s 148us/step - loss: 8718.8145 - mse: 8718.8154 - mae: 64.1434\n",
      "Epoch 64/80\n",
      "591/591 [==============================] - 0s 166us/step - loss: 8714.2571 - mse: 8714.2559 - mae: 64.1058\n",
      "Epoch 65/80\n",
      "591/591 [==============================] - 0s 162us/step - loss: 8763.0966 - mse: 8763.0967 - mae: 64.2967\n",
      "Epoch 66/80\n",
      "591/591 [==============================] - 0s 145us/step - loss: 8811.4696 - mse: 8811.4697 - mae: 64.5759\n",
      "Epoch 67/80\n",
      "591/591 [==============================] - 0s 160us/step - loss: 8690.8533 - mse: 8690.8535 - mae: 64.1990\n",
      "Epoch 68/80\n",
      "591/591 [==============================] - 0s 164us/step - loss: 8647.9048 - mse: 8647.9043 - mae: 63.8690\n",
      "Epoch 69/80\n",
      "591/591 [==============================] - 0s 161us/step - loss: 8609.5923 - mse: 8609.5928 - mae: 63.5350\n",
      "Epoch 70/80\n",
      "591/591 [==============================] - 0s 144us/step - loss: 8622.8997 - mse: 8622.9004 - mae: 63.5413\n",
      "Epoch 71/80\n",
      "591/591 [==============================] - 0s 147us/step - loss: 8732.4063 - mse: 8732.4062 - mae: 64.6923\n",
      "Epoch 72/80\n",
      "591/591 [==============================] - 0s 161us/step - loss: 8759.3922 - mse: 8759.3896 - mae: 64.2069\n",
      "Epoch 73/80\n",
      "591/591 [==============================] - 0s 161us/step - loss: 8695.4988 - mse: 8695.4971 - mae: 64.1296\n",
      "Epoch 74/80\n",
      "591/591 [==============================] - 0s 137us/step - loss: 8686.8861 - mse: 8686.8867 - mae: 64.0133\n",
      "Epoch 75/80\n",
      "591/591 [==============================] - 0s 139us/step - loss: 8647.7327 - mse: 8647.7314 - mae: 64.1298\n",
      "Epoch 76/80\n",
      "591/591 [==============================] - 0s 164us/step - loss: 8683.2700 - mse: 8683.2695 - mae: 63.9042\n",
      "Epoch 77/80\n",
      "591/591 [==============================] - 0s 156us/step - loss: 8749.3537 - mse: 8749.3516 - mae: 64.3486\n",
      "Epoch 78/80\n",
      "591/591 [==============================] - 0s 144us/step - loss: 8726.3476 - mse: 8726.3477 - mae: 64.4151\n",
      "Epoch 79/80\n",
      "591/591 [==============================] - 0s 149us/step - loss: 8635.0727 - mse: 8635.0732 - mae: 64.0371\n",
      "Epoch 80/80\n",
      "591/591 [==============================] - 0s 141us/step - loss: 8799.1893 - mse: 8799.1895 - mae: 64.7302\n",
      "1\n",
      "Epoch 1/80\n",
      "1176/1176 [==============================] - 0s 158us/step - loss: 6255.5304 - mse: 6255.5312 - mae: 52.9086\n",
      "Epoch 2/80\n",
      "1176/1176 [==============================] - 0s 150us/step - loss: 4008.4879 - mse: 4008.4885 - mae: 32.6767\n",
      "Epoch 3/80\n",
      "1176/1176 [==============================] - 0s 139us/step - loss: 3508.2276 - mse: 3508.2280 - mae: 30.7023\n",
      "Epoch 4/80\n",
      "1176/1176 [==============================] - 0s 144us/step - loss: 3436.6515 - mse: 3436.6516 - mae: 29.9242\n",
      "Epoch 5/80\n",
      "1176/1176 [==============================] - 0s 153us/step - loss: 3525.6829 - mse: 3525.6826 - mae: 31.7767\n",
      "Epoch 6/80\n",
      "1176/1176 [==============================] - 0s 146us/step - loss: 3511.8831 - mse: 3511.8823 - mae: 30.5525\n",
      "Epoch 7/80\n",
      "1176/1176 [==============================] - 0s 143us/step - loss: 3481.4818 - mse: 3481.4810 - mae: 31.4540\n",
      "Epoch 8/80\n",
      "1176/1176 [==============================] - 0s 137us/step - loss: 3562.2246 - mse: 3562.2249 - mae: 31.8355\n",
      "Epoch 9/80\n",
      "1176/1176 [==============================] - 0s 141us/step - loss: 3634.5976 - mse: 3634.5974 - mae: 31.7520\n",
      "Epoch 10/80\n",
      "1176/1176 [==============================] - 0s 151us/step - loss: 3569.9759 - mse: 3569.9761 - mae: 31.5347\n",
      "Epoch 11/80\n",
      "1176/1176 [==============================] - 0s 162us/step - loss: 3565.0737 - mse: 3565.0732 - mae: 30.9047\n",
      "Epoch 12/80\n",
      "1176/1176 [==============================] - 0s 145us/step - loss: 3619.1026 - mse: 3619.1025 - mae: 31.8046\n",
      "Epoch 13/80\n",
      "1176/1176 [==============================] - 0s 147us/step - loss: 3529.3713 - mse: 3529.3716 - mae: 31.3464\n",
      "Epoch 14/80\n",
      "1176/1176 [==============================] - 0s 156us/step - loss: 3559.9193 - mse: 3559.9189 - mae: 31.8655\n",
      "Epoch 15/80\n",
      "1176/1176 [==============================] - 0s 150us/step - loss: 3606.6318 - mse: 3606.6318 - mae: 31.0680\n",
      "Epoch 16/80\n",
      "1176/1176 [==============================] - 0s 140us/step - loss: 3560.3428 - mse: 3560.3425 - mae: 30.7787\n",
      "Epoch 17/80\n",
      "1176/1176 [==============================] - 0s 154us/step - loss: 3617.4338 - mse: 3617.4336 - mae: 31.9382\n",
      "Epoch 18/80\n",
      "1176/1176 [==============================] - 0s 160us/step - loss: 3540.4860 - mse: 3540.4851 - mae: 31.4028\n",
      "Epoch 19/80\n",
      "1176/1176 [==============================] - 0s 140us/step - loss: 3568.1659 - mse: 3568.1658 - mae: 31.5975\n",
      "Epoch 20/80\n",
      "1176/1176 [==============================] - 0s 163us/step - loss: 3480.0931 - mse: 3480.0930 - mae: 31.3599\n",
      "Epoch 21/80\n",
      "1176/1176 [==============================] - 0s 163us/step - loss: 3606.7175 - mse: 3606.7173 - mae: 31.6069\n",
      "Epoch 22/80\n",
      "1176/1176 [==============================] - 0s 158us/step - loss: 3430.3144 - mse: 3430.3145 - mae: 30.6603\n",
      "Epoch 23/80\n",
      "1176/1176 [==============================] - 0s 157us/step - loss: 3497.3568 - mse: 3497.3567 - mae: 31.5408\n",
      "Epoch 24/80\n",
      "1176/1176 [==============================] - 0s 159us/step - loss: 3460.7722 - mse: 3460.7722 - mae: 30.7612\n",
      "Epoch 25/80\n",
      "1176/1176 [==============================] - 0s 151us/step - loss: 3476.3563 - mse: 3476.3567 - mae: 30.9665\n",
      "Epoch 26/80\n",
      "1176/1176 [==============================] - 0s 157us/step - loss: 3526.8768 - mse: 3526.8774 - mae: 30.9014\n",
      "Epoch 27/80\n",
      "1176/1176 [==============================] - 0s 142us/step - loss: 3490.7198 - mse: 3490.7192 - mae: 31.3634\n",
      "Epoch 28/80\n",
      "1176/1176 [==============================] - 0s 146us/step - loss: 3573.1190 - mse: 3573.1187 - mae: 31.0781\n",
      "Epoch 29/80\n",
      "1176/1176 [==============================] - 0s 160us/step - loss: 3555.5901 - mse: 3555.5906 - mae: 31.3004\n",
      "Epoch 30/80\n",
      "1176/1176 [==============================] - 0s 149us/step - loss: 3529.1301 - mse: 3529.1299 - mae: 31.2734\n",
      "Epoch 31/80\n",
      "1176/1176 [==============================] - 0s 158us/step - loss: 3692.0887 - mse: 3692.0894 - mae: 32.7750\n",
      "Epoch 32/80\n",
      "1176/1176 [==============================] - 0s 153us/step - loss: 3556.2174 - mse: 3556.2173 - mae: 31.8844\n",
      "Epoch 33/80\n",
      "1176/1176 [==============================] - 0s 155us/step - loss: 3529.9821 - mse: 3529.9822 - mae: 31.7444\n",
      "Epoch 34/80\n",
      "1176/1176 [==============================] - 0s 142us/step - loss: 3543.4379 - mse: 3543.4380 - mae: 31.8683\n",
      "Epoch 35/80\n",
      "1176/1176 [==============================] - 0s 162us/step - loss: 3501.4678 - mse: 3501.4680 - mae: 31.6387\n",
      "Epoch 36/80\n",
      "1176/1176 [==============================] - 0s 153us/step - loss: 3551.9796 - mse: 3551.9795 - mae: 31.6218\n",
      "Epoch 37/80\n",
      "1176/1176 [==============================] - 0s 184us/step - loss: 3490.6756 - mse: 3490.6753 - mae: 31.1680\n",
      "Epoch 38/80\n",
      "1176/1176 [==============================] - 0s 187us/step - loss: 3607.9999 - mse: 3607.9993 - mae: 31.9680\n",
      "Epoch 39/80\n",
      "1176/1176 [==============================] - 0s 127us/step - loss: 3485.7622 - mse: 3485.7617 - mae: 31.5395\n",
      "Epoch 40/80\n",
      "1176/1176 [==============================] - 0s 141us/step - loss: 3505.9655 - mse: 3505.9656 - mae: 31.5161\n",
      "Epoch 41/80\n",
      "1176/1176 [==============================] - 0s 164us/step - loss: 3601.3915 - mse: 3601.3916 - mae: 31.7113\n",
      "Epoch 42/80\n",
      "1176/1176 [==============================] - 0s 187us/step - loss: 3523.4530 - mse: 3523.4531 - mae: 32.0895\n",
      "Epoch 43/80\n",
      "1176/1176 [==============================] - 0s 182us/step - loss: 3596.6325 - mse: 3596.6323 - mae: 31.3126\n",
      "Epoch 44/80\n",
      "1176/1176 [==============================] - 0s 220us/step - loss: 3613.4498 - mse: 3613.4500 - mae: 32.5845\n",
      "Epoch 45/80\n",
      "1176/1176 [==============================] - 0s 140us/step - loss: 3566.0891 - mse: 3566.0891 - mae: 30.7951\n",
      "Epoch 46/80\n",
      "1176/1176 [==============================] - 0s 165us/step - loss: 3466.1791 - mse: 3466.1785 - mae: 30.8233\n",
      "Epoch 47/80\n",
      "1176/1176 [==============================] - 0s 154us/step - loss: 3573.5231 - mse: 3573.5239 - mae: 31.5007\n",
      "Epoch 48/80\n",
      "1176/1176 [==============================] - 0s 150us/step - loss: 3562.4269 - mse: 3562.4268 - mae: 30.8639\n",
      "Epoch 49/80\n",
      "1176/1176 [==============================] - 0s 167us/step - loss: 3379.7899 - mse: 3379.7903 - mae: 30.7252\n",
      "Epoch 50/80\n",
      "1176/1176 [==============================] - 0s 131us/step - loss: 3525.0860 - mse: 3525.0864 - mae: 31.3262\n",
      "Epoch 51/80\n",
      "1176/1176 [==============================] - 0s 187us/step - loss: 3502.4279 - mse: 3502.4277 - mae: 31.2203\n",
      "Epoch 52/80\n",
      "1176/1176 [==============================] - 0s 190us/step - loss: 3544.0821 - mse: 3544.0823 - mae: 31.3008\n",
      "Epoch 53/80\n",
      "1176/1176 [==============================] - 0s 187us/step - loss: 3468.4538 - mse: 3468.4543 - mae: 30.8784\n",
      "Epoch 54/80\n",
      "1176/1176 [==============================] - 0s 191us/step - loss: 3474.6596 - mse: 3474.6599 - mae: 31.3906\n",
      "Epoch 55/80\n",
      "1176/1176 [==============================] - 0s 192us/step - loss: 3477.0942 - mse: 3477.0942 - mae: 31.0059\n",
      "Epoch 56/80\n",
      "1176/1176 [==============================] - 0s 192us/step - loss: 3679.6690 - mse: 3679.6687 - mae: 31.7156\n",
      "Epoch 57/80\n",
      "1176/1176 [==============================] - 0s 191us/step - loss: 3570.8793 - mse: 3570.8796 - mae: 32.0518\n",
      "Epoch 58/80\n",
      "1176/1176 [==============================] - 0s 188us/step - loss: 3490.6849 - mse: 3490.6851 - mae: 31.3290\n",
      "Epoch 59/80\n",
      "1176/1176 [==============================] - 0s 162us/step - loss: 3637.3738 - mse: 3637.3743 - mae: 32.0118\n",
      "Epoch 60/80\n",
      "1176/1176 [==============================] - 0s 151us/step - loss: 3529.6725 - mse: 3529.6719 - mae: 31.7561\n",
      "Epoch 61/80\n",
      "1176/1176 [==============================] - 0s 152us/step - loss: 3456.2184 - mse: 3456.2190 - mae: 31.1681\n",
      "Epoch 62/80\n",
      "1176/1176 [==============================] - 0s 143us/step - loss: 3672.7193 - mse: 3672.7190 - mae: 31.7798\n",
      "Epoch 63/80\n",
      "1176/1176 [==============================] - 0s 146us/step - loss: 3580.1400 - mse: 3580.1404 - mae: 31.4427\n",
      "Epoch 64/80\n",
      "1176/1176 [==============================] - 0s 159us/step - loss: 3586.4889 - mse: 3586.4890 - mae: 32.1589\n",
      "Epoch 65/80\n",
      "1176/1176 [==============================] - 0s 162us/step - loss: 3566.2478 - mse: 3566.2471 - mae: 32.0922\n",
      "Epoch 66/80\n",
      "1176/1176 [==============================] - 0s 156us/step - loss: 3627.8893 - mse: 3627.8899 - mae: 32.3572\n",
      "Epoch 67/80\n",
      "1176/1176 [==============================] - 0s 151us/step - loss: 3607.6775 - mse: 3607.6768 - mae: 31.1707\n",
      "Epoch 68/80\n",
      "1176/1176 [==============================] - 0s 137us/step - loss: 3469.5891 - mse: 3469.5891 - mae: 31.7350\n",
      "Epoch 69/80\n",
      "1176/1176 [==============================] - 0s 135us/step - loss: 3521.3583 - mse: 3521.3584 - mae: 31.0603\n",
      "Epoch 70/80\n",
      "1176/1176 [==============================] - 0s 149us/step - loss: 3489.8543 - mse: 3489.8542 - mae: 31.4410\n",
      "Epoch 71/80\n",
      "1176/1176 [==============================] - 0s 157us/step - loss: 3646.0561 - mse: 3646.0569 - mae: 32.0336\n",
      "Epoch 72/80\n",
      "1176/1176 [==============================] - 0s 192us/step - loss: 3516.6133 - mse: 3516.6125 - mae: 31.1290\n",
      "Epoch 73/80\n",
      "1176/1176 [==============================] - 0s 192us/step - loss: 3570.3760 - mse: 3570.3767 - mae: 32.3086\n",
      "Epoch 74/80\n",
      "1176/1176 [==============================] - 0s 186us/step - loss: 3546.2403 - mse: 3546.2402 - mae: 31.2863\n",
      "Epoch 75/80\n",
      "1176/1176 [==============================] - 0s 185us/step - loss: 3646.3608 - mse: 3646.3611 - mae: 31.7303\n",
      "Epoch 76/80\n",
      "1176/1176 [==============================] - 0s 186us/step - loss: 3669.9961 - mse: 3669.9961 - mae: 32.1134\n",
      "Epoch 77/80\n",
      "1176/1176 [==============================] - 0s 175us/step - loss: 3631.2777 - mse: 3631.2771 - mae: 32.6556\n",
      "Epoch 78/80\n",
      "1176/1176 [==============================] - 0s 140us/step - loss: 3679.0942 - mse: 3679.0928 - mae: 31.8091\n",
      "Epoch 79/80\n",
      "1176/1176 [==============================] - 0s 146us/step - loss: 3497.0089 - mse: 3497.0085 - mae: 31.6891\n",
      "Epoch 80/80\n",
      "1176/1176 [==============================] - 0s 166us/step - loss: 3639.4299 - mse: 3639.4307 - mae: 31.8125\n",
      "2\n",
      "Epoch 1/80\n",
      "1761/1761 [==============================] - 0s 163us/step - loss: 2791.2813 - mse: 2791.2815 - mae: 29.5478\n",
      "Epoch 2/80\n",
      "1761/1761 [==============================] - 0s 140us/step - loss: 2842.6733 - mse: 2842.6736 - mae: 29.8615\n",
      "Epoch 3/80\n",
      "1761/1761 [==============================] - 0s 157us/step - loss: 2788.6840 - mse: 2788.6848 - mae: 29.2599\n",
      "Epoch 4/80\n",
      "1761/1761 [==============================] - 0s 159us/step - loss: 2841.7308 - mse: 2841.7305 - mae: 29.8243\n",
      "Epoch 5/80\n",
      "1761/1761 [==============================] - 0s 149us/step - loss: 2762.7744 - mse: 2762.7749 - mae: 29.1963\n",
      "Epoch 6/80\n",
      "1761/1761 [==============================] - 0s 157us/step - loss: 2789.8795 - mse: 2789.8794 - mae: 29.2621\n",
      "Epoch 7/80\n",
      "1761/1761 [==============================] - 0s 155us/step - loss: 2797.1120 - mse: 2797.1118 - mae: 28.8893\n",
      "Epoch 8/80\n",
      "1761/1761 [==============================] - 0s 146us/step - loss: 2879.8487 - mse: 2879.8484 - mae: 29.7866\n",
      "Epoch 9/80\n",
      "1761/1761 [==============================] - 0s 147us/step - loss: 2816.2257 - mse: 2816.2266 - mae: 29.6153\n",
      "Epoch 10/80\n",
      "1761/1761 [==============================] - 0s 152us/step - loss: 2834.9047 - mse: 2834.9048 - mae: 29.2282\n",
      "Epoch 11/80\n",
      "1761/1761 [==============================] - 0s 151us/step - loss: 2827.8321 - mse: 2827.8315 - mae: 29.5531\n",
      "Epoch 12/80\n",
      "1761/1761 [==============================] - 0s 150us/step - loss: 2819.5233 - mse: 2819.5232 - mae: 29.4569\n",
      "Epoch 13/80\n",
      "1761/1761 [==============================] - 0s 155us/step - loss: 2843.5849 - mse: 2843.5847 - mae: 29.2006\n",
      "Epoch 14/80\n",
      "1761/1761 [==============================] - 0s 140us/step - loss: 2820.6658 - mse: 2820.6655 - mae: 29.5726\n",
      "Epoch 15/80\n",
      "1761/1761 [==============================] - 0s 157us/step - loss: 2864.6151 - mse: 2864.6157 - mae: 29.4209\n",
      "Epoch 16/80\n",
      "1761/1761 [==============================] - 0s 152us/step - loss: 2795.3048 - mse: 2795.3052 - mae: 28.9522\n",
      "Epoch 17/80\n",
      "1761/1761 [==============================] - 0s 133us/step - loss: 2825.5326 - mse: 2825.5327 - mae: 29.6175\n",
      "Epoch 18/80\n",
      "1761/1761 [==============================] - 0s 149us/step - loss: 2712.5006 - mse: 2712.5005 - mae: 28.8821\n",
      "Epoch 19/80\n",
      "1761/1761 [==============================] - 0s 156us/step - loss: 2728.9077 - mse: 2728.9072 - mae: 29.0984\n",
      "Epoch 20/80\n",
      "1761/1761 [==============================] - 0s 159us/step - loss: 2802.3242 - mse: 2802.3247 - mae: 28.8377\n",
      "Epoch 21/80\n",
      "1761/1761 [==============================] - 0s 135us/step - loss: 2814.1253 - mse: 2814.1252 - mae: 29.1107\n",
      "Epoch 22/80\n",
      "1761/1761 [==============================] - 0s 145us/step - loss: 2738.3806 - mse: 2738.3811 - mae: 29.0505\n",
      "Epoch 23/80\n",
      "1761/1761 [==============================] - 0s 153us/step - loss: 2821.3700 - mse: 2821.3691 - mae: 29.5634\n",
      "Epoch 24/80\n",
      "1761/1761 [==============================] - 0s 144us/step - loss: 2741.1187 - mse: 2741.1184 - mae: 28.6673\n",
      "Epoch 25/80\n",
      "1761/1761 [==============================] - 0s 149us/step - loss: 2809.6239 - mse: 2809.6240 - mae: 29.2395\n",
      "Epoch 26/80\n",
      "1761/1761 [==============================] - 0s 143us/step - loss: 2816.6497 - mse: 2816.6509 - mae: 28.8444\n",
      "Epoch 27/80\n",
      "1761/1761 [==============================] - 0s 156us/step - loss: 2805.7914 - mse: 2805.7915 - mae: 29.4404\n",
      "Epoch 28/80\n",
      "1761/1761 [==============================] - 0s 149us/step - loss: 2762.8870 - mse: 2762.8879 - mae: 28.9602\n",
      "Epoch 29/80\n",
      "1761/1761 [==============================] - 0s 149us/step - loss: 2764.6570 - mse: 2764.6570 - mae: 28.9993\n",
      "Epoch 30/80\n",
      "1761/1761 [==============================] - 0s 146us/step - loss: 2826.7413 - mse: 2826.7415 - mae: 29.2738\n",
      "Epoch 31/80\n",
      "1761/1761 [==============================] - 0s 154us/step - loss: 2776.2844 - mse: 2776.2847 - mae: 29.2324\n",
      "Epoch 32/80\n",
      "1761/1761 [==============================] - 0s 158us/step - loss: 2932.2654 - mse: 2932.2651 - mae: 29.7614\n",
      "Epoch 33/80\n",
      "1761/1761 [==============================] - 0s 143us/step - loss: 2806.7274 - mse: 2806.7275 - mae: 29.1084\n",
      "Epoch 34/80\n",
      "1761/1761 [==============================] - 0s 150us/step - loss: 2800.7803 - mse: 2800.7791 - mae: 29.5564\n",
      "Epoch 35/80\n",
      "1761/1761 [==============================] - 0s 158us/step - loss: 2780.7504 - mse: 2780.7502 - mae: 28.8814\n",
      "Epoch 36/80\n",
      "1761/1761 [==============================] - 0s 159us/step - loss: 2757.1599 - mse: 2757.1597 - mae: 28.8737\n",
      "Epoch 37/80\n",
      "1761/1761 [==============================] - 0s 158us/step - loss: 2770.2001 - mse: 2770.2004 - mae: 28.4600\n",
      "Epoch 38/80\n",
      "1761/1761 [==============================] - 0s 151us/step - loss: 2829.3369 - mse: 2829.3369 - mae: 29.4906\n",
      "Epoch 39/80\n",
      "1761/1761 [==============================] - 0s 136us/step - loss: 2852.6164 - mse: 2852.6167 - mae: 29.7225\n",
      "Epoch 40/80\n",
      "1761/1761 [==============================] - 0s 156us/step - loss: 2784.6584 - mse: 2784.6582 - mae: 29.5815\n",
      "Epoch 41/80\n",
      "1761/1761 [==============================] - 0s 155us/step - loss: 2814.3617 - mse: 2814.3611 - mae: 29.8760\n",
      "Epoch 42/80\n",
      "1761/1761 [==============================] - 0s 150us/step - loss: 2751.5348 - mse: 2751.5344 - mae: 29.3206\n",
      "Epoch 43/80\n",
      "1761/1761 [==============================] - 0s 154us/step - loss: 2782.8317 - mse: 2782.8323 - mae: 28.7156\n",
      "Epoch 44/80\n",
      "1761/1761 [==============================] - 0s 149us/step - loss: 2776.0355 - mse: 2776.0352 - mae: 29.2598\n",
      "Epoch 45/80\n",
      "1761/1761 [==============================] - 0s 138us/step - loss: 2807.7618 - mse: 2807.7627 - mae: 28.9060\n",
      "Epoch 46/80\n",
      "1761/1761 [==============================] - 0s 140us/step - loss: 2847.4658 - mse: 2847.4668 - mae: 28.7417\n",
      "Epoch 47/80\n",
      "1761/1761 [==============================] - 0s 161us/step - loss: 2803.9224 - mse: 2803.9219 - mae: 29.2402\n",
      "Epoch 48/80\n",
      "1761/1761 [==============================] - 0s 166us/step - loss: 2854.8437 - mse: 2854.8438 - mae: 29.6236\n",
      "Epoch 49/80\n",
      "1761/1761 [==============================] - 0s 160us/step - loss: 2826.4513 - mse: 2826.4517 - mae: 29.8768\n",
      "Epoch 50/80\n",
      "1761/1761 [==============================] - 0s 151us/step - loss: 2782.6783 - mse: 2782.6782 - mae: 29.1443\n",
      "Epoch 51/80\n",
      "1761/1761 [==============================] - 0s 160us/step - loss: 2740.8422 - mse: 2740.8416 - mae: 29.3904\n",
      "Epoch 52/80\n",
      "1761/1761 [==============================] - 0s 161us/step - loss: 2820.3358 - mse: 2820.3359 - mae: 29.4097\n",
      "Epoch 53/80\n",
      "1761/1761 [==============================] - 0s 160us/step - loss: 2808.2231 - mse: 2808.2231 - mae: 29.9209\n",
      "Epoch 54/80\n",
      "1761/1761 [==============================] - 0s 151us/step - loss: 2933.9841 - mse: 2933.9829 - mae: 30.1606\n",
      "Epoch 55/80\n",
      "1761/1761 [==============================] - 0s 142us/step - loss: 2874.0856 - mse: 2874.0854 - mae: 29.6295\n",
      "Epoch 56/80\n",
      "1761/1761 [==============================] - 0s 155us/step - loss: 2880.1691 - mse: 2880.1702 - mae: 29.9293\n",
      "Epoch 57/80\n",
      "1761/1761 [==============================] - 0s 149us/step - loss: 2873.5807 - mse: 2873.5798 - mae: 29.1773\n",
      "Epoch 58/80\n",
      "1761/1761 [==============================] - 0s 153us/step - loss: 2882.6199 - mse: 2882.6204 - mae: 29.2107\n",
      "Epoch 59/80\n",
      "1761/1761 [==============================] - 0s 157us/step - loss: 2864.2946 - mse: 2864.2944 - mae: 29.8628\n",
      "Epoch 60/80\n",
      "1761/1761 [==============================] - 0s 139us/step - loss: 2845.7549 - mse: 2845.7546 - mae: 29.4325\n",
      "Epoch 61/80\n",
      "1761/1761 [==============================] - 0s 153us/step - loss: 2841.3787 - mse: 2841.3774 - mae: 29.4943\n",
      "Epoch 62/80\n",
      "1761/1761 [==============================] - 0s 148us/step - loss: 2806.8484 - mse: 2806.8474 - mae: 29.5045\n",
      "Epoch 63/80\n",
      "1761/1761 [==============================] - 0s 155us/step - loss: 2864.0042 - mse: 2864.0054 - mae: 29.4633\n",
      "Epoch 64/80\n",
      "1761/1761 [==============================] - 0s 162us/step - loss: 2817.2218 - mse: 2817.2212 - mae: 29.3874\n",
      "Epoch 65/80\n",
      "1761/1761 [==============================] - 0s 156us/step - loss: 2801.8074 - mse: 2801.8069 - mae: 28.7488\n",
      "Epoch 66/80\n",
      "1761/1761 [==============================] - 0s 161us/step - loss: 2849.0800 - mse: 2849.0801 - mae: 29.2802\n",
      "Epoch 67/80\n",
      "1761/1761 [==============================] - 0s 145us/step - loss: 2755.4598 - mse: 2755.4592 - mae: 29.1145\n",
      "Epoch 68/80\n",
      "1761/1761 [==============================] - 0s 150us/step - loss: 2748.0003 - mse: 2748.0002 - mae: 28.6512\n",
      "Epoch 69/80\n",
      "1761/1761 [==============================] - 0s 154us/step - loss: 2809.7370 - mse: 2809.7371 - mae: 29.4873\n",
      "Epoch 70/80\n",
      "1761/1761 [==============================] - 0s 157us/step - loss: 2803.9245 - mse: 2803.9253 - mae: 29.3525\n",
      "Epoch 71/80\n",
      "1761/1761 [==============================] - 0s 161us/step - loss: 2825.5863 - mse: 2825.5867 - mae: 29.3679\n",
      "Epoch 72/80\n",
      "1761/1761 [==============================] - 0s 151us/step - loss: 2776.3133 - mse: 2776.3130 - mae: 29.3054\n",
      "Epoch 73/80\n",
      "1761/1761 [==============================] - 0s 152us/step - loss: 2751.3689 - mse: 2751.3682 - mae: 28.7608\n",
      "Epoch 74/80\n",
      "1761/1761 [==============================] - 0s 154us/step - loss: 2834.6501 - mse: 2834.6509 - mae: 29.3015\n",
      "Epoch 75/80\n",
      "1761/1761 [==============================] - 0s 161us/step - loss: 2784.5145 - mse: 2784.5146 - mae: 29.1472\n",
      "Epoch 76/80\n",
      "1761/1761 [==============================] - 0s 159us/step - loss: 2764.7417 - mse: 2764.7415 - mae: 29.4234\n",
      "Epoch 77/80\n",
      "1761/1761 [==============================] - 0s 162us/step - loss: 2773.8113 - mse: 2773.8105 - mae: 29.0756\n",
      "Epoch 78/80\n",
      "1761/1761 [==============================] - 0s 142us/step - loss: 2764.8309 - mse: 2764.8308 - mae: 28.9196\n",
      "Epoch 79/80\n",
      "1761/1761 [==============================] - 0s 147us/step - loss: 2851.5139 - mse: 2851.5144 - mae: 29.6717\n",
      "Epoch 80/80\n",
      "1761/1761 [==============================] - 0s 154us/step - loss: 2815.5221 - mse: 2815.5220 - mae: 29.4977\n",
      "3\n",
      "Epoch 1/80\n",
      "2346/2346 [==============================] - 0s 150us/step - loss: 2515.9989 - mse: 2515.9993 - mae: 29.1108\n",
      "Epoch 2/80\n",
      "2346/2346 [==============================] - 0s 149us/step - loss: 2474.6418 - mse: 2474.6414 - mae: 28.9012\n",
      "Epoch 3/80\n",
      "2346/2346 [==============================] - 0s 163us/step - loss: 2516.2745 - mse: 2516.2742 - mae: 29.6055\n",
      "Epoch 4/80\n",
      "2346/2346 [==============================] - 0s 155us/step - loss: 2544.1562 - mse: 2544.1565 - mae: 29.7775\n",
      "Epoch 5/80\n",
      "2346/2346 [==============================] - 0s 161us/step - loss: 2538.0933 - mse: 2538.0938 - mae: 29.1605\n",
      "Epoch 6/80\n",
      "2346/2346 [==============================] - 0s 148us/step - loss: 2461.5547 - mse: 2461.5544 - mae: 29.2933\n",
      "Epoch 7/80\n",
      "2346/2346 [==============================] - 0s 153us/step - loss: 2519.0401 - mse: 2519.0403 - mae: 29.1245\n",
      "Epoch 8/80\n",
      "2346/2346 [==============================] - 0s 161us/step - loss: 2543.3040 - mse: 2543.3042 - mae: 29.7069\n",
      "Epoch 9/80\n",
      "2346/2346 [==============================] - 0s 157us/step - loss: 2469.2725 - mse: 2469.2722 - mae: 29.0215\n",
      "Epoch 10/80\n",
      "2346/2346 [==============================] - 0s 152us/step - loss: 2460.5777 - mse: 2460.5784 - mae: 29.1491\n",
      "Epoch 11/80\n",
      "2346/2346 [==============================] - 0s 159us/step - loss: 2493.4856 - mse: 2493.4858 - mae: 29.6055\n",
      "Epoch 12/80\n",
      "2346/2346 [==============================] - 0s 157us/step - loss: 2437.2090 - mse: 2437.2085 - mae: 29.1266\n",
      "Epoch 13/80\n",
      "2346/2346 [==============================] - 0s 146us/step - loss: 2472.8050 - mse: 2472.8049 - mae: 28.9891\n",
      "Epoch 14/80\n",
      "2346/2346 [==============================] - 0s 157us/step - loss: 2482.2764 - mse: 2482.2761 - mae: 29.0502\n",
      "Epoch 15/80\n",
      "2346/2346 [==============================] - 0s 155us/step - loss: 2459.3135 - mse: 2459.3147 - mae: 29.0483\n",
      "Epoch 16/80\n",
      "2346/2346 [==============================] - 0s 150us/step - loss: 2519.8764 - mse: 2519.8760 - mae: 29.6239\n",
      "Epoch 17/80\n",
      "2346/2346 [==============================] - 0s 149us/step - loss: 2579.1110 - mse: 2579.1113 - mae: 29.3932\n",
      "Epoch 18/80\n",
      "2346/2346 [==============================] - 0s 161us/step - loss: 2543.8154 - mse: 2543.8152 - mae: 29.1852\n",
      "Epoch 19/80\n",
      "2346/2346 [==============================] - 0s 157us/step - loss: 2494.3879 - mse: 2494.3884 - mae: 29.1214\n",
      "Epoch 20/80\n",
      "2346/2346 [==============================] - 0s 150us/step - loss: 2577.4076 - mse: 2577.4065 - mae: 29.5351\n",
      "Epoch 21/80\n",
      "2346/2346 [==============================] - 0s 153us/step - loss: 2515.6392 - mse: 2515.6392 - mae: 28.8840\n",
      "Epoch 22/80\n",
      "2346/2346 [==============================] - 0s 142us/step - loss: 2433.8991 - mse: 2433.8992 - mae: 28.9978\n",
      "Epoch 23/80\n",
      "2346/2346 [==============================] - 0s 159us/step - loss: 2514.8993 - mse: 2514.8994 - mae: 29.1543\n",
      "Epoch 24/80\n",
      "2346/2346 [==============================] - 0s 160us/step - loss: 2473.7570 - mse: 2473.7576 - mae: 28.9640\n",
      "Epoch 25/80\n",
      "2346/2346 [==============================] - 0s 156us/step - loss: 2491.3818 - mse: 2491.3813 - mae: 29.5674\n",
      "Epoch 26/80\n",
      "2346/2346 [==============================] - 0s 150us/step - loss: 2528.0853 - mse: 2528.0862 - mae: 29.2206\n",
      "Epoch 27/80\n",
      "2346/2346 [==============================] - 0s 145us/step - loss: 2508.0478 - mse: 2508.0479 - mae: 29.5848\n",
      "Epoch 28/80\n",
      "2346/2346 [==============================] - 0s 156us/step - loss: 2462.6343 - mse: 2462.6345 - mae: 29.5140\n",
      "Epoch 29/80\n",
      "2346/2346 [==============================] - 0s 151us/step - loss: 2491.2404 - mse: 2491.2407 - mae: 29.0274\n",
      "Epoch 30/80\n",
      "2346/2346 [==============================] - 0s 162us/step - loss: 2501.4008 - mse: 2501.4006 - mae: 29.1955\n",
      "Epoch 31/80\n",
      "2346/2346 [==============================] - 0s 158us/step - loss: 2485.0897 - mse: 2485.0898 - mae: 28.9929\n",
      "Epoch 32/80\n",
      "2346/2346 [==============================] - 0s 160us/step - loss: 2490.6144 - mse: 2490.6143 - mae: 29.0840\n",
      "Epoch 33/80\n",
      "2346/2346 [==============================] - 0s 163us/step - loss: 2463.7170 - mse: 2463.7166 - mae: 28.5334\n",
      "Epoch 34/80\n",
      "2346/2346 [==============================] - 0s 164us/step - loss: 2491.6652 - mse: 2491.6648 - mae: 29.1592\n",
      "Epoch 35/80\n",
      "2346/2346 [==============================] - 0s 160us/step - loss: 2488.4586 - mse: 2488.4578 - mae: 29.2889\n",
      "Epoch 36/80\n",
      "2346/2346 [==============================] - 0s 160us/step - loss: 2479.3803 - mse: 2479.3796 - mae: 29.1676\n",
      "Epoch 37/80\n",
      "2346/2346 [==============================] - 0s 160us/step - loss: 2485.3468 - mse: 2485.3472 - mae: 29.3401\n",
      "Epoch 38/80\n",
      "2346/2346 [==============================] - 0s 163us/step - loss: 2484.3810 - mse: 2484.3816 - mae: 29.0728\n",
      "Epoch 39/80\n",
      "2346/2346 [==============================] - 0s 150us/step - loss: 2476.4745 - mse: 2476.4746 - mae: 29.5643\n",
      "Epoch 40/80\n",
      "2346/2346 [==============================] - 0s 158us/step - loss: 2446.3190 - mse: 2446.3184 - mae: 29.0441\n",
      "Epoch 41/80\n",
      "2346/2346 [==============================] - 0s 145us/step - loss: 2500.8824 - mse: 2500.8813 - mae: 29.4178\n",
      "Epoch 42/80\n",
      "2346/2346 [==============================] - 0s 160us/step - loss: 2491.2702 - mse: 2491.2700 - mae: 29.3651\n",
      "Epoch 43/80\n",
      "2346/2346 [==============================] - 0s 163us/step - loss: 2533.9256 - mse: 2533.9263 - mae: 29.3251\n",
      "Epoch 44/80\n",
      "2346/2346 [==============================] - 0s 149us/step - loss: 2523.7842 - mse: 2523.7844 - mae: 29.2115\n",
      "Epoch 45/80\n",
      "2346/2346 [==============================] - 0s 152us/step - loss: 2514.9660 - mse: 2514.9658 - mae: 29.1395\n",
      "Epoch 46/80\n",
      "2346/2346 [==============================] - 0s 169us/step - loss: 2495.4946 - mse: 2495.4949 - mae: 29.6281\n",
      "Epoch 47/80\n",
      "2346/2346 [==============================] - 0s 151us/step - loss: 2497.5566 - mse: 2497.5569 - mae: 29.2758\n",
      "Epoch 48/80\n",
      "2346/2346 [==============================] - 0s 158us/step - loss: 2478.6283 - mse: 2478.6294 - mae: 29.1039\n",
      "Epoch 49/80\n",
      "2346/2346 [==============================] - 0s 156us/step - loss: 2507.7868 - mse: 2507.7866 - mae: 29.2109\n",
      "Epoch 50/80\n",
      "2346/2346 [==============================] - 0s 152us/step - loss: 2550.0814 - mse: 2550.0823 - mae: 29.3428\n",
      "Epoch 51/80\n",
      "2346/2346 [==============================] - 0s 149us/step - loss: 2496.7330 - mse: 2496.7332 - mae: 29.2531\n",
      "Epoch 52/80\n",
      "2346/2346 [==============================] - 0s 153us/step - loss: 2529.4277 - mse: 2529.4275 - mae: 29.6058\n",
      "Epoch 53/80\n",
      "2346/2346 [==============================] - 0s 159us/step - loss: 2528.1066 - mse: 2528.1072 - mae: 29.2734\n",
      "Epoch 54/80\n",
      "2346/2346 [==============================] - 0s 159us/step - loss: 2497.4291 - mse: 2497.4290 - mae: 29.0547\n",
      "Epoch 55/80\n",
      "2346/2346 [==============================] - 0s 159us/step - loss: 2463.9364 - mse: 2463.9358 - mae: 28.8010\n",
      "Epoch 56/80\n",
      "2346/2346 [==============================] - 0s 154us/step - loss: 2464.6048 - mse: 2464.6047 - mae: 28.8039\n",
      "Epoch 57/80\n",
      "2346/2346 [==============================] - 0s 166us/step - loss: 2487.1141 - mse: 2487.1147 - mae: 28.8413\n",
      "Epoch 58/80\n",
      "2346/2346 [==============================] - 0s 159us/step - loss: 2412.5951 - mse: 2412.5955 - mae: 28.3978\n",
      "Epoch 59/80\n",
      "2346/2346 [==============================] - 0s 150us/step - loss: 2544.5700 - mse: 2544.5701 - mae: 29.3825\n",
      "Epoch 60/80\n",
      "2346/2346 [==============================] - 0s 161us/step - loss: 2490.4744 - mse: 2490.4739 - mae: 29.2906\n",
      "Epoch 61/80\n",
      "2346/2346 [==============================] - 0s 158us/step - loss: 2481.4929 - mse: 2481.4924 - mae: 29.0314\n",
      "Epoch 62/80\n",
      "2346/2346 [==============================] - 0s 167us/step - loss: 2536.8508 - mse: 2536.8496 - mae: 29.0280\n",
      "Epoch 63/80\n",
      "2346/2346 [==============================] - 0s 181us/step - loss: 2535.0549 - mse: 2535.0547 - mae: 29.3252\n",
      "Epoch 64/80\n",
      "2346/2346 [==============================] - 0s 148us/step - loss: 2509.5885 - mse: 2509.5891 - mae: 29.1631\n",
      "Epoch 65/80\n",
      "2346/2346 [==============================] - 0s 157us/step - loss: 2517.8887 - mse: 2517.8884 - mae: 29.3740\n",
      "Epoch 66/80\n",
      "2346/2346 [==============================] - 0s 155us/step - loss: 2474.7564 - mse: 2474.7576 - mae: 29.3916\n",
      "Epoch 67/80\n",
      "2346/2346 [==============================] - 0s 160us/step - loss: 2524.3010 - mse: 2524.3013 - mae: 29.2779\n",
      "Epoch 68/80\n",
      "2346/2346 [==============================] - 0s 153us/step - loss: 2561.4633 - mse: 2561.4629 - mae: 29.4357\n",
      "Epoch 69/80\n",
      "2346/2346 [==============================] - 0s 156us/step - loss: 2492.7852 - mse: 2492.7859 - mae: 29.3276\n",
      "Epoch 70/80\n",
      "2346/2346 [==============================] - 0s 159us/step - loss: 2484.1838 - mse: 2484.1833 - mae: 29.0158\n",
      "Epoch 71/80\n",
      "2346/2346 [==============================] - 0s 163us/step - loss: 2518.5917 - mse: 2518.5916 - mae: 29.5578\n",
      "Epoch 72/80\n",
      "2346/2346 [==============================] - 0s 153us/step - loss: 2500.2531 - mse: 2500.2524 - mae: 28.8867\n",
      "Epoch 73/80\n",
      "2346/2346 [==============================] - 0s 152us/step - loss: 2498.9587 - mse: 2498.9587 - mae: 28.7488\n",
      "Epoch 74/80\n",
      "2346/2346 [==============================] - 0s 152us/step - loss: 2499.5785 - mse: 2499.5784 - mae: 29.2666\n",
      "Epoch 75/80\n",
      "2346/2346 [==============================] - 0s 152us/step - loss: 2507.6319 - mse: 2507.6304 - mae: 29.1504\n",
      "Epoch 76/80\n",
      "2346/2346 [==============================] - 0s 157us/step - loss: 2467.1847 - mse: 2467.1851 - mae: 29.3727\n",
      "Epoch 77/80\n",
      "2346/2346 [==============================] - 0s 162us/step - loss: 2497.1462 - mse: 2497.1465 - mae: 29.3519\n",
      "Epoch 78/80\n",
      "2346/2346 [==============================] - 0s 148us/step - loss: 2491.4024 - mse: 2491.4023 - mae: 29.5118\n",
      "Epoch 79/80\n",
      "2346/2346 [==============================] - 0s 166us/step - loss: 2449.9678 - mse: 2449.9685 - mae: 29.0740\n",
      "Epoch 80/80\n",
      "2346/2346 [==============================] - 0s 151us/step - loss: 2549.7852 - mse: 2549.7854 - mae: 29.6247\n",
      "4\n",
      "Epoch 1/80\n",
      "2931/2931 [==============================] - 0s 143us/step - loss: 2315.0474 - mse: 2315.0466 - mae: 29.1337\n",
      "Epoch 2/80\n",
      "2931/2931 [==============================] - 0s 135us/step - loss: 2304.3089 - mse: 2304.3086 - mae: 28.8859\n",
      "Epoch 3/80\n",
      "2931/2931 [==============================] - 0s 140us/step - loss: 2280.5345 - mse: 2280.5337 - mae: 28.6430\n",
      "Epoch 4/80\n",
      "2931/2931 [==============================] - 0s 149us/step - loss: 2298.7057 - mse: 2298.7058 - mae: 28.9333\n",
      "Epoch 5/80\n",
      "2931/2931 [==============================] - 0s 162us/step - loss: 2294.8713 - mse: 2294.8711 - mae: 29.0972\n",
      "Epoch 6/80\n",
      "2931/2931 [==============================] - 0s 157us/step - loss: 2299.0702 - mse: 2299.0691 - mae: 28.7272\n",
      "Epoch 7/80\n",
      "2931/2931 [==============================] - 0s 152us/step - loss: 2274.5838 - mse: 2274.5835 - mae: 28.8380\n",
      "Epoch 8/80\n",
      "2931/2931 [==============================] - 0s 141us/step - loss: 2281.1881 - mse: 2281.1873 - mae: 28.9507\n",
      "Epoch 9/80\n",
      "2931/2931 [==============================] - 0s 156us/step - loss: 2232.5548 - mse: 2232.5542 - mae: 28.4657\n",
      "Epoch 10/80\n",
      "2931/2931 [==============================] - 1s 187us/step - loss: 2233.0973 - mse: 2233.0977 - mae: 28.7619\n",
      "Epoch 11/80\n",
      "2931/2931 [==============================] - 0s 158us/step - loss: 2269.8296 - mse: 2269.8296 - mae: 28.1800\n",
      "Epoch 12/80\n",
      "2931/2931 [==============================] - 1s 176us/step - loss: 2335.0664 - mse: 2335.0667 - mae: 29.2368\n",
      "Epoch 13/80\n",
      "2931/2931 [==============================] - 0s 161us/step - loss: 2271.4403 - mse: 2271.4402 - mae: 28.4908\n",
      "Epoch 14/80\n",
      "2931/2931 [==============================] - 0s 139us/step - loss: 2259.0300 - mse: 2259.0303 - mae: 28.7355\n",
      "Epoch 15/80\n",
      "2931/2931 [==============================] - 0s 143us/step - loss: 2304.9351 - mse: 2304.9351 - mae: 28.4534\n",
      "Epoch 16/80\n",
      "2931/2931 [==============================] - 0s 162us/step - loss: 2275.9584 - mse: 2275.9578 - mae: 28.8193\n",
      "Epoch 17/80\n",
      "2931/2931 [==============================] - 0s 149us/step - loss: 2255.8571 - mse: 2255.8569 - mae: 28.4642\n",
      "Epoch 18/80\n",
      "2931/2931 [==============================] - 0s 151us/step - loss: 2273.0493 - mse: 2273.0491 - mae: 28.7346\n",
      "Epoch 19/80\n",
      "2931/2931 [==============================] - 0s 157us/step - loss: 2261.0023 - mse: 2261.0020 - mae: 28.4184\n",
      "Epoch 20/80\n",
      "2931/2931 [==============================] - 0s 151us/step - loss: 2274.4018 - mse: 2274.4023 - mae: 28.5438\n",
      "Epoch 21/80\n",
      "2931/2931 [==============================] - 0s 138us/step - loss: 2270.6472 - mse: 2270.6482 - mae: 28.7405\n",
      "Epoch 22/80\n",
      "2931/2931 [==============================] - 0s 150us/step - loss: 2244.3667 - mse: 2244.3665 - mae: 28.6867\n",
      "Epoch 23/80\n",
      "2931/2931 [==============================] - 0s 149us/step - loss: 2280.1330 - mse: 2280.1333 - mae: 28.5456\n",
      "Epoch 24/80\n",
      "2931/2931 [==============================] - 0s 153us/step - loss: 2274.4832 - mse: 2274.4834 - mae: 28.5428\n",
      "Epoch 25/80\n",
      "2931/2931 [==============================] - 0s 160us/step - loss: 2258.9748 - mse: 2258.9744 - mae: 28.5373\n",
      "Epoch 26/80\n",
      "2931/2931 [==============================] - 0s 149us/step - loss: 2267.0479 - mse: 2267.0483 - mae: 28.9264\n",
      "Epoch 27/80\n",
      "2931/2931 [==============================] - 0s 151us/step - loss: 2330.2717 - mse: 2330.2717 - mae: 28.8875\n",
      "Epoch 28/80\n",
      "2931/2931 [==============================] - 0s 162us/step - loss: 2262.7602 - mse: 2262.7598 - mae: 28.4905\n",
      "Epoch 29/80\n",
      "2931/2931 [==============================] - 0s 165us/step - loss: 2224.6998 - mse: 2224.7007 - mae: 28.3451\n",
      "Epoch 30/80\n",
      "2931/2931 [==============================] - 0s 150us/step - loss: 2329.2659 - mse: 2329.2664 - mae: 29.0305\n",
      "Epoch 31/80\n",
      "2931/2931 [==============================] - 0s 149us/step - loss: 2252.2422 - mse: 2252.2424 - mae: 28.6447\n",
      "Epoch 32/80\n",
      "2931/2931 [==============================] - 0s 153us/step - loss: 2268.4184 - mse: 2268.4187 - mae: 28.8626\n",
      "Epoch 33/80\n",
      "2931/2931 [==============================] - 0s 157us/step - loss: 2281.1881 - mse: 2281.1877 - mae: 28.5182\n",
      "Epoch 34/80\n",
      "2931/2931 [==============================] - 0s 161us/step - loss: 2261.9881 - mse: 2261.9873 - mae: 28.4854\n",
      "Epoch 35/80\n",
      "2931/2931 [==============================] - 0s 152us/step - loss: 2289.8796 - mse: 2289.8799 - mae: 28.5640\n",
      "Epoch 36/80\n",
      "2931/2931 [==============================] - 0s 150us/step - loss: 2324.7104 - mse: 2324.7109 - mae: 28.6807\n",
      "Epoch 37/80\n",
      "2931/2931 [==============================] - 0s 161us/step - loss: 2321.5589 - mse: 2321.5586 - mae: 28.9538\n",
      "Epoch 38/80\n",
      "2931/2931 [==============================] - 0s 160us/step - loss: 2247.6260 - mse: 2247.6257 - mae: 28.6093\n",
      "Epoch 39/80\n",
      "2931/2931 [==============================] - 0s 157us/step - loss: 2313.3329 - mse: 2313.3328 - mae: 28.8061\n",
      "Epoch 40/80\n",
      "2931/2931 [==============================] - 0s 157us/step - loss: 2291.4550 - mse: 2291.4541 - mae: 28.9584\n",
      "Epoch 41/80\n",
      "2931/2931 [==============================] - 0s 157us/step - loss: 2291.9544 - mse: 2291.9546 - mae: 28.9317\n",
      "Epoch 42/80\n",
      "2931/2931 [==============================] - 0s 151us/step - loss: 2285.0716 - mse: 2285.0710 - mae: 28.4163\n",
      "Epoch 43/80\n",
      "2931/2931 [==============================] - 0s 155us/step - loss: 2289.3823 - mse: 2289.3821 - mae: 28.9166\n",
      "Epoch 44/80\n",
      "2931/2931 [==============================] - 0s 158us/step - loss: 2263.1855 - mse: 2263.1855 - mae: 28.3944\n",
      "Epoch 45/80\n",
      "2931/2931 [==============================] - 0s 160us/step - loss: 2324.2450 - mse: 2324.2456 - mae: 28.6086\n",
      "Epoch 46/80\n",
      "2931/2931 [==============================] - 0s 158us/step - loss: 2316.4810 - mse: 2316.4805 - mae: 29.0279\n",
      "Epoch 47/80\n",
      "2931/2931 [==============================] - 0s 154us/step - loss: 2270.6181 - mse: 2270.6187 - mae: 29.2190\n",
      "Epoch 48/80\n",
      "2931/2931 [==============================] - 0s 148us/step - loss: 2222.6972 - mse: 2222.6968 - mae: 28.1380\n",
      "Epoch 49/80\n",
      "2931/2931 [==============================] - 0s 152us/step - loss: 2259.6747 - mse: 2259.6748 - mae: 28.4361\n",
      "Epoch 50/80\n",
      "2931/2931 [==============================] - 0s 143us/step - loss: 2261.7283 - mse: 2261.7285 - mae: 28.5673\n",
      "Epoch 51/80\n",
      "2931/2931 [==============================] - 0s 163us/step - loss: 2280.0627 - mse: 2280.0625 - mae: 28.7417\n",
      "Epoch 52/80\n",
      "2931/2931 [==============================] - 0s 153us/step - loss: 2312.8332 - mse: 2312.8330 - mae: 29.1813\n",
      "Epoch 53/80\n",
      "2931/2931 [==============================] - 0s 152us/step - loss: 2302.8060 - mse: 2302.8054 - mae: 28.5818\n",
      "Epoch 54/80\n",
      "2931/2931 [==============================] - 0s 151us/step - loss: 2224.7907 - mse: 2224.7903 - mae: 28.0416\n",
      "Epoch 55/80\n",
      "2931/2931 [==============================] - 0s 157us/step - loss: 2240.0876 - mse: 2240.0872 - mae: 28.6366\n",
      "Epoch 56/80\n",
      "2931/2931 [==============================] - 0s 162us/step - loss: 2269.4116 - mse: 2269.4111 - mae: 28.4226\n",
      "Epoch 57/80\n",
      "2931/2931 [==============================] - 0s 148us/step - loss: 2212.5182 - mse: 2212.5183 - mae: 28.1873\n",
      "Epoch 58/80\n",
      "2931/2931 [==============================] - 0s 142us/step - loss: 2317.8409 - mse: 2317.8401 - mae: 28.7524\n",
      "Epoch 59/80\n",
      "2931/2931 [==============================] - 0s 153us/step - loss: 2291.8940 - mse: 2291.8938 - mae: 28.9912\n",
      "Epoch 60/80\n",
      "2931/2931 [==============================] - 0s 163us/step - loss: 2264.3897 - mse: 2264.3896 - mae: 28.2849\n",
      "Epoch 61/80\n",
      "2931/2931 [==============================] - 0s 154us/step - loss: 2291.5043 - mse: 2291.5049 - mae: 28.9017\n",
      "Epoch 62/80\n",
      "2931/2931 [==============================] - 0s 152us/step - loss: 2260.8192 - mse: 2260.8196 - mae: 28.2104\n",
      "Epoch 63/80\n",
      "2931/2931 [==============================] - 0s 159us/step - loss: 2327.0072 - mse: 2327.0071 - mae: 28.9825\n",
      "Epoch 64/80\n",
      "2931/2931 [==============================] - 0s 154us/step - loss: 2253.5879 - mse: 2253.5874 - mae: 28.2897\n",
      "Epoch 65/80\n",
      "2931/2931 [==============================] - 0s 153us/step - loss: 2240.1226 - mse: 2240.1226 - mae: 28.7222\n",
      "Epoch 66/80\n",
      "2931/2931 [==============================] - 0s 149us/step - loss: 2239.8708 - mse: 2239.8706 - mae: 28.4695\n",
      "Epoch 67/80\n",
      "2931/2931 [==============================] - 0s 156us/step - loss: 2268.6205 - mse: 2268.6201 - mae: 28.7895\n",
      "Epoch 68/80\n",
      "2931/2931 [==============================] - 0s 152us/step - loss: 2247.0884 - mse: 2247.0886 - mae: 28.6869\n",
      "Epoch 69/80\n",
      "2931/2931 [==============================] - 0s 157us/step - loss: 2294.5665 - mse: 2294.5674 - mae: 29.1020\n",
      "Epoch 70/80\n",
      "2931/2931 [==============================] - 0s 152us/step - loss: 2245.0875 - mse: 2245.0869 - mae: 28.4506\n",
      "Epoch 71/80\n",
      "2931/2931 [==============================] - 0s 150us/step - loss: 2298.6617 - mse: 2298.6614 - mae: 28.6771\n",
      "Epoch 72/80\n",
      "2931/2931 [==============================] - 0s 153us/step - loss: 2256.5303 - mse: 2256.5305 - mae: 28.4433\n",
      "Epoch 73/80\n",
      "2931/2931 [==============================] - 0s 158us/step - loss: 2311.7569 - mse: 2311.7566 - mae: 29.2507\n",
      "Epoch 74/80\n",
      "2931/2931 [==============================] - 0s 147us/step - loss: 2241.2155 - mse: 2241.2156 - mae: 28.5774\n",
      "Epoch 75/80\n",
      "2931/2931 [==============================] - 0s 149us/step - loss: 2318.3495 - mse: 2318.3499 - mae: 28.6700\n",
      "Epoch 76/80\n",
      "2931/2931 [==============================] - 0s 144us/step - loss: 2254.0112 - mse: 2254.0120 - mae: 28.9378\n",
      "Epoch 77/80\n",
      "2931/2931 [==============================] - 0s 159us/step - loss: 2287.6604 - mse: 2287.6599 - mae: 28.8870\n",
      "Epoch 78/80\n",
      "2931/2931 [==============================] - 0s 165us/step - loss: 2295.8414 - mse: 2295.8418 - mae: 28.8145\n",
      "Epoch 79/80\n",
      "2931/2931 [==============================] - 0s 157us/step - loss: 2267.0725 - mse: 2267.0718 - mae: 28.5717\n",
      "Epoch 80/80\n",
      "2931/2931 [==============================] - 0s 156us/step - loss: 2307.6918 - mse: 2307.6921 - mae: 28.7774\n",
      "5\n",
      "Epoch 1/80\n",
      "3516/3516 [==============================] - 1s 151us/step - loss: 2747.0114 - mse: 2747.0117 - mae: 29.1680\n",
      "Epoch 2/80\n",
      "3516/3516 [==============================] - 1s 152us/step - loss: 2655.0808 - mse: 2655.0813 - mae: 28.5086\n",
      "Epoch 3/80\n",
      "3516/3516 [==============================] - 1s 148us/step - loss: 2689.9207 - mse: 2689.9219 - mae: 28.8010\n",
      "Epoch 4/80\n",
      "3516/3516 [==============================] - 1s 176us/step - loss: 2737.3647 - mse: 2737.3650 - mae: 28.7727\n",
      "Epoch 5/80\n",
      "3516/3516 [==============================] - 1s 174us/step - loss: 2715.4446 - mse: 2715.4453 - mae: 28.7263\n",
      "Epoch 6/80\n",
      "3516/3516 [==============================] - 1s 180us/step - loss: 2696.3421 - mse: 2696.3416 - mae: 28.7564\n",
      "Epoch 7/80\n",
      "3516/3516 [==============================] - 1s 179us/step - loss: 2670.8671 - mse: 2670.8669 - mae: 28.5162\n",
      "Epoch 8/80\n",
      "3516/3516 [==============================] - 1s 163us/step - loss: 2641.3211 - mse: 2641.3208 - mae: 28.2805\n",
      "Epoch 9/80\n",
      "3516/3516 [==============================] - 1s 163us/step - loss: 2642.2607 - mse: 2642.2625 - mae: 28.6574\n",
      "Epoch 10/80\n",
      "3516/3516 [==============================] - 1s 156us/step - loss: 2627.0054 - mse: 2627.0063 - mae: 28.3774\n",
      "Epoch 11/80\n",
      "3516/3516 [==============================] - 1s 170us/step - loss: 2664.6136 - mse: 2664.6123 - mae: 28.6489\n",
      "Epoch 12/80\n",
      "3516/3516 [==============================] - 1s 178us/step - loss: 2678.8579 - mse: 2678.8582 - mae: 28.2597\n",
      "Epoch 13/80\n",
      "3516/3516 [==============================] - 1s 167us/step - loss: 2693.8425 - mse: 2693.8420 - mae: 28.5752\n",
      "Epoch 14/80\n",
      "3516/3516 [==============================] - 1s 152us/step - loss: 2665.4782 - mse: 2665.4788 - mae: 28.7016\n",
      "Epoch 15/80\n",
      "3516/3516 [==============================] - 1s 152us/step - loss: 2712.5812 - mse: 2712.5803 - mae: 28.5889\n",
      "Epoch 16/80\n",
      "3516/3516 [==============================] - 1s 150us/step - loss: 2666.2567 - mse: 2666.2551 - mae: 28.4495\n",
      "Epoch 17/80\n",
      "3516/3516 [==============================] - 1s 143us/step - loss: 2659.7861 - mse: 2659.7864 - mae: 28.2989\n",
      "Epoch 18/80\n",
      "3516/3516 [==============================] - 1s 151us/step - loss: 2694.2318 - mse: 2694.2312 - mae: 28.6428\n",
      "Epoch 19/80\n",
      "3516/3516 [==============================] - 1s 150us/step - loss: 2630.4245 - mse: 2630.4246 - mae: 28.3872\n",
      "Epoch 20/80\n",
      "3516/3516 [==============================] - 1s 150us/step - loss: 2647.5181 - mse: 2647.5183 - mae: 28.4074\n",
      "Epoch 21/80\n",
      "3516/3516 [==============================] - 1s 145us/step - loss: 2670.7742 - mse: 2670.7747 - mae: 28.4960\n",
      "Epoch 22/80\n",
      "3516/3516 [==============================] - 1s 152us/step - loss: 2673.5991 - mse: 2673.6016 - mae: 28.4892\n",
      "Epoch 23/80\n",
      "3516/3516 [==============================] - 1s 151us/step - loss: 2717.6910 - mse: 2717.6902 - mae: 28.6151\n",
      "Epoch 24/80\n",
      "3516/3516 [==============================] - 1s 148us/step - loss: 2674.4227 - mse: 2674.4231 - mae: 28.4917\n",
      "Epoch 25/80\n",
      "3516/3516 [==============================] - 1s 150us/step - loss: 2692.2760 - mse: 2692.2759 - mae: 28.9047\n",
      "Epoch 26/80\n",
      "3516/3516 [==============================] - 1s 154us/step - loss: 2667.1139 - mse: 2667.1138 - mae: 28.7744\n",
      "Epoch 27/80\n",
      "3516/3516 [==============================] - 1s 161us/step - loss: 2680.5712 - mse: 2680.5713 - mae: 28.7861\n",
      "Epoch 28/80\n",
      "3516/3516 [==============================] - 1s 159us/step - loss: 2618.2522 - mse: 2618.2532 - mae: 28.0554\n",
      "Epoch 29/80\n",
      "3516/3516 [==============================] - 1s 152us/step - loss: 2682.2870 - mse: 2682.2876 - mae: 28.5016\n",
      "Epoch 30/80\n",
      "3516/3516 [==============================] - 1s 155us/step - loss: 2641.3730 - mse: 2641.3728 - mae: 28.0408\n",
      "Epoch 31/80\n",
      "3516/3516 [==============================] - 1s 156us/step - loss: 2656.3872 - mse: 2656.3865 - mae: 28.3754\n",
      "Epoch 32/80\n",
      "3516/3516 [==============================] - 1s 159us/step - loss: 2642.5800 - mse: 2642.5786 - mae: 28.2813\n",
      "Epoch 33/80\n",
      "3516/3516 [==============================] - 1s 144us/step - loss: 2645.3351 - mse: 2645.3350 - mae: 28.3029\n",
      "Epoch 34/80\n",
      "3516/3516 [==============================] - 1s 156us/step - loss: 2681.2814 - mse: 2681.2815 - mae: 28.3464\n",
      "Epoch 35/80\n",
      "3516/3516 [==============================] - 1s 150us/step - loss: 2692.9297 - mse: 2692.9299 - mae: 28.6321\n",
      "Epoch 36/80\n",
      "3516/3516 [==============================] - 1s 153us/step - loss: 2668.4148 - mse: 2668.4143 - mae: 28.5945\n",
      "Epoch 37/80\n",
      "3516/3516 [==============================] - 1s 155us/step - loss: 2674.8405 - mse: 2674.8401 - mae: 28.1682\n",
      "Epoch 38/80\n",
      "3516/3516 [==============================] - 1s 158us/step - loss: 2636.0385 - mse: 2636.0391 - mae: 28.3755\n",
      "Epoch 39/80\n",
      "3516/3516 [==============================] - 1s 157us/step - loss: 2691.1520 - mse: 2691.1514 - mae: 28.7870\n",
      "Epoch 40/80\n",
      "3516/3516 [==============================] - 1s 154us/step - loss: 2669.1829 - mse: 2669.1826 - mae: 28.5662\n",
      "Epoch 41/80\n",
      "3516/3516 [==============================] - 1s 151us/step - loss: 2651.1074 - mse: 2651.1069 - mae: 28.6665\n",
      "Epoch 42/80\n",
      "3516/3516 [==============================] - 1s 156us/step - loss: 2651.4008 - mse: 2651.4014 - mae: 28.0940\n",
      "Epoch 43/80\n",
      "3516/3516 [==============================] - 1s 163us/step - loss: 2682.5904 - mse: 2682.5913 - mae: 28.2449\n",
      "Epoch 44/80\n",
      "3516/3516 [==============================] - 1s 156us/step - loss: 2662.0795 - mse: 2662.0789 - mae: 28.4892\n",
      "Epoch 45/80\n",
      "3516/3516 [==============================] - 1s 152us/step - loss: 2660.7050 - mse: 2660.7048 - mae: 28.3142\n",
      "Epoch 46/80\n",
      "3516/3516 [==============================] - 1s 160us/step - loss: 2690.6212 - mse: 2690.6206 - mae: 28.8314\n",
      "Epoch 47/80\n",
      "3516/3516 [==============================] - 1s 149us/step - loss: 2634.9245 - mse: 2634.9243 - mae: 28.4443\n",
      "Epoch 48/80\n",
      "3516/3516 [==============================] - 1s 156us/step - loss: 2677.9344 - mse: 2677.9341 - mae: 28.5713\n",
      "Epoch 49/80\n",
      "3516/3516 [==============================] - 1s 151us/step - loss: 2639.4137 - mse: 2639.4138 - mae: 28.5720\n",
      "Epoch 50/80\n",
      "3516/3516 [==============================] - 1s 160us/step - loss: 2640.7804 - mse: 2640.7800 - mae: 28.4535\n",
      "Epoch 51/80\n",
      "3516/3516 [==============================] - 1s 150us/step - loss: 2704.4974 - mse: 2704.4961 - mae: 29.0800\n",
      "Epoch 52/80\n",
      "3516/3516 [==============================] - 1s 154us/step - loss: 2660.4419 - mse: 2660.4414 - mae: 28.6296\n",
      "Epoch 53/80\n",
      "3516/3516 [==============================] - 1s 154us/step - loss: 2689.0917 - mse: 2689.0918 - mae: 28.5020\n",
      "Epoch 54/80\n",
      "3516/3516 [==============================] - 1s 160us/step - loss: 2660.2647 - mse: 2660.2644 - mae: 28.2592\n",
      "Epoch 55/80\n",
      "3516/3516 [==============================] - 1s 154us/step - loss: 2643.4692 - mse: 2643.4700 - mae: 28.4045\n",
      "Epoch 56/80\n",
      "3516/3516 [==============================] - 1s 157us/step - loss: 2678.2789 - mse: 2678.2793 - mae: 28.5974\n",
      "Epoch 57/80\n",
      "3516/3516 [==============================] - 1s 155us/step - loss: 2652.1322 - mse: 2652.1323 - mae: 28.4540\n",
      "Epoch 58/80\n",
      "3516/3516 [==============================] - 1s 150us/step - loss: 2652.2342 - mse: 2652.2346 - mae: 28.2279\n",
      "Epoch 59/80\n",
      "3516/3516 [==============================] - 1s 158us/step - loss: 2684.2619 - mse: 2684.2622 - mae: 28.5966\n",
      "Epoch 60/80\n",
      "3516/3516 [==============================] - 1s 154us/step - loss: 2631.3393 - mse: 2631.3398 - mae: 28.4392\n",
      "Epoch 61/80\n",
      "3516/3516 [==============================] - 1s 156us/step - loss: 2696.5040 - mse: 2696.5042 - mae: 28.6336\n",
      "Epoch 62/80\n",
      "3516/3516 [==============================] - 1s 159us/step - loss: 2682.5302 - mse: 2682.5300 - mae: 28.5008\n",
      "Epoch 63/80\n",
      "3516/3516 [==============================] - 1s 150us/step - loss: 2658.4704 - mse: 2658.4707 - mae: 28.6087\n",
      "Epoch 64/80\n",
      "3516/3516 [==============================] - 1s 149us/step - loss: 2711.9177 - mse: 2711.9185 - mae: 29.0172\n",
      "Epoch 65/80\n",
      "3516/3516 [==============================] - 1s 148us/step - loss: 2636.4892 - mse: 2636.4895 - mae: 28.3148\n",
      "Epoch 66/80\n",
      "3516/3516 [==============================] - 1s 157us/step - loss: 2686.5144 - mse: 2686.5137 - mae: 28.8299\n",
      "Epoch 67/80\n",
      "3516/3516 [==============================] - 1s 153us/step - loss: 2662.3441 - mse: 2662.3447 - mae: 28.9268\n",
      "Epoch 68/80\n",
      "3516/3516 [==============================] - 1s 170us/step - loss: 2691.6205 - mse: 2691.6206 - mae: 28.7000\n",
      "Epoch 69/80\n",
      "3516/3516 [==============================] - 1s 158us/step - loss: 2676.3441 - mse: 2676.3433 - mae: 28.9720\n",
      "Epoch 70/80\n",
      "3516/3516 [==============================] - 1s 171us/step - loss: 2685.3125 - mse: 2685.3123 - mae: 28.8087\n",
      "Epoch 71/80\n",
      "3516/3516 [==============================] - 1s 172us/step - loss: 2678.2596 - mse: 2678.2598 - mae: 28.3588\n",
      "Epoch 72/80\n",
      "3516/3516 [==============================] - 1s 163us/step - loss: 2660.5253 - mse: 2660.5254 - mae: 28.4032\n",
      "Epoch 73/80\n",
      "3516/3516 [==============================] - 0s 134us/step - loss: 2676.7246 - mse: 2676.7253 - mae: 28.2363\n",
      "Epoch 74/80\n",
      "3516/3516 [==============================] - 0s 131us/step - loss: 2628.3355 - mse: 2628.3350 - mae: 28.2745\n",
      "Epoch 75/80\n",
      "3516/3516 [==============================] - 0s 137us/step - loss: 2685.6792 - mse: 2685.6804 - mae: 28.5386\n",
      "Epoch 76/80\n",
      "3516/3516 [==============================] - 1s 159us/step - loss: 2688.2418 - mse: 2688.2419 - mae: 28.6268\n",
      "Epoch 77/80\n",
      "3516/3516 [==============================] - 1s 159us/step - loss: 2689.5710 - mse: 2689.5708 - mae: 28.6075\n",
      "Epoch 78/80\n",
      "3516/3516 [==============================] - 1s 154us/step - loss: 2634.1706 - mse: 2634.1724 - mae: 28.5960\n",
      "Epoch 79/80\n",
      "3516/3516 [==============================] - 1s 156us/step - loss: 2619.3817 - mse: 2619.3804 - mae: 28.3320\n",
      "Epoch 80/80\n",
      "3516/3516 [==============================] - 1s 161us/step - loss: 2743.3050 - mse: 2743.3049 - mae: 28.8582\n",
      "6\n",
      "Epoch 1/80\n",
      "4101/4101 [==============================] - 1s 159us/step - loss: 2762.0293 - mse: 2762.0293 - mae: 29.5962\n",
      "Epoch 2/80\n",
      "4101/4101 [==============================] - 1s 160us/step - loss: 2798.9612 - mse: 2798.9612 - mae: 29.4990\n",
      "Epoch 3/80\n",
      "4101/4101 [==============================] - 1s 150us/step - loss: 2827.8275 - mse: 2827.8276 - mae: 29.6739\n",
      "Epoch 4/80\n",
      "4101/4101 [==============================] - 1s 153us/step - loss: 2783.1383 - mse: 2783.1372 - mae: 29.9449\n",
      "Epoch 5/80\n",
      "4101/4101 [==============================] - 1s 152us/step - loss: 2810.6162 - mse: 2810.6160 - mae: 29.3768\n",
      "Epoch 6/80\n",
      "4101/4101 [==============================] - 1s 155us/step - loss: 2794.1579 - mse: 2794.1575 - mae: 29.4560\n",
      "Epoch 7/80\n",
      "4101/4101 [==============================] - 1s 153us/step - loss: 2766.8340 - mse: 2766.8345 - mae: 29.3479\n",
      "Epoch 8/80\n",
      "4101/4101 [==============================] - 1s 147us/step - loss: 2772.8414 - mse: 2772.8416 - mae: 29.7198\n",
      "Epoch 9/80\n",
      "4101/4101 [==============================] - 1s 166us/step - loss: 2737.1211 - mse: 2737.1201 - mae: 29.2660\n",
      "Epoch 10/80\n",
      "4101/4101 [==============================] - 1s 164us/step - loss: 2782.5446 - mse: 2782.5449 - mae: 29.5738\n",
      "Epoch 11/80\n",
      "4101/4101 [==============================] - 1s 150us/step - loss: 2775.7836 - mse: 2775.7842 - mae: 29.4806\n",
      "Epoch 12/80\n",
      "4101/4101 [==============================] - 1s 151us/step - loss: 2760.0800 - mse: 2760.0796 - mae: 29.2750\n",
      "Epoch 13/80\n",
      "4101/4101 [==============================] - 1s 150us/step - loss: 2756.5894 - mse: 2756.5908 - mae: 29.3845\n",
      "Epoch 14/80\n",
      "4101/4101 [==============================] - 1s 145us/step - loss: 2757.5100 - mse: 2757.5095 - mae: 29.1456\n",
      "Epoch 15/80\n",
      "4101/4101 [==============================] - 1s 145us/step - loss: 2786.2626 - mse: 2786.2627 - mae: 29.1677\n",
      "Epoch 16/80\n",
      "4101/4101 [==============================] - 1s 152us/step - loss: 2744.7427 - mse: 2744.7429 - mae: 29.3075\n",
      "Epoch 17/80\n",
      "4101/4101 [==============================] - 1s 155us/step - loss: 2767.9636 - mse: 2767.9631 - mae: 29.1966\n",
      "Epoch 18/80\n",
      "4101/4101 [==============================] - 1s 144us/step - loss: 2737.1228 - mse: 2737.1221 - mae: 29.2556\n",
      "Epoch 19/80\n",
      "4101/4101 [==============================] - 1s 143us/step - loss: 2728.2718 - mse: 2728.2712 - mae: 29.1094\n",
      "Epoch 20/80\n",
      "4101/4101 [==============================] - 1s 159us/step - loss: 2748.3610 - mse: 2748.3616 - mae: 29.2209\n",
      "Epoch 21/80\n",
      "4101/4101 [==============================] - 1s 148us/step - loss: 2741.5737 - mse: 2741.5735 - mae: 29.2618\n",
      "Epoch 22/80\n",
      "4101/4101 [==============================] - 1s 158us/step - loss: 2769.7390 - mse: 2769.7375 - mae: 29.2828\n",
      "Epoch 23/80\n",
      "4101/4101 [==============================] - 1s 149us/step - loss: 2752.8961 - mse: 2752.8960 - mae: 29.3048\n",
      "Epoch 24/80\n",
      "4101/4101 [==============================] - 1s 151us/step - loss: 2779.2737 - mse: 2779.2732 - mae: 29.6420\n",
      "Epoch 25/80\n",
      "4101/4101 [==============================] - 1s 148us/step - loss: 2765.5592 - mse: 2765.5588 - mae: 29.3045\n",
      "Epoch 26/80\n",
      "4101/4101 [==============================] - 1s 147us/step - loss: 2705.1151 - mse: 2705.1150 - mae: 29.0237\n",
      "Epoch 27/80\n",
      "4101/4101 [==============================] - 1s 157us/step - loss: 2745.9498 - mse: 2745.9490 - mae: 29.3867\n",
      "Epoch 28/80\n",
      "4101/4101 [==============================] - 1s 154us/step - loss: 2739.9137 - mse: 2739.9136 - mae: 29.2136\n",
      "Epoch 29/80\n",
      "4101/4101 [==============================] - 1s 154us/step - loss: 2735.9300 - mse: 2735.9299 - mae: 29.1455\n",
      "Epoch 30/80\n",
      "4101/4101 [==============================] - 1s 151us/step - loss: 2766.9885 - mse: 2766.9878 - mae: 29.3846\n",
      "Epoch 31/80\n",
      "4101/4101 [==============================] - 1s 153us/step - loss: 2739.6788 - mse: 2739.6792 - mae: 29.1046\n",
      "Epoch 32/80\n",
      "4101/4101 [==============================] - 1s 158us/step - loss: 2746.8807 - mse: 2746.8818 - mae: 29.4817\n",
      "Epoch 33/80\n",
      "4101/4101 [==============================] - 1s 151us/step - loss: 2805.8483 - mse: 2805.8494 - mae: 29.5522\n",
      "Epoch 34/80\n",
      "4101/4101 [==============================] - 1s 145us/step - loss: 2785.6957 - mse: 2785.6936 - mae: 29.3186\n",
      "Epoch 35/80\n",
      "4101/4101 [==============================] - 1s 156us/step - loss: 2755.5114 - mse: 2755.5110 - mae: 29.3915\n",
      "Epoch 36/80\n",
      "4101/4101 [==============================] - 1s 153us/step - loss: 2771.0094 - mse: 2771.0107 - mae: 29.1176\n",
      "Epoch 37/80\n",
      "4101/4101 [==============================] - 1s 159us/step - loss: 2738.2170 - mse: 2738.2173 - mae: 29.0729\n",
      "Epoch 38/80\n",
      "4101/4101 [==============================] - 1s 165us/step - loss: 2759.8278 - mse: 2759.8279 - mae: 28.9833\n",
      "Epoch 39/80\n",
      "4101/4101 [==============================] - 1s 151us/step - loss: 2762.7757 - mse: 2762.7754 - mae: 29.4552\n",
      "Epoch 40/80\n",
      "4101/4101 [==============================] - 1s 154us/step - loss: 2770.0780 - mse: 2770.0781 - mae: 29.8071\n",
      "Epoch 41/80\n",
      "4101/4101 [==============================] - 1s 186us/step - loss: 2756.8945 - mse: 2756.8943 - mae: 28.9895\n",
      "Epoch 42/80\n",
      "4101/4101 [==============================] - 1s 187us/step - loss: 2788.5274 - mse: 2788.5286 - mae: 29.2164\n",
      "Epoch 43/80\n",
      "4101/4101 [==============================] - 1s 164us/step - loss: 2745.4275 - mse: 2745.4270 - mae: 29.0018\n",
      "Epoch 44/80\n",
      "4101/4101 [==============================] - 1s 146us/step - loss: 2728.7029 - mse: 2728.7039 - mae: 29.0738\n",
      "Epoch 45/80\n",
      "4101/4101 [==============================] - 1s 155us/step - loss: 2757.0311 - mse: 2757.0310 - mae: 29.1142\n",
      "Epoch 46/80\n",
      "4101/4101 [==============================] - 1s 184us/step - loss: 2752.7739 - mse: 2752.7742 - mae: 29.2374\n",
      "Epoch 47/80\n",
      "4101/4101 [==============================] - 1s 166us/step - loss: 2758.4945 - mse: 2758.4944 - mae: 29.0566\n",
      "Epoch 48/80\n",
      "4101/4101 [==============================] - 1s 180us/step - loss: 2734.8367 - mse: 2734.8364 - mae: 28.8848\n",
      "Epoch 49/80\n",
      "4101/4101 [==============================] - 1s 204us/step - loss: 2765.9032 - mse: 2765.9028 - mae: 29.3997\n",
      "Epoch 50/80\n",
      "4101/4101 [==============================] - 1s 154us/step - loss: 2744.7041 - mse: 2744.7031 - mae: 29.0915\n",
      "Epoch 51/80\n",
      "4101/4101 [==============================] - 1s 151us/step - loss: 2744.2713 - mse: 2744.2715 - mae: 29.1339\n",
      "Epoch 52/80\n",
      "4101/4101 [==============================] - 1s 153us/step - loss: 2777.0532 - mse: 2777.0527 - mae: 29.3947\n",
      "Epoch 53/80\n",
      "4101/4101 [==============================] - 1s 147us/step - loss: 2768.2477 - mse: 2768.2468 - mae: 29.2128\n",
      "Epoch 54/80\n",
      "4101/4101 [==============================] - 1s 147us/step - loss: 2772.5834 - mse: 2772.5828 - mae: 28.8160\n",
      "Epoch 55/80\n",
      "4101/4101 [==============================] - 1s 149us/step - loss: 2769.5224 - mse: 2769.5225 - mae: 29.5473\n",
      "Epoch 56/80\n",
      "4101/4101 [==============================] - 1s 154us/step - loss: 2713.3905 - mse: 2713.3909 - mae: 29.0700\n",
      "Epoch 57/80\n",
      "4101/4101 [==============================] - 1s 148us/step - loss: 2742.4809 - mse: 2742.4802 - mae: 28.8791\n",
      "Epoch 58/80\n",
      "4101/4101 [==============================] - 1s 150us/step - loss: 2752.7145 - mse: 2752.7144 - mae: 29.3779\n",
      "Epoch 59/80\n",
      "4101/4101 [==============================] - 1s 153us/step - loss: 2738.3206 - mse: 2738.3188 - mae: 29.2439\n",
      "Epoch 60/80\n",
      "4101/4101 [==============================] - 1s 154us/step - loss: 2725.6681 - mse: 2725.6689 - mae: 28.6489\n",
      "Epoch 61/80\n",
      "4101/4101 [==============================] - 1s 148us/step - loss: 2737.6253 - mse: 2737.6243 - mae: 29.1781\n",
      "Epoch 62/80\n",
      "4101/4101 [==============================] - 1s 158us/step - loss: 2747.2127 - mse: 2747.2126 - mae: 29.0175\n",
      "Epoch 63/80\n",
      "4101/4101 [==============================] - 1s 158us/step - loss: 2714.2027 - mse: 2714.2029 - mae: 28.9781\n",
      "Epoch 64/80\n",
      "4101/4101 [==============================] - 1s 153us/step - loss: 2768.9547 - mse: 2768.9553 - mae: 29.2073\n",
      "Epoch 65/80\n",
      "4101/4101 [==============================] - 1s 153us/step - loss: 2776.5626 - mse: 2776.5615 - mae: 29.2513\n",
      "Epoch 66/80\n",
      "4101/4101 [==============================] - 1s 154us/step - loss: 2773.4531 - mse: 2773.4526 - mae: 29.4743\n",
      "Epoch 67/80\n",
      "4101/4101 [==============================] - 1s 148us/step - loss: 2756.1353 - mse: 2756.1357 - mae: 29.0207\n",
      "Epoch 68/80\n",
      "4101/4101 [==============================] - 1s 155us/step - loss: 2740.6840 - mse: 2740.6831 - mae: 29.3309\n",
      "Epoch 69/80\n",
      "4101/4101 [==============================] - 1s 150us/step - loss: 2727.8849 - mse: 2727.8850 - mae: 29.2129\n",
      "Epoch 70/80\n",
      "4101/4101 [==============================] - 1s 150us/step - loss: 2739.6374 - mse: 2739.6367 - mae: 29.0707\n",
      "Epoch 71/80\n",
      "4101/4101 [==============================] - 1s 148us/step - loss: 2774.2731 - mse: 2774.2744 - mae: 29.3365\n",
      "Epoch 72/80\n",
      "4101/4101 [==============================] - 1s 148us/step - loss: 2781.9428 - mse: 2781.9436 - mae: 29.3097\n",
      "Epoch 73/80\n",
      "4101/4101 [==============================] - 1s 137us/step - loss: 2761.1190 - mse: 2761.1191 - mae: 29.3017\n",
      "Epoch 74/80\n",
      "4101/4101 [==============================] - 1s 151us/step - loss: 2733.9589 - mse: 2733.9585 - mae: 29.1849\n",
      "Epoch 75/80\n",
      "4101/4101 [==============================] - 1s 146us/step - loss: 2798.8159 - mse: 2798.8167 - mae: 29.3411\n",
      "Epoch 76/80\n",
      "4101/4101 [==============================] - 1s 156us/step - loss: 2734.0383 - mse: 2734.0386 - mae: 29.3136\n",
      "Epoch 77/80\n",
      "4101/4101 [==============================] - 1s 149us/step - loss: 2711.4951 - mse: 2711.4949 - mae: 29.0301\n",
      "Epoch 78/80\n",
      "4101/4101 [==============================] - 1s 150us/step - loss: 2723.7903 - mse: 2723.7891 - mae: 29.0340\n",
      "Epoch 79/80\n",
      "4101/4101 [==============================] - 1s 151us/step - loss: 2757.5386 - mse: 2757.5381 - mae: 29.0604\n",
      "Epoch 80/80\n",
      "4101/4101 [==============================] - 1s 152us/step - loss: 2719.8434 - mse: 2719.8418 - mae: 28.8121\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "# data\n",
    "data = pd.read_csv('Data_set_1_smaller.csv', index_col = 0)\n",
    "data = data.loc[data.index > 2018090000, :]\n",
    "    \n",
    "# reset index\n",
    "data.reset_index(inplace = True)\n",
    "data.drop('index', axis = 1, inplace = True)\n",
    "    \n",
    "# Divide features and labels\n",
    "X = data.iloc[:, 0:15]\n",
    "y = data.loc[:, 'Offers']\n",
    "\n",
    "X.fillna(X.mean(), inplace = True)\n",
    "y.fillna(y.mean(), inplace = True)\n",
    "    \n",
    "X = X.astype('float64')\n",
    "X = X.round(20)\n",
    "    \n",
    "# divide data into train and test with 20% test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "             X, y, test_size=0.2, shuffle=False)\n",
    "    \n",
    "# feature scaling\n",
    "sc_X = MinMaxScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)\n",
    "    \n",
    "import keras\n",
    "from keras.models import Sequential # to initialise the NN\n",
    "from keras.layers import Dense # to create layers\n",
    "from keras.layers import Dropout\n",
    "from keras import initializers\n",
    "from keras import optimizers\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "    \n",
    "# possible debug\n",
    "X_train = np.nan_to_num(X_train)\n",
    "X_test = np.nan_to_num(X_test)\n",
    "    \n",
    "def regressor_tunning(n_hidden = 2, \n",
    "                      n_neurons = 30,  \n",
    "                      kernel_initializer = \"he_normal\",\n",
    "                      bias_initializer = initializers.Ones()):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = n_neurons, input_dim = 15))        \n",
    "    model.add(keras.layers.LeakyReLU(alpha = 0.2))\n",
    "    model.add(Dropout(rate = 0.1))        \n",
    "    for layer in range(n_hidden):\n",
    "        model.add(Dense(n_neurons))\n",
    "        model.add(keras.layers.LeakyReLU(alpha = 0.2))\n",
    "        model.add(Dropout(rate = 0.1))\n",
    "    model.add(Dense(units = 1, activation = 'linear'))\n",
    "    optimizer = optimizers.Adamax(lr = 0.001)\n",
    "    model.compile(loss = 'mse', optimizer = optimizer, metrics = ['mse', 'mae'])\n",
    "    return model\n",
    "\n",
    "def exponential_decay_fn(epoch):\n",
    "    return 0.001 * 0.1 ** (epoch / 20)\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits = 7)\n",
    "    \n",
    "hist_list = pd.DataFrame()\n",
    "count = 1\n",
    "    \n",
    "regressor = regressor_tunning()\n",
    "    \n",
    "for train_index, test_index in tscv.split(X_train):\n",
    "    X_train_split, X_test_split = X_train[train_index], X_train[test_index]\n",
    "    y_train_split, y_test_split = y_train[train_index], y_train[test_index]\n",
    "    lr_scheduler = keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
    "    hist = regressor.fit(X_train_split, y_train_split, batch_size = 15, epochs = 80, callbacks = [lr_scheduler])\n",
    "    hist_list = hist_list.append(hist.history, ignore_index = True)\n",
    "    print(count)\n",
    "    count = count + 1\n",
    "\n",
    "a = []\n",
    "b = []\n",
    "\n",
    "for i in range(len(hist_list.mse)):\n",
    "    a.append(np.mean(hist_list.mse[i]))\n",
    "    b.append(np.mean(hist_list.mae[i]))\n",
    "\n",
    "mse_cv.append(np.mean(a))\n",
    "mae_cv.append(np.mean(b))\n",
    "\n",
    "# predict for X_test  \n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "\n",
    "rmse_error = mse(y_test, y_pred, squared = False)\n",
    "mse_error = mse(y_test, y_pred) # 1479.61335\n",
    "mae_error = mae(y_test, y_pred) # 23.1525\n",
    "\n",
    "rmse_gen.append(rmse_error)\n",
    "mse_gen.append(mse_error)\n",
    "mae_gen.append(mae_error)\n",
    "\n",
    "# =============================================================================\n",
    "# Metrics evaluation on spike regions\n",
    "# =============================================================================\n",
    "\n",
    "y_spike_occ = pd.read_csv('Spike_binary_1std.csv', usecols = [6])\n",
    "\n",
    "# create array same size as y_test\n",
    "y_spike_occ = y_spike_occ.iloc[- len(y_test):]\n",
    "y_spike_occ = pd.Series(y_spike_occ.iloc[:,0]).values\n",
    "\n",
    "\n",
    "# smal adjustment\n",
    "y_test.replace(0, 0.0001,inplace = True)\n",
    "\n",
    "\n",
    "# select y_pred and y_test only for regions with spikes\n",
    "y_test_spike = (y_test.T * y_spike_occ).T\n",
    "y_pred_spike = (y_pred.T * y_spike_occ).T\n",
    "y_test_spike = y_test_spike[y_test_spike != 0]\n",
    "y_pred_spike = y_pred_spike[y_pred_spike != 0]\n",
    "\n",
    "# calculate metric\n",
    "rmse_spike = mse(y_test_spike, y_pred_spike, squared = False)\n",
    "mse_spike = mse(y_test_spike, y_pred_spike)\n",
    "mae_spike = mae(y_test_spike, y_pred_spike)\n",
    "\n",
    "rmse_spi.append(rmse_spike)\n",
    "mse_spi.append(mse_spike)\n",
    "mae_spi.append(mae_spike)\n",
    "\n",
    "# =============================================================================\n",
    "# Metric evaluation on normal regions\n",
    "# =============================================================================\n",
    "\n",
    "# inverse y_spike_occ so the only normal occurences are chosen\n",
    "y_normal_occ = (y_spike_occ - 1) * (-1)\n",
    "\n",
    "# sanity check\n",
    "y_normal_occ.sum() + y_spike_occ.sum() # gives the correct total \n",
    "\n",
    "# select y_pred and y_test only for normal regions\n",
    "y_test_normal = (y_test.T * y_normal_occ).T\n",
    "y_pred_normal = (y_pred.T * y_normal_occ).T\n",
    "y_test_normal = y_test_normal[y_test_normal != 0.00]\n",
    "y_pred_normal = y_pred_normal[y_pred_normal != 0.00]\n",
    "\n",
    "# calculate metric\n",
    "rmse_normal = mse(y_test_normal, y_pred_normal, squared = False)\n",
    "mse_normal = mse(y_test_normal, y_pred_normal)\n",
    "mae_normal = mae(y_test_normal, y_pred_normal)\n",
    "\n",
    "rmse_nor.append(rmse_normal)\n",
    "mse_nor.append(mse_normal)\n",
    "mae_nor.append(mae_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse_cv</th>\n",
       "      <th>mae_cv</th>\n",
       "      <th>rmse_general</th>\n",
       "      <th>mae_general</th>\n",
       "      <th>rmse_spike</th>\n",
       "      <th>mae_spike</th>\n",
       "      <th>rmse_normal</th>\n",
       "      <th>mae_normal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lr = 0.001</th>\n",
       "      <td>55.276041</td>\n",
       "      <td>28.981050</td>\n",
       "      <td>33.480437</td>\n",
       "      <td>25.72624</td>\n",
       "      <td>70.280266</td>\n",
       "      <td>57.429934</td>\n",
       "      <td>23.855083</td>\n",
       "      <td>21.144065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp schedueling</th>\n",
       "      <td>61.821680</td>\n",
       "      <td>35.702667</td>\n",
       "      <td>33.925013</td>\n",
       "      <td>26.66175</td>\n",
       "      <td>71.837222</td>\n",
       "      <td>59.189063</td>\n",
       "      <td>23.903608</td>\n",
       "      <td>21.960537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   rmse_cv     mae_cv  rmse_general  mae_general  rmse_spike  \\\n",
       "lr = 0.001       55.276041  28.981050     33.480437     25.72624   70.280266   \n",
       "exp schedueling  61.821680  35.702667     33.925013     26.66175   71.837222   \n",
       "\n",
       "                 mae_spike  rmse_normal  mae_normal  \n",
       "lr = 0.001       57.429934    23.855083   21.144065  \n",
       "exp schedueling  59.189063    23.903608   21.960537  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_cv = []\n",
    "for i in mse_cv:\n",
    "    rmse_cv.append(i ** 0.5)\n",
    "    \n",
    "results = pd.DataFrame({'rmse_cv':rmse_cv,\n",
    "              \n",
    "                        'mae_cv': mae_cv,\n",
    "                        \n",
    "                        'rmse_general': rmse_gen, \n",
    "                 \n",
    "                        'mae_general': mae_gen,\n",
    "                        \n",
    "                        'rmse_spike': rmse_spi,\n",
    "                 \n",
    "                        'mae_spike': mae_spi,\n",
    "                        \n",
    "                        'rmse_normal': rmse_nor,\n",
    "                    \n",
    "                        'mae_normal': mae_nor}, index = ['lr = 0.001', 'exp schedueling'])\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_3da1de8c_c464_11ea_b95d_4ded42f9afe5row0_col0 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_3da1de8c_c464_11ea_b95d_4ded42f9afe5row0_col1 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_3da1de8c_c464_11ea_b95d_4ded42f9afe5row0_col2 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_3da1de8c_c464_11ea_b95d_4ded42f9afe5row0_col3 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_3da1de8c_c464_11ea_b95d_4ded42f9afe5row0_col4 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_3da1de8c_c464_11ea_b95d_4ded42f9afe5row0_col5 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_3da1de8c_c464_11ea_b95d_4ded42f9afe5row0_col6 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_3da1de8c_c464_11ea_b95d_4ded42f9afe5row0_col7 {\n",
       "            background-color:  yellow;\n",
       "        }</style><table id=\"T_3da1de8c_c464_11ea_b95d_4ded42f9afe5\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >rmse_cv</th>        <th class=\"col_heading level0 col1\" >mae_cv</th>        <th class=\"col_heading level0 col2\" >rmse_general</th>        <th class=\"col_heading level0 col3\" >mae_general</th>        <th class=\"col_heading level0 col4\" >rmse_spike</th>        <th class=\"col_heading level0 col5\" >mae_spike</th>        <th class=\"col_heading level0 col6\" >rmse_normal</th>        <th class=\"col_heading level0 col7\" >mae_normal</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_3da1de8c_c464_11ea_b95d_4ded42f9afe5level0_row0\" class=\"row_heading level0 row0\" >lr = 0.001</th>\n",
       "                        <td id=\"T_3da1de8c_c464_11ea_b95d_4ded42f9afe5row0_col0\" class=\"data row0 col0\" >55.276041</td>\n",
       "                        <td id=\"T_3da1de8c_c464_11ea_b95d_4ded42f9afe5row0_col1\" class=\"data row0 col1\" >28.981050</td>\n",
       "                        <td id=\"T_3da1de8c_c464_11ea_b95d_4ded42f9afe5row0_col2\" class=\"data row0 col2\" >33.480437</td>\n",
       "                        <td id=\"T_3da1de8c_c464_11ea_b95d_4ded42f9afe5row0_col3\" class=\"data row0 col3\" >25.726240</td>\n",
       "                        <td id=\"T_3da1de8c_c464_11ea_b95d_4ded42f9afe5row0_col4\" class=\"data row0 col4\" >70.280266</td>\n",
       "                        <td id=\"T_3da1de8c_c464_11ea_b95d_4ded42f9afe5row0_col5\" class=\"data row0 col5\" >57.429934</td>\n",
       "                        <td id=\"T_3da1de8c_c464_11ea_b95d_4ded42f9afe5row0_col6\" class=\"data row0 col6\" >23.855083</td>\n",
       "                        <td id=\"T_3da1de8c_c464_11ea_b95d_4ded42f9afe5row0_col7\" class=\"data row0 col7\" >21.144065</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_3da1de8c_c464_11ea_b95d_4ded42f9afe5level0_row1\" class=\"row_heading level0 row1\" >exp schedueling</th>\n",
       "                        <td id=\"T_3da1de8c_c464_11ea_b95d_4ded42f9afe5row1_col0\" class=\"data row1 col0\" >61.821680</td>\n",
       "                        <td id=\"T_3da1de8c_c464_11ea_b95d_4ded42f9afe5row1_col1\" class=\"data row1 col1\" >35.702667</td>\n",
       "                        <td id=\"T_3da1de8c_c464_11ea_b95d_4ded42f9afe5row1_col2\" class=\"data row1 col2\" >33.925013</td>\n",
       "                        <td id=\"T_3da1de8c_c464_11ea_b95d_4ded42f9afe5row1_col3\" class=\"data row1 col3\" >26.661750</td>\n",
       "                        <td id=\"T_3da1de8c_c464_11ea_b95d_4ded42f9afe5row1_col4\" class=\"data row1 col4\" >71.837222</td>\n",
       "                        <td id=\"T_3da1de8c_c464_11ea_b95d_4ded42f9afe5row1_col5\" class=\"data row1 col5\" >59.189063</td>\n",
       "                        <td id=\"T_3da1de8c_c464_11ea_b95d_4ded42f9afe5row1_col6\" class=\"data row1 col6\" >23.903608</td>\n",
       "                        <td id=\"T_3da1de8c_c464_11ea_b95d_4ded42f9afe5row1_col7\" class=\"data row1 col7\" >21.960537</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fd44c47fd50>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def highlight_min(s):\n",
    "    '''\n",
    "    highlight the maximum in a Series yellow.\n",
    "    '''\n",
    "    is_max = s == s.min()\n",
    "    return ['background-color: yellow' if v else '' for v in is_max]\n",
    "\n",
    "results.style.apply(highlight_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
