{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Parameter Tunning with MinMax\n",
    "    \n",
    "    RandomizedCV for: hidden layers, \n",
    "    neurons, optimizer, kernel initializer and bias initializer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages (1.0.5)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages (from pandas) (1.18.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages (from pandas) (2020.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas) (1.14.0)\n",
      "Requirement already satisfied: sklearn in /home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages (from sklearn) (0.23.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.4.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.18.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages (from scikit-learn->sklearn) (0.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install sklearn\n",
    "\n",
    "import pandas as pd;\n",
    "import numpy as np;\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split, cross_validate, cross_val_predict;\n",
    "from sklearn.preprocessing import MinMaxScaler;\n",
    "from sklearn import metrics;\n",
    "from sklearn.model_selection import TimeSeriesSplit;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data; set X and y; fill nan values and split in test and training  data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/pandas/core/generic.py:6245: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "# import data\n",
    "data = pd.read_csv('Data_set_1_smaller.csv', index_col = 0)\n",
    "bin_dataset = pd.read_csv('Spike_binary_1std.csv', index_col = 0)\n",
    "bin_dataset = bin_dataset['spike_occurance']\n",
    "\n",
    "# filter max values for offer if required\n",
    "print(data.Offers.max()) #max is 2500... no need to filter max values\n",
    "\n",
    "# 2017 & 2018 data\n",
    "data = data.loc[data.index > 2018060000, :]\n",
    "bin_dataset = bin_dataset.loc[bin_dataset.index > 2018060000]\n",
    "\n",
    "# reset index\n",
    "data.reset_index(drop = True, inplace = True)\n",
    "bin_dataset.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# Divide features and labels\n",
    "X = data.iloc[:, 0:15]\n",
    "y = bin_dataset\n",
    "\n",
    "# fill nan values\n",
    "X.fillna(method = 'ffill', inplace = True)\n",
    "\n",
    "X = X.astype('float64')\n",
    "X = X.round(20)\n",
    "\n",
    "# divide data into train and test with 20% test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "         X, y, test_size=0.1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply feature scaling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_X = MinMaxScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the Keras libraries and packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential # to initialise the NN\n",
    "from keras.layers import Dense # to create layers\n",
    "from keras.layers import Dropout\n",
    "import keras.optimizers\n",
    "from keras import initializers\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create regressor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# possible debug\n",
    "X_train = np.nan_to_num(X_train)\n",
    "X_test = np.nan_to_num(X_test)\n",
    "\n",
    "def regressor_tunning(n_hidden = 1, \n",
    "                      n_neurons = 11, \n",
    "                      optimizer = 'RMSprop', \n",
    "                      kernel_initializer=\"he_normal\",\n",
    "                      bias_initializer= initializers.Ones():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(output_dim = n_neurons, \n",
    "                    input_dim = 15))\n",
    "    model.add(keras.layers.LeakyReLU(alpha = 0.2))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(Dense(n_neurons))\n",
    "        model.add(keras.layers.LeakyReLU(alpha = 0.2))\n",
    "    model.add(Dense(output_dim = 1, \n",
    "                    activation = 'sigmoid'))\n",
    "    model.compile(loss = 'mse', optimizer = optimizer, metrics = ['mse', 'mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Randomized tunning for the whole ANN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=45)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "1850/1850 [==============================] - 6s 3ms/step - loss: 11769.0269 - mse: 11769.0273 - mae: 103.6678\n",
      "Epoch 2/60\n",
      "1850/1850 [==============================] - 1s 731us/step - loss: 8459.8813 - mse: 8459.8818 - mae: 85.9329\n",
      "Epoch 3/60\n",
      "1850/1850 [==============================] - 1s 729us/step - loss: 3721.4481 - mse: 3721.4487 - mae: 50.9239\n",
      "Epoch 4/60\n",
      "1850/1850 [==============================] - 1s 711us/step - loss: 1203.7260 - mse: 1203.7260 - mae: 23.5375\n",
      "Epoch 5/60\n",
      "1850/1850 [==============================] - 1s 665us/step - loss: 1039.3145 - mse: 1039.3145 - mae: 22.4298\n",
      "Epoch 6/60\n",
      "1850/1850 [==============================] - 1s 621us/step - loss: 1035.4982 - mse: 1035.4982 - mae: 22.4625\n",
      "Epoch 7/60\n",
      "1850/1850 [==============================] - 1s 647us/step - loss: 1025.7811 - mse: 1025.7812 - mae: 22.1371\n",
      "Epoch 8/60\n",
      "1850/1850 [==============================] - 1s 663us/step - loss: 1025.0591 - mse: 1025.0590 - mae: 22.1933\n",
      "Epoch 9/60\n",
      "1850/1850 [==============================] - 1s 687us/step - loss: 1022.5032 - mse: 1022.5032 - mae: 22.1223\n",
      "Epoch 10/60\n",
      "1850/1850 [==============================] - 1s 643us/step - loss: 1015.8124 - mse: 1015.8124 - mae: 21.9639\n",
      "Epoch 11/60\n",
      "1850/1850 [==============================] - 1s 621us/step - loss: 1015.1020 - mse: 1015.1021 - mae: 21.9261\n",
      "Epoch 12/60\n",
      "1850/1850 [==============================] - 1s 643us/step - loss: 1014.0536 - mse: 1014.0536 - mae: 21.8046\n",
      "Epoch 13/60\n",
      "1850/1850 [==============================] - 1s 688us/step - loss: 1011.9308 - mse: 1011.9308 - mae: 21.8038\n",
      "Epoch 14/60\n",
      "1850/1850 [==============================] - 1s 728us/step - loss: 1010.3944 - mse: 1010.3943 - mae: 21.7311\n",
      "Epoch 15/60\n",
      "1850/1850 [==============================] - 1s 730us/step - loss: 1009.6731 - mse: 1009.6732 - mae: 21.7011\n",
      "Epoch 16/60\n",
      "1850/1850 [==============================] - 1s 618us/step - loss: 1007.6832 - mse: 1007.6833 - mae: 21.6425\n",
      "Epoch 17/60\n",
      "1850/1850 [==============================] - 1s 642us/step - loss: 1007.4048 - mse: 1007.4049 - mae: 21.6333\n",
      "Epoch 18/60\n",
      "1850/1850 [==============================] - 1s 663us/step - loss: 1006.1648 - mse: 1006.1649 - mae: 21.6061\n",
      "Epoch 19/60\n",
      "1850/1850 [==============================] - 1s 644us/step - loss: 1003.7178 - mse: 1003.7179 - mae: 21.5602\n",
      "Epoch 20/60\n",
      "1850/1850 [==============================] - 1s 692us/step - loss: 1004.4778 - mse: 1004.4778 - mae: 21.5374\n",
      "Epoch 21/60\n",
      "1850/1850 [==============================] - 1s 643us/step - loss: 1002.7916 - mse: 1002.7917 - mae: 21.4876\n",
      "Epoch 22/60\n",
      "1850/1850 [==============================] - 1s 620us/step - loss: 1000.9622 - mse: 1000.9624 - mae: 21.5290\n",
      "Epoch 23/60\n",
      "1850/1850 [==============================] - 1s 662us/step - loss: 1001.6298 - mse: 1001.6297 - mae: 21.4051\n",
      "Epoch 24/60\n",
      "1850/1850 [==============================] - 1s 730us/step - loss: 996.4894 - mse: 996.4894 - mae: 21.4082\n",
      "Epoch 25/60\n",
      "1850/1850 [==============================] - 1s 729us/step - loss: 1001.7173 - mse: 1001.7172 - mae: 21.4299\n",
      "Epoch 26/60\n",
      "1850/1850 [==============================] - 1s 644us/step - loss: 998.9493 - mse: 998.9494 - mae: 21.4137\n",
      "Epoch 27/60\n",
      "1850/1850 [==============================] - 1s 620us/step - loss: 999.1435 - mse: 999.1434 - mae: 21.3361\n",
      "Epoch 28/60\n",
      "1850/1850 [==============================] - 1s 620us/step - loss: 995.3796 - mse: 995.3796 - mae: 21.3578\n",
      "Epoch 29/60\n",
      "1850/1850 [==============================] - 1s 620us/step - loss: 999.9363 - mse: 999.9361 - mae: 21.2922\n",
      "Epoch 30/60\n",
      "1850/1850 [==============================] - 1s 601us/step - loss: 995.0865 - mse: 995.0865 - mae: 21.3020\n",
      "Epoch 31/60\n",
      "1850/1850 [==============================] - 1s 646us/step - loss: 996.7138 - mse: 996.7139 - mae: 21.3514\n",
      "Epoch 32/60\n",
      "1850/1850 [==============================] - 1s 555us/step - loss: 995.6350 - mse: 995.6349 - mae: 21.3496\n",
      "Epoch 33/60\n",
      "1850/1850 [==============================] - 2s 844us/step - loss: 993.1198 - mse: 993.1201 - mae: 21.1782\n",
      "Epoch 34/60\n",
      "1850/1850 [==============================] - 1s 665us/step - loss: 992.7375 - mse: 992.7374 - mae: 21.2814\n",
      "Epoch 35/60\n",
      "1850/1850 [==============================] - 1s 665us/step - loss: 992.7534 - mse: 992.7532 - mae: 21.2681\n",
      "Epoch 36/60\n",
      "1850/1850 [==============================] - 1s 690us/step - loss: 990.0525 - mse: 990.0527 - mae: 21.2426\n",
      "Epoch 37/60\n",
      "1850/1850 [==============================] - 1s 557us/step - loss: 993.2302 - mse: 993.2303 - mae: 21.1932\n",
      "Epoch 38/60\n",
      "1850/1850 [==============================] - 1s 621us/step - loss: 992.5998 - mse: 992.5996 - mae: 21.2194\n",
      "Epoch 39/60\n",
      "1850/1850 [==============================] - 1s 600us/step - loss: 990.1397 - mse: 990.1397 - mae: 21.2169\n",
      "Epoch 40/60\n",
      "1850/1850 [==============================] - 1s 600us/step - loss: 990.6790 - mse: 990.6792 - mae: 21.1744\n",
      "Epoch 41/60\n",
      "1850/1850 [==============================] - 1s 603us/step - loss: 991.2302 - mse: 991.2303 - mae: 21.1665\n",
      "Epoch 42/60\n",
      "1850/1850 [==============================] - 1s 601us/step - loss: 992.0301 - mse: 992.0302 - mae: 21.1803\n",
      "Epoch 43/60\n",
      "1850/1850 [==============================] - 1s 621us/step - loss: 987.8418 - mse: 987.8419 - mae: 21.0938\n",
      "Epoch 44/60\n",
      "1850/1850 [==============================] - 1s 645us/step - loss: 987.4073 - mse: 987.4072 - mae: 21.1455\n",
      "Epoch 45/60\n",
      "1850/1850 [==============================] - 2s 860us/step - loss: 991.1996 - mse: 991.1997 - mae: 21.1062\n",
      "Epoch 46/60\n",
      "1850/1850 [==============================] - 2s 972us/step - loss: 989.1303 - mse: 989.1304 - mae: 21.0860\n",
      "Epoch 47/60\n",
      "1850/1850 [==============================] - 1s 620us/step - loss: 986.4363 - mse: 986.4363 - mae: 21.0395\n",
      "Epoch 48/60\n",
      "1850/1850 [==============================] - 1s 620us/step - loss: 986.6879 - mse: 986.6877 - mae: 21.0511\n",
      "Epoch 49/60\n",
      "1850/1850 [==============================] - 1s 597us/step - loss: 989.0838 - mse: 989.0839 - mae: 21.0900\n",
      "Epoch 50/60\n",
      "1850/1850 [==============================] - 1s 599us/step - loss: 986.9174 - mse: 986.9174 - mae: 21.0682\n",
      "Epoch 51/60\n",
      "1850/1850 [==============================] - 1s 576us/step - loss: 986.5949 - mse: 986.5950 - mae: 21.0956\n",
      "Epoch 52/60\n",
      "1850/1850 [==============================] - 1s 600us/step - loss: 987.0677 - mse: 987.0677 - mae: 21.0759\n",
      "Epoch 53/60\n",
      "1850/1850 [==============================] - 1s 623us/step - loss: 987.3069 - mse: 987.3069 - mae: 21.0501\n",
      "Epoch 54/60\n",
      "1850/1850 [==============================] - 1s 579us/step - loss: 983.7142 - mse: 983.7141 - mae: 21.0052\n",
      "Epoch 55/60\n",
      "1850/1850 [==============================] - 1s 599us/step - loss: 984.6388 - mse: 984.6390 - mae: 21.0267\n",
      "Epoch 56/60\n",
      "1850/1850 [==============================] - 1s 600us/step - loss: 986.2062 - mse: 986.2060 - mae: 21.0018\n",
      "Epoch 57/60\n",
      "1850/1850 [==============================] - 1s 664us/step - loss: 982.9608 - mse: 982.9607 - mae: 20.9632\n",
      "Epoch 58/60\n",
      "1850/1850 [==============================] - 1s 751us/step - loss: 982.4153 - mse: 982.4153 - mae: 20.9817\n",
      "Epoch 59/60\n",
      "1850/1850 [==============================] - 1s 623us/step - loss: 982.5414 - mse: 982.5414 - mae: 20.9537\n",
      "Epoch 60/60\n",
      "1850/1850 [==============================] - 1s 558us/step - loss: 983.2298 - mse: 983.2300 - mae: 20.9866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=45)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "3699/3699 [==============================] - 7s 2ms/step - loss: 9649.9854 - mse: 9649.9893 - mae: 91.6820\n",
      "Epoch 2/60\n",
      "3699/3699 [==============================] - 2s 654us/step - loss: 2219.1847 - mse: 2219.1848 - mae: 33.6190\n",
      "Epoch 3/60\n",
      "3699/3699 [==============================] - 2s 633us/step - loss: 1142.7195 - mse: 1142.7196 - mae: 23.1229\n",
      "Epoch 4/60\n",
      "3699/3699 [==============================] - 2s 643us/step - loss: 1135.2183 - mse: 1135.2184 - mae: 22.9910\n",
      "Epoch 5/60\n",
      "3699/3699 [==============================] - 2s 632us/step - loss: 1132.3443 - mse: 1132.3442 - mae: 23.0339\n",
      "Epoch 6/60\n",
      "3699/3699 [==============================] - 3s 717us/step - loss: 1127.4828 - mse: 1127.4828 - mae: 22.9512\n",
      "Epoch 7/60\n",
      "3699/3699 [==============================] - 3s 719us/step - loss: 1126.9325 - mse: 1126.9327 - mae: 22.8807\n",
      "Epoch 8/60\n",
      "3699/3699 [==============================] - 3s 698us/step - loss: 1123.9382 - mse: 1123.9384 - mae: 22.8232\n",
      "Epoch 9/60\n",
      "3699/3699 [==============================] - 2s 654us/step - loss: 1124.2133 - mse: 1124.2134 - mae: 22.8310\n",
      "Epoch 10/60\n",
      "3699/3699 [==============================] - 2s 567us/step - loss: 1122.7717 - mse: 1122.7717 - mae: 22.8461\n",
      "Epoch 11/60\n",
      "3699/3699 [==============================] - 2s 635us/step - loss: 1121.8090 - mse: 1121.8091 - mae: 22.8028\n",
      "Epoch 12/60\n",
      "3699/3699 [==============================] - 3s 698us/step - loss: 1118.3452 - mse: 1118.3448 - mae: 22.7265\n",
      "Epoch 13/60\n",
      "3699/3699 [==============================] - 2s 642us/step - loss: 1118.8846 - mse: 1118.8844 - mae: 22.7650\n",
      "Epoch 14/60\n",
      "3699/3699 [==============================] - 2s 611us/step - loss: 1116.6796 - mse: 1116.6797 - mae: 22.6986\n",
      "Epoch 15/60\n",
      "3699/3699 [==============================] - 2s 578us/step - loss: 1118.4995 - mse: 1118.4994 - mae: 22.7851\n",
      "Epoch 16/60\n",
      "3699/3699 [==============================] - 2s 600us/step - loss: 1117.1876 - mse: 1117.1879 - mae: 22.7131\n",
      "Epoch 17/60\n",
      "3699/3699 [==============================] - 2s 580us/step - loss: 1117.1695 - mse: 1117.1697 - mae: 22.6016\n",
      "Epoch 18/60\n",
      "3699/3699 [==============================] - 2s 642us/step - loss: 1113.4387 - mse: 1113.4387 - mae: 22.6669\n",
      "Epoch 19/60\n",
      "3699/3699 [==============================] - 3s 686us/step - loss: 1116.6060 - mse: 1116.6060 - mae: 22.7284\n",
      "Epoch 20/60\n",
      "3699/3699 [==============================] - 2s 578us/step - loss: 1116.7825 - mse: 1116.7826 - mae: 22.6499\n",
      "Epoch 21/60\n",
      "3699/3699 [==============================] - 2s 590us/step - loss: 1112.1282 - mse: 1112.1279 - mae: 22.6391\n",
      "Epoch 22/60\n",
      "3699/3699 [==============================] - 2s 590us/step - loss: 1113.8819 - mse: 1113.8821 - mae: 22.6614\n",
      "Epoch 23/60\n",
      "3699/3699 [==============================] - 3s 698us/step - loss: 1112.9307 - mse: 1112.9305 - mae: 22.6285\n",
      "Epoch 24/60\n",
      "3699/3699 [==============================] - 3s 842us/step - loss: 1113.8238 - mse: 1113.8237 - mae: 22.6208\n",
      "Epoch 25/60\n",
      "3699/3699 [==============================] - 1s 323us/step - loss: 1111.4152 - mse: 1111.4155 - mae: 22.6280\n",
      "Epoch 26/60\n",
      "3699/3699 [==============================] - 0s 37us/step - loss: 1111.7143 - mse: 1111.7146 - mae: 22.6150\n",
      "Epoch 27/60\n",
      "3699/3699 [==============================] - 0s 37us/step - loss: 1110.3437 - mse: 1110.3438 - mae: 22.5549\n",
      "Epoch 28/60\n",
      "3699/3699 [==============================] - 0s 37us/step - loss: 1109.3979 - mse: 1109.3978 - mae: 22.5803\n",
      "Epoch 29/60\n",
      "3699/3699 [==============================] - 0s 37us/step - loss: 1108.7980 - mse: 1108.7980 - mae: 22.5759\n",
      "Epoch 30/60\n",
      "3699/3699 [==============================] - 0s 37us/step - loss: 1110.6365 - mse: 1110.6364 - mae: 22.4955\n",
      "Epoch 31/60\n",
      "3699/3699 [==============================] - 0s 37us/step - loss: 1107.7098 - mse: 1107.7095 - mae: 22.4805\n",
      "Epoch 32/60\n",
      "3699/3699 [==============================] - 0s 38us/step - loss: 1109.0813 - mse: 1109.0813 - mae: 22.4489\n",
      "Epoch 33/60\n",
      "3699/3699 [==============================] - 0s 38us/step - loss: 1106.4879 - mse: 1106.4879 - mae: 22.5160\n",
      "Epoch 34/60\n",
      "3699/3699 [==============================] - 0s 38us/step - loss: 1107.8490 - mse: 1107.8488 - mae: 22.5281\n",
      "Epoch 35/60\n",
      "3699/3699 [==============================] - 0s 38us/step - loss: 1107.4823 - mse: 1107.4823 - mae: 22.5399\n",
      "Epoch 36/60\n",
      "3699/3699 [==============================] - 0s 38us/step - loss: 1105.7877 - mse: 1105.7876 - mae: 22.4656\n",
      "Epoch 37/60\n",
      "3699/3699 [==============================] - 0s 38us/step - loss: 1106.5403 - mse: 1106.5403 - mae: 22.4563\n",
      "Epoch 38/60\n",
      "3699/3699 [==============================] - 0s 38us/step - loss: 1107.8464 - mse: 1107.8462 - mae: 22.4550\n",
      "Epoch 39/60\n",
      "3699/3699 [==============================] - 0s 38us/step - loss: 1105.8163 - mse: 1105.8162 - mae: 22.4652\n",
      "Epoch 40/60\n",
      "3699/3699 [==============================] - 0s 38us/step - loss: 1105.5500 - mse: 1105.5502 - mae: 22.4662\n",
      "Epoch 41/60\n",
      "3699/3699 [==============================] - 0s 38us/step - loss: 1104.8084 - mse: 1104.8086 - mae: 22.4407\n",
      "Epoch 42/60\n",
      "3699/3699 [==============================] - 0s 38us/step - loss: 1102.8309 - mse: 1102.8309 - mae: 22.4955\n",
      "Epoch 43/60\n",
      "3699/3699 [==============================] - 0s 38us/step - loss: 1103.5821 - mse: 1103.5822 - mae: 22.4793\n",
      "Epoch 44/60\n",
      "3699/3699 [==============================] - 0s 38us/step - loss: 1103.5029 - mse: 1103.5029 - mae: 22.4475\n",
      "Epoch 45/60\n",
      "3699/3699 [==============================] - 0s 38us/step - loss: 1105.2854 - mse: 1105.2854 - mae: 22.4665\n",
      "Epoch 46/60\n",
      "3699/3699 [==============================] - 0s 38us/step - loss: 1102.5625 - mse: 1102.5623 - mae: 22.4688\n",
      "Epoch 47/60\n",
      "3699/3699 [==============================] - 0s 38us/step - loss: 1103.5101 - mse: 1103.5103 - mae: 22.4084\n",
      "Epoch 48/60\n",
      "3699/3699 [==============================] - 0s 38us/step - loss: 1101.6543 - mse: 1101.6542 - mae: 22.4184\n",
      "Epoch 49/60\n",
      "3699/3699 [==============================] - 0s 37us/step - loss: 1101.4392 - mse: 1101.4391 - mae: 22.3483\n",
      "Epoch 50/60\n",
      "3699/3699 [==============================] - 0s 38us/step - loss: 1101.9913 - mse: 1101.9913 - mae: 22.3936\n",
      "Epoch 51/60\n",
      "3699/3699 [==============================] - 0s 37us/step - loss: 1102.1795 - mse: 1102.1792 - mae: 22.3794\n",
      "Epoch 52/60\n",
      "3699/3699 [==============================] - 0s 37us/step - loss: 1100.7474 - mse: 1100.7472 - mae: 22.3705\n",
      "Epoch 53/60\n",
      "3699/3699 [==============================] - 0s 37us/step - loss: 1102.3973 - mse: 1102.3972 - mae: 22.3148\n",
      "Epoch 54/60\n",
      "3699/3699 [==============================] - 0s 37us/step - loss: 1097.3460 - mse: 1097.3461 - mae: 22.3935\n",
      "Epoch 55/60\n",
      "3699/3699 [==============================] - 0s 37us/step - loss: 1100.4272 - mse: 1100.4269 - mae: 22.2898\n",
      "Epoch 56/60\n",
      "3699/3699 [==============================] - 0s 37us/step - loss: 1099.8929 - mse: 1099.8928 - mae: 22.3272\n",
      "Epoch 57/60\n",
      "3699/3699 [==============================] - 0s 37us/step - loss: 1100.6589 - mse: 1100.6589 - mae: 22.3834\n",
      "Epoch 58/60\n",
      "3699/3699 [==============================] - 0s 37us/step - loss: 1100.9208 - mse: 1100.9205 - mae: 22.3589\n",
      "Epoch 59/60\n",
      "3699/3699 [==============================] - 0s 38us/step - loss: 1098.4120 - mse: 1098.4121 - mae: 22.3252\n",
      "Epoch 60/60\n",
      "3699/3699 [==============================] - 0s 47us/step - loss: 1098.0565 - mse: 1098.0565 - mae: 22.3478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=45)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "5548/5548 [==============================] - 1s 157us/step - loss: 9640.8292 - mse: 9640.8281 - mae: 86.6045\n",
      "Epoch 2/60\n",
      "5548/5548 [==============================] - 0s 56us/step - loss: 1795.5698 - mse: 1795.5703 - mae: 25.7170\n",
      "Epoch 3/60\n",
      "5548/5548 [==============================] - 0s 56us/step - loss: 1670.3834 - mse: 1670.3832 - mae: 25.1767\n",
      "Epoch 4/60\n",
      "5548/5548 [==============================] - 0s 56us/step - loss: 1666.4850 - mse: 1666.4849 - mae: 25.1038\n",
      "Epoch 5/60\n",
      "5548/5548 [==============================] - 0s 56us/step - loss: 1663.2100 - mse: 1663.2098 - mae: 25.0127\n",
      "Epoch 6/60\n",
      "5548/5548 [==============================] - 0s 56us/step - loss: 1658.8227 - mse: 1658.8229 - mae: 25.0131\n",
      "Epoch 7/60\n",
      "5548/5548 [==============================] - 0s 56us/step - loss: 1656.2056 - mse: 1656.2058 - mae: 24.8658\n",
      "Epoch 8/60\n",
      "5548/5548 [==============================] - 0s 57us/step - loss: 1651.0994 - mse: 1651.0991 - mae: 24.8842\n",
      "Epoch 9/60\n",
      "5548/5548 [==============================] - 0s 56us/step - loss: 1650.7820 - mse: 1650.7815 - mae: 24.7689\n",
      "Epoch 10/60\n",
      "5548/5548 [==============================] - 0s 56us/step - loss: 1644.9043 - mse: 1644.9041 - mae: 24.8624\n",
      "Epoch 11/60\n",
      "5548/5548 [==============================] - 0s 56us/step - loss: 1644.2393 - mse: 1644.2395 - mae: 24.8248\n",
      "Epoch 12/60\n",
      "5548/5548 [==============================] - 0s 61us/step - loss: 1643.2314 - mse: 1643.2316 - mae: 24.7912\n",
      "Epoch 13/60\n",
      "5548/5548 [==============================] - 1s 101us/step - loss: 1644.4870 - mse: 1644.4872 - mae: 24.6745\n",
      "Epoch 14/60\n",
      "5548/5548 [==============================] - 1s 102us/step - loss: 1641.9162 - mse: 1641.9164 - mae: 24.7802\n",
      "Epoch 15/60\n",
      "5548/5548 [==============================] - 1s 100us/step - loss: 1639.0259 - mse: 1639.0258 - mae: 24.7761\n",
      "Epoch 16/60\n",
      "5548/5548 [==============================] - 1s 102us/step - loss: 1636.8968 - mse: 1636.8969 - mae: 24.6512\n",
      "Epoch 17/60\n",
      "5548/5548 [==============================] - 1s 105us/step - loss: 1634.4151 - mse: 1634.4160 - mae: 24.7803\n",
      "Epoch 18/60\n",
      "5548/5548 [==============================] - 1s 104us/step - loss: 1635.9519 - mse: 1635.9520 - mae: 24.6369\n",
      "Epoch 19/60\n",
      "5548/5548 [==============================] - 1s 103us/step - loss: 1631.8030 - mse: 1631.8033 - mae: 24.6997\n",
      "Epoch 20/60\n",
      "5548/5548 [==============================] - 1s 101us/step - loss: 1632.0099 - mse: 1632.0106 - mae: 24.5928\n",
      "Epoch 21/60\n",
      "5548/5548 [==============================] - 2s 342us/step - loss: 1632.1129 - mse: 1632.1134 - mae: 24.6122\n",
      "Epoch 22/60\n",
      "5548/5548 [==============================] - 4s 722us/step - loss: 1631.7429 - mse: 1631.7433 - mae: 24.6726\n",
      "Epoch 23/60\n",
      "5548/5548 [==============================] - 4s 636us/step - loss: 1629.8663 - mse: 1629.8662 - mae: 24.5746\n",
      "Epoch 24/60\n",
      "5548/5548 [==============================] - 4s 673us/step - loss: 1627.1138 - mse: 1627.1135 - mae: 24.6252\n",
      "Epoch 25/60\n",
      "5548/5548 [==============================] - 3s 622us/step - loss: 1626.8277 - mse: 1626.8276 - mae: 24.5545\n",
      "Epoch 26/60\n",
      "5548/5548 [==============================] - 3s 614us/step - loss: 1625.4331 - mse: 1625.4326 - mae: 24.6755\n",
      "Epoch 27/60\n",
      "5548/5548 [==============================] - 3s 572us/step - loss: 1625.3617 - mse: 1625.3612 - mae: 24.6136\n",
      "Epoch 28/60\n",
      "5548/5548 [==============================] - 4s 652us/step - loss: 1625.6804 - mse: 1625.6812 - mae: 24.5655\n",
      "Epoch 29/60\n",
      "5548/5548 [==============================] - 3s 630us/step - loss: 1625.5078 - mse: 1625.5074 - mae: 24.5787\n",
      "Epoch 30/60\n",
      "5548/5548 [==============================] - 3s 591us/step - loss: 1622.0273 - mse: 1622.0270 - mae: 24.6441\n",
      "Epoch 31/60\n",
      "5548/5548 [==============================] - 3s 583us/step - loss: 1625.2967 - mse: 1625.2960 - mae: 24.5372\n",
      "Epoch 32/60\n",
      "5548/5548 [==============================] - 4s 651us/step - loss: 1621.7851 - mse: 1621.7848 - mae: 24.5574\n",
      "Epoch 33/60\n",
      "5548/5548 [==============================] - 4s 716us/step - loss: 1621.0571 - mse: 1621.0568 - mae: 24.5679\n",
      "Epoch 34/60\n",
      "5548/5548 [==============================] - 4s 680us/step - loss: 1621.6256 - mse: 1621.6256 - mae: 24.4586\n",
      "Epoch 35/60\n",
      "5548/5548 [==============================] - 3s 616us/step - loss: 1621.5561 - mse: 1621.5566 - mae: 24.5305\n",
      "Epoch 36/60\n",
      "5548/5548 [==============================] - 4s 660us/step - loss: 1620.7850 - mse: 1620.7852 - mae: 24.5001\n",
      "Epoch 37/60\n",
      "5548/5548 [==============================] - 4s 660us/step - loss: 1617.3017 - mse: 1617.3010 - mae: 24.5073\n",
      "Epoch 38/60\n",
      "5548/5548 [==============================] - 3s 609us/step - loss: 1621.3168 - mse: 1621.3167 - mae: 24.4995\n",
      "Epoch 39/60\n",
      "5548/5548 [==============================] - 3s 608us/step - loss: 1619.2353 - mse: 1619.2350 - mae: 24.5022\n",
      "Epoch 40/60\n",
      "5548/5548 [==============================] - 4s 680us/step - loss: 1620.3789 - mse: 1620.3793 - mae: 24.5108\n",
      "Epoch 41/60\n",
      "5548/5548 [==============================] - 4s 638us/step - loss: 1617.9156 - mse: 1617.9152 - mae: 24.4109\n",
      "Epoch 42/60\n",
      "5548/5548 [==============================] - 3s 601us/step - loss: 1614.8318 - mse: 1614.8325 - mae: 24.5059\n",
      "Epoch 43/60\n",
      "5548/5548 [==============================] - 3s 629us/step - loss: 1617.7051 - mse: 1617.7053 - mae: 24.4726\n",
      "Epoch 44/60\n",
      "5548/5548 [==============================] - 4s 709us/step - loss: 1615.3841 - mse: 1615.3839 - mae: 24.3884\n",
      "Epoch 45/60\n",
      "5548/5548 [==============================] - 3s 608us/step - loss: 1613.0952 - mse: 1613.0950 - mae: 24.4838\n",
      "Epoch 46/60\n",
      "5548/5548 [==============================] - 3s 585us/step - loss: 1615.4087 - mse: 1615.4088 - mae: 24.4320\n",
      "Epoch 47/60\n",
      "5548/5548 [==============================] - 3s 600us/step - loss: 1616.6232 - mse: 1616.6230 - mae: 24.4740\n",
      "Epoch 48/60\n",
      "5548/5548 [==============================] - 4s 704us/step - loss: 1615.8075 - mse: 1615.8070 - mae: 24.3853\n",
      "Epoch 49/60\n",
      "5548/5548 [==============================] - 3s 627us/step - loss: 1615.3045 - mse: 1615.3042 - mae: 24.4213\n",
      "Epoch 50/60\n",
      "5548/5548 [==============================] - 4s 648us/step - loss: 1615.8417 - mse: 1615.8418 - mae: 24.4306\n",
      "Epoch 51/60\n",
      "5548/5548 [==============================] - 3s 592us/step - loss: 1615.1123 - mse: 1615.1123 - mae: 24.4806\n",
      "Epoch 52/60\n",
      "5548/5548 [==============================] - 4s 687us/step - loss: 1614.8521 - mse: 1614.8521 - mae: 24.4362\n",
      "Epoch 53/60\n",
      "5548/5548 [==============================] - 3s 616us/step - loss: 1616.0985 - mse: 1616.0990 - mae: 24.4750\n",
      "Epoch 54/60\n",
      "5548/5548 [==============================] - 3s 587us/step - loss: 1615.5053 - mse: 1615.5052 - mae: 24.4248\n",
      "Epoch 55/60\n",
      "5548/5548 [==============================] - 4s 638us/step - loss: 1616.3322 - mse: 1616.3324 - mae: 24.3483\n",
      "Epoch 56/60\n",
      "5548/5548 [==============================] - 4s 715us/step - loss: 1615.3361 - mse: 1615.3358 - mae: 24.3755\n",
      "Epoch 57/60\n",
      "5548/5548 [==============================] - 4s 666us/step - loss: 1614.0358 - mse: 1614.0363 - mae: 24.4696\n",
      "Epoch 58/60\n",
      "5548/5548 [==============================] - 3s 593us/step - loss: 1614.8013 - mse: 1614.8015 - mae: 24.3335\n",
      "Epoch 59/60\n",
      "5548/5548 [==============================] - 4s 690us/step - loss: 1612.9922 - mse: 1612.9921 - mae: 24.3554\n",
      "Epoch 60/60\n",
      "5548/5548 [==============================] - 4s 644us/step - loss: 1613.3765 - mse: 1613.3763 - mae: 24.4021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=45)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "7397/7397 [==============================] - 9s 1ms/step - loss: 7875.9956 - mse: 7875.9956 - mae: 73.2202\n",
      "Epoch 2/60\n",
      "7397/7397 [==============================] - 5s 652us/step - loss: 1609.0548 - mse: 1609.0543 - mae: 25.3224\n",
      "Epoch 3/60\n",
      "7397/7397 [==============================] - 5s 654us/step - loss: 1601.0775 - mse: 1601.0778 - mae: 25.2747\n",
      "Epoch 4/60\n",
      "7397/7397 [==============================] - 5s 688us/step - loss: 1593.4251 - mse: 1593.4255 - mae: 25.2932\n",
      "Epoch 5/60\n",
      "7397/7397 [==============================] - 5s 611us/step - loss: 1590.1394 - mse: 1590.1393 - mae: 25.1873\n",
      "Epoch 6/60\n",
      "7397/7397 [==============================] - 5s 628us/step - loss: 1585.8674 - mse: 1585.8676 - mae: 25.1244\n",
      "Epoch 7/60\n",
      "7397/7397 [==============================] - 5s 639us/step - loss: 1582.9669 - mse: 1582.9673 - mae: 25.1704\n",
      "Epoch 8/60\n",
      "7397/7397 [==============================] - 4s 579us/step - loss: 1581.6588 - mse: 1581.6591 - mae: 25.0632\n",
      "Epoch 9/60\n",
      "7397/7397 [==============================] - 5s 617us/step - loss: 1578.3860 - mse: 1578.3861 - mae: 25.1397\n",
      "Epoch 10/60\n",
      "7397/7397 [==============================] - 5s 610us/step - loss: 1576.4136 - mse: 1576.4135 - mae: 25.0881\n",
      "Epoch 11/60\n",
      "7397/7397 [==============================] - 5s 639us/step - loss: 1574.6771 - mse: 1574.6770 - mae: 24.9965\n",
      "Epoch 12/60\n",
      "7397/7397 [==============================] - 5s 676us/step - loss: 1573.6566 - mse: 1573.6564 - mae: 25.0514\n",
      "Epoch 13/60\n",
      "7397/7397 [==============================] - 5s 639us/step - loss: 1571.1043 - mse: 1571.1041 - mae: 24.9633\n",
      "Epoch 14/60\n",
      "7397/7397 [==============================] - 5s 617us/step - loss: 1569.0922 - mse: 1569.0923 - mae: 24.9814\n",
      "Epoch 15/60\n",
      "7397/7397 [==============================] - 5s 664us/step - loss: 1567.9356 - mse: 1567.9359 - mae: 24.9718\n",
      "Epoch 16/60\n",
      "7397/7397 [==============================] - 5s 691us/step - loss: 1567.3479 - mse: 1567.3472 - mae: 24.9325\n",
      "Epoch 17/60\n",
      "7397/7397 [==============================] - 5s 670us/step - loss: 1565.9059 - mse: 1565.9059 - mae: 24.9534\n",
      "Epoch 18/60\n",
      "7397/7397 [==============================] - 5s 675us/step - loss: 1563.9816 - mse: 1563.9811 - mae: 24.8559\n",
      "Epoch 19/60\n",
      "7397/7397 [==============================] - 5s 637us/step - loss: 1565.4434 - mse: 1565.4437 - mae: 24.9172\n",
      "Epoch 20/60\n",
      "7397/7397 [==============================] - 5s 665us/step - loss: 1564.1760 - mse: 1564.1757 - mae: 24.8755\n",
      "Epoch 21/60\n",
      "7397/7397 [==============================] - 5s 640us/step - loss: 1561.3797 - mse: 1561.3794 - mae: 24.9151\n",
      "Epoch 22/60\n",
      "7397/7397 [==============================] - 5s 650us/step - loss: 1560.7214 - mse: 1560.7213 - mae: 24.8745\n",
      "Epoch 23/60\n",
      "7397/7397 [==============================] - 5s 622us/step - loss: 1560.4657 - mse: 1560.4658 - mae: 24.8965\n",
      "Epoch 24/60\n",
      "7397/7397 [==============================] - 5s 615us/step - loss: 1560.9085 - mse: 1560.9093 - mae: 24.8433\n",
      "Epoch 25/60\n",
      "7397/7397 [==============================] - 4s 594us/step - loss: 1558.2682 - mse: 1558.2679 - mae: 24.8492\n",
      "Epoch 26/60\n",
      "7397/7397 [==============================] - 4s 595us/step - loss: 1556.7377 - mse: 1556.7380 - mae: 24.8494\n",
      "Epoch 27/60\n",
      "7397/7397 [==============================] - 5s 612us/step - loss: 1558.1015 - mse: 1558.1017 - mae: 24.8357\n",
      "Epoch 28/60\n",
      "7397/7397 [==============================] - 5s 691us/step - loss: 1556.2670 - mse: 1556.2670 - mae: 24.7753\n",
      "Epoch 29/60\n",
      "7397/7397 [==============================] - 5s 671us/step - loss: 1556.6543 - mse: 1556.6545 - mae: 24.7916\n",
      "Epoch 30/60\n",
      "7397/7397 [==============================] - 5s 705us/step - loss: 1553.8623 - mse: 1553.8621 - mae: 24.8555\n",
      "Epoch 31/60\n",
      "7397/7397 [==============================] - 5s 612us/step - loss: 1556.4748 - mse: 1556.4746 - mae: 24.8130\n",
      "Epoch 32/60\n",
      "7397/7397 [==============================] - 4s 606us/step - loss: 1554.8457 - mse: 1554.8457 - mae: 24.7567\n",
      "Epoch 33/60\n",
      "7397/7397 [==============================] - 4s 592us/step - loss: 1556.3574 - mse: 1556.3571 - mae: 24.7599\n",
      "Epoch 34/60\n",
      "7397/7397 [==============================] - 5s 622us/step - loss: 1553.7213 - mse: 1553.7213 - mae: 24.7490\n",
      "Epoch 35/60\n",
      "7397/7397 [==============================] - 4s 600us/step - loss: 1554.8220 - mse: 1554.8215 - mae: 24.7952\n",
      "Epoch 36/60\n",
      "7397/7397 [==============================] - 5s 642us/step - loss: 1553.2244 - mse: 1553.2250 - mae: 24.7367\n",
      "Epoch 37/60\n",
      "7397/7397 [==============================] - 5s 649us/step - loss: 1554.7194 - mse: 1554.7192 - mae: 24.7697\n",
      "Epoch 38/60\n",
      "7397/7397 [==============================] - 5s 639us/step - loss: 1553.4032 - mse: 1553.4033 - mae: 24.7032\n",
      "Epoch 39/60\n",
      "7397/7397 [==============================] - 5s 670us/step - loss: 1553.5880 - mse: 1553.5884 - mae: 24.7354\n",
      "Epoch 40/60\n",
      "7397/7397 [==============================] - 5s 631us/step - loss: 1551.5683 - mse: 1551.5688 - mae: 24.7309\n",
      "Epoch 41/60\n",
      "7397/7397 [==============================] - 5s 648us/step - loss: 1552.7374 - mse: 1552.7373 - mae: 24.6826\n",
      "Epoch 42/60\n",
      "7397/7397 [==============================] - 5s 689us/step - loss: 1550.8475 - mse: 1550.8475 - mae: 24.7790\n",
      "Epoch 43/60\n",
      "7397/7397 [==============================] - 5s 633us/step - loss: 1551.2086 - mse: 1551.2086 - mae: 24.7380\n",
      "Epoch 44/60\n",
      "7397/7397 [==============================] - 5s 611us/step - loss: 1552.1420 - mse: 1552.1420 - mae: 24.6615\n",
      "Epoch 45/60\n",
      "7397/7397 [==============================] - 5s 703us/step - loss: 1552.6612 - mse: 1552.6611 - mae: 24.6933\n",
      "Epoch 46/60\n",
      "7397/7397 [==============================] - 5s 655us/step - loss: 1552.4158 - mse: 1552.4159 - mae: 24.6878\n",
      "Epoch 47/60\n",
      "7397/7397 [==============================] - 5s 628us/step - loss: 1550.7077 - mse: 1550.7081 - mae: 24.6760\n",
      "Epoch 48/60\n",
      "7397/7397 [==============================] - 5s 705us/step - loss: 1550.2639 - mse: 1550.2638 - mae: 24.6867\n",
      "Epoch 49/60\n",
      "7397/7397 [==============================] - 5s 644us/step - loss: 1547.4354 - mse: 1547.4354 - mae: 24.7519\n",
      "Epoch 50/60\n",
      "7397/7397 [==============================] - 5s 629us/step - loss: 1549.4555 - mse: 1549.4553 - mae: 24.7513\n",
      "Epoch 51/60\n",
      "7397/7397 [==============================] - 5s 626us/step - loss: 1550.1326 - mse: 1550.1331 - mae: 24.7232\n",
      "Epoch 52/60\n",
      "7397/7397 [==============================] - 5s 617us/step - loss: 1548.5855 - mse: 1548.5854 - mae: 24.6897\n",
      "Epoch 53/60\n",
      "7397/7397 [==============================] - 5s 653us/step - loss: 1550.1569 - mse: 1550.1570 - mae: 24.6656\n",
      "Epoch 54/60\n",
      "7397/7397 [==============================] - 5s 671us/step - loss: 1549.3268 - mse: 1549.3268 - mae: 24.6816\n",
      "Epoch 55/60\n",
      "7397/7397 [==============================] - 5s 617us/step - loss: 1549.7389 - mse: 1549.7394 - mae: 24.6958\n",
      "Epoch 56/60\n",
      "7397/7397 [==============================] - 5s 660us/step - loss: 1551.5361 - mse: 1551.5352 - mae: 24.6347\n",
      "Epoch 57/60\n",
      "7397/7397 [==============================] - 5s 661us/step - loss: 1551.2367 - mse: 1551.2366 - mae: 24.6647\n",
      "Epoch 58/60\n",
      "7397/7397 [==============================] - 5s 634us/step - loss: 1549.2807 - mse: 1549.2806 - mae: 24.6527\n",
      "Epoch 59/60\n",
      "7397/7397 [==============================] - 5s 655us/step - loss: 1548.7136 - mse: 1548.7142 - mae: 24.6880\n",
      "Epoch 60/60\n",
      "7397/7397 [==============================] - 5s 650us/step - loss: 1548.7173 - mse: 1548.7172 - mae: 24.6582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=15)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "1850/1850 [==============================] - 8s 5ms/step - loss: 12288.7845 - mse: 12288.7822 - mae: 106.1433\n",
      "Epoch 2/60\n",
      "1850/1850 [==============================] - 1s 691us/step - loss: 8825.6630 - mse: 8825.6621 - mae: 87.5515\n",
      "Epoch 3/60\n",
      "1850/1850 [==============================] - 1s 689us/step - loss: 1921.1556 - mse: 1921.1554 - mae: 31.6371\n",
      "Epoch 4/60\n",
      "1850/1850 [==============================] - 1s 687us/step - loss: 1064.2289 - mse: 1064.2289 - mae: 23.1152\n",
      "Epoch 5/60\n",
      "1850/1850 [==============================] - 1s 731us/step - loss: 1048.5294 - mse: 1048.5294 - mae: 22.8602\n",
      "Epoch 6/60\n",
      "1850/1850 [==============================] - 2s 864us/step - loss: 1043.1406 - mse: 1043.1405 - mae: 22.7480 - loss: 824\n",
      "Epoch 7/60\n",
      "1850/1850 [==============================] - 2s 840us/step - loss: 1033.3427 - mse: 1033.3425 - mae: 22.5584\n",
      "Epoch 8/60\n",
      "1850/1850 [==============================] - 1s 777us/step - loss: 1028.5015 - mse: 1028.5015 - mae: 22.3993\n",
      "Epoch 9/60\n",
      "1850/1850 [==============================] - 1s 753us/step - loss: 1025.7734 - mse: 1025.7734 - mae: 22.3276\n",
      "Epoch 10/60\n",
      "1850/1850 [==============================] - 1s 710us/step - loss: 1018.7449 - mse: 1018.7449 - mae: 22.2215\n",
      "Epoch 11/60\n",
      "1850/1850 [==============================] - 1s 730us/step - loss: 1013.5463 - mse: 1013.5461 - mae: 22.1471\n",
      "Epoch 12/60\n",
      "1850/1850 [==============================] - 1s 687us/step - loss: 1016.2453 - mse: 1016.2455 - mae: 22.0765\n",
      "Epoch 13/60\n",
      "1850/1850 [==============================] - 1s 754us/step - loss: 1009.0070 - mse: 1009.0069 - mae: 21.9979\n",
      "Epoch 14/60\n",
      "1850/1850 [==============================] - 1s 690us/step - loss: 1013.7900 - mse: 1013.7902 - mae: 21.8796\n",
      "Epoch 15/60\n",
      "1850/1850 [==============================] - 1s 690us/step - loss: 1007.5378 - mse: 1007.5379 - mae: 21.7765\n",
      "Epoch 16/60\n",
      "1850/1850 [==============================] - 2s 818us/step - loss: 1008.5429 - mse: 1008.5431 - mae: 21.8284\n",
      "Epoch 17/60\n",
      "1850/1850 [==============================] - 2s 816us/step - loss: 1006.0508 - mse: 1006.0507 - mae: 21.7350\n",
      "Epoch 18/60\n",
      "1850/1850 [==============================] - 1s 711us/step - loss: 1003.2801 - mse: 1003.2801 - mae: 21.8547\n",
      "Epoch 19/60\n",
      "1850/1850 [==============================] - 1s 712us/step - loss: 1003.1401 - mse: 1003.1401 - mae: 21.6313\n",
      "Epoch 20/60\n",
      "1850/1850 [==============================] - 1s 734us/step - loss: 996.4035 - mse: 996.4036 - mae: 21.5772\n",
      "Epoch 21/60\n",
      "1850/1850 [==============================] - 1s 690us/step - loss: 1002.5864 - mse: 1002.5864 - mae: 21.6300\n",
      "Epoch 22/60\n",
      "1850/1850 [==============================] - 2s 843us/step - loss: 1001.0988 - mse: 1001.0988 - mae: 21.5879\n",
      "Epoch 23/60\n",
      "1850/1850 [==============================] - 1s 778us/step - loss: 1001.1818 - mse: 1001.1817 - mae: 21.5568\n",
      "Epoch 24/60\n",
      "1850/1850 [==============================] - 1s 755us/step - loss: 996.4397 - mse: 996.4399 - mae: 21.4789\n",
      "Epoch 25/60\n",
      "1850/1850 [==============================] - 2s 821us/step - loss: 1000.5871 - mse: 1000.5870 - mae: 21.5447\n",
      "Epoch 26/60\n",
      "1850/1850 [==============================] - 2s 865us/step - loss: 997.5590 - mse: 997.5591 - mae: 21.3984\n",
      "Epoch 27/60\n",
      "1850/1850 [==============================] - 2s 821us/step - loss: 997.5473 - mse: 997.5472 - mae: 21.5191\n",
      "Epoch 28/60\n",
      "1850/1850 [==============================] - 1s 756us/step - loss: 996.5643 - mse: 996.5643 - mae: 21.4171\n",
      "Epoch 29/60\n",
      "1850/1850 [==============================] - 2s 868us/step - loss: 994.8241 - mse: 994.8240 - mae: 21.3953\n",
      "Epoch 30/60\n",
      "1850/1850 [==============================] - 1s 712us/step - loss: 997.3543 - mse: 997.3543 - mae: 21.4388\n",
      "Epoch 31/60\n",
      "1850/1850 [==============================] - 1s 666us/step - loss: 993.8522 - mse: 993.8522 - mae: 21.4046\n",
      "Epoch 32/60\n",
      "1850/1850 [==============================] - 1s 648us/step - loss: 991.8038 - mse: 991.8040 - mae: 21.3062\n",
      "Epoch 33/60\n",
      "1850/1850 [==============================] - 1s 755us/step - loss: 993.0561 - mse: 993.0560 - mae: 21.2977\n",
      "Epoch 34/60\n",
      "1850/1850 [==============================] - 1s 707us/step - loss: 990.6903 - mse: 990.6902 - mae: 21.3642\n",
      "Epoch 35/60\n",
      "1850/1850 [==============================] - 1s 731us/step - loss: 992.2035 - mse: 992.2032 - mae: 21.2820\n",
      "Epoch 36/60\n",
      "1850/1850 [==============================] - 1s 751us/step - loss: 993.1938 - mse: 993.1937 - mae: 21.3116\n",
      "Epoch 37/60\n",
      "1850/1850 [==============================] - 1s 752us/step - loss: 989.5265 - mse: 989.5264 - mae: 21.2949\n",
      "Epoch 38/60\n",
      "1850/1850 [==============================] - 1s 691us/step - loss: 994.4807 - mse: 994.4807 - mae: 21.3459\n",
      "Epoch 39/60\n",
      "1850/1850 [==============================] - 1s 712us/step - loss: 990.2951 - mse: 990.2953 - mae: 21.3175\n",
      "Epoch 40/60\n",
      "1850/1850 [==============================] - 1s 709us/step - loss: 989.3109 - mse: 989.3109 - mae: 21.2899\n",
      "Epoch 41/60\n",
      "1850/1850 [==============================] - 1s 686us/step - loss: 986.7435 - mse: 986.7436 - mae: 21.1949\n",
      "Epoch 42/60\n",
      "1850/1850 [==============================] - 1s 711us/step - loss: 994.4353 - mse: 994.4352 - mae: 21.2734\n",
      "Epoch 43/60\n",
      "1850/1850 [==============================] - 1s 710us/step - loss: 988.4328 - mse: 988.4329 - mae: 21.2356\n",
      "Epoch 44/60\n",
      "1850/1850 [==============================] - 1s 734us/step - loss: 982.1456 - mse: 982.1456 - mae: 21.1782\n",
      "Epoch 45/60\n",
      "1850/1850 [==============================] - 1s 730us/step - loss: 992.1847 - mse: 992.1848 - mae: 21.1745\n",
      "Epoch 46/60\n",
      "1850/1850 [==============================] - 1s 708us/step - loss: 985.9208 - mse: 985.9207 - mae: 21.2134\n",
      "Epoch 47/60\n",
      "1850/1850 [==============================] - 1s 752us/step - loss: 987.3634 - mse: 987.3635 - mae: 21.1812\n",
      "Epoch 48/60\n",
      "1850/1850 [==============================] - 1s 754us/step - loss: 984.4999 - mse: 984.5001 - mae: 21.1077\n",
      "Epoch 49/60\n",
      "1850/1850 [==============================] - 2s 818us/step - loss: 985.6738 - mse: 985.6739 - mae: 21.2117\n",
      "Epoch 50/60\n",
      "1850/1850 [==============================] - 1s 773us/step - loss: 985.7702 - mse: 985.7700 - mae: 21.1083\n",
      "Epoch 51/60\n",
      "1850/1850 [==============================] - 1s 798us/step - loss: 986.2324 - mse: 986.2324 - mae: 21.0181\n",
      "Epoch 52/60\n",
      "1850/1850 [==============================] - 2s 864us/step - loss: 987.0674 - mse: 987.0675 - mae: 21.0755\n",
      "Epoch 53/60\n",
      "1850/1850 [==============================] - 1s 777us/step - loss: 982.5505 - mse: 982.5505 - mae: 21.0680\n",
      "Epoch 54/60\n",
      "1850/1850 [==============================] - 2s 843us/step - loss: 983.4303 - mse: 983.4303 - mae: 21.0395\n",
      "Epoch 55/60\n",
      "1850/1850 [==============================] - 2s 866us/step - loss: 985.6509 - mse: 985.6510 - mae: 21.1369\n",
      "Epoch 56/60\n",
      "1850/1850 [==============================] - 2s 844us/step - loss: 982.3362 - mse: 982.3362 - mae: 21.1122\n",
      "Epoch 57/60\n",
      "1850/1850 [==============================] - 2s 818us/step - loss: 979.7218 - mse: 979.7218 - mae: 20.9684\n",
      "Epoch 58/60\n",
      "1850/1850 [==============================] - 1s 778us/step - loss: 983.9723 - mse: 983.9723 - mae: 21.0949\n",
      "Epoch 59/60\n",
      "1850/1850 [==============================] - 1s 754us/step - loss: 982.4928 - mse: 982.4929 - mae: 21.0358\n",
      "Epoch 60/60\n",
      "1850/1850 [==============================] - 1s 796us/step - loss: 978.1505 - mse: 978.1505 - mae: 20.9640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=15)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "3699/3699 [==============================] - 11s 3ms/step - loss: 10467.6308 - mse: 10467.6279 - mae: 95.8165\n",
      "Epoch 2/60\n",
      "3699/3699 [==============================] - 3s 832us/step - loss: 1553.8008 - mse: 1553.8003 - mae: 27.4795\n",
      "Epoch 3/60\n",
      "3699/3699 [==============================] - 3s 842us/step - loss: 1153.9001 - mse: 1153.9001 - mae: 23.2379\n",
      "Epoch 4/60\n",
      "3699/3699 [==============================] - 3s 766us/step - loss: 1146.2403 - mse: 1146.2401 - mae: 23.0569\n",
      "Epoch 5/60\n",
      "3699/3699 [==============================] - 3s 763us/step - loss: 1139.5327 - mse: 1139.5327 - mae: 23.0114\n",
      "Epoch 6/60\n",
      "3699/3699 [==============================] - 3s 733us/step - loss: 1133.0828 - mse: 1133.0826 - mae: 22.9741\n",
      "Epoch 7/60\n",
      "3699/3699 [==============================] - 3s 778us/step - loss: 1132.2573 - mse: 1132.2573 - mae: 22.9413\n",
      "Epoch 8/60\n",
      "3699/3699 [==============================] - 3s 747us/step - loss: 1129.8728 - mse: 1129.8729 - mae: 22.8957\n",
      "Epoch 9/60\n",
      "3699/3699 [==============================] - 3s 756us/step - loss: 1127.4512 - mse: 1127.4513 - mae: 22.8242\n",
      "Epoch 10/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1123.0281 - mse: 1123.0284 - mae: 22.8097\n",
      "Epoch 11/60\n",
      "3699/3699 [==============================] - 3s 807us/step - loss: 1125.3858 - mse: 1125.3856 - mae: 22.8529\n",
      "Epoch 12/60\n",
      "3699/3699 [==============================] - 3s 862us/step - loss: 1124.1504 - mse: 1124.1503 - mae: 22.8110\n",
      "Epoch 13/60\n",
      "3699/3699 [==============================] - 3s 680us/step - loss: 1121.9800 - mse: 1121.9797 - mae: 22.7702\n",
      "Epoch 14/60\n",
      "3699/3699 [==============================] - 3s 711us/step - loss: 1119.6930 - mse: 1119.6929 - mae: 22.7800\n",
      "Epoch 15/60\n",
      "3699/3699 [==============================] - 3s 742us/step - loss: 1120.8214 - mse: 1120.8214 - mae: 22.7428\n",
      "Epoch 16/60\n",
      "3699/3699 [==============================] - 3s 720us/step - loss: 1118.7052 - mse: 1118.7054 - mae: 22.7514\n",
      "Epoch 17/60\n",
      "3699/3699 [==============================] - 3s 808us/step - loss: 1115.3354 - mse: 1115.3354 - mae: 22.7065\n",
      "Epoch 18/60\n",
      "3699/3699 [==============================] - 3s 712us/step - loss: 1116.9284 - mse: 1116.9281 - mae: 22.6745\n",
      "Epoch 19/60\n",
      "3699/3699 [==============================] - 3s 690us/step - loss: 1116.0918 - mse: 1116.0916 - mae: 22.6845\n",
      "Epoch 20/60\n",
      "3699/3699 [==============================] - 3s 687us/step - loss: 1114.1968 - mse: 1114.1967 - mae: 22.6698\n",
      "Epoch 21/60\n",
      "3699/3699 [==============================] - 3s 723us/step - loss: 1113.4851 - mse: 1113.4852 - mae: 22.6239\n",
      "Epoch 22/60\n",
      "3699/3699 [==============================] - 3s 806us/step - loss: 1115.0077 - mse: 1115.0077 - mae: 22.6442\n",
      "Epoch 23/60\n",
      "3699/3699 [==============================] - 3s 722us/step - loss: 1108.0641 - mse: 1108.0638 - mae: 22.6013\n",
      "Epoch 24/60\n",
      "3699/3699 [==============================] - 3s 688us/step - loss: 1111.1957 - mse: 1111.1959 - mae: 22.6398\n",
      "Epoch 25/60\n",
      "3699/3699 [==============================] - 3s 712us/step - loss: 1110.3914 - mse: 1110.3914 - mae: 22.5663\n",
      "Epoch 26/60\n",
      "3699/3699 [==============================] - 3s 766us/step - loss: 1109.6825 - mse: 1109.6823 - mae: 22.6420\n",
      "Epoch 27/60\n",
      "3699/3699 [==============================] - 3s 876us/step - loss: 1109.5463 - mse: 1109.5464 - mae: 22.4935\n",
      "Epoch 28/60\n",
      "3699/3699 [==============================] - 3s 840us/step - loss: 1108.7886 - mse: 1108.7883 - mae: 22.5576\n",
      "Epoch 29/60\n",
      "3699/3699 [==============================] - 3s 722us/step - loss: 1110.8075 - mse: 1110.8077 - mae: 22.5709\n",
      "Epoch 30/60\n",
      "3699/3699 [==============================] - 3s 783us/step - loss: 1108.6688 - mse: 1108.6688 - mae: 22.4960\n",
      "Epoch 31/60\n",
      "3699/3699 [==============================] - 3s 809us/step - loss: 1107.2568 - mse: 1107.2567 - mae: 22.4928\n",
      "Epoch 32/60\n",
      "3699/3699 [==============================] - 3s 852us/step - loss: 1108.3916 - mse: 1108.3917 - mae: 22.5423\n",
      "Epoch 33/60\n",
      "3699/3699 [==============================] - 3s 711us/step - loss: 1104.3292 - mse: 1104.3292 - mae: 22.4505\n",
      "Epoch 34/60\n",
      "3699/3699 [==============================] - 3s 743us/step - loss: 1107.1727 - mse: 1107.1727 - mae: 22.4509\n",
      "Epoch 35/60\n",
      "3699/3699 [==============================] - 3s 745us/step - loss: 1105.9540 - mse: 1105.9537 - mae: 22.4550\n",
      "Epoch 36/60\n",
      "3699/3699 [==============================] - 3s 832us/step - loss: 1108.1142 - mse: 1108.1140 - mae: 22.4763\n",
      "Epoch 37/60\n",
      "3699/3699 [==============================] - 3s 801us/step - loss: 1107.3522 - mse: 1107.3521 - mae: 22.4156\n",
      "Epoch 38/60\n",
      "3699/3699 [==============================] - 3s 778us/step - loss: 1103.6101 - mse: 1103.6097 - mae: 22.4686\n",
      "Epoch 39/60\n",
      "3699/3699 [==============================] - 3s 689us/step - loss: 1104.4300 - mse: 1104.4302 - mae: 22.4323\n",
      "Epoch 40/60\n",
      "3699/3699 [==============================] - 3s 698us/step - loss: 1100.1770 - mse: 1100.1772 - mae: 22.3818\n",
      "Epoch 41/60\n",
      "3699/3699 [==============================] - 3s 752us/step - loss: 1104.6178 - mse: 1104.6177 - mae: 22.4254\n",
      "Epoch 42/60\n",
      "3699/3699 [==============================] - 3s 720us/step - loss: 1104.9734 - mse: 1104.9738 - mae: 22.4835\n",
      "Epoch 43/60\n",
      "3699/3699 [==============================] - 3s 711us/step - loss: 1102.8714 - mse: 1102.8716 - mae: 22.3826\n",
      "Epoch 44/60\n",
      "3699/3699 [==============================] - 3s 690us/step - loss: 1103.9422 - mse: 1103.9423 - mae: 22.4443\n",
      "Epoch 45/60\n",
      "3699/3699 [==============================] - 2s 657us/step - loss: 1101.6616 - mse: 1101.6615 - mae: 22.4377\n",
      "Epoch 46/60\n",
      "3699/3699 [==============================] - 3s 734us/step - loss: 1102.0303 - mse: 1102.0300 - mae: 22.4190\n",
      "Epoch 47/60\n",
      "3699/3699 [==============================] - 3s 821us/step - loss: 1101.5086 - mse: 1101.5083 - mae: 22.2997\n",
      "Epoch 48/60\n",
      "3699/3699 [==============================] - 3s 721us/step - loss: 1104.1365 - mse: 1104.1365 - mae: 22.4553\n",
      "Epoch 49/60\n",
      "3699/3699 [==============================] - 3s 689us/step - loss: 1103.4094 - mse: 1103.4094 - mae: 22.4053\n",
      "Epoch 50/60\n",
      "3699/3699 [==============================] - 3s 691us/step - loss: 1101.9704 - mse: 1101.9706 - mae: 22.4306\n",
      "Epoch 51/60\n",
      "3699/3699 [==============================] - 3s 701us/step - loss: 1102.1285 - mse: 1102.1287 - mae: 22.3790\n",
      "Epoch 52/60\n",
      "3699/3699 [==============================] - 3s 808us/step - loss: 1102.0603 - mse: 1102.0601 - mae: 22.4048\n",
      "Epoch 53/60\n",
      "3699/3699 [==============================] - 3s 797us/step - loss: 1101.6819 - mse: 1101.6816 - mae: 22.4030\n",
      "Epoch 54/60\n",
      "3699/3699 [==============================] - 3s 743us/step - loss: 1099.6059 - mse: 1099.6056 - mae: 22.2450\n",
      "Epoch 55/60\n",
      "3699/3699 [==============================] - 3s 724us/step - loss: 1101.1906 - mse: 1101.1907 - mae: 22.4855\n",
      "Epoch 56/60\n",
      "3699/3699 [==============================] - 3s 701us/step - loss: 1099.7848 - mse: 1099.7848 - mae: 22.3268\n",
      "Epoch 57/60\n",
      "3699/3699 [==============================] - 3s 721us/step - loss: 1098.4874 - mse: 1098.4875 - mae: 22.2736\n",
      "Epoch 58/60\n",
      "3699/3699 [==============================] - 3s 741us/step - loss: 1098.0702 - mse: 1098.0701 - mae: 22.2688\n",
      "Epoch 59/60\n",
      "3699/3699 [==============================] - 3s 735us/step - loss: 1100.3679 - mse: 1100.3677 - mae: 22.4068\n",
      "Epoch 60/60\n",
      "3699/3699 [==============================] - 3s 801us/step - loss: 1101.2432 - mse: 1101.2433 - mae: 22.2543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=15)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "5548/5548 [==============================] - 12s 2ms/step - loss: 8123.3363 - mse: 8123.3345 - mae: 73.5157\n",
      "Epoch 2/60\n",
      "5548/5548 [==============================] - 4s 775us/step - loss: 1694.7179 - mse: 1694.7175 - mae: 25.3887\n",
      "Epoch 3/60\n",
      "5548/5548 [==============================] - 4s 689us/step - loss: 1688.1537 - mse: 1688.1539 - mae: 25.3127\n",
      "Epoch 4/60\n",
      "5548/5548 [==============================] - 4s 740us/step - loss: 1685.4033 - mse: 1685.4032 - mae: 25.1226\n",
      "Epoch 5/60\n",
      "5548/5548 [==============================] - 4s 726us/step - loss: 1681.4306 - mse: 1681.4312 - mae: 25.1462\n",
      "Epoch 6/60\n",
      "5548/5548 [==============================] - 4s 788us/step - loss: 1675.5605 - mse: 1675.5605 - mae: 25.1876\n",
      "Epoch 7/60\n",
      "5548/5548 [==============================] - 4s 731us/step - loss: 1668.9770 - mse: 1668.9769 - mae: 25.0724\n",
      "Epoch 8/60\n",
      "5548/5548 [==============================] - 4s 753us/step - loss: 1668.1725 - mse: 1668.1721 - mae: 25.1357\n",
      "Epoch 9/60\n",
      "5548/5548 [==============================] - 4s 797us/step - loss: 1664.8614 - mse: 1664.8615 - mae: 25.0069\n",
      "Epoch 10/60\n",
      "5548/5548 [==============================] - 4s 690us/step - loss: 1661.9351 - mse: 1661.9347 - mae: 24.9758\n",
      "Epoch 11/60\n",
      "5548/5548 [==============================] - 4s 741us/step - loss: 1658.4666 - mse: 1658.4670 - mae: 24.9492\n",
      "Epoch 12/60\n",
      "5548/5548 [==============================] - 4s 804us/step - loss: 1659.0618 - mse: 1659.0625 - mae: 24.9373\n",
      "Epoch 13/60\n",
      "5548/5548 [==============================] - 4s 731us/step - loss: 1654.7390 - mse: 1654.7391 - mae: 24.8965\n",
      "Epoch 14/60\n",
      "5548/5548 [==============================] - 4s 749us/step - loss: 1652.4998 - mse: 1652.5000 - mae: 24.8558\n",
      "Epoch 15/60\n",
      "5548/5548 [==============================] - 4s 755us/step - loss: 1654.0769 - mse: 1654.0776 - mae: 24.8457\n",
      "Epoch 16/60\n",
      "5548/5548 [==============================] - 4s 710us/step - loss: 1651.8201 - mse: 1651.8207 - mae: 24.7630\n",
      "Epoch 17/60\n",
      "5548/5548 [==============================] - 4s 690us/step - loss: 1645.3106 - mse: 1645.3105 - mae: 24.7259\n",
      "Epoch 18/60\n",
      "5548/5548 [==============================] - 4s 696us/step - loss: 1645.4565 - mse: 1645.4562 - mae: 24.7340\n",
      "Epoch 19/60\n",
      "5548/5548 [==============================] - 4s 768us/step - loss: 1642.8365 - mse: 1642.8358 - mae: 24.7447\n",
      "Epoch 20/60\n",
      "5548/5548 [==============================] - 4s 761us/step - loss: 1637.7688 - mse: 1637.7688 - mae: 24.7198\n",
      "Epoch 21/60\n",
      "5548/5548 [==============================] - 4s 768us/step - loss: 1641.6873 - mse: 1641.6873 - mae: 24.7678\n",
      "Epoch 22/60\n",
      "5548/5548 [==============================] - 5s 827us/step - loss: 1640.6428 - mse: 1640.6429 - mae: 24.7316\n",
      "Epoch 23/60\n",
      "5548/5548 [==============================] - 4s 798us/step - loss: 1639.7847 - mse: 1639.7848 - mae: 24.7046\n",
      "Epoch 24/60\n",
      "5548/5548 [==============================] - 4s 777us/step - loss: 1634.1202 - mse: 1634.1204 - mae: 24.7702\n",
      "Epoch 25/60\n",
      "5548/5548 [==============================] - 5s 893us/step - loss: 1633.8790 - mse: 1633.8789 - mae: 24.57420s - loss: 1304.2234 - mse: 1304.223\n",
      "Epoch 26/60\n",
      "5548/5548 [==============================] - 4s 792us/step - loss: 1634.9101 - mse: 1634.9099 - mae: 24.7105\n",
      "Epoch 27/60\n",
      "5548/5548 [==============================] - 4s 710us/step - loss: 1631.9349 - mse: 1631.9349 - mae: 24.7099\n",
      "Epoch 28/60\n",
      "5548/5548 [==============================] - 4s 784us/step - loss: 1629.0938 - mse: 1629.0939 - mae: 24.5886\n",
      "Epoch 29/60\n",
      "5548/5548 [==============================] - 4s 761us/step - loss: 1630.5449 - mse: 1630.5443 - mae: 24.6447\n",
      "Epoch 30/60\n",
      "5548/5548 [==============================] - 4s 689us/step - loss: 1632.0013 - mse: 1632.0009 - mae: 24.6194\n",
      "Epoch 31/60\n",
      "5548/5548 [==============================] - 4s 682us/step - loss: 1628.0919 - mse: 1628.0918 - mae: 24.7055\n",
      "Epoch 32/60\n",
      "5548/5548 [==============================] - 4s 723us/step - loss: 1628.6599 - mse: 1628.6597 - mae: 24.6585\n",
      "Epoch 33/60\n",
      "5548/5548 [==============================] - 4s 689us/step - loss: 1628.0963 - mse: 1628.0957 - mae: 24.6123\n",
      "Epoch 34/60\n",
      "5548/5548 [==============================] - ETA: 0s - loss: 1628.2377 - mse: 1628.2377 - mae: 24.57 - 4s 718us/step - loss: 1625.5051 - mse: 1625.5052 - mae: 24.5610\n",
      "Epoch 35/60\n",
      "5548/5548 [==============================] - 5s 840us/step - loss: 1628.8118 - mse: 1628.8118 - mae: 24.4904\n",
      "Epoch 36/60\n",
      "5548/5548 [==============================] - 0s 87us/step - loss: 1621.3491 - mse: 1621.3490 - mae: 24.5869\n",
      "Epoch 37/60\n",
      "5548/5548 [==============================] - 0s 44us/step - loss: 1623.7382 - mse: 1623.7382 - mae: 24.5749\n",
      "Epoch 38/60\n",
      "5548/5548 [==============================] - 0s 44us/step - loss: 1622.4880 - mse: 1622.4879 - mae: 24.5328\n",
      "Epoch 39/60\n",
      "5548/5548 [==============================] - 0s 44us/step - loss: 1623.4755 - mse: 1623.4758 - mae: 24.5162\n",
      "Epoch 40/60\n",
      "5548/5548 [==============================] - 0s 44us/step - loss: 1622.2974 - mse: 1622.2974 - mae: 24.5107\n",
      "Epoch 41/60\n",
      "5548/5548 [==============================] - 0s 44us/step - loss: 1619.4867 - mse: 1619.4868 - mae: 24.5008\n",
      "Epoch 42/60\n",
      "5548/5548 [==============================] - 0s 44us/step - loss: 1619.0136 - mse: 1619.0133 - mae: 24.5193\n",
      "Epoch 43/60\n",
      "5548/5548 [==============================] - 0s 44us/step - loss: 1619.9808 - mse: 1619.9806 - mae: 24.4703\n",
      "Epoch 44/60\n",
      "5548/5548 [==============================] - 0s 44us/step - loss: 1621.1994 - mse: 1621.1996 - mae: 24.5406\n",
      "Epoch 45/60\n",
      "5548/5548 [==============================] - 0s 44us/step - loss: 1621.9772 - mse: 1621.9771 - mae: 24.5919\n",
      "Epoch 46/60\n",
      "5548/5548 [==============================] - 0s 44us/step - loss: 1620.7083 - mse: 1620.7087 - mae: 24.4573\n",
      "Epoch 47/60\n",
      "5548/5548 [==============================] - 0s 44us/step - loss: 1620.9477 - mse: 1620.9482 - mae: 24.4625\n",
      "Epoch 48/60\n",
      "5548/5548 [==============================] - 0s 44us/step - loss: 1620.1898 - mse: 1620.1902 - mae: 24.4611\n",
      "Epoch 49/60\n",
      "5548/5548 [==============================] - 0s 44us/step - loss: 1619.7124 - mse: 1619.7123 - mae: 24.4623\n",
      "Epoch 50/60\n",
      "5548/5548 [==============================] - 0s 44us/step - loss: 1622.2542 - mse: 1622.2542 - mae: 24.4853\n",
      "Epoch 51/60\n",
      "5548/5548 [==============================] - 0s 43us/step - loss: 1621.6340 - mse: 1621.6342 - mae: 24.4339\n",
      "Epoch 52/60\n",
      "5548/5548 [==============================] - 0s 43us/step - loss: 1618.7249 - mse: 1618.7247 - mae: 24.4045\n",
      "Epoch 53/60\n",
      "5548/5548 [==============================] - 0s 43us/step - loss: 1622.9516 - mse: 1622.9519 - mae: 24.4998\n",
      "Epoch 54/60\n",
      "5548/5548 [==============================] - 0s 43us/step - loss: 1620.0176 - mse: 1620.0181 - mae: 24.4938\n",
      "Epoch 55/60\n",
      "5548/5548 [==============================] - 0s 43us/step - loss: 1616.5817 - mse: 1616.5817 - mae: 24.4864\n",
      "Epoch 56/60\n",
      "5548/5548 [==============================] - 0s 59us/step - loss: 1614.3297 - mse: 1614.3301 - mae: 24.4963\n",
      "Epoch 57/60\n",
      "5548/5548 [==============================] - 0s 64us/step - loss: 1618.6515 - mse: 1618.6521 - mae: 24.4785\n",
      "Epoch 58/60\n",
      "5548/5548 [==============================] - 0s 65us/step - loss: 1618.0371 - mse: 1618.0370 - mae: 24.4120\n",
      "Epoch 59/60\n",
      "5548/5548 [==============================] - 0s 63us/step - loss: 1618.5015 - mse: 1618.5012 - mae: 24.4290\n",
      "Epoch 60/60\n",
      "5548/5548 [==============================] - 0s 65us/step - loss: 1620.4594 - mse: 1620.4596 - mae: 24.4624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=15)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "7397/7397 [==============================] - 1s 185us/step - loss: 6517.1992 - mse: 6517.1973 - mae: 61.6292\n",
      "Epoch 2/60\n",
      "7397/7397 [==============================] - 0s 63us/step - loss: 1626.9644 - mse: 1626.9648 - mae: 25.4770\n",
      "Epoch 3/60\n",
      "7397/7397 [==============================] - 0s 61us/step - loss: 1607.4706 - mse: 1607.4703 - mae: 25.4023\n",
      "Epoch 4/60\n",
      "7397/7397 [==============================] - 1s 106us/step - loss: 1603.5411 - mse: 1603.5413 - mae: 25.3272\n",
      "Epoch 5/60\n",
      "7397/7397 [==============================] - 1s 117us/step - loss: 1593.1665 - mse: 1593.1658 - mae: 25.2932\n",
      "Epoch 6/60\n",
      "7397/7397 [==============================] - 1s 116us/step - loss: 1589.4139 - mse: 1589.4141 - mae: 25.1694\n",
      "Epoch 7/60\n",
      "7397/7397 [==============================] - 1s 120us/step - loss: 1587.7138 - mse: 1587.7134 - mae: 25.1859\n",
      "Epoch 8/60\n",
      "7397/7397 [==============================] - 1s 119us/step - loss: 1584.7332 - mse: 1584.7332 - mae: 25.1089\n",
      "Epoch 9/60\n",
      "7397/7397 [==============================] - 1s 179us/step - loss: 1581.7621 - mse: 1581.7622 - mae: 25.1220\n",
      "Epoch 10/60\n",
      "7397/7397 [==============================] - 5s 722us/step - loss: 1580.5435 - mse: 1580.5432 - mae: 25.1319\n",
      "Epoch 11/60\n",
      "7397/7397 [==============================] - 6s 794us/step - loss: 1576.3124 - mse: 1576.3125 - mae: 25.0801\n",
      "Epoch 12/60\n",
      "7397/7397 [==============================] - 6s 781us/step - loss: 1574.6765 - mse: 1574.6764 - mae: 25.0669\n",
      "Epoch 13/60\n",
      "7397/7397 [==============================] - 5s 710us/step - loss: 1575.0772 - mse: 1575.0776 - mae: 24.9978\n",
      "Epoch 14/60\n",
      "7397/7397 [==============================] - 6s 789us/step - loss: 1570.1676 - mse: 1570.1678 - mae: 25.0436\n",
      "Epoch 15/60\n",
      "7397/7397 [==============================] - 5s 727us/step - loss: 1573.1102 - mse: 1573.1108 - mae: 24.9994\n",
      "Epoch 16/60\n",
      "7397/7397 [==============================] - 5s 717us/step - loss: 1568.2230 - mse: 1568.2238 - mae: 24.9406\n",
      "Epoch 17/60\n",
      "7397/7397 [==============================] - 6s 853us/step - loss: 1569.0080 - mse: 1569.0078 - mae: 24.9375\n",
      "Epoch 18/60\n",
      "7397/7397 [==============================] - 6s 787us/step - loss: 1565.8897 - mse: 1565.8898 - mae: 24.8783\n",
      "Epoch 19/60\n",
      "7397/7397 [==============================] - 6s 760us/step - loss: 1566.4677 - mse: 1566.4674 - mae: 24.9266\n",
      "Epoch 20/60\n",
      "7397/7397 [==============================] - 6s 783us/step - loss: 1567.3540 - mse: 1567.3539 - mae: 24.8524\n",
      "Epoch 21/60\n",
      "7397/7397 [==============================] - 5s 734us/step - loss: 1565.2865 - mse: 1565.2863 - mae: 24.8802\n",
      "Epoch 22/60\n",
      "7397/7397 [==============================] - 6s 814us/step - loss: 1563.8576 - mse: 1563.8571 - mae: 24.9219\n",
      "Epoch 23/60\n",
      "7397/7397 [==============================] - 6s 765us/step - loss: 1563.8410 - mse: 1563.8406 - mae: 24.8574\n",
      "Epoch 24/60\n",
      "7397/7397 [==============================] - 6s 787us/step - loss: 1562.8167 - mse: 1562.8165 - mae: 24.9385\n",
      "Epoch 25/60\n",
      "7397/7397 [==============================] - 5s 743us/step - loss: 1564.5199 - mse: 1564.5200 - mae: 24.8915\n",
      "Epoch 26/60\n",
      "7397/7397 [==============================] - 5s 667us/step - loss: 1559.6918 - mse: 1559.6918 - mae: 24.8590\n",
      "Epoch 27/60\n",
      "7397/7397 [==============================] - 6s 824us/step - loss: 1557.0779 - mse: 1557.0780 - mae: 24.8858\n",
      "Epoch 28/60\n",
      "7397/7397 [==============================] - 5s 689us/step - loss: 1558.6126 - mse: 1558.6127 - mae: 24.8637\n",
      "Epoch 29/60\n",
      "7397/7397 [==============================] - 6s 770us/step - loss: 1558.1417 - mse: 1558.1414 - mae: 24.8508\n",
      "Epoch 30/60\n",
      "7397/7397 [==============================] - 5s 712us/step - loss: 1559.0925 - mse: 1559.0913 - mae: 24.8213\n",
      "Epoch 31/60\n",
      "7397/7397 [==============================] - 5s 695us/step - loss: 1559.0588 - mse: 1559.0587 - mae: 24.7893\n",
      "Epoch 32/60\n",
      "7397/7397 [==============================] - 6s 770us/step - loss: 1558.3962 - mse: 1558.3964 - mae: 24.8063\n",
      "Epoch 33/60\n",
      "7397/7397 [==============================] - 6s 805us/step - loss: 1556.5264 - mse: 1556.5265 - mae: 24.7833\n",
      "Epoch 34/60\n",
      "7397/7397 [==============================] - 6s 789us/step - loss: 1557.3331 - mse: 1557.3331 - mae: 24.8252\n",
      "Epoch 35/60\n",
      "7397/7397 [==============================] - 5s 734us/step - loss: 1557.6379 - mse: 1557.6379 - mae: 24.7613\n",
      "Epoch 36/60\n",
      "7397/7397 [==============================] - 5s 722us/step - loss: 1555.8173 - mse: 1555.8167 - mae: 24.8020\n",
      "Epoch 37/60\n",
      "7397/7397 [==============================] - 5s 705us/step - loss: 1557.0371 - mse: 1557.0369 - mae: 24.8069\n",
      "Epoch 38/60\n",
      "7397/7397 [==============================] - 6s 771us/step - loss: 1553.7963 - mse: 1553.7960 - mae: 24.7499\n",
      "Epoch 39/60\n",
      "7397/7397 [==============================] - 6s 803us/step - loss: 1555.2165 - mse: 1555.2166 - mae: 24.8493\n",
      "Epoch 40/60\n",
      "7397/7397 [==============================] - 6s 760us/step - loss: 1556.7024 - mse: 1556.7023 - mae: 24.6892\n",
      "Epoch 41/60\n",
      "7397/7397 [==============================] - 6s 761us/step - loss: 1553.7881 - mse: 1553.7877 - mae: 24.8416\n",
      "Epoch 42/60\n",
      "7397/7397 [==============================] - 6s 788us/step - loss: 1556.7318 - mse: 1556.7325 - mae: 24.7990\n",
      "Epoch 43/60\n",
      "7397/7397 [==============================] - 5s 710us/step - loss: 1555.5966 - mse: 1555.5964 - mae: 24.7672\n",
      "Epoch 44/60\n",
      "7397/7397 [==============================] - 6s 812us/step - loss: 1552.7423 - mse: 1552.7418 - mae: 24.8517\n",
      "Epoch 45/60\n",
      "7397/7397 [==============================] - 5s 732us/step - loss: 1555.9978 - mse: 1555.9979 - mae: 24.8056\n",
      "Epoch 46/60\n",
      "7397/7397 [==============================] - 5s 727us/step - loss: 1556.3095 - mse: 1556.3094 - mae: 24.7468\n",
      "Epoch 47/60\n",
      "7397/7397 [==============================] - 5s 720us/step - loss: 1555.1508 - mse: 1555.1504 - mae: 24.7576\n",
      "Epoch 48/60\n",
      "7397/7397 [==============================] - 5s 716us/step - loss: 1553.8186 - mse: 1553.8191 - mae: 24.7536\n",
      "Epoch 49/60\n",
      "7397/7397 [==============================] - 6s 825us/step - loss: 1551.5737 - mse: 1551.5737 - mae: 24.6806\n",
      "Epoch 50/60\n",
      "7397/7397 [==============================] - 6s 820us/step - loss: 1553.5632 - mse: 1553.5636 - mae: 24.7691\n",
      "Epoch 51/60\n",
      "7397/7397 [==============================] - 6s 781us/step - loss: 1552.5672 - mse: 1552.5674 - mae: 24.7301\n",
      "Epoch 52/60\n",
      "7397/7397 [==============================] - 6s 814us/step - loss: 1551.8592 - mse: 1551.8599 - mae: 24.7331\n",
      "Epoch 53/60\n",
      "7397/7397 [==============================] - 6s 772us/step - loss: 1551.7158 - mse: 1551.7161 - mae: 24.6237\n",
      "Epoch 54/60\n",
      "7397/7397 [==============================] - 6s 815us/step - loss: 1553.1489 - mse: 1553.1492 - mae: 24.6615\n",
      "Epoch 55/60\n",
      "7397/7397 [==============================] - 5s 733us/step - loss: 1551.2560 - mse: 1551.2555 - mae: 24.7122\n",
      "Epoch 56/60\n",
      "7397/7397 [==============================] - 5s 689us/step - loss: 1548.7035 - mse: 1548.7039 - mae: 24.6771\n",
      "Epoch 57/60\n",
      "7397/7397 [==============================] - 6s 777us/step - loss: 1552.4049 - mse: 1552.4045 - mae: 24.6976\n",
      "Epoch 58/60\n",
      "7397/7397 [==============================] - 5s 706us/step - loss: 1549.2441 - mse: 1549.2438 - mae: 24.6708\n",
      "Epoch 59/60\n",
      "7397/7397 [==============================] - 7s 903us/step - loss: 1547.2647 - mse: 1547.2646 - mae: 24.6160\n",
      "Epoch 60/60\n",
      "7397/7397 [==============================] - 6s 825us/step - loss: 1547.3051 - mse: 1547.3048 - mae: 24.6235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=25)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "1850/1850 [==============================] - 12s 6ms/step - loss: 11814.5123 - mse: 11814.5137 - mae: 103.7870TA: 1:01 - loss: 12220.7164 - mse\n",
      "Epoch 2/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 2689.8200 - mse: 2689.8198 - mae: 38.6966\n",
      "Epoch 3/60\n",
      "1850/1850 [==============================] - 2s 930us/step - loss: 1057.3306 - mse: 1057.3307 - mae: 22.8901\n",
      "Epoch 4/60\n",
      "1850/1850 [==============================] - 2s 868us/step - loss: 1046.0546 - mse: 1046.0546 - mae: 22.6179\n",
      "Epoch 5/60\n",
      "1850/1850 [==============================] - 2s 846us/step - loss: 1041.8233 - mse: 1041.8231 - mae: 22.5680\n",
      "Epoch 6/60\n",
      "1850/1850 [==============================] - 2s 908us/step - loss: 1031.0481 - mse: 1031.0482 - mae: 22.2900 - loss: 633\n",
      "Epoch 7/60\n",
      "1850/1850 [==============================] - 2s 867us/step - loss: 1030.5553 - mse: 1030.5553 - mae: 22.3024\n",
      "Epoch 8/60\n",
      "1850/1850 [==============================] - 2s 823us/step - loss: 1027.6337 - mse: 1027.6335 - mae: 22.1891\n",
      "Epoch 9/60\n",
      "1850/1850 [==============================] - 2s 821us/step - loss: 1023.5724 - mse: 1023.5725 - mae: 22.1551\n",
      "Epoch 10/60\n",
      "1850/1850 [==============================] - 2s 950us/step - loss: 1015.8481 - mse: 1015.8480 - mae: 21.9157\n",
      "Epoch 11/60\n",
      "1850/1850 [==============================] - 2s 952us/step - loss: 1018.2688 - mse: 1018.2690 - mae: 21.8884\n",
      "Epoch 12/60\n",
      "1850/1850 [==============================] - 2s 846us/step - loss: 1021.8953 - mse: 1021.8951 - mae: 21.8314\n",
      "Epoch 13/60\n",
      "1850/1850 [==============================] - 2s 823us/step - loss: 1018.2628 - mse: 1018.2626 - mae: 21.9130\n",
      "Epoch 14/60\n",
      "1850/1850 [==============================] - 2s 821us/step - loss: 1018.6303 - mse: 1018.6305 - mae: 21.8262\n",
      "Epoch 15/60\n",
      "1850/1850 [==============================] - 2s 869us/step - loss: 1009.9180 - mse: 1009.9180 - mae: 21.7280\n",
      "Epoch 16/60\n",
      "1850/1850 [==============================] - 2s 825us/step - loss: 1008.0762 - mse: 1008.0761 - mae: 21.6147\n",
      "Epoch 17/60\n",
      "1850/1850 [==============================] - 2s 823us/step - loss: 1018.4384 - mse: 1018.4383 - mae: 21.8806\n",
      "Epoch 18/60\n",
      "1850/1850 [==============================] - ETA: 0s - loss: 1013.1603 - mse: 1013.1605 - mae: 21.54 - 2s 937us/step - loss: 1004.8803 - mse: 1004.8805 - mae: 21.5346\n",
      "Epoch 19/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 1015.5084 - mse: 1015.5084 - mae: 21.6954\n",
      "Epoch 20/60\n",
      "1850/1850 [==============================] - 2s 972us/step - loss: 1002.5575 - mse: 1002.5575 - mae: 21.40310s - loss: 1017.3243 - mse: 1017.324\n",
      "Epoch 21/60\n",
      "1850/1850 [==============================] - 2s 972us/step - loss: 1009.5475 - mse: 1009.5474 - mae: 21.5734\n",
      "Epoch 22/60\n",
      "1850/1850 [==============================] - 2s 887us/step - loss: 1030.5106 - mse: 1030.5105 - mae: 21.8632\n",
      "Epoch 23/60\n",
      "1850/1850 [==============================] - 2s 977us/step - loss: 999.1617 - mse: 999.1616 - mae: 21.2840\n",
      "Epoch 24/60\n",
      "1850/1850 [==============================] - 2s 887us/step - loss: 1011.4973 - mse: 1011.4973 - mae: 21.6529\n",
      "Epoch 25/60\n",
      "1850/1850 [==============================] - 2s 871us/step - loss: 1000.2829 - mse: 1000.2829 - mae: 21.4152 - loss: 854.8222 \n",
      "Epoch 26/60\n",
      "1850/1850 [==============================] - 2s 930us/step - loss: 1002.3204 - mse: 1002.3204 - mae: 21.4085\n",
      "Epoch 27/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 998.7949 - mse: 998.7950 - mae: 21.3535: 1s - loss: 769.1\n",
      "Epoch 28/60\n",
      "1850/1850 [==============================] - 2s 930us/step - loss: 993.8942 - mse: 993.8944 - mae: 21.2668\n",
      "Epoch 29/60\n",
      "1850/1850 [==============================] - 2s 870us/step - loss: 1001.8463 - mse: 1001.8464 - mae: 21.3800 - loss: 646\n",
      "Epoch 30/60\n",
      "1850/1850 [==============================] - 2s 910us/step - loss: 1000.9132 - mse: 1000.9133 - mae: 21.35561s - loss: 1072.\n",
      "Epoch 31/60\n",
      "1850/1850 [==============================] - 1s 799us/step - loss: 1002.6151 - mse: 1002.6152 - mae: 21.4058\n",
      "Epoch 32/60\n",
      "1850/1850 [==============================] - 1s 799us/step - loss: 999.0955 - mse: 999.0956 - mae: 21.3723\n",
      "Epoch 33/60\n",
      "1850/1850 [==============================] - 2s 825us/step - loss: 1006.6227 - mse: 1006.6229 - mae: 21.4537\n",
      "Epoch 34/60\n",
      "1850/1850 [==============================] - 2s 840us/step - loss: 1021.1267 - mse: 1021.1267 - mae: 21.7440\n",
      "Epoch 35/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 998.0028 - mse: 998.0029 - mae: 21.2513\n",
      "Epoch 36/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 990.8539 - mse: 990.8539 - mae: 21.1743\n",
      "Epoch 37/60\n",
      "1850/1850 [==============================] - 2s 866us/step - loss: 984.4593 - mse: 984.4594 - mae: 21.1165\n",
      "Epoch 38/60\n",
      "1850/1850 [==============================] - 2s 865us/step - loss: 991.3590 - mse: 991.3591 - mae: 21.2017\n",
      "Epoch 39/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 997.3015 - mse: 997.3011 - mae: 21.1506\n",
      "Epoch 40/60\n",
      "1850/1850 [==============================] - 2s 957us/step - loss: 987.8755 - mse: 987.8757 - mae: 21.1547\n",
      "Epoch 41/60\n",
      "1850/1850 [==============================] - 2s 933us/step - loss: 991.5203 - mse: 991.5203 - mae: 21.2360\n",
      "Epoch 42/60\n",
      "1850/1850 [==============================] - 2s 973us/step - loss: 993.2780 - mse: 993.2780 - mae: 21.2871\n",
      "Epoch 43/60\n",
      "1850/1850 [==============================] - 2s 972us/step - loss: 987.2085 - mse: 987.2086 - mae: 21.0500\n",
      "Epoch 44/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 988.1134 - mse: 988.1135 - mae: 21.1708: 1s - los\n",
      "Epoch 45/60\n",
      "1850/1850 [==============================] - 2s 821us/step - loss: 984.0352 - mse: 984.0355 - mae: 21.0872\n",
      "Epoch 46/60\n",
      "1850/1850 [==============================] - 2s 820us/step - loss: 985.2794 - mse: 985.2795 - mae: 21.0389\n",
      "Epoch 47/60\n",
      "1850/1850 [==============================] - 2s 846us/step - loss: 980.5540 - mse: 980.5541 - mae: 21.0022\n",
      "Epoch 48/60\n",
      "1850/1850 [==============================] - 2s 822us/step - loss: 985.2221 - mse: 985.2222 - mae: 20.9951\n",
      "Epoch 49/60\n",
      "1850/1850 [==============================] - 2s 843us/step - loss: 979.4549 - mse: 979.4550 - mae: 20.9453\n",
      "Epoch 50/60\n",
      "1850/1850 [==============================] - 2s 825us/step - loss: 980.4204 - mse: 980.4204 - mae: 20.8516\n",
      "Epoch 51/60\n",
      "1850/1850 [==============================] - 2s 846us/step - loss: 980.6338 - mse: 980.6338 - mae: 20.9828\n",
      "Epoch 52/60\n",
      "1850/1850 [==============================] - 2s 817us/step - loss: 986.5449 - mse: 986.5450 - mae: 21.1416\n",
      "Epoch 53/60\n",
      "1850/1850 [==============================] - 2s 885us/step - loss: 974.8883 - mse: 974.8884 - mae: 20.8822\n",
      "Epoch 54/60\n",
      "1850/1850 [==============================] - 2s 931us/step - loss: 984.0614 - mse: 984.0613 - mae: 20.9851\n",
      "Epoch 55/60\n",
      "1850/1850 [==============================] - 2s 927us/step - loss: 986.5506 - mse: 986.5505 - mae: 21.0416\n",
      "Epoch 56/60\n",
      "1850/1850 [==============================] - 2s 952us/step - loss: 980.7386 - mse: 980.7385 - mae: 21.0599\n",
      "Epoch 57/60\n",
      "1850/1850 [==============================] - 2s 886us/step - loss: 982.4850 - mse: 982.4849 - mae: 20.9848\n",
      "Epoch 58/60\n",
      "1850/1850 [==============================] - 2s 908us/step - loss: 971.7822 - mse: 971.7823 - mae: 20.7655\n",
      "Epoch 59/60\n",
      "1850/1850 [==============================] - 2s 973us/step - loss: 989.9420 - mse: 989.9418 - mae: 21.0944\n",
      "Epoch 60/60\n",
      "1850/1850 [==============================] - 2s 951us/step - loss: 980.2036 - mse: 980.2036 - mae: 20.9357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=25)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "3699/3699 [==============================] - 13s 4ms/step - loss: 6469.9353 - mse: 6469.9375 - mae: 65.0866 1s - loss: 7226.7742 - mse: 7226.7749 - \n",
      "Epoch 2/60\n",
      "3699/3699 [==============================] - 3s 844us/step - loss: 1146.5356 - mse: 1146.5355 - mae: 23.1647\n",
      "Epoch 3/60\n",
      "3699/3699 [==============================] - 4s 974us/step - loss: 1143.4910 - mse: 1143.4910 - mae: 22.9700\n",
      "Epoch 4/60\n",
      "3699/3699 [==============================] - 3s 889us/step - loss: 1132.4381 - mse: 1132.4380 - mae: 22.9297\n",
      "Epoch 5/60\n",
      "3699/3699 [==============================] - 3s 845us/step - loss: 1130.8404 - mse: 1130.8406 - mae: 22.9120\n",
      "Epoch 6/60\n",
      "3699/3699 [==============================] - 3s 919us/step - loss: 1132.8861 - mse: 1132.8861 - mae: 22.9206\n",
      "Epoch 7/60\n",
      "3699/3699 [==============================] - 4s 996us/step - loss: 1124.5151 - mse: 1124.5149 - mae: 22.7589\n",
      "Epoch 8/60\n",
      "3699/3699 [==============================] - 4s 998us/step - loss: 1122.8517 - mse: 1122.8517 - mae: 22.8000\n",
      "Epoch 9/60\n",
      "3699/3699 [==============================] - 3s 851us/step - loss: 1140.7369 - mse: 1140.7368 - mae: 23.0335\n",
      "Epoch 10/60\n",
      "3699/3699 [==============================] - 3s 940us/step - loss: 1126.0402 - mse: 1126.0403 - mae: 22.75200s - loss: 1203.6591 - mse: 12\n",
      "Epoch 11/60\n",
      "3699/3699 [==============================] - 4s 974us/step - loss: 1118.8363 - mse: 1118.8363 - mae: 22.6908\n",
      "Epoch 12/60\n",
      "3699/3699 [==============================] - 3s 909us/step - loss: 1115.2549 - mse: 1115.2549 - mae: 22.7167\n",
      "Epoch 13/60\n",
      "3699/3699 [==============================] - 3s 866us/step - loss: 1125.8182 - mse: 1125.8182 - mae: 22.7662\n",
      "Epoch 14/60\n",
      "3699/3699 [==============================] - 3s 810us/step - loss: 1119.8009 - mse: 1119.8010 - mae: 22.6626\n",
      "Epoch 15/60\n",
      "3699/3699 [==============================] - 3s 907us/step - loss: 1120.2739 - mse: 1120.2738 - mae: 22.7670\n",
      "Epoch 16/60\n",
      "3699/3699 [==============================] - 3s 832us/step - loss: 1122.9460 - mse: 1122.9457 - mae: 22.5982\n",
      "Epoch 17/60\n",
      "3699/3699 [==============================] - 3s 847us/step - loss: 1116.6091 - mse: 1116.6094 - mae: 22.7484\n",
      "Epoch 18/60\n",
      "3699/3699 [==============================] - 3s 888us/step - loss: 1114.5682 - mse: 1114.5682 - mae: 22.5313\n",
      "Epoch 19/60\n",
      "3699/3699 [==============================] - 3s 921us/step - loss: 1125.8074 - mse: 1125.8075 - mae: 22.7272\n",
      "Epoch 20/60\n",
      "3699/3699 [==============================] - 3s 932us/step - loss: 1111.3208 - mse: 1111.3208 - mae: 22.5217\n",
      "Epoch 21/60\n",
      "3699/3699 [==============================] - 3s 833us/step - loss: 1115.1356 - mse: 1115.1355 - mae: 22.5621\n",
      "Epoch 22/60\n",
      "3699/3699 [==============================] - 3s 921us/step - loss: 1108.7509 - mse: 1108.7509 - mae: 22.5224\n",
      "Epoch 23/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1117.1805 - mse: 1117.1803 - mae: 22.5474\n",
      "Epoch 24/60\n",
      "3699/3699 [==============================] - 4s 955us/step - loss: 1107.8884 - mse: 1107.8884 - mae: 22.5600\n",
      "Epoch 25/60\n",
      "3699/3699 [==============================] - 3s 922us/step - loss: 1112.3591 - mse: 1112.3590 - mae: 22.5359\n",
      "Epoch 26/60\n",
      "3699/3699 [==============================] - 3s 880us/step - loss: 1112.4512 - mse: 1112.4513 - mae: 22.5431\n",
      "Epoch 27/60\n",
      "3699/3699 [==============================] - 4s 954us/step - loss: 1111.6442 - mse: 1111.6444 - mae: 22.42830s - loss: 1099.6125 - mse: 1099.6125 - mae: 22.\n",
      "Epoch 28/60\n",
      "3699/3699 [==============================] - 4s 951us/step - loss: 1109.5889 - mse: 1109.5891 - mae: 22.50180s - loss: 1120.2907 - mse: 1120.2908 - ma\n",
      "Epoch 29/60\n",
      "3699/3699 [==============================] - 5s 1ms/step - loss: 1114.7579 - mse: 1114.7582 - mae: 22.5690\n",
      "Epoch 30/60\n",
      "3699/3699 [==============================] - 4s 962us/step - loss: 1109.2499 - mse: 1109.2498 - mae: 22.5062\n",
      "Epoch 31/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1116.4136 - mse: 1116.4135 - mae: 22.4419: 1s - los\n",
      "Epoch 32/60\n",
      "3699/3699 [==============================] - 3s 932us/step - loss: 1115.9515 - mse: 1115.9515 - mae: 22.5453\n",
      "Epoch 33/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1104.3278 - mse: 1104.3278 - mae: 22.4176\n",
      "Epoch 34/60\n",
      "3699/3699 [==============================] - 3s 911us/step - loss: 1104.9123 - mse: 1104.9122 - mae: 22.4470\n",
      "Epoch 35/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1109.4007 - mse: 1109.4008 - mae: 22.3953\n",
      "Epoch 36/60\n",
      "3699/3699 [==============================] - 3s 910us/step - loss: 1101.2606 - mse: 1101.2609 - mae: 22.3572\n",
      "Epoch 37/60\n",
      "3699/3699 [==============================] - 3s 878us/step - loss: 1100.8388 - mse: 1100.8389 - mae: 22.2750\n",
      "Epoch 38/60\n",
      "3699/3699 [==============================] - 3s 923us/step - loss: 1098.9924 - mse: 1098.9923 - mae: 22.4106\n",
      "Epoch 39/60\n",
      "3699/3699 [==============================] - 3s 941us/step - loss: 1107.6059 - mse: 1107.6061 - mae: 22.4259\n",
      "Epoch 40/60\n",
      "3699/3699 [==============================] - 3s 820us/step - loss: 1101.0163 - mse: 1101.0161 - mae: 22.3278\n",
      "Epoch 41/60\n",
      "3699/3699 [==============================] - 3s 835us/step - loss: 1100.1668 - mse: 1100.1670 - mae: 22.3398\n",
      "Epoch 42/60\n",
      "3699/3699 [==============================] - 3s 835us/step - loss: 1106.3811 - mse: 1106.3812 - mae: 22.4820\n",
      "Epoch 43/60\n",
      "3699/3699 [==============================] - 4s 988us/step - loss: 1101.3881 - mse: 1101.3883 - mae: 22.3299\n",
      "Epoch 44/60\n",
      "3699/3699 [==============================] - 4s 974us/step - loss: 1096.6532 - mse: 1096.6528 - mae: 22.2960\n",
      "Epoch 45/60\n",
      "3699/3699 [==============================] - 4s 974us/step - loss: 1098.5643 - mse: 1098.5643 - mae: 22.2368\n",
      "Epoch 46/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1094.0224 - mse: 1094.0222 - mae: 22.1953: 0s - loss: 1079.1680 - mse: 1079.1678 - \n",
      "Epoch 47/60\n",
      "3699/3699 [==============================] - 3s 943us/step - loss: 1101.8224 - mse: 1101.8220 - mae: 22.2909\n",
      "Epoch 48/60\n",
      "3699/3699 [==============================] - 3s 869us/step - loss: 1099.9594 - mse: 1099.9591 - mae: 22.2118\n",
      "Epoch 49/60\n",
      "3699/3699 [==============================] - 3s 846us/step - loss: 1097.7448 - mse: 1097.7448 - mae: 22.3031\n",
      "Epoch 50/60\n",
      "3699/3699 [==============================] - 3s 864us/step - loss: 1103.4432 - mse: 1103.4435 - mae: 22.3104\n",
      "Epoch 51/60\n",
      "3699/3699 [==============================] - 4s 957us/step - loss: 1100.8156 - mse: 1100.8157 - mae: 22.2661\n",
      "Epoch 52/60\n",
      "3699/3699 [==============================] - 3s 878us/step - loss: 1102.1315 - mse: 1102.1317 - mae: 22.2510\n",
      "Epoch 53/60\n",
      "3699/3699 [==============================] - 3s 865us/step - loss: 1092.6210 - mse: 1092.6211 - mae: 22.1404\n",
      "Epoch 54/60\n",
      "3699/3699 [==============================] - 3s 856us/step - loss: 1091.9179 - mse: 1091.9180 - mae: 22.2448\n",
      "Epoch 55/60\n",
      "3699/3699 [==============================] - 4s 977us/step - loss: 1099.5332 - mse: 1099.5332 - mae: 22.2764\n",
      "Epoch 56/60\n",
      "3699/3699 [==============================] - 3s 920us/step - loss: 1093.0830 - mse: 1093.0830 - mae: 22.1896\n",
      "Epoch 57/60\n",
      "3699/3699 [==============================] - 3s 878us/step - loss: 1096.8475 - mse: 1096.8475 - mae: 22.1475\n",
      "Epoch 58/60\n",
      "3699/3699 [==============================] - 3s 888us/step - loss: 1088.7433 - mse: 1088.7432 - mae: 22.1883\n",
      "Epoch 59/60\n",
      "3699/3699 [==============================] - ETA: 0s - loss: 1092.7489 - mse: 1092.7487 - mae: 22.18 - 4s 963us/step - loss: 1091.7675 - mse: 1091.7672 - mae: 22.2124\n",
      "Epoch 60/60\n",
      "3699/3699 [==============================] - 3s 866us/step - loss: 1094.0454 - mse: 1094.0454 - mae: 22.1129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=25)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "5548/5548 [==============================] - 14s 3ms/step - loss: 6100.1082 - mse: 6100.1079 - mae: 57.9755\n",
      "Epoch 2/60\n",
      "5548/5548 [==============================] - 5s 946us/step - loss: 1693.6292 - mse: 1693.6293 - mae: 25.3456\n",
      "Epoch 3/60\n",
      "5548/5548 [==============================] - 5s 874us/step - loss: 1682.8921 - mse: 1682.8921 - mae: 25.3159\n",
      "Epoch 4/60\n",
      "5548/5548 [==============================] - 6s 999us/step - loss: 1667.5767 - mse: 1667.5768 - mae: 24.9813\n",
      "Epoch 5/60\n",
      "5548/5548 [==============================] - 5s 932us/step - loss: 1660.0251 - mse: 1660.0253 - mae: 24.9888\n",
      "Epoch 6/60\n",
      "5548/5548 [==============================] - 5s 912us/step - loss: 1665.3518 - mse: 1665.3517 - mae: 25.0219\n",
      "Epoch 7/60\n",
      "5548/5548 [==============================] - 5s 948us/step - loss: 1655.1316 - mse: 1655.1312 - mae: 24.9090\n",
      "Epoch 8/60\n",
      "5548/5548 [==============================] - 5s 925us/step - loss: 1655.4949 - mse: 1655.4948 - mae: 24.8373\n",
      "Epoch 9/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1645.8210 - mse: 1645.8210 - mae: 24.8204: 1s - loss: 139\n",
      "Epoch 10/60\n",
      "5548/5548 [==============================] - 5s 933us/step - loss: 1644.4968 - mse: 1644.4971 - mae: 24.8950\n",
      "Epoch 11/60\n",
      "5548/5548 [==============================] - 6s 992us/step - loss: 1642.8272 - mse: 1642.8269 - mae: 24.82760s - loss: 1708.6412 - mse: 1708\n",
      "Epoch 12/60\n",
      "5548/5548 [==============================] - 5s 982us/step - loss: 1646.3350 - mse: 1646.3351 - mae: 24.7553\n",
      "Epoch 13/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1641.4683 - mse: 1641.4685 - mae: 24.8264\n",
      "Epoch 14/60\n",
      "5548/5548 [==============================] - 5s 939us/step - loss: 1635.3280 - mse: 1635.3280 - mae: 24.6788\n",
      "Epoch 15/60\n",
      "5548/5548 [==============================] - 5s 955us/step - loss: 1638.6840 - mse: 1638.6842 - mae: 24.7386\n",
      "Epoch 16/60\n",
      "5548/5548 [==============================] - 5s 888us/step - loss: 1638.7716 - mse: 1638.7712 - mae: 24.7822\n",
      "Epoch 17/60\n",
      "5548/5548 [==============================] - 5s 915us/step - loss: 1635.2752 - mse: 1635.2753 - mae: 24.7184\n",
      "Epoch 18/60\n",
      "5548/5548 [==============================] - 5s 860us/step - loss: 1628.3867 - mse: 1628.3868 - mae: 24.6941\n",
      "Epoch 19/60\n",
      "5548/5548 [==============================] - 5s 852us/step - loss: 1634.9937 - mse: 1634.9939 - mae: 24.5585\n",
      "Epoch 20/60\n",
      "5548/5548 [==============================] - 5s 921us/step - loss: 1622.0581 - mse: 1622.0575 - mae: 24.6130\n",
      "Epoch 21/60\n",
      "5548/5548 [==============================] - 5s 937us/step - loss: 1639.3946 - mse: 1639.3944 - mae: 24.63361s - loss:\n",
      "Epoch 22/60\n",
      "5548/5548 [==============================] - 5s 880us/step - loss: 1635.2838 - mse: 1635.2844 - mae: 24.6449\n",
      "Epoch 23/60\n",
      "5548/5548 [==============================] - 5s 957us/step - loss: 1630.1991 - mse: 1630.1986 - mae: 24.51423s - loss: 2557.91\n",
      "Epoch 24/60\n",
      "5548/5548 [==============================] - 5s 955us/step - loss: 1626.8910 - mse: 1626.8906 - mae: 24.5498\n",
      "Epoch 25/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1619.6792 - mse: 1619.6792 - mae: 24.5871: 3s - loss: 2160.6475 - mse: 21 -\n",
      "Epoch 26/60\n",
      "5548/5548 [==============================] - 5s 882us/step - loss: 1619.3291 - mse: 1619.3290 - mae: 24.4529\n",
      "Epoch 27/60\n",
      "5548/5548 [==============================] - 5s 883us/step - loss: 1625.8658 - mse: 1625.8661 - mae: 24.4324\n",
      "Epoch 28/60\n",
      "5548/5548 [==============================] - 5s 945us/step - loss: 1641.5931 - mse: 1641.5934 - mae: 24.8069\n",
      "Epoch 29/60\n",
      "5548/5548 [==============================] - 5s 816us/step - loss: 1627.7585 - mse: 1627.7588 - mae: 24.5383\n",
      "Epoch 30/60\n",
      "5548/5548 [==============================] - 5s 883us/step - loss: 1622.1068 - mse: 1622.1060 - mae: 24.6205\n",
      "Epoch 31/60\n",
      "5548/5548 [==============================] - 5s 949us/step - loss: 1614.0288 - mse: 1614.0291 - mae: 24.4821\n",
      "Epoch 32/60\n",
      "5548/5548 [==============================] - 5s 892us/step - loss: 1616.7211 - mse: 1616.7209 - mae: 24.4089\n",
      "Epoch 33/60\n",
      "5548/5548 [==============================] - 6s 996us/step - loss: 1616.9756 - mse: 1616.9758 - mae: 24.4526\n",
      "Epoch 34/60\n",
      "5548/5548 [==============================] - 5s 923us/step - loss: 1610.8941 - mse: 1610.8937 - mae: 24.4324\n",
      "Epoch 35/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1612.5971 - mse: 1612.5973 - mae: 24.5252: 0s - loss: 1691.8586 - m\n",
      "Epoch 36/60\n",
      "5548/5548 [==============================] - 8s 1ms/step - loss: 1618.3312 - mse: 1618.3317 - mae: 24.3900\n",
      "Epoch 37/60\n",
      "5548/5548 [==============================] - 6s 997us/step - loss: 1612.9381 - mse: 1612.9380 - mae: 24.3972\n",
      "Epoch 38/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1616.6092 - mse: 1616.6094 - mae: 24.4884\n",
      "Epoch 39/60\n",
      "5548/5548 [==============================] - 5s 896us/step - loss: 1611.7077 - mse: 1611.7076 - mae: 24.3751\n",
      "Epoch 40/60\n",
      "5548/5548 [==============================] - 5s 868us/step - loss: 1619.4024 - mse: 1619.4021 - mae: 24.3824\n",
      "Epoch 41/60\n",
      "5548/5548 [==============================] - 5s 952us/step - loss: 1611.3261 - mse: 1611.3263 - mae: 24.3755\n",
      "Epoch 42/60\n",
      "5548/5548 [==============================] - 5s 853us/step - loss: 1614.7672 - mse: 1614.7671 - mae: 24.3583\n",
      "Epoch 43/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1608.0635 - mse: 1608.0629 - mae: 24.3507\n",
      "Epoch 44/60\n",
      "5548/5548 [==============================] - 1s 148us/step - loss: 1610.3746 - mse: 1610.3749 - mae: 24.3544\n",
      "Epoch 45/60\n",
      "5548/5548 [==============================] - 0s 50us/step - loss: 1626.5329 - mse: 1626.5328 - mae: 24.6505\n",
      "Epoch 46/60\n",
      "5548/5548 [==============================] - 0s 50us/step - loss: 1611.3626 - mse: 1611.3628 - mae: 24.4187\n",
      "Epoch 47/60\n",
      "5548/5548 [==============================] - 0s 50us/step - loss: 1607.5313 - mse: 1607.5315 - mae: 24.2906\n",
      "Epoch 48/60\n",
      "5548/5548 [==============================] - 0s 51us/step - loss: 1606.1718 - mse: 1606.1720 - mae: 24.2570\n",
      "Epoch 49/60\n",
      "5548/5548 [==============================] - 0s 51us/step - loss: 1607.5657 - mse: 1607.5663 - mae: 24.2813\n",
      "Epoch 50/60\n",
      "5548/5548 [==============================] - 0s 51us/step - loss: 1610.4530 - mse: 1610.4528 - mae: 24.2909\n",
      "Epoch 51/60\n",
      "5548/5548 [==============================] - 0s 51us/step - loss: 1606.6547 - mse: 1606.6544 - mae: 24.3560\n",
      "Epoch 52/60\n",
      "5548/5548 [==============================] - 0s 51us/step - loss: 1606.6146 - mse: 1606.6150 - mae: 24.2148\n",
      "Epoch 53/60\n",
      "5548/5548 [==============================] - 0s 51us/step - loss: 1601.1130 - mse: 1601.1124 - mae: 24.2122\n",
      "Epoch 54/60\n",
      "5548/5548 [==============================] - 0s 51us/step - loss: 1598.1946 - mse: 1598.1945 - mae: 24.2286\n",
      "Epoch 55/60\n",
      "5548/5548 [==============================] - 0s 51us/step - loss: 1598.7033 - mse: 1598.7037 - mae: 24.2617\n",
      "Epoch 56/60\n",
      "5548/5548 [==============================] - 0s 51us/step - loss: 1595.3479 - mse: 1595.3479 - mae: 24.1302\n",
      "Epoch 57/60\n",
      "5548/5548 [==============================] - 0s 51us/step - loss: 1600.0353 - mse: 1600.0352 - mae: 24.1689\n",
      "Epoch 58/60\n",
      "5548/5548 [==============================] - 0s 51us/step - loss: 1599.9613 - mse: 1599.9607 - mae: 24.1386\n",
      "Epoch 59/60\n",
      "5548/5548 [==============================] - 0s 50us/step - loss: 1605.1155 - mse: 1605.1157 - mae: 24.3188\n",
      "Epoch 60/60\n",
      "5548/5548 [==============================] - 0s 50us/step - loss: 1596.7956 - mse: 1596.7960 - mae: 24.1238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=25)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "7397/7397 [==============================] - 2s 233us/step - loss: 5203.6419 - mse: 5203.6431 - mae: 51.4938\n",
      "Epoch 2/60\n",
      "7397/7397 [==============================] - 1s 71us/step - loss: 1610.3173 - mse: 1610.3179 - mae: 25.3980\n",
      "Epoch 3/60\n",
      "7397/7397 [==============================] - 1s 73us/step - loss: 1608.3281 - mse: 1608.3280 - mae: 25.2766\n",
      "Epoch 4/60\n",
      "7397/7397 [==============================] - 1s 74us/step - loss: 1602.4960 - mse: 1602.4960 - mae: 25.3114\n",
      "Epoch 5/60\n",
      "7397/7397 [==============================] - 1s 75us/step - loss: 1588.7292 - mse: 1588.7290 - mae: 25.1810\n",
      "Epoch 6/60\n",
      "7397/7397 [==============================] - 1s 112us/step - loss: 1582.8529 - mse: 1582.8527 - mae: 25.1853\n",
      "Epoch 7/60\n",
      "7397/7397 [==============================] - 1s 137us/step - loss: 1579.5763 - mse: 1579.5767 - mae: 25.0297\n",
      "Epoch 8/60\n",
      "7397/7397 [==============================] - 1s 137us/step - loss: 1579.4083 - mse: 1579.4086 - mae: 25.2143\n",
      "Epoch 9/60\n",
      "7397/7397 [==============================] - 1s 137us/step - loss: 1575.1103 - mse: 1575.1106 - mae: 25.0311\n",
      "Epoch 10/60\n",
      "7397/7397 [==============================] - 1s 138us/step - loss: 1575.9153 - mse: 1575.9154 - mae: 25.1183\n",
      "Epoch 11/60\n",
      "7397/7397 [==============================] - 5s 684us/step - loss: 1577.0816 - mse: 1577.0819 - mae: 25.0339\n",
      "Epoch 12/60\n",
      "7397/7397 [==============================] - 7s 894us/step - loss: 1580.2273 - mse: 1580.2274 - mae: 25.0400\n",
      "Epoch 13/60\n",
      "7397/7397 [==============================] - 7s 932us/step - loss: 1564.8312 - mse: 1564.8314 - mae: 24.9937\n",
      "Epoch 14/60\n",
      "7397/7397 [==============================] - 7s 901us/step - loss: 1569.0947 - mse: 1569.0952 - mae: 24.98390s - loss: 1603.7488 - mse: 1603\n",
      "Epoch 15/60\n",
      "7397/7397 [==============================] - 7s 1ms/step - loss: 1566.0268 - mse: 1566.0269 - mae: 24.9443\n",
      "Epoch 16/60\n",
      "7397/7397 [==============================] - 7s 950us/step - loss: 1565.9442 - mse: 1565.9442 - mae: 24.9378\n",
      "Epoch 17/60\n",
      "7397/7397 [==============================] - 7s 1ms/step - loss: 1563.9956 - mse: 1563.9957 - mae: 24.9103\n",
      "Epoch 18/60\n",
      "7397/7397 [==============================] - 6s 834us/step - loss: 1563.7311 - mse: 1563.7310 - mae: 24.8862\n",
      "Epoch 19/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1568.0283 - mse: 1568.0287 - mae: 25.0037\n",
      "Epoch 20/60\n",
      "7397/7397 [==============================] - 6s 811us/step - loss: 1560.7101 - mse: 1560.7100 - mae: 24.8644\n",
      "Epoch 21/60\n",
      "7397/7397 [==============================] - 7s 999us/step - loss: 1557.5459 - mse: 1557.5458 - mae: 24.8761\n",
      "Epoch 22/60\n",
      "7397/7397 [==============================] - 6s 824us/step - loss: 1571.1423 - mse: 1571.1425 - mae: 24.9621\n",
      "Epoch 23/60\n",
      "7397/7397 [==============================] - 7s 978us/step - loss: 1569.9503 - mse: 1569.9508 - mae: 24.8914\n",
      "Epoch 24/60\n",
      "7397/7397 [==============================] - 7s 893us/step - loss: 1562.3567 - mse: 1562.3571 - mae: 24.8921\n",
      "Epoch 25/60\n",
      "7397/7397 [==============================] - 7s 961us/step - loss: 1564.8943 - mse: 1564.8947 - mae: 24.9103\n",
      "Epoch 26/60\n",
      "7397/7397 [==============================] - 7s 887us/step - loss: 1565.7536 - mse: 1565.7539 - mae: 24.90401s -\n",
      "Epoch 27/60\n",
      "7397/7397 [==============================] - 7s 914us/step - loss: 1563.1979 - mse: 1563.1976 - mae: 24.9206\n",
      "Epoch 28/60\n",
      "7397/7397 [==============================] - 6s 850us/step - loss: 1559.7800 - mse: 1559.7806 - mae: 24.7763\n",
      "Epoch 29/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1558.5489 - mse: 1558.5493 - mae: 24.8184\n",
      "Epoch 30/60\n",
      "7397/7397 [==============================] - 7s 890us/step - loss: 1554.3689 - mse: 1554.3689 - mae: 24.8015\n",
      "Epoch 31/60\n",
      "7397/7397 [==============================] - 6s 872us/step - loss: 1555.1095 - mse: 1555.1097 - mae: 24.7234\n",
      "Epoch 32/60\n",
      "7397/7397 [==============================] - 6s 855us/step - loss: 1556.3081 - mse: 1556.3077 - mae: 24.7693\n",
      "Epoch 33/60\n",
      "7397/7397 [==============================] - 7s 900us/step - loss: 1553.7718 - mse: 1553.7719 - mae: 24.77920s - loss: 1530.1728 - mse: 1530.1727 - mae: 24.\n",
      "Epoch 34/60\n",
      "7397/7397 [==============================] - 7s 898us/step - loss: 1559.6285 - mse: 1559.6288 - mae: 24.8578\n",
      "Epoch 35/60\n",
      "7397/7397 [==============================] - 7s 920us/step - loss: 1555.8843 - mse: 1555.8845 - mae: 24.7430\n",
      "Epoch 36/60\n",
      "7397/7397 [==============================] - 6s 871us/step - loss: 1555.3209 - mse: 1555.3207 - mae: 24.7811\n",
      "Epoch 37/60\n",
      "7397/7397 [==============================] - 7s 913us/step - loss: 1555.4318 - mse: 1555.4315 - mae: 24.8220\n",
      "Epoch 38/60\n",
      "7397/7397 [==============================] - 6s 878us/step - loss: 1557.3633 - mse: 1557.3636 - mae: 24.6687\n",
      "Epoch 39/60\n",
      "7397/7397 [==============================] - 7s 926us/step - loss: 1555.5352 - mse: 1555.5349 - mae: 24.7182\n",
      "Epoch 40/60\n",
      "7397/7397 [==============================] - 7s 974us/step - loss: 1553.7762 - mse: 1553.7760 - mae: 24.7304\n",
      "Epoch 41/60\n",
      "7397/7397 [==============================] - 7s 990us/step - loss: 1555.8116 - mse: 1555.8114 - mae: 24.7896\n",
      "Epoch 42/60\n",
      "7397/7397 [==============================] - 7s 957us/step - loss: 1556.5131 - mse: 1556.5133 - mae: 24.8727\n",
      "Epoch 43/60\n",
      "7397/7397 [==============================] - 7s 944us/step - loss: 1553.4801 - mse: 1553.4802 - mae: 24.7241\n",
      "Epoch 44/60\n",
      "7397/7397 [==============================] - 7s 959us/step - loss: 1551.3501 - mse: 1551.3500 - mae: 24.7356\n",
      "Epoch 45/60\n",
      "7397/7397 [==============================] - 7s 965us/step - loss: 1561.9551 - mse: 1561.9548 - mae: 24.8106\n",
      "Epoch 46/60\n",
      "7397/7397 [==============================] - 7s 988us/step - loss: 1553.6278 - mse: 1553.6278 - mae: 24.7574\n",
      "Epoch 47/60\n",
      "7397/7397 [==============================] - 7s 899us/step - loss: 1552.3543 - mse: 1552.3542 - mae: 24.7289\n",
      "Epoch 48/60\n",
      "7397/7397 [==============================] - 7s 943us/step - loss: 1555.0106 - mse: 1555.0114 - mae: 24.7387\n",
      "Epoch 49/60\n",
      "7397/7397 [==============================] - 7s 927us/step - loss: 1555.6383 - mse: 1555.6382 - mae: 24.7324\n",
      "Epoch 50/60\n",
      "7397/7397 [==============================] - 7s 897us/step - loss: 1559.6956 - mse: 1559.6960 - mae: 24.8092\n",
      "Epoch 51/60\n",
      "7397/7397 [==============================] - 6s 839us/step - loss: 1557.8665 - mse: 1557.8666 - mae: 24.8030\n",
      "Epoch 52/60\n",
      "7397/7397 [==============================] - 7s 1ms/step - loss: 1552.9689 - mse: 1552.9684 - mae: 24.6615\n",
      "Epoch 53/60\n",
      "7397/7397 [==============================] - 6s 872us/step - loss: 1552.8507 - mse: 1552.8506 - mae: 24.7601\n",
      "Epoch 54/60\n",
      "7397/7397 [==============================] - 7s 969us/step - loss: 1551.3939 - mse: 1551.3938 - mae: 24.6750\n",
      "Epoch 55/60\n",
      "7397/7397 [==============================] - 7s 904us/step - loss: 1551.5117 - mse: 1551.5120 - mae: 24.7590\n",
      "Epoch 56/60\n",
      "7397/7397 [==============================] - 7s 920us/step - loss: 1556.4042 - mse: 1556.4045 - mae: 24.7748\n",
      "Epoch 57/60\n",
      "7397/7397 [==============================] - 6s 833us/step - loss: 1548.9520 - mse: 1548.9514 - mae: 24.6471\n",
      "Epoch 58/60\n",
      "7397/7397 [==============================] - 7s 900us/step - loss: 1560.4275 - mse: 1560.4277 - mae: 24.8313\n",
      "Epoch 59/60\n",
      "7397/7397 [==============================] - 6s 859us/step - loss: 1550.2631 - mse: 1550.2628 - mae: 24.7357\n",
      "Epoch 60/60\n",
      "7397/7397 [==============================] - 7s 937us/step - loss: 1555.6803 - mse: 1555.6804 - mae: 24.70230s - loss: 1574.4371 - mse: 1574.4373 - mae:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=60)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "1850/1850 [==============================] - 9s 5ms/step - loss: 7304.6397 - mse: 7304.6396 - mae: 73.0350\n",
      "Epoch 2/60\n",
      "1850/1850 [==============================] - 2s 978us/step - loss: 1068.2899 - mse: 1068.2900 - mae: 22.5398\n",
      "Epoch 3/60\n",
      "1850/1850 [==============================] - 2s 932us/step - loss: 1048.5844 - mse: 1048.5844 - mae: 22.6045\n",
      "Epoch 4/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 1031.4465 - mse: 1031.4464 - mae: 22.3945\n",
      "Epoch 5/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 1025.9326 - mse: 1025.9325 - mae: 22.2744\n",
      "Epoch 6/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 1029.8155 - mse: 1029.8154 - mae: 22.2172: 1s - loss: 1051.\n",
      "Epoch 7/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 1020.6303 - mse: 1020.6302 - mae: 22.0453\n",
      "Epoch 8/60\n",
      "1850/1850 [==============================] - 2s 976us/step - loss: 1014.3402 - mse: 1014.3403 - mae: 21.8962\n",
      "Epoch 9/60\n",
      "1850/1850 [==============================] - 2s 997us/step - loss: 1011.3793 - mse: 1011.3793 - mae: 21.7459\n",
      "Epoch 10/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 1021.6399 - mse: 1021.6399 - mae: 21.9003\n",
      "Epoch 11/60\n",
      "1850/1850 [==============================] - 2s 955us/step - loss: 1014.5709 - mse: 1014.5709 - mae: 21.5419\n",
      "Epoch 12/60\n",
      "1850/1850 [==============================] - 2s 913us/step - loss: 1004.1174 - mse: 1004.1174 - mae: 21.5284\n",
      "Epoch 13/60\n",
      "1850/1850 [==============================] - ETA: 0s - loss: 1020.1253 - mse: 1020.1254 - mae: 21.85 - 2s 1ms/step - loss: 1021.4895 - mse: 1021.4895 - mae: 21.9047\n",
      "Epoch 14/60\n",
      "1850/1850 [==============================] - 2s 994us/step - loss: 1006.1200 - mse: 1006.1199 - mae: 21.4035\n",
      "Epoch 15/60\n",
      "1850/1850 [==============================] - 2s 933us/step - loss: 1008.0248 - mse: 1008.0247 - mae: 21.4386\n",
      "Epoch 16/60\n",
      "1850/1850 [==============================] - 2s 934us/step - loss: 1004.9376 - mse: 1004.9376 - mae: 21.4846\n",
      "Epoch 17/60\n",
      "1850/1850 [==============================] - 2s 869us/step - loss: 1014.7095 - mse: 1014.7095 - mae: 21.6058\n",
      "Epoch 18/60\n",
      "1850/1850 [==============================] - 2s 890us/step - loss: 1004.6849 - mse: 1004.6849 - mae: 21.4332\n",
      "Epoch 19/60\n",
      "1850/1850 [==============================] - 2s 933us/step - loss: 1007.9625 - mse: 1007.9624 - mae: 21.4510\n",
      "Epoch 20/60\n",
      "1850/1850 [==============================] - 2s 912us/step - loss: 1003.5492 - mse: 1003.5492 - mae: 21.3149\n",
      "Epoch 21/60\n",
      "1850/1850 [==============================] - 2s 928us/step - loss: 1005.4144 - mse: 1005.4142 - mae: 21.2884\n",
      "Epoch 22/60\n",
      "1850/1850 [==============================] - 2s 909us/step - loss: 987.9886 - mse: 987.9886 - mae: 21.2004\n",
      "Epoch 23/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 996.2321 - mse: 996.2322 - mae: 21.2722: 0s - loss: 990.9182 - mse: 990.9182 - ma\n",
      "Epoch 24/60\n",
      "1850/1850 [==============================] - 2s 958us/step - loss: 1002.7012 - mse: 1002.7012 - mae: 21.4075\n",
      "Epoch 25/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 1001.8673 - mse: 1001.8673 - mae: 21.2724\n",
      "Epoch 26/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 1003.7505 - mse: 1003.7505 - mae: 21.4367\n",
      "Epoch 27/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 992.6158 - mse: 992.6157 - mae: 21.1924\n",
      "Epoch 28/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 985.6026 - mse: 985.6027 - mae: 21.0779TA: 0s - loss: 1124.9691 - mse: 11\n",
      "Epoch 29/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 985.5709 - mse: 985.5709 - mae: 21.0655\n",
      "Epoch 30/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 980.5588 - mse: 980.5590 - mae: 20.8871\n",
      "Epoch 31/60\n",
      "1850/1850 [==============================] - 2s 931us/step - loss: 975.6040 - mse: 975.6039 - mae: 20.9001\n",
      "Epoch 32/60\n",
      "1850/1850 [==============================] - 2s 932us/step - loss: 976.0877 - mse: 976.0878 - mae: 20.8869\n",
      "Epoch 33/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 973.9688 - mse: 973.9688 - mae: 21.0718\n",
      "Epoch 34/60\n",
      "1850/1850 [==============================] - 2s 954us/step - loss: 972.5794 - mse: 972.5794 - mae: 20.8721\n",
      "Epoch 35/60\n",
      "1850/1850 [==============================] - 2s 999us/step - loss: 976.4119 - mse: 976.4117 - mae: 20.8324\n",
      "Epoch 36/60\n",
      "1850/1850 [==============================] - 2s 1000us/step - loss: 970.5581 - mse: 970.5581 - mae: 20.7876s - loss: 1150.8761 - mse: 1150\n",
      "Epoch 37/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 973.7371 - mse: 973.7369 - mae: 20.8620\n",
      "Epoch 38/60\n",
      "1850/1850 [==============================] - 2s 867us/step - loss: 975.5529 - mse: 975.5528 - mae: 20.9358\n",
      "Epoch 39/60\n",
      "1850/1850 [==============================] - 2s 868us/step - loss: 971.4622 - mse: 971.4623 - mae: 20.7314\n",
      "Epoch 40/60\n",
      "1850/1850 [==============================] - 2s 977us/step - loss: 975.6119 - mse: 975.6119 - mae: 20.9964\n",
      "Epoch 41/60\n",
      "1850/1850 [==============================] - 2s 933us/step - loss: 969.3489 - mse: 969.3491 - mae: 20.6848\n",
      "Epoch 42/60\n",
      "1850/1850 [==============================] - 2s 931us/step - loss: 965.3623 - mse: 965.3624 - mae: 20.7340\n",
      "Epoch 43/60\n",
      "1850/1850 [==============================] - 2s 976us/step - loss: 966.8308 - mse: 966.8308 - mae: 20.6837: 1s - loss: 1112.5871 - mse: 1112.587 - ETA: 0s - loss: 1135.0678 - mse: \n",
      "Epoch 44/60\n",
      "1850/1850 [==============================] - 2s 951us/step - loss: 967.2512 - mse: 967.2513 - mae: 20.7903\n",
      "Epoch 45/60\n",
      "1850/1850 [==============================] - 2s 931us/step - loss: 955.9528 - mse: 955.9528 - mae: 20.4670\n",
      "Epoch 46/60\n",
      "1850/1850 [==============================] - 2s 908us/step - loss: 972.2296 - mse: 972.2294 - mae: 21.0733\n",
      "Epoch 47/60\n",
      "1850/1850 [==============================] - 2s 869us/step - loss: 962.9784 - mse: 962.9783 - mae: 20.6824\n",
      "Epoch 48/60\n",
      "1850/1850 [==============================] - 2s 910us/step - loss: 971.2468 - mse: 971.2469 - mae: 20.9699\n",
      "Epoch 49/60\n",
      "1850/1850 [==============================] - 2s 932us/step - loss: 959.3885 - mse: 959.3884 - mae: 20.6659\n",
      "Epoch 50/60\n",
      "1850/1850 [==============================] - 2s 890us/step - loss: 953.6632 - mse: 953.6634 - mae: 20.6610\n",
      "Epoch 51/60\n",
      "1850/1850 [==============================] - 2s 952us/step - loss: 950.7091 - mse: 950.7090 - mae: 20.5370\n",
      "Epoch 52/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 960.9711 - mse: 960.9711 - mae: 20.5588\n",
      "Epoch 53/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 946.5134 - mse: 946.5134 - mae: 20.5939TA: 1s - loss: 1334.\n",
      "Epoch 54/60\n",
      "1850/1850 [==============================] - 2s 934us/step - loss: 955.7260 - mse: 955.7261 - mae: 20.5760\n",
      "Epoch 55/60\n",
      "1850/1850 [==============================] - 2s 911us/step - loss: 950.8216 - mse: 950.8215 - mae: 20.3377\n",
      "Epoch 56/60\n",
      "1850/1850 [==============================] - 2s 913us/step - loss: 955.9830 - mse: 955.9830 - mae: 20.67780s - loss: 825.9935 - mse: 825.9935 - mae: 1 - ETA: 0s - loss: 845.8021 - mse: 8\n",
      "Epoch 57/60\n",
      "1850/1850 [==============================] - 2s 950us/step - loss: 947.6080 - mse: 947.6079 - mae: 20.46420s - loss: 922.3862 - mse: 922.3861 - mae: 20.\n",
      "Epoch 58/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 956.5613 - mse: 956.5616 - mae: 20.6535\n",
      "Epoch 59/60\n",
      "1850/1850 [==============================] - 2s 952us/step - loss: 945.6776 - mse: 945.6776 - mae: 20.4605\n",
      "Epoch 60/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 948.4692 - mse: 948.4692 - mae: 20.5929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=60)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "3699/3699 [==============================] - 12s 3ms/step - loss: 4344.8842 - mse: 4344.8848 - mae: 48.7498\n",
      "Epoch 2/60\n",
      "3699/3699 [==============================] - 3s 931us/step - loss: 1137.4209 - mse: 1137.4211 - mae: 23.0224\n",
      "Epoch 3/60\n",
      "3699/3699 [==============================] - 4s 955us/step - loss: 1137.9313 - mse: 1137.9315 - mae: 23.0119\n",
      "Epoch 4/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1133.0059 - mse: 1133.0060 - mae: 23.0076\n",
      "Epoch 5/60\n",
      "3699/3699 [==============================] - 3s 902us/step - loss: 1133.7091 - mse: 1133.7092 - mae: 22.9050\n",
      "Epoch 6/60\n",
      "3699/3699 [==============================] - 3s 912us/step - loss: 1132.9295 - mse: 1132.9296 - mae: 22.9868\n",
      "Epoch 7/60\n",
      "3699/3699 [==============================] - 4s 958us/step - loss: 1138.9975 - mse: 1138.9976 - mae: 23.0195\n",
      "Epoch 8/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1127.6125 - mse: 1127.6128 - mae: 22.8213\n",
      "Epoch 9/60\n",
      "3699/3699 [==============================] - 3s 934us/step - loss: 1124.6314 - mse: 1124.6312 - mae: 22.8196\n",
      "Epoch 10/60\n",
      "3699/3699 [==============================] - 3s 912us/step - loss: 1132.5774 - mse: 1132.5775 - mae: 22.9206\n",
      "Epoch 11/60\n",
      "3699/3699 [==============================] - 4s 998us/step - loss: 1120.4555 - mse: 1120.4554 - mae: 22.7487\n",
      "Epoch 12/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1127.9681 - mse: 1127.9679 - mae: 22.7722\n",
      "Epoch 13/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1124.5192 - mse: 1124.5192 - mae: 22.6988: 0s - loss: 1133.0616 - mse: 1133.0615 - mae:\n",
      "Epoch 14/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1126.9240 - mse: 1126.9240 - mae: 22.8348\n",
      "Epoch 15/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1115.8500 - mse: 1115.8500 - mae: 22.6345: 1s - loss: 107\n",
      "Epoch 16/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1115.1850 - mse: 1115.1848 - mae: 22.5257: 1s - los\n",
      "Epoch 17/60\n",
      "3699/3699 [==============================] - 4s 966us/step - loss: 1149.2193 - mse: 1149.2195 - mae: 23.0031\n",
      "Epoch 18/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1117.5170 - mse: 1117.5171 - mae: 22.7064\n",
      "Epoch 19/60\n",
      "3699/3699 [==============================] - 4s 986us/step - loss: 1105.3950 - mse: 1105.3950 - mae: 22.4960\n",
      "Epoch 20/60\n",
      "3699/3699 [==============================] - 3s 889us/step - loss: 1106.0155 - mse: 1106.0155 - mae: 22.4364\n",
      "Epoch 21/60\n",
      "3699/3699 [==============================] - 3s 880us/step - loss: 1109.2557 - mse: 1109.2559 - mae: 22.5725\n",
      "Epoch 22/60\n",
      "3699/3699 [==============================] - 3s 922us/step - loss: 1112.7049 - mse: 1112.7050 - mae: 22.5066\n",
      "Epoch 23/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1102.5225 - mse: 1102.5228 - mae: 22.4990\n",
      "Epoch 24/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1107.3582 - mse: 1107.3582 - mae: 22.5053: 0s - loss: 1116.0703 - mse: 1116\n",
      "Epoch 25/60\n",
      "3699/3699 [==============================] - 4s 998us/step - loss: 1116.2335 - mse: 1116.2334 - mae: 22.5602\n",
      "Epoch 26/60\n",
      "3699/3699 [==============================] - 4s 999us/step - loss: 1102.6973 - mse: 1102.6973 - mae: 22.4322\n",
      "Epoch 27/60\n",
      "3699/3699 [==============================] - 5s 1ms/step - loss: 1105.6900 - mse: 1105.6898 - mae: 22.4232\n",
      "Epoch 28/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1108.1856 - mse: 1108.1859 - mae: 22.3886\n",
      "Epoch 29/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1104.8209 - mse: 1104.8209 - mae: 22.4460: \n",
      "Epoch 30/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1110.4690 - mse: 1110.4691 - mae: 22.4704\n",
      "Epoch 31/60\n",
      "3699/3699 [==============================] - 4s 967us/step - loss: 1108.4297 - mse: 1108.4297 - mae: 22.2487\n",
      "Epoch 32/60\n",
      "3699/3699 [==============================] - 3s 912us/step - loss: 1109.2291 - mse: 1109.2291 - mae: 22.5557\n",
      "Epoch 33/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1101.8385 - mse: 1101.8386 - mae: 22.3081\n",
      "Epoch 34/60\n",
      "3699/3699 [==============================] - 4s 986us/step - loss: 1103.1079 - mse: 1103.1082 - mae: 22.2434\n",
      "Epoch 35/60\n",
      "3699/3699 [==============================] - 3s 933us/step - loss: 1106.0026 - mse: 1106.0028 - mae: 22.4496\n",
      "Epoch 36/60\n",
      "3699/3699 [==============================] - 3s 935us/step - loss: 1096.1447 - mse: 1096.1447 - mae: 22.2952\n",
      "Epoch 37/60\n",
      "3699/3699 [==============================] - 4s 966us/step - loss: 1098.7043 - mse: 1098.7045 - mae: 22.2921\n",
      "Epoch 38/60\n",
      "3699/3699 [==============================] - 4s 965us/step - loss: 1099.1887 - mse: 1099.1886 - mae: 22.2133\n",
      "Epoch 39/60\n",
      "3699/3699 [==============================] - 3s 913us/step - loss: 1092.5261 - mse: 1092.5262 - mae: 22.2532\n",
      "Epoch 40/60\n",
      "3699/3699 [==============================] - 4s 963us/step - loss: 1089.9332 - mse: 1089.9332 - mae: 22.2158\n",
      "Epoch 41/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1104.7400 - mse: 1104.7399 - mae: 22.3474\n",
      "Epoch 42/60\n",
      "3699/3699 [==============================] - 3s 933us/step - loss: 1102.6738 - mse: 1102.6742 - mae: 22.4625\n",
      "Epoch 43/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1092.8236 - mse: 1092.8236 - mae: 22.1712\n",
      "Epoch 44/60\n",
      "3699/3699 [==============================] - 4s 985us/step - loss: 1091.8131 - mse: 1091.8129 - mae: 22.2241\n",
      "Epoch 45/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1092.3877 - mse: 1092.3877 - mae: 22.1594\n",
      "Epoch 46/60\n",
      "3699/3699 [==============================] - 4s 954us/step - loss: 1087.5018 - mse: 1087.5021 - mae: 22.1269\n",
      "Epoch 47/60\n",
      "3699/3699 [==============================] - 3s 921us/step - loss: 1092.3120 - mse: 1092.3119 - mae: 22.2088\n",
      "Epoch 48/60\n",
      "3699/3699 [==============================] - 4s 988us/step - loss: 1087.8974 - mse: 1087.8972 - mae: 22.0886\n",
      "Epoch 49/60\n",
      "3699/3699 [==============================] - 4s 995us/step - loss: 1090.2640 - mse: 1090.2640 - mae: 22.2161\n",
      "Epoch 50/60\n",
      "3699/3699 [==============================] - 4s 946us/step - loss: 1094.5503 - mse: 1094.5505 - mae: 22.1771\n",
      "Epoch 51/60\n",
      "3699/3699 [==============================] - 3s 879us/step - loss: 1103.1787 - mse: 1103.1787 - mae: 22.3170\n",
      "Epoch 52/60\n",
      "3699/3699 [==============================] - 4s 967us/step - loss: 1087.0214 - mse: 1087.0212 - mae: 22.07571s - loss: 1126.90 - ETA: 0s - loss: 1141.3556 - mse: 11\n",
      "Epoch 53/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1088.5534 - mse: 1088.5532 - mae: 22.0624\n",
      "Epoch 54/60\n",
      "3699/3699 [==============================] - 3s 890us/step - loss: 1087.0126 - mse: 1087.0126 - mae: 22.0876\n",
      "Epoch 55/60\n",
      "3699/3699 [==============================] - 3s 913us/step - loss: 1084.1607 - mse: 1084.1610 - mae: 22.0325 - loss: 924.8180 - mse: 924.8181 - ma - ETA: 1s - l\n",
      "Epoch 56/60\n",
      "3699/3699 [==============================] - 4s 968us/step - loss: 1088.6094 - mse: 1088.6094 - mae: 22.0400\n",
      "Epoch 57/60\n",
      "3699/3699 [==============================] - 4s 986us/step - loss: 1084.3032 - mse: 1084.3031 - mae: 22.0194\n",
      "Epoch 58/60\n",
      "3699/3699 [==============================] - 4s 998us/step - loss: 1079.2369 - mse: 1079.2371 - mae: 21.9404\n",
      "Epoch 59/60\n",
      "3699/3699 [==============================] - 4s 957us/step - loss: 1083.7345 - mse: 1083.7344 - mae: 22.0518\n",
      "Epoch 60/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1081.7243 - mse: 1081.7244 - mae: 22.0581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=60)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "5548/5548 [==============================] - 13s 2ms/step - loss: 3844.9950 - mse: 3844.9956 - mae: 41.9439\n",
      "Epoch 2/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1687.1424 - mse: 1687.1422 - mae: 25.2405\n",
      "Epoch 3/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1686.9869 - mse: 1686.9868 - mae: 25.1749\n",
      "Epoch 4/60\n",
      "5548/5548 [==============================] - 5s 955us/step - loss: 1676.8604 - mse: 1676.8597 - mae: 25.0789\n",
      "Epoch 5/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1666.9252 - mse: 1666.9250 - mae: 25.0031: 1s - loss: 1368.4701 - mse: 1368.4698 - mae: 24. - ETA: 1s - loss: 1\n",
      "Epoch 6/60\n",
      "5548/5548 [==============================] - 5s 991us/step - loss: 1658.9037 - mse: 1658.9036 - mae: 24.9626\n",
      "Epoch 7/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1661.7401 - mse: 1661.7402 - mae: 24.8870\n",
      "Epoch 8/60\n",
      "5548/5548 [==============================] - 5s 973us/step - loss: 1653.4973 - mse: 1653.4978 - mae: 24.9982\n",
      "Epoch 9/60\n",
      "5548/5548 [==============================] - 5s 982us/step - loss: 1645.3587 - mse: 1645.3589 - mae: 24.7918\n",
      "Epoch 10/60\n",
      "5548/5548 [==============================] - ETA: 0s - loss: 1659.7757 - mse: 1659.7759 - mae: 24.88 - 6s 1ms/step - loss: 1657.4807 - mse: 1657.4808 - mae: 24.8752\n",
      "Epoch 11/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1642.7742 - mse: 1642.7738 - mae: 24.7278\n",
      "Epoch 12/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1639.1769 - mse: 1639.1771 - mae: 24.7738\n",
      "Epoch 13/60\n",
      "5548/5548 [==============================] - 5s 975us/step - loss: 1640.8179 - mse: 1640.8177 - mae: 24.5997\n",
      "Epoch 14/60\n",
      "5548/5548 [==============================] - 5s 911us/step - loss: 1633.6199 - mse: 1633.6200 - mae: 24.7230\n",
      "Epoch 15/60\n",
      "5548/5548 [==============================] - 5s 975us/step - loss: 1635.8846 - mse: 1635.8848 - mae: 24.6413\n",
      "Epoch 16/60\n",
      "5548/5548 [==============================] - 5s 972us/step - loss: 1631.2812 - mse: 1631.2814 - mae: 24.53912s\n",
      "Epoch 17/60\n",
      "5548/5548 [==============================] - 5s 942us/step - loss: 1626.5188 - mse: 1626.5192 - mae: 24.6303\n",
      "Epoch 18/60\n",
      "5548/5548 [==============================] - 5s 946us/step - loss: 1625.1583 - mse: 1625.1581 - mae: 24.60391s - l\n",
      "Epoch 19/60\n",
      "5548/5548 [==============================] - 5s 981us/step - loss: 1627.6735 - mse: 1627.6736 - mae: 24.5738\n",
      "Epoch 20/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1619.4867 - mse: 1619.4871 - mae: 24.4844\n",
      "Epoch 21/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1630.2064 - mse: 1630.2062 - mae: 24.6446\n",
      "Epoch 22/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1619.7697 - mse: 1619.7698 - mae: 24.4210\n",
      "Epoch 23/60\n",
      "5548/5548 [==============================] - 7s 1ms/step - loss: 1615.7097 - mse: 1615.7102 - mae: 24.4532\n",
      "Epoch 24/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1613.3836 - mse: 1613.3842 - mae: 24.4038\n",
      "Epoch 25/60\n",
      "5548/5548 [==============================] - 5s 955us/step - loss: 1610.1454 - mse: 1610.1455 - mae: 24.4419\n",
      "Epoch 26/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1624.2908 - mse: 1624.2909 - mae: 24.4598\n",
      "Epoch 27/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1611.4608 - mse: 1611.4614 - mae: 24.4022\n",
      "Epoch 28/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1618.2970 - mse: 1618.2974 - mae: 24.5358\n",
      "Epoch 29/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1611.2442 - mse: 1611.2440 - mae: 24.2773: 1s\n",
      "Epoch 30/60\n",
      "5548/5548 [==============================] - 3s 604us/step - loss: 1607.7314 - mse: 1607.7316 - mae: 24.3529\n",
      "Epoch 31/60\n",
      "5548/5548 [==============================] - 0s 54us/step - loss: 1607.8082 - mse: 1607.8080 - mae: 24.2611\n",
      "Epoch 32/60\n",
      "5548/5548 [==============================] - 0s 54us/step - loss: 1608.0726 - mse: 1608.0725 - mae: 24.3798\n",
      "Epoch 33/60\n",
      "5548/5548 [==============================] - 0s 54us/step - loss: 1608.3637 - mse: 1608.3638 - mae: 24.3499 0s - loss: 2007.7160 - mse: 2007.7158 - mae: 23.73 - ETA: 0s - loss: 1915.5480 - mse: 1915.5480 - mae: 2\n",
      "Epoch 34/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1608.5988 - mse: 1608.5986 - mae: 24.3632\n",
      "Epoch 35/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1603.4463 - mse: 1603.4462 - mae: 24.3022\n",
      "Epoch 36/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1607.1686 - mse: 1607.1686 - mae: 24.3091\n",
      "Epoch 37/60\n",
      "5548/5548 [==============================] - 0s 54us/step - loss: 1606.5009 - mse: 1606.5007 - mae: 24.2457\n",
      "Epoch 38/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1607.8868 - mse: 1607.8870 - mae: 24.2826\n",
      "Epoch 39/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1603.4760 - mse: 1603.4761 - mae: 24.2697\n",
      "Epoch 40/60\n",
      "5548/5548 [==============================] - 0s 54us/step - loss: 1603.3423 - mse: 1603.3427 - mae: 24.2874\n",
      "Epoch 41/60\n",
      "5548/5548 [==============================] - 0s 54us/step - loss: 1599.6607 - mse: 1599.6610 - mae: 24.2292\n",
      "Epoch 42/60\n",
      "5548/5548 [==============================] - 0s 54us/step - loss: 1603.1677 - mse: 1603.1680 - mae: 24.2784\n",
      "Epoch 43/60\n",
      "5548/5548 [==============================] - 0s 54us/step - loss: 1602.9576 - mse: 1602.9578 - mae: 24.1772\n",
      "Epoch 44/60\n",
      "5548/5548 [==============================] - 0s 54us/step - loss: 1601.8832 - mse: 1601.8834 - mae: 24.2995\n",
      "Epoch 45/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1605.2187 - mse: 1605.2181 - mae: 24.3416\n",
      "Epoch 46/60\n",
      "5548/5548 [==============================] - 0s 53us/step - loss: 1596.8809 - mse: 1596.8809 - mae: 24.1083\n",
      "Epoch 47/60\n",
      "5548/5548 [==============================] - 0s 73us/step - loss: 1600.3943 - mse: 1600.3944 - mae: 24.2130\n",
      "Epoch 48/60\n",
      "5548/5548 [==============================] - 0s 79us/step - loss: 1600.6322 - mse: 1600.6320 - mae: 24.1643\n",
      "Epoch 49/60\n",
      "5548/5548 [==============================] - 0s 77us/step - loss: 1598.6204 - mse: 1598.6200 - mae: 24.2661\n",
      "Epoch 50/60\n",
      "5548/5548 [==============================] - 0s 77us/step - loss: 1596.6750 - mse: 1596.6750 - mae: 24.1419\n",
      "Epoch 51/60\n",
      "5548/5548 [==============================] - 0s 79us/step - loss: 1598.1004 - mse: 1598.1006 - mae: 24.2160\n",
      "Epoch 52/60\n",
      "5548/5548 [==============================] - 0s 77us/step - loss: 1593.3704 - mse: 1593.3700 - mae: 24.1205\n",
      "Epoch 53/60\n",
      "5548/5548 [==============================] - 0s 79us/step - loss: 1593.6905 - mse: 1593.6907 - mae: 24.1442\n",
      "Epoch 54/60\n",
      "5548/5548 [==============================] - 0s 77us/step - loss: 1606.0531 - mse: 1606.0536 - mae: 24.3132\n",
      "Epoch 55/60\n",
      "5548/5548 [==============================] - 0s 79us/step - loss: 1597.8201 - mse: 1597.8199 - mae: 24.2138\n",
      "Epoch 56/60\n",
      "5548/5548 [==============================] - 0s 79us/step - loss: 1597.0958 - mse: 1597.0961 - mae: 24.1129\n",
      "Epoch 57/60\n",
      "5548/5548 [==============================] - 0s 79us/step - loss: 1598.7510 - mse: 1598.7511 - mae: 24.1464\n",
      "Epoch 58/60\n",
      "5548/5548 [==============================] - 1s 110us/step - loss: 1594.0379 - mse: 1594.0377 - mae: 24.1595\n",
      "Epoch 59/60\n",
      "5548/5548 [==============================] - 1s 144us/step - loss: 1588.8284 - mse: 1588.8282 - mae: 24.0655\n",
      "Epoch 60/60\n",
      "5548/5548 [==============================] - 1s 144us/step - loss: 1590.8132 - mse: 1590.8132 - mae: 24.0956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=60)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "7397/7397 [==============================] - 12s 2ms/step - loss: 3643.5073 - mse: 3643.5078 - mae: 40.2910\n",
      "Epoch 2/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1616.8262 - mse: 1616.8263 - mae: 25.5106: 0s - loss: 1614.5561 - mse: 1614.5563 - mae: 2\n",
      "Epoch 3/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1605.5013 - mse: 1605.5017 - mae: 25.3105\n",
      "Epoch 4/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1603.7803 - mse: 1603.7804 - mae: 25.2683\n",
      "Epoch 5/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1595.2603 - mse: 1595.2604 - mae: 25.2976\n",
      "Epoch 6/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1584.4494 - mse: 1584.4495 - mae: 25.2125\n",
      "Epoch 7/60\n",
      "7397/7397 [==============================] - 7s 971us/step - loss: 1583.1327 - mse: 1583.1324 - mae: 25.1090\n",
      "Epoch 8/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1583.3787 - mse: 1583.3784 - mae: 25.1252\n",
      "Epoch 9/60\n",
      "7397/7397 [==============================] - 7s 917us/step - loss: 1575.4965 - mse: 1575.4965 - mae: 25.0336\n",
      "Epoch 10/60\n",
      "7397/7397 [==============================] - 7s 964us/step - loss: 1570.2639 - mse: 1570.2634 - mae: 25.0228\n",
      "Epoch 11/60\n",
      "7397/7397 [==============================] - 7s 896us/step - loss: 1574.0092 - mse: 1574.0093 - mae: 24.9873\n",
      "Epoch 12/60\n",
      "7397/7397 [==============================] - 7s 977us/step - loss: 1566.1609 - mse: 1566.1609 - mae: 24.9518\n",
      "Epoch 13/60\n",
      "7397/7397 [==============================] - 7s 927us/step - loss: 1563.3194 - mse: 1563.3195 - mae: 24.9274\n",
      "Epoch 14/60\n",
      "7397/7397 [==============================] - ETA: 0s - loss: 1571.7396 - mse: 1571.7404 - mae: 24.96 - 7s 969us/step - loss: 1572.0167 - mse: 1572.0175 - mae: 24.9749\n",
      "Epoch 15/60\n",
      "7397/7397 [==============================] - 7s 951us/step - loss: 1563.0875 - mse: 1563.0873 - mae: 24.9213\n",
      "Epoch 16/60\n",
      "7397/7397 [==============================] - 7s 993us/step - loss: 1553.0889 - mse: 1553.0884 - mae: 24.8180\n",
      "Epoch 17/60\n",
      "7397/7397 [==============================] - 7s 911us/step - loss: 1558.0710 - mse: 1558.0714 - mae: 24.8368\n",
      "Epoch 18/60\n",
      "7397/7397 [==============================] - 7s 991us/step - loss: 1554.6137 - mse: 1554.6133 - mae: 24.76901s -\n",
      "Epoch 19/60\n",
      "7397/7397 [==============================] - 7s 964us/step - loss: 1561.9726 - mse: 1561.9727 - mae: 24.8155\n",
      "Epoch 20/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1554.6142 - mse: 1554.6146 - mae: 24.8218: 0s - loss: 1571.0558 - mse: 15\n",
      "Epoch 21/60\n",
      "7397/7397 [==============================] - 7s 934us/step - loss: 1550.5218 - mse: 1550.5217 - mae: 24.68301s - loss: 130\n",
      "Epoch 22/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1557.2246 - mse: 1557.2242 - mae: 24.8099\n",
      "Epoch 23/60\n",
      "7397/7397 [==============================] - 7s 934us/step - loss: 1545.8855 - mse: 1545.8862 - mae: 24.6980\n",
      "Epoch 24/60\n",
      "7397/7397 [==============================] - 7s 931us/step - loss: 1547.6223 - mse: 1547.6224 - mae: 24.7003\n",
      "Epoch 25/60\n",
      "7397/7397 [==============================] - 7s 988us/step - loss: 1552.4854 - mse: 1552.4847 - mae: 24.7447\n",
      "Epoch 26/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1545.2815 - mse: 1545.2808 - mae: 24.6398\n",
      "Epoch 27/60\n",
      "7397/7397 [==============================] - 7s 961us/step - loss: 1541.1255 - mse: 1541.1250 - mae: 24.65203s - loss: 1768.8517 - mse: \n",
      "Epoch 28/60\n",
      "7397/7397 [==============================] - 7s 960us/step - loss: 1538.9494 - mse: 1538.9496 - mae: 24.5722\n",
      "Epoch 29/60\n",
      "7397/7397 [==============================] - 7s 929us/step - loss: 1543.2832 - mse: 1543.2834 - mae: 24.5850\n",
      "Epoch 30/60\n",
      "7397/7397 [==============================] - 7s 967us/step - loss: 1542.4577 - mse: 1542.4576 - mae: 24.6580\n",
      "Epoch 31/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1538.7563 - mse: 1538.7565 - mae: 24.5588\n",
      "Epoch 32/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1540.8806 - mse: 1540.8804 - mae: 24.5862\n",
      "Epoch 33/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1538.9780 - mse: 1538.9781 - mae: 24.5534\n",
      "Epoch 34/60\n",
      "7397/7397 [==============================] - 7s 1ms/step - loss: 1537.3939 - mse: 1537.3939 - mae: 24.5579\n",
      "Epoch 35/60\n",
      "7397/7397 [==============================] - 7s 939us/step - loss: 1536.5188 - mse: 1536.5192 - mae: 24.44232s - loss: 134 - ETA: 1s - loss: 1590.4787\n",
      "Epoch 36/60\n",
      "7397/7397 [==============================] - 7s 976us/step - loss: 1533.3789 - mse: 1533.3787 - mae: 24.4569\n",
      "Epoch 37/60\n",
      "7397/7397 [==============================] - 7s 982us/step - loss: 1533.7345 - mse: 1533.7344 - mae: 24.5221\n",
      "Epoch 38/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1534.5255 - mse: 1534.5255 - mae: 24.4648\n",
      "Epoch 39/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1536.2415 - mse: 1536.2413 - mae: 24.5531\n",
      "Epoch 40/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1529.5072 - mse: 1529.5068 - mae: 24.4352\n",
      "Epoch 41/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1530.3873 - mse: 1530.3870 - mae: 24.4509\n",
      "Epoch 42/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1535.3286 - mse: 1535.3284 - mae: 24.5319\n",
      "Epoch 43/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1529.1860 - mse: 1529.1860 - mae: 24.3829\n",
      "Epoch 44/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1532.4526 - mse: 1532.4524 - mae: 24.4932: 2s - loss: 1645.6356 - mse: 1645.6354 - ma - ETA: 1s - l\n",
      "Epoch 45/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1528.6823 - mse: 1528.6823 - mae: 24.3804\n",
      "Epoch 46/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1526.3723 - mse: 1526.3722 - mae: 24.3557\n",
      "Epoch 47/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1524.2967 - mse: 1524.2965 - mae: 24.4117\n",
      "Epoch 48/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1525.6798 - mse: 1525.6801 - mae: 24.2957\n",
      "Epoch 49/60\n",
      "7397/7397 [==============================] - 7s 1ms/step - loss: 1525.1675 - mse: 1525.1674 - mae: 24.3664\n",
      "Epoch 50/60\n",
      "7397/7397 [==============================] - 7s 1ms/step - loss: 1525.4696 - mse: 1525.4691 - mae: 24.3276\n",
      "Epoch 51/60\n",
      "7397/7397 [==============================] - 7s 966us/step - loss: 1526.6484 - mse: 1526.6483 - mae: 24.3869\n",
      "Epoch 52/60\n",
      "7397/7397 [==============================] - 7s 998us/step - loss: 1523.5420 - mse: 1523.5421 - mae: 24.3581\n",
      "Epoch 53/60\n",
      "7397/7397 [==============================] - 7s 984us/step - loss: 1519.8888 - mse: 1519.8884 - mae: 24.2490\n",
      "Epoch 54/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1516.6815 - mse: 1516.6807 - mae: 24.2677: 3s - loss: 120 - ETA: 1s - l\n",
      "Epoch 55/60\n",
      "7397/7397 [==============================] - 7s 982us/step - loss: 1523.3831 - mse: 1523.3834 - mae: 24.2998 - ETA: 0s - loss: 1561.8254 - mse: \n",
      "Epoch 56/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1522.0618 - mse: 1522.0625 - mae: 24.2557\n",
      "Epoch 57/60\n",
      "7397/7397 [==============================] - 7s 954us/step - loss: 1525.5129 - mse: 1525.5132 - mae: 24.3146\n",
      "Epoch 58/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1516.1998 - mse: 1516.1996 - mae: 24.1853\n",
      "Epoch 59/60\n",
      "7397/7397 [==============================] - 7s 954us/step - loss: 1516.2821 - mse: 1516.2821 - mae: 24.19540s - loss: 1516.5996 - mse: 1516.5997 - mae: 24.19\n",
      "Epoch 60/60\n",
      "7397/7397 [==============================] - 7s 969us/step - loss: 1516.7687 - mse: 1516.7693 - mae: 24.1995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=60)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "1850/1850 [==============================] - 14s 7ms/step - loss: 4971.9339 - mse: 4971.9331 - mae: 52.7679\n",
      "Epoch 2/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 1045.7599 - mse: 1045.7600 - mae: 22.5599\n",
      "Epoch 3/60\n",
      "1850/1850 [==============================] - 2s 978us/step - loss: 1040.9493 - mse: 1040.9493 - mae: 22.3945\n",
      "Epoch 4/60\n",
      "1850/1850 [==============================] - 2s 957us/step - loss: 1023.0276 - mse: 1023.0277 - mae: 22.0653\n",
      "Epoch 5/60\n",
      "1850/1850 [==============================] - 2s 910us/step - loss: 1021.3368 - mse: 1021.3367 - mae: 21.8524\n",
      "Epoch 6/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 1027.3186 - mse: 1027.3186 - mae: 21.9301: 0s - loss: 1124.6831 - mse: \n",
      "Epoch 7/60\n",
      "1850/1850 [==============================] - 2s 996us/step - loss: 1027.0698 - mse: 1027.0697 - mae: 21.8774\n",
      "Epoch 8/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 1015.5173 - mse: 1015.5175 - mae: 21.6958\n",
      "Epoch 9/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 1007.8344 - mse: 1007.8344 - mae: 21.4631\n",
      "Epoch 10/60\n",
      "1850/1850 [==============================] - 2s 956us/step - loss: 1010.3892 - mse: 1010.3893 - mae: 21.5460\n",
      "Epoch 11/60\n",
      "1850/1850 [==============================] - 2s 978us/step - loss: 1016.8810 - mse: 1016.8809 - mae: 21.7131\n",
      "Epoch 12/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 1012.3000 - mse: 1012.3000 - mae: 21.5591\n",
      "Epoch 13/60\n",
      "1850/1850 [==============================] - 2s 977us/step - loss: 1003.6790 - mse: 1003.6792 - mae: 21.4534\n",
      "Epoch 14/60\n",
      "1850/1850 [==============================] - 3s 2ms/step - loss: 1004.9078 - mse: 1004.9078 - mae: 21.2673: 0s - loss: 1061.7686 - mse: \n",
      "Epoch 15/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 999.8792 - mse: 999.8792 - mae: 21.2662\n",
      "Epoch 16/60\n",
      "1850/1850 [==============================] - 2s 978us/step - loss: 996.9975 - mse: 996.9974 - mae: 21.2244\n",
      "Epoch 17/60\n",
      "1850/1850 [==============================] - 2s 999us/step - loss: 992.1801 - mse: 992.1802 - mae: 21.2101\n",
      "Epoch 18/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 996.8090 - mse: 996.8091 - mae: 21.1404\n",
      "Epoch 19/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 1002.9103 - mse: 1002.9103 - mae: 21.43271s - loss: 9\n",
      "Epoch 20/60\n",
      "1850/1850 [==============================] - 2s 999us/step - loss: 996.7387 - mse: 996.7387 - mae: 21.2204\n",
      "Epoch 21/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 994.5685 - mse: 994.5683 - mae: 21.1489\n",
      "Epoch 22/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 985.2642 - mse: 985.2641 - mae: 21.2410\n",
      "Epoch 23/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 988.1293 - mse: 988.1294 - mae: 21.0861\n",
      "Epoch 24/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 993.3170 - mse: 993.3171 - mae: 21.0354\n",
      "Epoch 25/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 988.0004 - mse: 988.0005 - mae: 21.0920\n",
      "Epoch 26/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 987.3066 - mse: 987.3066 - mae: 21.1292\n",
      "Epoch 27/60\n",
      "1850/1850 [==============================] - 2s 994us/step - loss: 979.9469 - mse: 979.9469 - mae: 20.9383\n",
      "Epoch 28/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 983.1234 - mse: 983.1234 - mae: 20.8574\n",
      "Epoch 29/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 981.4181 - mse: 981.4181 - mae: 21.0639\n",
      "Epoch 30/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 977.9270 - mse: 977.9270 - mae: 20.9131TA: 0s - loss: 1003.5725 - mse: 1003.5726 - \n",
      "Epoch 31/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 983.7568 - mse: 983.7570 - mae: 20.9480\n",
      "Epoch 32/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 970.4413 - mse: 970.4413 - mae: 20.7858\n",
      "Epoch 33/60\n",
      "1850/1850 [==============================] - 3s 1ms/step - loss: 969.6188 - mse: 969.6186 - mae: 20.7423\n",
      "Epoch 34/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 969.6990 - mse: 969.6988 - mae: 20.7855\n",
      "Epoch 35/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 969.7497 - mse: 969.7499 - mae: 20.7327\n",
      "Epoch 36/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 970.0606 - mse: 970.0606 - mae: 20.8181\n",
      "Epoch 37/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 972.5714 - mse: 972.5714 - mae: 20.7908\n",
      "Epoch 38/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 977.2503 - mse: 977.2502 - mae: 20.9048\n",
      "Epoch 39/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 974.2144 - mse: 974.2144 - mae: 20.7587\n",
      "Epoch 40/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 973.8604 - mse: 973.8605 - mae: 20.7835\n",
      "Epoch 41/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 970.8848 - mse: 970.8849 - mae: 20.8504\n",
      "Epoch 42/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 970.0136 - mse: 970.0136 - mae: 20.7546\n",
      "Epoch 43/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 972.1589 - mse: 972.1588 - mae: 20.9444\n",
      "Epoch 44/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 960.6742 - mse: 960.6742 - mae: 20.7218\n",
      "Epoch 45/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 963.6133 - mse: 963.6135 - mae: 20.6248\n",
      "Epoch 46/60\n",
      "1850/1850 [==============================] - 2s 980us/step - loss: 959.5694 - mse: 959.5694 - mae: 20.7074\n",
      "Epoch 47/60\n",
      "1850/1850 [==============================] - 2s 958us/step - loss: 969.4737 - mse: 969.4736 - mae: 20.6667\n",
      "Epoch 48/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 955.7803 - mse: 955.7803 - mae: 20.6684\n",
      "Epoch 49/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 964.3641 - mse: 964.3641 - mae: 20.7124\n",
      "Epoch 50/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 969.6237 - mse: 969.6237 - mae: 20.6528\n",
      "Epoch 51/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 958.3066 - mse: 958.3067 - mae: 20.5990\n",
      "Epoch 52/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 956.4734 - mse: 956.4734 - mae: 20.6038\n",
      "Epoch 53/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 955.3659 - mse: 955.3657 - mae: 20.7271\n",
      "Epoch 54/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 951.8246 - mse: 951.8246 - mae: 20.5969\n",
      "Epoch 55/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 955.0073 - mse: 955.0072 - mae: 20.6403\n",
      "Epoch 56/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 951.1657 - mse: 951.1658 - mae: 20.5036\n",
      "Epoch 57/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 948.5444 - mse: 948.5443 - mae: 20.7419\n",
      "Epoch 58/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 947.5800 - mse: 947.5800 - mae: 20.5762\n",
      "Epoch 59/60\n",
      "1850/1850 [==============================] - 2s 997us/step - loss: 951.0416 - mse: 951.0417 - mae: 20.5589\n",
      "Epoch 60/60\n",
      "1850/1850 [==============================] - 2s 956us/step - loss: 955.5895 - mse: 955.5896 - mae: 20.7290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=60)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "3699/3699 [==============================] - 14s 4ms/step - loss: 3053.7317 - mse: 3053.7319 - mae: 37.9623\n",
      "Epoch 2/60\n",
      "3699/3699 [==============================] - 4s 997us/step - loss: 1142.9477 - mse: 1142.9479 - mae: 22.9864\n",
      "Epoch 3/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1138.8526 - mse: 1138.8527 - mae: 22.9048\n",
      "Epoch 4/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1138.0534 - mse: 1138.0536 - mae: 22.8383\n",
      "Epoch 5/60\n",
      "3699/3699 [==============================] - 4s 967us/step - loss: 1133.6394 - mse: 1133.6393 - mae: 22.8056\n",
      "Epoch 6/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1123.5144 - mse: 1123.5146 - mae: 22.6439\n",
      "Epoch 7/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1130.9735 - mse: 1130.9734 - mae: 22.7477\n",
      "Epoch 8/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1128.8709 - mse: 1128.8711 - mae: 22.6952\n",
      "Epoch 9/60\n",
      "3699/3699 [==============================] - 3s 922us/step - loss: 1118.6781 - mse: 1118.6783 - mae: 22.6755\n",
      "Epoch 10/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1119.0883 - mse: 1119.0884 - mae: 22.7004\n",
      "Epoch 11/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1114.8254 - mse: 1114.8252 - mae: 22.5986\n",
      "Epoch 12/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1121.5318 - mse: 1121.5319 - mae: 22.5267\n",
      "Epoch 13/60\n",
      "3699/3699 [==============================] - 4s 978us/step - loss: 1112.4173 - mse: 1112.4175 - mae: 22.4409\n",
      "Epoch 14/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1108.5352 - mse: 1108.5348 - mae: 22.3919\n",
      "Epoch 15/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1107.5359 - mse: 1107.5361 - mae: 22.3281\n",
      "Epoch 16/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1110.7168 - mse: 1110.7168 - mae: 22.4196\n",
      "Epoch 17/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1109.8504 - mse: 1109.8506 - mae: 22.3624\n",
      "Epoch 18/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1106.4123 - mse: 1106.4122 - mae: 22.3783\n",
      "Epoch 19/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1100.1205 - mse: 1100.1206 - mae: 22.2585\n",
      "Epoch 20/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1112.2015 - mse: 1112.2012 - mae: 22.4122\n",
      "Epoch 21/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1103.5634 - mse: 1103.5631 - mae: 22.3558: 0s - loss: 1105.6679 - mse: 1105.6676 - mae: 22.38\n",
      "Epoch 22/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1101.8728 - mse: 1101.8727 - mae: 22.1944: 0s - loss: 1115.8836 - mse: 1115.8835 - mae: 2 - ETA: 0s - loss: 1110.5842 - mse: 1110.5841 - mae: 22.\n",
      "Epoch 23/60\n",
      "3699/3699 [==============================] - 4s 975us/step - loss: 1102.7460 - mse: 1102.7460 - mae: 22.2455\n",
      "Epoch 24/60\n",
      "3699/3699 [==============================] - 3s 933us/step - loss: 1096.4350 - mse: 1096.4349 - mae: 22.1223\n",
      "Epoch 25/60\n",
      "3699/3699 [==============================] - 4s 968us/step - loss: 1104.4787 - mse: 1104.4786 - mae: 22.3292\n",
      "Epoch 26/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1100.2203 - mse: 1100.2202 - mae: 22.2301\n",
      "Epoch 27/60\n",
      "3699/3699 [==============================] - 4s 989us/step - loss: 1103.6555 - mse: 1103.6554 - mae: 22.2181\n",
      "Epoch 28/60\n",
      "3699/3699 [==============================] - 3s 945us/step - loss: 1094.0099 - mse: 1094.0098 - mae: 22.0371\n",
      "Epoch 29/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1093.1435 - mse: 1093.1434 - mae: 22.1869\n",
      "Epoch 30/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1091.0920 - mse: 1091.0920 - mae: 22.19633s - loss: 832\n",
      "Epoch 31/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1098.9397 - mse: 1098.9396 - mae: 22.1926\n",
      "Epoch 32/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1095.8027 - mse: 1095.8025 - mae: 22.0891\n",
      "Epoch 33/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1099.6181 - mse: 1099.6179 - mae: 22.2604\n",
      "Epoch 34/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1099.9497 - mse: 1099.9496 - mae: 22.2057\n",
      "Epoch 35/60\n",
      "3699/3699 [==============================] - 4s 967us/step - loss: 1093.6427 - mse: 1093.6428 - mae: 22.1801\n",
      "Epoch 36/60\n",
      "3699/3699 [==============================] - 4s 1000us/step - loss: 1099.1773 - mse: 1099.1774 - mae: 22.2209\n",
      "Epoch 37/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1085.6037 - mse: 1085.6038 - mae: 21.9327\n",
      "Epoch 38/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1086.8283 - mse: 1086.8282 - mae: 22.1113\n",
      "Epoch 39/60\n",
      "3699/3699 [==============================] - 4s 964us/step - loss: 1088.4125 - mse: 1088.4126 - mae: 22.1495\n",
      "Epoch 40/60\n",
      "3699/3699 [==============================] - 3s 923us/step - loss: 1086.4158 - mse: 1086.4158 - mae: 22.0298\n",
      "Epoch 41/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1086.1277 - mse: 1086.1279 - mae: 22.0440\n",
      "Epoch 42/60\n",
      "3699/3699 [==============================] - 3s 934us/step - loss: 1085.3916 - mse: 1085.3916 - mae: 22.0785\n",
      "Epoch 43/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1090.6035 - mse: 1090.6033 - mae: 22.0746\n",
      "Epoch 44/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1087.9849 - mse: 1087.9851 - mae: 22.0983\n",
      "Epoch 45/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1083.9873 - mse: 1083.9873 - mae: 21.9997\n",
      "Epoch 46/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1080.5704 - mse: 1080.5704 - mae: 22.0341\n",
      "Epoch 47/60\n",
      "3699/3699 [==============================] - 4s 973us/step - loss: 1082.4498 - mse: 1082.4497 - mae: 21.9213\n",
      "Epoch 48/60\n",
      "3699/3699 [==============================] - ETA: 0s - loss: 1074.0103 - mse: 1074.0101 - mae: 21.89 - 4s 1ms/step - loss: 1074.6632 - mse: 1074.6632 - mae: 21.9209\n",
      "Epoch 49/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1081.6630 - mse: 1081.6630 - mae: 21.8827\n",
      "Epoch 50/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1081.7775 - mse: 1081.7777 - mae: 21.9954: 1s - los\n",
      "Epoch 51/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1083.2198 - mse: 1083.2198 - mae: 21.9688\n",
      "Epoch 52/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1079.3481 - mse: 1079.3484 - mae: 21.9758\n",
      "Epoch 53/60\n",
      "3699/3699 [==============================] - 4s 974us/step - loss: 1080.0119 - mse: 1080.0118 - mae: 21.8847\n",
      "Epoch 54/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1075.2362 - mse: 1075.2361 - mae: 21.9320\n",
      "Epoch 55/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1076.1707 - mse: 1076.1705 - mae: 21.9402\n",
      "Epoch 56/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1074.3945 - mse: 1074.3945 - mae: 21.7879\n",
      "Epoch 57/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1076.4364 - mse: 1076.4363 - mae: 21.8548\n",
      "Epoch 58/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1071.9749 - mse: 1071.9751 - mae: 21.7953\n",
      "Epoch 59/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1071.5286 - mse: 1071.5291 - mae: 21.7936: 2s\n",
      "Epoch 60/60\n",
      "3699/3699 [==============================] - 4s 967us/step - loss: 1073.1767 - mse: 1073.1766 - mae: 21.8838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=60)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "5548/5548 [==============================] - 16s 3ms/step - loss: 3054.4703 - mse: 3054.4697 - mae: 35.0047\n",
      "Epoch 2/60\n",
      "5548/5548 [==============================] - 7s 1ms/step - loss: 1691.4818 - mse: 1691.4812 - mae: 25.2216\n",
      "Epoch 3/60\n",
      "5548/5548 [==============================] - 0s 55us/step - loss: 1678.8765 - mse: 1678.8762 - mae: 25.0197\n",
      "Epoch 4/60\n",
      "5548/5548 [==============================] - 0s 55us/step - loss: 1663.9924 - mse: 1663.9924 - mae: 25.0003\n",
      "Epoch 5/60\n",
      "5548/5548 [==============================] - 0s 55us/step - loss: 1652.1263 - mse: 1652.1262 - mae: 24.8981\n",
      "Epoch 6/60\n",
      "5548/5548 [==============================] - 0s 55us/step - loss: 1651.4197 - mse: 1651.4198 - mae: 24.8497\n",
      "Epoch 7/60\n",
      "5548/5548 [==============================] - 0s 55us/step - loss: 1639.4080 - mse: 1639.4081 - mae: 24.7434\n",
      "Epoch 8/60\n",
      "5548/5548 [==============================] - 0s 55us/step - loss: 1643.8083 - mse: 1643.8087 - mae: 24.7516\n",
      "Epoch 9/60\n",
      "5548/5548 [==============================] - 0s 55us/step - loss: 1646.0287 - mse: 1646.0284 - mae: 24.7015\n",
      "Epoch 10/60\n",
      "5548/5548 [==============================] - 0s 55us/step - loss: 1642.4509 - mse: 1642.4512 - mae: 24.7324\n",
      "Epoch 11/60\n",
      "5548/5548 [==============================] - 0s 55us/step - loss: 1640.9674 - mse: 1640.9675 - mae: 24.5869\n",
      "Epoch 12/60\n",
      "5548/5548 [==============================] - 0s 55us/step - loss: 1635.2172 - mse: 1635.2178 - mae: 24.6590\n",
      "Epoch 13/60\n",
      "5548/5548 [==============================] - 0s 54us/step - loss: 1631.4343 - mse: 1631.4347 - mae: 24.5482\n",
      "Epoch 14/60\n",
      "5548/5548 [==============================] - 0s 55us/step - loss: 1634.6322 - mse: 1634.6327 - mae: 24.6402\n",
      "Epoch 15/60\n",
      "5548/5548 [==============================] - 0s 55us/step - loss: 1631.2677 - mse: 1631.2678 - mae: 24.5475\n",
      "Epoch 16/60\n",
      "5548/5548 [==============================] - 0s 55us/step - loss: 1629.1091 - mse: 1629.1090 - mae: 24.5615\n",
      "Epoch 17/60\n",
      "5548/5548 [==============================] - 0s 56us/step - loss: 1629.6472 - mse: 1629.6475 - mae: 24.5278\n",
      "Epoch 18/60\n",
      "5548/5548 [==============================] - 0s 55us/step - loss: 1629.9600 - mse: 1629.9603 - mae: 24.6117\n",
      "Epoch 19/60\n",
      "5548/5548 [==============================] - 0s 78us/step - loss: 1628.6610 - mse: 1628.6610 - mae: 24.4761\n",
      "Epoch 20/60\n",
      "5548/5548 [==============================] - 0s 77us/step - loss: 1625.8355 - mse: 1625.8358 - mae: 24.4511\n",
      "Epoch 21/60\n",
      "5548/5548 [==============================] - 0s 80us/step - loss: 1619.1427 - mse: 1619.1431 - mae: 24.4227\n",
      "Epoch 22/60\n",
      "5548/5548 [==============================] - 0s 80us/step - loss: 1616.2927 - mse: 1616.2924 - mae: 24.3368\n",
      "Epoch 23/60\n",
      "5548/5548 [==============================] - 0s 79us/step - loss: 1611.8086 - mse: 1611.8082 - mae: 24.4262\n",
      "Epoch 24/60\n",
      "5548/5548 [==============================] - 0s 80us/step - loss: 1615.4432 - mse: 1615.4432 - mae: 24.2749\n",
      "Epoch 25/60\n",
      "5548/5548 [==============================] - 0s 79us/step - loss: 1617.3532 - mse: 1617.3540 - mae: 24.3637\n",
      "Epoch 26/60\n",
      "5548/5548 [==============================] - 0s 81us/step - loss: 1609.5159 - mse: 1609.5155 - mae: 24.2362\n",
      "Epoch 27/60\n",
      "5548/5548 [==============================] - 0s 80us/step - loss: 1608.9775 - mse: 1608.9774 - mae: 24.2231\n",
      "Epoch 28/60\n",
      "5548/5548 [==============================] - 0s 79us/step - loss: 1611.8394 - mse: 1611.8392 - mae: 24.2202\n",
      "Epoch 29/60\n",
      "5548/5548 [==============================] - 0s 81us/step - loss: 1612.5368 - mse: 1612.5363 - mae: 24.2860\n",
      "Epoch 30/60\n",
      "5548/5548 [==============================] - 1s 135us/step - loss: 1599.9127 - mse: 1599.9130 - mae: 24.0789\n",
      "Epoch 31/60\n",
      "5548/5548 [==============================] - 1s 157us/step - loss: 1602.7049 - mse: 1602.7046 - mae: 24.1733\n",
      "Epoch 32/60\n",
      "5548/5548 [==============================] - 1s 150us/step - loss: 1599.4589 - mse: 1599.4591 - mae: 24.1133\n",
      "Epoch 33/60\n",
      "5548/5548 [==============================] - 1s 149us/step - loss: 1595.5092 - mse: 1595.5094 - mae: 24.0289\n",
      "Epoch 34/60\n",
      "5548/5548 [==============================] - 1s 147us/step - loss: 1596.5271 - mse: 1596.5276 - mae: 24.0726\n",
      "Epoch 35/60\n",
      "5548/5548 [==============================] - 1s 154us/step - loss: 1590.4441 - mse: 1590.4441 - mae: 24.0515\n",
      "Epoch 36/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1596.2152 - mse: 1596.2152 - mae: 24.0870\n",
      "Epoch 37/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1590.6143 - mse: 1590.6146 - mae: 23.9779: 4s\n",
      "Epoch 38/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1589.4164 - mse: 1589.4165 - mae: 23.9433\n",
      "Epoch 39/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1586.6436 - mse: 1586.6433 - mae: 23.9620\n",
      "Epoch 40/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1589.2459 - mse: 1589.2458 - mae: 23.9720\n",
      "Epoch 41/60\n",
      "5548/5548 [==============================] - 6s 1000us/step - loss: 1583.7575 - mse: 1583.7577 - mae: 23.9238\n",
      "Epoch 42/60\n",
      "5548/5548 [==============================] - 6s 997us/step - loss: 1583.3946 - mse: 1583.3948 - mae: 23.8904\n",
      "Epoch 43/60\n",
      "5548/5548 [==============================] - 7s 1ms/step - loss: 1585.7105 - mse: 1585.7111 - mae: 23.9714: 0s - loss: 1653.8014 - mse: 1653\n",
      "Epoch 44/60\n",
      "5548/5548 [==============================] - 6s 993us/step - loss: 1580.9736 - mse: 1580.9735 - mae: 23.9255\n",
      "Epoch 45/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1585.5369 - mse: 1585.5364 - mae: 23.8786: 0s - loss: 1657.2394 - mse: \n",
      "Epoch 46/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1579.5974 - mse: 1579.5977 - mae: 23.9248\n",
      "Epoch 47/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1576.5146 - mse: 1576.5148 - mae: 23.8679\n",
      "Epoch 48/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1572.9742 - mse: 1572.9746 - mae: 23.8330\n",
      "Epoch 49/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1568.8132 - mse: 1568.8132 - mae: 23.7873\n",
      "Epoch 50/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1582.3399 - mse: 1582.3401 - mae: 23.9539\n",
      "Epoch 51/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1569.2252 - mse: 1569.2253 - mae: 23.7894\n",
      "Epoch 52/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1572.1481 - mse: 1572.1483 - mae: 23.7261\n",
      "Epoch 53/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1575.7174 - mse: 1575.7178 - mae: 23.8266\n",
      "Epoch 54/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1569.9453 - mse: 1569.9456 - mae: 23.7791\n",
      "Epoch 55/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1559.2609 - mse: 1559.2612 - mae: 23.7234\n",
      "Epoch 56/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1567.5012 - mse: 1567.5007 - mae: 23.7278: 1s - loss: 1641.43\n",
      "Epoch 57/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1566.9086 - mse: 1566.9086 - mae: 23.8010\n",
      "Epoch 58/60\n",
      "5548/5548 [==============================] - 5s 978us/step - loss: 1562.9204 - mse: 1562.9207 - mae: 23.7825\n",
      "Epoch 59/60\n",
      "5548/5548 [==============================] - 5s 978us/step - loss: 1559.5347 - mse: 1559.5347 - mae: 23.7559\n",
      "Epoch 60/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1551.8684 - mse: 1551.8684 - mae: 23.6312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=60)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "7397/7397 [==============================] - 19s 3ms/step - loss: 2603.8244 - mse: 2603.8245 - mae: 32.9208\n",
      "Epoch 2/60\n",
      "7397/7397 [==============================] - 7s 989us/step - loss: 1609.9505 - mse: 1609.9504 - mae: 25.2970\n",
      "Epoch 3/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1590.3724 - mse: 1590.3724 - mae: 25.1590\n",
      "Epoch 4/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1585.9899 - mse: 1585.9896 - mae: 25.1588\n",
      "Epoch 5/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1582.9376 - mse: 1582.9370 - mae: 25.0532\n",
      "Epoch 6/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1577.7028 - mse: 1577.7029 - mae: 24.9982\n",
      "Epoch 7/60\n",
      "7397/7397 [==============================] - 7s 1ms/step - loss: 1577.7018 - mse: 1577.7018 - mae: 24.8810\n",
      "Epoch 8/60\n",
      "7397/7397 [==============================] - 9s 1ms/step - loss: 1570.5489 - mse: 1570.5485 - mae: 24.9316\n",
      "Epoch 9/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1573.9985 - mse: 1573.9990 - mae: 24.9413\n",
      "Epoch 10/60\n",
      "7397/7397 [==============================] - 9s 1ms/step - loss: 1569.1981 - mse: 1569.1979 - mae: 24.8561: 0s - loss: 1546.2625 - mse: 1546.2625 - \n",
      "Epoch 11/60\n",
      "7397/7397 [==============================] - 9s 1ms/step - loss: 1566.4045 - mse: 1566.4042 - mae: 24.8409\n",
      "Epoch 12/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1560.8276 - mse: 1560.8279 - mae: 24.7610\n",
      "Epoch 13/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1563.6581 - mse: 1563.6581 - mae: 24.7260\n",
      "Epoch 14/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1563.7924 - mse: 1563.7922 - mae: 24.8157\n",
      "Epoch 15/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1561.8448 - mse: 1561.8453 - mae: 24.7519\n",
      "Epoch 16/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1559.5493 - mse: 1559.5493 - mae: 24.7565\n",
      "Epoch 17/60\n",
      "7397/7397 [==============================] - 7s 949us/step - loss: 1550.4348 - mse: 1550.4348 - mae: 24.6453\n",
      "Epoch 18/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1551.2553 - mse: 1551.2549 - mae: 24.6755\n",
      "Epoch 19/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1545.9191 - mse: 1545.9194 - mae: 24.5963\n",
      "Epoch 20/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1548.7705 - mse: 1548.7700 - mae: 24.5618\n",
      "Epoch 21/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1543.9610 - mse: 1543.9609 - mae: 24.5010\n",
      "Epoch 22/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1545.9220 - mse: 1545.9218 - mae: 24.6221\n",
      "Epoch 23/60\n",
      "7397/7397 [==============================] - 7s 993us/step - loss: 1535.8594 - mse: 1535.8593 - mae: 24.4593\n",
      "Epoch 24/60\n",
      "7397/7397 [==============================] - 7s 994us/step - loss: 1539.0606 - mse: 1539.0613 - mae: 24.4579\n",
      "Epoch 25/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1537.6618 - mse: 1537.6615 - mae: 24.3967\n",
      "Epoch 26/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1535.7913 - mse: 1535.7911 - mae: 24.4097: 2s - loss: 1610.2190 - mse: 1610.2190  - E\n",
      "Epoch 27/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1530.6959 - mse: 1530.6960 - mae: 24.3099\n",
      "Epoch 28/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1531.3886 - mse: 1531.3887 - mae: 24.4043\n",
      "Epoch 29/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1529.0335 - mse: 1529.0332 - mae: 24.2804\n",
      "Epoch 30/60\n",
      "7397/7397 [==============================] - 9s 1ms/step - loss: 1522.8627 - mse: 1522.8622 - mae: 24.2056\n",
      "Epoch 31/60\n",
      "7397/7397 [==============================] - 7s 950us/step - loss: 1521.2507 - mse: 1521.2509 - mae: 24.2170\n",
      "Epoch 32/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1521.3300 - mse: 1521.3298 - mae: 24.1976\n",
      "Epoch 33/60\n",
      "7397/7397 [==============================] - 7s 983us/step - loss: 1519.2844 - mse: 1519.2839 - mae: 24.2088\n",
      "Epoch 34/60\n",
      "7397/7397 [==============================] - 7s 989us/step - loss: 1518.8502 - mse: 1518.8501 - mae: 24.2490\n",
      "Epoch 35/60\n",
      "7397/7397 [==============================] - 7s 1ms/step - loss: 1522.0092 - mse: 1522.0090 - mae: 24.1494\n",
      "Epoch 36/60\n",
      "7397/7397 [==============================] - 7s 1ms/step - loss: 1516.1327 - mse: 1516.1326 - mae: 24.0673\n",
      "Epoch 37/60\n",
      "7397/7397 [==============================] - 7s 970us/step - loss: 1513.5156 - mse: 1513.5156 - mae: 24.1196\n",
      "Epoch 38/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1515.2052 - mse: 1515.2054 - mae: 24.1797\n",
      "Epoch 39/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1512.8813 - mse: 1512.8812 - mae: 24.1286\n",
      "Epoch 40/60\n",
      "7397/7397 [==============================] - 7s 953us/step - loss: 1507.0574 - mse: 1507.0576 - mae: 24.0143\n",
      "Epoch 41/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1510.9428 - mse: 1510.9429 - mae: 24.0596\n",
      "Epoch 42/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1503.4704 - mse: 1503.4705 - mae: 24.0347\n",
      "Epoch 43/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1503.2059 - mse: 1503.2059 - mae: 24.0487: 0s - loss: 1535.1689 - mse: 1535.1\n",
      "Epoch 44/60\n",
      "7397/7397 [==============================] - 7s 971us/step - loss: 1499.9298 - mse: 1499.9299 - mae: 23.9450\n",
      "Epoch 45/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1502.2391 - mse: 1502.2389 - mae: 23.9526\n",
      "Epoch 46/60\n",
      "7397/7397 [==============================] - 9s 1ms/step - loss: 1490.3383 - mse: 1490.3381 - mae: 23.8089\n",
      "Epoch 47/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1494.4535 - mse: 1494.4536 - mae: 23.8990\n",
      "Epoch 48/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1486.8821 - mse: 1486.8816 - mae: 23.8404\n",
      "Epoch 49/60\n",
      "7397/7397 [==============================] - 7s 972us/step - loss: 1496.0304 - mse: 1496.0306 - mae: 23.9334\n",
      "Epoch 50/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1489.1672 - mse: 1489.1675 - mae: 23.9345\n",
      "Epoch 51/60\n",
      "7397/7397 [==============================] - 7s 956us/step - loss: 1486.9988 - mse: 1486.9990 - mae: 23.8371\n",
      "Epoch 52/60\n",
      "7397/7397 [==============================] - 7s 1ms/step - loss: 1486.0576 - mse: 1486.0574 - mae: 23.7987\n",
      "Epoch 53/60\n",
      "7397/7397 [==============================] - 9s 1ms/step - loss: 1478.8841 - mse: 1478.8843 - mae: 23.7705\n",
      "Epoch 54/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1479.9221 - mse: 1479.9221 - mae: 23.8031\n",
      "Epoch 55/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1482.7061 - mse: 1482.7058 - mae: 23.7329\n",
      "Epoch 56/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1485.9887 - mse: 1485.9884 - mae: 23.8683\n",
      "Epoch 57/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1482.1014 - mse: 1482.1014 - mae: 23.7033: 3s - loss: 1771.6715 - mse: 17\n",
      "Epoch 58/60\n",
      "7397/7397 [==============================] - 7s 939us/step - loss: 1479.7116 - mse: 1479.7114 - mae: 23.7052\n",
      "Epoch 59/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1469.5288 - mse: 1469.5292 - mae: 23.7238\n",
      "Epoch 60/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1474.5105 - mse: 1474.5101 - mae: 23.7687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=50)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "1850/1850 [==============================] - 9s 5ms/step - loss: 7169.1685 - mse: 7169.1689 - mae: 72.4191 ETA: 16s - loss: 12417.0298 - mse\n",
      "Epoch 2/60\n",
      "1850/1850 [==============================] - 2s 956us/step - loss: 1068.9034 - mse: 1068.9033 - mae: 22.8135\n",
      "Epoch 3/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 1034.0223 - mse: 1034.0222 - mae: 22.2778\n",
      "Epoch 4/60\n",
      "1850/1850 [==============================] - 2s 913us/step - loss: 1038.3057 - mse: 1038.3057 - mae: 22.5095\n",
      "Epoch 5/60\n",
      "1850/1850 [==============================] - 2s 911us/step - loss: 1025.7279 - mse: 1025.7279 - mae: 22.1318\n",
      "Epoch 6/60\n",
      "1850/1850 [==============================] - 2s 932us/step - loss: 1030.0098 - mse: 1030.0099 - mae: 22.1399\n",
      "Epoch 7/60\n",
      "1850/1850 [==============================] - 2s 887us/step - loss: 1021.3649 - mse: 1021.3649 - mae: 22.0440\n",
      "Epoch 8/60\n",
      "1850/1850 [==============================] - 2s 867us/step - loss: 1027.6050 - mse: 1027.6050 - mae: 22.0305\n",
      "Epoch 9/60\n",
      "1850/1850 [==============================] - 2s 890us/step - loss: 1019.7183 - mse: 1019.7182 - mae: 21.9133\n",
      "Epoch 10/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 1016.7565 - mse: 1016.7565 - mae: 21.9181\n",
      "Epoch 11/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 1019.3025 - mse: 1019.3026 - mae: 21.7835\n",
      "Epoch 12/60\n",
      "1850/1850 [==============================] - ETA: 0s - loss: 1021.6067 - mse: 1021.6066 - mae: 21.69 - 2s 891us/step - loss: 1018.3248 - mse: 1018.3247 - mae: 21.7386\n",
      "Epoch 13/60\n",
      "1850/1850 [==============================] - 2s 910us/step - loss: 1014.8494 - mse: 1014.8496 - mae: 21.7857\n",
      "Epoch 14/60\n",
      "1850/1850 [==============================] - 2s 912us/step - loss: 1012.6465 - mse: 1012.6464 - mae: 21.6619\n",
      "Epoch 15/60\n",
      "1850/1850 [==============================] - 2s 910us/step - loss: 1016.9114 - mse: 1016.9115 - mae: 21.8085\n",
      "Epoch 16/60\n",
      "1850/1850 [==============================] - 2s 931us/step - loss: 1015.4550 - mse: 1015.4549 - mae: 21.7725\n",
      "Epoch 17/60\n",
      "1850/1850 [==============================] - 2s 890us/step - loss: 1015.8972 - mse: 1015.8973 - mae: 21.7084\n",
      "Epoch 18/60\n",
      "1850/1850 [==============================] - 2s 998us/step - loss: 1020.3900 - mse: 1020.3899 - mae: 21.7128\n",
      "Epoch 19/60\n",
      "1850/1850 [==============================] - 2s 993us/step - loss: 1012.8072 - mse: 1012.8073 - mae: 21.6152\n",
      "Epoch 20/60\n",
      "1850/1850 [==============================] - 2s 977us/step - loss: 1022.7992 - mse: 1022.7991 - mae: 21.6940\n",
      "Epoch 21/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 1003.9717 - mse: 1003.9716 - mae: 21.4728\n",
      "Epoch 22/60\n",
      "1850/1850 [==============================] - 2s 972us/step - loss: 1005.6239 - mse: 1005.6237 - mae: 21.3868\n",
      "Epoch 23/60\n",
      "1850/1850 [==============================] - 2s 911us/step - loss: 1010.5947 - mse: 1010.5948 - mae: 21.5264\n",
      "Epoch 24/60\n",
      "1850/1850 [==============================] - 2s 933us/step - loss: 1006.1178 - mse: 1006.1181 - mae: 21.5876\n",
      "Epoch 25/60\n",
      "1850/1850 [==============================] - 2s 973us/step - loss: 997.0309 - mse: 997.0308 - mae: 21.2870\n",
      "Epoch 26/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 999.0865 - mse: 999.0865 - mae: 21.3195\n",
      "Epoch 27/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 998.2977 - mse: 998.2978 - mae: 21.2368\n",
      "Epoch 28/60\n",
      "1850/1850 [==============================] - 2s 930us/step - loss: 1014.4279 - mse: 1014.4280 - mae: 21.4690\n",
      "Epoch 29/60\n",
      "1850/1850 [==============================] - 2s 950us/step - loss: 1006.1741 - mse: 1006.1741 - mae: 21.3917\n",
      "Epoch 30/60\n",
      "1850/1850 [==============================] - 2s 911us/step - loss: 999.7821 - mse: 999.7821 - mae: 21.1783\n",
      "Epoch 31/60\n",
      "1850/1850 [==============================] - 2s 868us/step - loss: 993.7323 - mse: 993.7322 - mae: 21.3634\n",
      "Epoch 32/60\n",
      "1850/1850 [==============================] - 2s 930us/step - loss: 993.4889 - mse: 993.4889 - mae: 21.1682\n",
      "Epoch 33/60\n",
      "1850/1850 [==============================] - 2s 976us/step - loss: 992.6948 - mse: 992.6947 - mae: 21.3051\n",
      "Epoch 34/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 998.7357 - mse: 998.7356 - mae: 21.1568\n",
      "Epoch 35/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 986.3424 - mse: 986.3423 - mae: 21.1167\n",
      "Epoch 36/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 988.5909 - mse: 988.5908 - mae: 21.0768\n",
      "Epoch 37/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 983.4893 - mse: 983.4893 - mae: 21.0452\n",
      "Epoch 38/60\n",
      "1850/1850 [==============================] - 2s 955us/step - loss: 984.1909 - mse: 984.1910 - mae: 20.9484\n",
      "Epoch 39/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 984.2628 - mse: 984.2628 - mae: 21.1663\n",
      "Epoch 40/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 996.4178 - mse: 996.4179 - mae: 21.2734TA: 1s - loss: 1150.2390 - mse: \n",
      "Epoch 41/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 978.5403 - mse: 978.5403 - mae: 20.9519\n",
      "Epoch 42/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 983.7481 - mse: 983.7482 - mae: 21.1127\n",
      "Epoch 43/60\n",
      "1850/1850 [==============================] - 2s 976us/step - loss: 984.4101 - mse: 984.4101 - mae: 20.8804\n",
      "Epoch 44/60\n",
      "1850/1850 [==============================] - 2s 952us/step - loss: 977.1758 - mse: 977.1759 - mae: 20.9032\n",
      "Epoch 45/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 977.4091 - mse: 977.4091 - mae: 21.0752\n",
      "Epoch 46/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 997.2775 - mse: 997.2774 - mae: 21.0553\n",
      "Epoch 47/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 972.8200 - mse: 972.8200 - mae: 20.8696: 0s - loss: 851.1511 - mse: 8\n",
      "Epoch 48/60\n",
      "1850/1850 [==============================] - ETA: 0s - loss: 977.5871 - mse: 977.5870 - mae: 20.97 - 2s 1ms/step - loss: 972.7628 - mse: 972.7628 - mae: 20.9191\n",
      "Epoch 49/60\n",
      "1850/1850 [==============================] - 2s 956us/step - loss: 981.8833 - mse: 981.8833 - mae: 20.90990s - loss: 941.2101 - ms\n",
      "Epoch 50/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 973.7458 - mse: 973.7457 - mae: 20.7772\n",
      "Epoch 51/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 983.4650 - mse: 983.4648 - mae: 21.0455\n",
      "Epoch 52/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 972.7614 - mse: 972.7615 - mae: 20.6963\n",
      "Epoch 53/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 972.2652 - mse: 972.2651 - mae: 20.9499\n",
      "Epoch 54/60\n",
      "1850/1850 [==============================] - 2s 885us/step - loss: 966.7981 - mse: 966.7981 - mae: 20.7401\n",
      "Epoch 55/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 965.8366 - mse: 965.8366 - mae: 20.8874\n",
      "Epoch 56/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 970.2653 - mse: 970.2652 - mae: 20.7636\n",
      "Epoch 57/60\n",
      "1850/1850 [==============================] - 2s 995us/step - loss: 966.2123 - mse: 966.2123 - mae: 20.5923\n",
      "Epoch 58/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 976.1442 - mse: 976.1441 - mae: 20.8628\n",
      "Epoch 59/60\n",
      "1850/1850 [==============================] - 2s 973us/step - loss: 964.0605 - mse: 964.0604 - mae: 20.7455\n",
      "Epoch 60/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 974.0876 - mse: 974.0876 - mae: 20.7692: 0s - loss: 764.7520 - mse:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=50)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "3699/3699 [==============================] - 11s 3ms/step - loss: 4784.9014 - mse: 4784.9019 - mae: 51.9730\n",
      "Epoch 2/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1142.7399 - mse: 1142.7402 - mae: 23.0398\n",
      "Epoch 3/60\n",
      "3699/3699 [==============================] - 3s 877us/step - loss: 1133.7049 - mse: 1133.7050 - mae: 22.8760\n",
      "Epoch 4/60\n",
      "3699/3699 [==============================] - 3s 833us/step - loss: 1129.3667 - mse: 1129.3668 - mae: 22.8035\n",
      "Epoch 5/60\n",
      "3699/3699 [==============================] - 4s 962us/step - loss: 1124.9657 - mse: 1124.9657 - mae: 22.84320s - loss: 1110.9385 - m\n",
      "Epoch 6/60\n",
      "3699/3699 [==============================] - 3s 942us/step - loss: 1129.2267 - mse: 1129.2267 - mae: 22.8133\n",
      "Epoch 7/60\n",
      "3699/3699 [==============================] - 3s 911us/step - loss: 1118.5702 - mse: 1118.5702 - mae: 22.7349\n",
      "Epoch 8/60\n",
      "3699/3699 [==============================] - 4s 987us/step - loss: 1124.7613 - mse: 1124.7612 - mae: 22.6882\n",
      "Epoch 9/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1129.3667 - mse: 1129.3667 - mae: 22.6411\n",
      "Epoch 10/60\n",
      "3699/3699 [==============================] - 4s 953us/step - loss: 1128.0175 - mse: 1128.0173 - mae: 22.8405\n",
      "Epoch 11/60\n",
      "3699/3699 [==============================] - 4s 973us/step - loss: 1119.4222 - mse: 1119.4220 - mae: 22.6364\n",
      "Epoch 12/60\n",
      "3699/3699 [==============================] - 4s 962us/step - loss: 1115.0180 - mse: 1115.0179 - mae: 22.5776\n",
      "Epoch 13/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1117.1322 - mse: 1117.1321 - mae: 22.6122\n",
      "Epoch 14/60\n",
      "3699/3699 [==============================] - 4s 996us/step - loss: 1115.5907 - mse: 1115.5906 - mae: 22.5850\n",
      "Epoch 15/60\n",
      "3699/3699 [==============================] - 3s 931us/step - loss: 1107.0436 - mse: 1107.0435 - mae: 22.4910\n",
      "Epoch 16/60\n",
      "3699/3699 [==============================] - 3s 944us/step - loss: 1111.4586 - mse: 1111.4587 - mae: 22.4840\n",
      "Epoch 17/60\n",
      "3699/3699 [==============================] - 4s 995us/step - loss: 1111.3798 - mse: 1111.3799 - mae: 22.5578\n",
      "Epoch 18/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1109.3650 - mse: 1109.3647 - mae: 22.4593\n",
      "Epoch 19/60\n",
      "3699/3699 [==============================] - 3s 932us/step - loss: 1109.9781 - mse: 1109.9781 - mae: 22.5687\n",
      "Epoch 20/60\n",
      "3699/3699 [==============================] - 4s 997us/step - loss: 1111.8014 - mse: 1111.8011 - mae: 22.49660s - loss: 1125.9008 - mse: 1125.9005 - ma\n",
      "Epoch 21/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1104.4176 - mse: 1104.4178 - mae: 22.4317: 2s - loss: 1201.5872 - mse: 12 - ETA: 1s - loss: 1006.4589 - mse: 1006 - ETA: 1s - loss: 1049.5011\n",
      "Epoch 22/60\n",
      "3699/3699 [==============================] - 4s 997us/step - loss: 1109.3843 - mse: 1109.3843 - mae: 22.4818\n",
      "Epoch 23/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1104.9787 - mse: 1104.9785 - mae: 22.4244\n",
      "Epoch 24/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1111.4058 - mse: 1111.4060 - mae: 22.4279\n",
      "Epoch 25/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1104.7241 - mse: 1104.7240 - mae: 22.4901\n",
      "Epoch 26/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1104.2479 - mse: 1104.2478 - mae: 22.3822\n",
      "Epoch 27/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1113.9224 - mse: 1113.9224 - mae: 22.4374\n",
      "Epoch 28/60\n",
      "3699/3699 [==============================] - 3s 884us/step - loss: 1102.8042 - mse: 1102.8041 - mae: 22.3980\n",
      "Epoch 29/60\n",
      "3699/3699 [==============================] - 0s 52us/step - loss: 1112.6326 - mse: 1112.6323 - mae: 22.5432\n",
      "Epoch 30/60\n",
      "3699/3699 [==============================] - 0s 52us/step - loss: 1098.7232 - mse: 1098.7233 - mae: 22.2761\n",
      "Epoch 31/60\n",
      "3699/3699 [==============================] - 0s 52us/step - loss: 1097.7300 - mse: 1097.7303 - mae: 22.2731\n",
      "Epoch 32/60\n",
      "3699/3699 [==============================] - 0s 52us/step - loss: 1098.2594 - mse: 1098.2592 - mae: 22.3431\n",
      "Epoch 33/60\n",
      "3699/3699 [==============================] - 0s 52us/step - loss: 1099.4341 - mse: 1099.4342 - mae: 22.1691\n",
      "Epoch 34/60\n",
      "3699/3699 [==============================] - 0s 52us/step - loss: 1101.8344 - mse: 1101.8344 - mae: 22.3458\n",
      "Epoch 35/60\n",
      "3699/3699 [==============================] - 0s 53us/step - loss: 1098.1767 - mse: 1098.1766 - mae: 22.2421\n",
      "Epoch 36/60\n",
      "3699/3699 [==============================] - 0s 52us/step - loss: 1089.3442 - mse: 1089.3442 - mae: 22.2786\n",
      "Epoch 37/60\n",
      "3699/3699 [==============================] - 0s 52us/step - loss: 1096.4535 - mse: 1096.4535 - mae: 22.2288\n",
      "Epoch 38/60\n",
      "3699/3699 [==============================] - 0s 52us/step - loss: 1093.9056 - mse: 1093.9054 - mae: 22.2505\n",
      "Epoch 39/60\n",
      "3699/3699 [==============================] - 0s 52us/step - loss: 1095.7644 - mse: 1095.7644 - mae: 22.2669\n",
      "Epoch 40/60\n",
      "3699/3699 [==============================] - 0s 52us/step - loss: 1095.0535 - mse: 1095.0533 - mae: 22.1257\n",
      "Epoch 41/60\n",
      "3699/3699 [==============================] - 0s 52us/step - loss: 1090.5605 - mse: 1090.5603 - mae: 22.1685\n",
      "Epoch 42/60\n",
      "3699/3699 [==============================] - 0s 52us/step - loss: 1095.2989 - mse: 1095.2992 - mae: 22.2365\n",
      "Epoch 43/60\n",
      "3699/3699 [==============================] - 0s 52us/step - loss: 1099.8603 - mse: 1099.8605 - mae: 22.1839\n",
      "Epoch 44/60\n",
      "3699/3699 [==============================] - 0s 52us/step - loss: 1094.9199 - mse: 1094.9202 - mae: 22.1710\n",
      "Epoch 45/60\n",
      "3699/3699 [==============================] - 0s 52us/step - loss: 1095.1531 - mse: 1095.1532 - mae: 22.2429\n",
      "Epoch 46/60\n",
      "3699/3699 [==============================] - 0s 52us/step - loss: 1094.2295 - mse: 1094.2295 - mae: 22.1178\n",
      "Epoch 47/60\n",
      "3699/3699 [==============================] - 0s 53us/step - loss: 1094.4753 - mse: 1094.4752 - mae: 22.1828\n",
      "Epoch 48/60\n",
      "3699/3699 [==============================] - 0s 52us/step - loss: 1091.5169 - mse: 1091.5168 - mae: 22.1921\n",
      "Epoch 49/60\n",
      "3699/3699 [==============================] - 0s 52us/step - loss: 1094.3921 - mse: 1094.3922 - mae: 22.1740\n",
      "Epoch 50/60\n",
      "3699/3699 [==============================] - 0s 52us/step - loss: 1089.4988 - mse: 1089.4985 - mae: 22.0699\n",
      "Epoch 51/60\n",
      "3699/3699 [==============================] - 0s 52us/step - loss: 1095.1492 - mse: 1095.1489 - mae: 22.1902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=50)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "5548/5548 [==============================] - 1s 260us/step - loss: 4156.8840 - mse: 4156.8838 - mae: 44.2611\n",
      "Epoch 2/60\n",
      "5548/5548 [==============================] - 0s 77us/step - loss: 1688.1594 - mse: 1688.1595 - mae: 25.2870\n",
      "Epoch 3/60\n",
      "5548/5548 [==============================] - 0s 76us/step - loss: 1686.0408 - mse: 1686.0413 - mae: 25.2422\n",
      "Epoch 4/60\n",
      "5548/5548 [==============================] - 0s 77us/step - loss: 1690.2954 - mse: 1690.2953 - mae: 25.2507\n",
      "Epoch 5/60\n",
      "5548/5548 [==============================] - 0s 78us/step - loss: 1680.5315 - mse: 1680.5319 - mae: 25.2422\n",
      "Epoch 6/60\n",
      "5548/5548 [==============================] - 0s 77us/step - loss: 1674.4389 - mse: 1674.4388 - mae: 25.1851\n",
      "Epoch 7/60\n",
      "5548/5548 [==============================] - 0s 76us/step - loss: 1670.1913 - mse: 1670.1917 - mae: 25.0213\n",
      "Epoch 8/60\n",
      "5548/5548 [==============================] - 0s 76us/step - loss: 1662.8426 - mse: 1662.8431 - mae: 25.0343\n",
      "Epoch 9/60\n",
      "5548/5548 [==============================] - 1s 114us/step - loss: 1662.3271 - mse: 1662.3273 - mae: 24.9924\n",
      "Epoch 10/60\n",
      "5548/5548 [==============================] - 1s 144us/step - loss: 1656.1001 - mse: 1656.0997 - mae: 24.9602\n",
      "Epoch 11/60\n",
      "5548/5548 [==============================] - 1s 149us/step - loss: 1654.0039 - mse: 1654.0039 - mae: 24.9515\n",
      "Epoch 12/60\n",
      "5548/5548 [==============================] - 1s 144us/step - loss: 1648.3933 - mse: 1648.3934 - mae: 24.8308\n",
      "Epoch 13/60\n",
      "5548/5548 [==============================] - 1s 141us/step - loss: 1643.1974 - mse: 1643.1971 - mae: 24.8244\n",
      "Epoch 14/60\n",
      "5548/5548 [==============================] - 1s 145us/step - loss: 1640.7423 - mse: 1640.7424 - mae: 24.7777\n",
      "Epoch 15/60\n",
      "5548/5548 [==============================] - 3s 528us/step - loss: 1633.1517 - mse: 1633.1512 - mae: 24.5702\n",
      "Epoch 16/60\n",
      "5548/5548 [==============================] - 5s 926us/step - loss: 1636.4646 - mse: 1636.4637 - mae: 24.73780s - loss: 1584.6014 - mse: 1584.6008 - \n",
      "Epoch 17/60\n",
      "5548/5548 [==============================] - 5s 982us/step - loss: 1629.5558 - mse: 1629.5560 - mae: 24.6614\n",
      "Epoch 18/60\n",
      "5548/5548 [==============================] - 5s 904us/step - loss: 1626.0384 - mse: 1626.0381 - mae: 24.5440\n",
      "Epoch 19/60\n",
      "5548/5548 [==============================] - 5s 925us/step - loss: 1620.9000 - mse: 1620.9000 - mae: 24.5154\n",
      "Epoch 20/60\n",
      "5548/5548 [==============================] - 5s 917us/step - loss: 1619.1561 - mse: 1619.1566 - mae: 24.4805\n",
      "Epoch 21/60\n",
      "5548/5548 [==============================] - 5s 908us/step - loss: 1619.2525 - mse: 1619.2529 - mae: 24.4965\n",
      "Epoch 22/60\n",
      "5548/5548 [==============================] - 5s 974us/step - loss: 1613.8822 - mse: 1613.8821 - mae: 24.3955\n",
      "Epoch 23/60\n",
      "5548/5548 [==============================] - ETA: 0s - loss: 1618.4074 - mse: 1618.4071 - mae: 24.36 - 6s 1ms/step - loss: 1617.0757 - mse: 1617.0756 - mae: 24.3719\n",
      "Epoch 24/60\n",
      "5548/5548 [==============================] - 6s 992us/step - loss: 1610.1079 - mse: 1610.1078 - mae: 24.4957\n",
      "Epoch 25/60\n",
      "5548/5548 [==============================] - 5s 918us/step - loss: 1619.5389 - mse: 1619.5386 - mae: 24.4716\n",
      "Epoch 26/60\n",
      "5548/5548 [==============================] - 5s 909us/step - loss: 1611.2819 - mse: 1611.2814 - mae: 24.3265\n",
      "Epoch 27/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1608.1111 - mse: 1608.1108 - mae: 24.3200\n",
      "Epoch 28/60\n",
      "5548/5548 [==============================] - 5s 918us/step - loss: 1610.8352 - mse: 1610.8347 - mae: 24.30711s - loss: 174\n",
      "Epoch 29/60\n",
      "5548/5548 [==============================] - 5s 976us/step - loss: 1606.0500 - mse: 1606.0498 - mae: 24.29230s - loss: 1251.5493 - mse: \n",
      "Epoch 30/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1603.2679 - mse: 1603.2682 - mae: 24.2502: 0s - loss: 1243.7070 - mse: 12\n",
      "Epoch 31/60\n",
      "5548/5548 [==============================] - 5s 955us/step - loss: 1605.5557 - mse: 1605.5560 - mae: 24.3053\n",
      "Epoch 32/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1604.8892 - mse: 1604.8889 - mae: 24.3051\n",
      "Epoch 33/60\n",
      "5548/5548 [==============================] - 7s 1ms/step - loss: 1604.4098 - mse: 1604.4093 - mae: 24.2589\n",
      "Epoch 34/60\n",
      "5548/5548 [==============================] - 5s 988us/step - loss: 1600.7303 - mse: 1600.7302 - mae: 24.30612s - loss: 1884.8047 - mse: 1884.8046 - mae: 2 - E\n",
      "Epoch 35/60\n",
      "5548/5548 [==============================] - 5s 984us/step - loss: 1611.6718 - mse: 1611.6720 - mae: 24.3428\n",
      "Epoch 36/60\n",
      "5548/5548 [==============================] - 5s 882us/step - loss: 1608.0094 - mse: 1608.0090 - mae: 24.3189\n",
      "Epoch 37/60\n",
      "5548/5548 [==============================] - 5s 968us/step - loss: 1599.6904 - mse: 1599.6907 - mae: 24.1727\n",
      "Epoch 38/60\n",
      "5548/5548 [==============================] - 5s 906us/step - loss: 1602.1319 - mse: 1602.1317 - mae: 24.2879\n",
      "Epoch 39/60\n",
      "5548/5548 [==============================] - 5s 917us/step - loss: 1597.0179 - mse: 1597.0175 - mae: 24.1023\n",
      "Epoch 40/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1599.4974 - mse: 1599.4971 - mae: 24.2606\n",
      "Epoch 41/60\n",
      "5548/5548 [==============================] - 5s 976us/step - loss: 1599.1890 - mse: 1599.1895 - mae: 24.15750s - loss: 1652.9076 - mse: 1652.907\n",
      "Epoch 42/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1595.1978 - mse: 1595.1982 - mae: 24.2027\n",
      "Epoch 43/60\n",
      "5548/5548 [==============================] - 5s 912us/step - loss: 1596.1769 - mse: 1596.1775 - mae: 24.2241\n",
      "Epoch 44/60\n",
      "5548/5548 [==============================] - 5s 896us/step - loss: 1594.8864 - mse: 1594.8861 - mae: 24.1583\n",
      "Epoch 45/60\n",
      "5548/5548 [==============================] - 5s 988us/step - loss: 1589.5953 - mse: 1589.5950 - mae: 24.0508\n",
      "Epoch 46/60\n",
      "5548/5548 [==============================] - 5s 934us/step - loss: 1597.9800 - mse: 1597.9800 - mae: 24.1531\n",
      "Epoch 47/60\n",
      "5548/5548 [==============================] - 5s 926us/step - loss: 1592.3348 - mse: 1592.3348 - mae: 24.0932\n",
      "Epoch 48/60\n",
      "5548/5548 [==============================] - 5s 984us/step - loss: 1592.4143 - mse: 1592.4141 - mae: 24.0131\n",
      "Epoch 49/60\n",
      "5548/5548 [==============================] - 6s 995us/step - loss: 1593.8563 - mse: 1593.8566 - mae: 24.0902\n",
      "Epoch 50/60\n",
      "5548/5548 [==============================] - 5s 948us/step - loss: 1592.4234 - mse: 1592.4233 - mae: 24.1772\n",
      "Epoch 51/60\n",
      "5548/5548 [==============================] - 5s 983us/step - loss: 1593.3704 - mse: 1593.3702 - mae: 24.0827\n",
      "Epoch 52/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1599.3890 - mse: 1599.3892 - mae: 24.1692\n",
      "Epoch 53/60\n",
      "5548/5548 [==============================] - 5s 974us/step - loss: 1584.7492 - mse: 1584.7491 - mae: 24.10831s - loss:\n",
      "Epoch 54/60\n",
      "5548/5548 [==============================] - 5s 882us/step - loss: 1588.5751 - mse: 1588.5746 - mae: 24.0738\n",
      "Epoch 55/60\n",
      "5548/5548 [==============================] - 5s 867us/step - loss: 1589.2394 - mse: 1589.2394 - mae: 24.0060\n",
      "Epoch 56/60\n",
      "5548/5548 [==============================] - 5s 989us/step - loss: 1588.7414 - mse: 1588.7412 - mae: 24.0449\n",
      "Epoch 57/60\n",
      "5548/5548 [==============================] - 5s 968us/step - loss: 1588.9819 - mse: 1588.9818 - mae: 24.1243\n",
      "Epoch 58/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1591.9949 - mse: 1591.9954 - mae: 24.1414\n",
      "Epoch 59/60\n",
      "5548/5548 [==============================] - 5s 962us/step - loss: 1589.0967 - mse: 1589.0968 - mae: 24.0255\n",
      "Epoch 60/60\n",
      "5548/5548 [==============================] - 5s 940us/step - loss: 1591.0033 - mse: 1591.0034 - mae: 23.9733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=50)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "7397/7397 [==============================] - 15s 2ms/step - loss: 3695.8758 - mse: 3695.8772 - mae: 41.0236\n",
      "Epoch 2/60\n",
      "7397/7397 [==============================] - 7s 900us/step - loss: 1616.0526 - mse: 1616.0529 - mae: 25.4345\n",
      "Epoch 3/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1607.9441 - mse: 1607.9445 - mae: 25.4000\n",
      "Epoch 4/60\n",
      "7397/7397 [==============================] - 7s 986us/step - loss: 1602.3850 - mse: 1602.3857 - mae: 25.2259\n",
      "Epoch 5/60\n",
      "7397/7397 [==============================] - 7s 923us/step - loss: 1597.0691 - mse: 1597.0684 - mae: 25.2287\n",
      "Epoch 6/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1588.3000 - mse: 1588.2996 - mae: 25.2586\n",
      "Epoch 7/60\n",
      "7397/7397 [==============================] - 7s 981us/step - loss: 1583.4762 - mse: 1583.4752 - mae: 25.1373\n",
      "Epoch 8/60\n",
      "7397/7397 [==============================] - 7s 1ms/step - loss: 1581.3390 - mse: 1581.3389 - mae: 25.0709\n",
      "Epoch 9/60\n",
      "7397/7397 [==============================] - 7s 945us/step - loss: 1581.1869 - mse: 1581.1870 - mae: 25.1187\n",
      "Epoch 10/60\n",
      "7397/7397 [==============================] - 7s 949us/step - loss: 1575.2912 - mse: 1575.2909 - mae: 25.0298\n",
      "Epoch 11/60\n",
      "7397/7397 [==============================] - 7s 931us/step - loss: 1569.5418 - mse: 1569.5414 - mae: 24.9687\n",
      "Epoch 12/60\n",
      "7397/7397 [==============================] - 7s 952us/step - loss: 1571.7095 - mse: 1571.7094 - mae: 25.0724\n",
      "Epoch 13/60\n",
      "7397/7397 [==============================] - 7s 890us/step - loss: 1566.3434 - mse: 1566.3441 - mae: 24.8811\n",
      "Epoch 14/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1561.6558 - mse: 1561.6559 - mae: 24.9261\n",
      "Epoch 15/60\n",
      "7397/7397 [==============================] - 7s 938us/step - loss: 1565.8128 - mse: 1565.8126 - mae: 24.9550\n",
      "Epoch 16/60\n",
      "7397/7397 [==============================] - 7s 978us/step - loss: 1561.7961 - mse: 1561.7959 - mae: 24.8681\n",
      "Epoch 17/60\n",
      "7397/7397 [==============================] - 7s 901us/step - loss: 1561.5962 - mse: 1561.5963 - mae: 24.9951\n",
      "Epoch 18/60\n",
      "7397/7397 [==============================] - 7s 972us/step - loss: 1557.6659 - mse: 1557.6654 - mae: 24.8433\n",
      "Epoch 19/60\n",
      "7397/7397 [==============================] - 6s 867us/step - loss: 1558.1193 - mse: 1558.1195 - mae: 24.8698\n",
      "Epoch 20/60\n",
      "7397/7397 [==============================] - 7s 1ms/step - loss: 1558.9522 - mse: 1558.9519 - mae: 24.8515\n",
      "Epoch 21/60\n",
      "7397/7397 [==============================] - 7s 911us/step - loss: 1552.6701 - mse: 1552.6704 - mae: 24.7664\n",
      "Epoch 22/60\n",
      "7397/7397 [==============================] - 7s 928us/step - loss: 1549.8447 - mse: 1549.8447 - mae: 24.7713\n",
      "Epoch 23/60\n",
      "7397/7397 [==============================] - 7s 996us/step - loss: 1549.7605 - mse: 1549.7600 - mae: 24.7081\n",
      "Epoch 24/60\n",
      "7397/7397 [==============================] - 7s 990us/step - loss: 1547.8928 - mse: 1547.8932 - mae: 24.69402s - loss: - ETA: 1s - loss: 1610.2525\n",
      "Epoch 25/60\n",
      "7397/7397 [==============================] - 7s 928us/step - loss: 1546.3504 - mse: 1546.3513 - mae: 24.6862\n",
      "Epoch 26/60\n",
      "7397/7397 [==============================] - 7s 949us/step - loss: 1543.5496 - mse: 1543.5496 - mae: 24.6655\n",
      "Epoch 27/60\n",
      "7397/7397 [==============================] - 6s 870us/step - loss: 1566.7982 - mse: 1566.7983 - mae: 25.4907\n",
      "Epoch 28/60\n",
      "7397/7397 [==============================] - 7s 888us/step - loss: 1539.2684 - mse: 1539.2687 - mae: 24.6275\n",
      "Epoch 29/60\n",
      "7397/7397 [==============================] - 7s 953us/step - loss: 1540.3285 - mse: 1540.3291 - mae: 24.6035\n",
      "Epoch 30/60\n",
      "7397/7397 [==============================] - 7s 909us/step - loss: 1539.7241 - mse: 1539.7241 - mae: 24.6362\n",
      "Epoch 31/60\n",
      "7397/7397 [==============================] - 7s 901us/step - loss: 1540.1427 - mse: 1540.1427 - mae: 24.6295\n",
      "Epoch 32/60\n",
      "7397/7397 [==============================] - 7s 992us/step - loss: 1539.7088 - mse: 1539.7090 - mae: 24.7264\n",
      "Epoch 33/60\n",
      "7397/7397 [==============================] - 7s 993us/step - loss: 1540.3508 - mse: 1540.3505 - mae: 24.6547\n",
      "Epoch 34/60\n",
      "7397/7397 [==============================] - ETA: 0s - loss: 1542.8951 - mse: 1542.8951 - mae: 24.67 - 7s 932us/step - loss: 1542.4090 - mse: 1542.4091 - mae: 24.6768\n",
      "Epoch 35/60\n",
      "7397/7397 [==============================] - 7s 890us/step - loss: 1545.7642 - mse: 1545.7643 - mae: 24.6757\n",
      "Epoch 36/60\n",
      "7397/7397 [==============================] - 7s 945us/step - loss: 1540.4331 - mse: 1540.4326 - mae: 24.6068\n",
      "Epoch 37/60\n",
      "7397/7397 [==============================] - 7s 955us/step - loss: 1538.8519 - mse: 1538.8519 - mae: 24.6433\n",
      "Epoch 38/60\n",
      "7397/7397 [==============================] - 7s 1ms/step - loss: 1541.9343 - mse: 1541.9346 - mae: 24.5186\n",
      "Epoch 39/60\n",
      "7397/7397 [==============================] - 7s 988us/step - loss: 1538.0393 - mse: 1538.0393 - mae: 24.74020s - loss: 1566.1507 - mse: 1566.1508 - ma\n",
      "Epoch 40/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1535.4528 - mse: 1535.4526 - mae: 24.4846\n",
      "Epoch 41/60\n",
      "7397/7397 [==============================] - 7s 933us/step - loss: 1540.6612 - mse: 1540.6609 - mae: 24.6090\n",
      "Epoch 42/60\n",
      "7397/7397 [==============================] - ETA: 0s - loss: 1538.9383 - mse: 1538.9379 - mae: 24.5483 ETA: 0s - loss: 1574.4697 - m - 7s 1ms/step - loss: 1538.5221 - mse: 1538.5219 - mae: 24.5476\n",
      "Epoch 43/60\n",
      "7397/7397 [==============================] - 7s 906us/step - loss: 1541.3328 - mse: 1541.3325 - mae: 24.6094\n",
      "Epoch 44/60\n",
      "7397/7397 [==============================] - 7s 952us/step - loss: 1532.5936 - mse: 1532.5938 - mae: 24.5358\n",
      "Epoch 45/60\n",
      "7397/7397 [==============================] - 7s 975us/step - loss: 1539.4078 - mse: 1539.4077 - mae: 24.5825\n",
      "Epoch 46/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1536.7660 - mse: 1536.7656 - mae: 24.4519\n",
      "Epoch 47/60\n",
      "7397/7397 [==============================] - 7s 970us/step - loss: 1540.1205 - mse: 1540.1205 - mae: 24.5719\n",
      "Epoch 48/60\n",
      "7397/7397 [==============================] - 7s 991us/step - loss: 1531.3758 - mse: 1531.3762 - mae: 24.4357\n",
      "Epoch 49/60\n",
      "7397/7397 [==============================] - 7s 939us/step - loss: 1531.0892 - mse: 1531.0898 - mae: 24.5082\n",
      "Epoch 50/60\n",
      "7397/7397 [==============================] - 7s 944us/step - loss: 1529.4323 - mse: 1529.4324 - mae: 24.4364\n",
      "Epoch 51/60\n",
      "7397/7397 [==============================] - 7s 894us/step - loss: 1525.9026 - mse: 1525.9023 - mae: 24.4305\n",
      "Epoch 52/60\n",
      "7397/7397 [==============================] - 7s 941us/step - loss: 1525.7083 - mse: 1525.7085 - mae: 24.4172\n",
      "Epoch 53/60\n",
      "7397/7397 [==============================] - 7s 975us/step - loss: 1532.4170 - mse: 1532.4171 - mae: 24.3693\n",
      "Epoch 54/60\n",
      "7397/7397 [==============================] - ETA: 0s - loss: 1528.0497 - mse: 1528.0494 - mae: 24.3993 ETA - ETA: 2s - loss: 1594. - ETA: 1s - loss: 1563.4486 - m - 8s 1ms/step - loss: 1527.3984 - mse: 1527.3979 - mae: 24.3964\n",
      "Epoch 55/60\n",
      "7397/7397 [==============================] - 7s 996us/step - loss: 1523.8365 - mse: 1523.8375 - mae: 24.3124\n",
      "Epoch 56/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1525.6566 - mse: 1525.6565 - mae: 24.2855\n",
      "Epoch 57/60\n",
      "7397/7397 [==============================] - ETA: 0s - loss: 1526.1176 - mse: 1526.1179 - mae: 24.35 - 9s 1ms/step - loss: 1526.1342 - mse: 1526.1346 - mae: 24.3635\n",
      "Epoch 58/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1522.4980 - mse: 1522.4979 - mae: 24.2801\n",
      "Epoch 59/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1525.7075 - mse: 1525.7078 - mae: 24.4500\n",
      "Epoch 60/60\n",
      "7397/7397 [==============================] - 7s 928us/step - loss: 1520.0421 - mse: 1520.0424 - mae: 24.3122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=55)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "1850/1850 [==============================] - 7s 4ms/step - loss: 9303.0800 - mse: 9303.0801 - mae: 89.3893\n",
      "Epoch 2/60\n",
      "1850/1850 [==============================] - 1s 778us/step - loss: 1347.3800 - mse: 1347.3798 - mae: 25.8614\n",
      "Epoch 3/60\n",
      "1850/1850 [==============================] - 2s 839us/step - loss: 1034.6779 - mse: 1034.6779 - mae: 22.4088\n",
      "Epoch 4/60\n",
      "1850/1850 [==============================] - 2s 905us/step - loss: 1032.8748 - mse: 1032.8746 - mae: 22.3090\n",
      "Epoch 5/60\n",
      "1850/1850 [==============================] - 1s 751us/step - loss: 1028.2993 - mse: 1028.2993 - mae: 22.2301\n",
      "Epoch 6/60\n",
      "1850/1850 [==============================] - 1s 711us/step - loss: 1019.7323 - mse: 1019.7323 - mae: 22.0580\n",
      "Epoch 7/60\n",
      "1850/1850 [==============================] - 1s 773us/step - loss: 1016.2400 - mse: 1016.2397 - mae: 21.8697\n",
      "Epoch 8/60\n",
      "1850/1850 [==============================] - 1s 755us/step - loss: 1012.0581 - mse: 1012.0577 - mae: 21.7927\n",
      "Epoch 9/60\n",
      "1850/1850 [==============================] - 1s 754us/step - loss: 1011.5879 - mse: 1011.5880 - mae: 21.7500\n",
      "Epoch 10/60\n",
      "1850/1850 [==============================] - 1s 732us/step - loss: 1011.8337 - mse: 1011.8337 - mae: 21.6206\n",
      "Epoch 11/60\n",
      "1850/1850 [==============================] - 1s 755us/step - loss: 1007.6435 - mse: 1007.6434 - mae: 21.6435\n",
      "Epoch 12/60\n",
      "1850/1850 [==============================] - 1s 752us/step - loss: 1010.7084 - mse: 1010.7083 - mae: 21.6177\n",
      "Epoch 13/60\n",
      "1850/1850 [==============================] - 2s 841us/step - loss: 1004.5925 - mse: 1004.5925 - mae: 21.5196\n",
      "Epoch 14/60\n",
      "1850/1850 [==============================] - 1s 775us/step - loss: 1004.7890 - mse: 1004.7890 - mae: 21.5313\n",
      "Epoch 15/60\n",
      "1850/1850 [==============================] - 1s 709us/step - loss: 1007.5165 - mse: 1007.5165 - mae: 21.5420\n",
      "Epoch 16/60\n",
      "1850/1850 [==============================] - 1s 734us/step - loss: 1004.0548 - mse: 1004.0548 - mae: 21.4035\n",
      "Epoch 17/60\n",
      "1850/1850 [==============================] - 1s 776us/step - loss: 1001.7499 - mse: 1001.7500 - mae: 21.3845\n",
      "Epoch 18/60\n",
      "1850/1850 [==============================] - 1s 775us/step - loss: 1001.7366 - mse: 1001.7365 - mae: 21.4170\n",
      "Epoch 19/60\n",
      "1850/1850 [==============================] - 1s 775us/step - loss: 1007.1807 - mse: 1007.1807 - mae: 21.3354\n",
      "Epoch 20/60\n",
      "1850/1850 [==============================] - 2s 840us/step - loss: 998.3544 - mse: 998.3546 - mae: 21.3834\n",
      "Epoch 21/60\n",
      "1850/1850 [==============================] - 1s 775us/step - loss: 1004.9397 - mse: 1004.9399 - mae: 21.3662\n",
      "Epoch 22/60\n",
      "1850/1850 [==============================] - 2s 861us/step - loss: 1002.3287 - mse: 1002.3286 - mae: 21.3384\n",
      "Epoch 23/60\n",
      "1850/1850 [==============================] - 2s 843us/step - loss: 994.0307 - mse: 994.0308 - mae: 21.1302\n",
      "Epoch 24/60\n",
      "1850/1850 [==============================] - 1s 711us/step - loss: 997.5848 - mse: 997.5848 - mae: 21.2922\n",
      "Epoch 25/60\n",
      "1850/1850 [==============================] - 1s 689us/step - loss: 990.9237 - mse: 990.9237 - mae: 21.1293\n",
      "Epoch 26/60\n",
      "1850/1850 [==============================] - 1s 777us/step - loss: 993.1219 - mse: 993.1219 - mae: 21.1823\n",
      "Epoch 27/60\n",
      "1850/1850 [==============================] - 1s 691us/step - loss: 995.7346 - mse: 995.7347 - mae: 21.1537\n",
      "Epoch 28/60\n",
      "1850/1850 [==============================] - 1s 688us/step - loss: 992.9713 - mse: 992.9716 - mae: 21.1027\n",
      "Epoch 29/60\n",
      "1850/1850 [==============================] - 1s 667us/step - loss: 989.5803 - mse: 989.5803 - mae: 21.0862\n",
      "Epoch 30/60\n",
      "1850/1850 [==============================] - 1s 688us/step - loss: 989.9847 - mse: 989.9847 - mae: 21.1132\n",
      "Epoch 31/60\n",
      "1850/1850 [==============================] - 1s 756us/step - loss: 992.7074 - mse: 992.7076 - mae: 21.1496\n",
      "Epoch 32/60\n",
      "1850/1850 [==============================] - 2s 864us/step - loss: 988.1850 - mse: 988.1851 - mae: 20.9893\n",
      "Epoch 33/60\n",
      "1850/1850 [==============================] - 2s 821us/step - loss: 992.8080 - mse: 992.8080 - mae: 21.1785\n",
      "Epoch 34/60\n",
      "1850/1850 [==============================] - 1s 756us/step - loss: 984.5302 - mse: 984.5302 - mae: 21.0339\n",
      "Epoch 35/60\n",
      "1850/1850 [==============================] - 1s 712us/step - loss: 984.7935 - mse: 984.7936 - mae: 21.1474\n",
      "Epoch 36/60\n",
      "1850/1850 [==============================] - 1s 668us/step - loss: 988.4977 - mse: 988.4975 - mae: 21.1078\n",
      "Epoch 37/60\n",
      "1850/1850 [==============================] - 1s 688us/step - loss: 989.9543 - mse: 989.9545 - mae: 21.0804\n",
      "Epoch 38/60\n",
      "1850/1850 [==============================] - 1s 645us/step - loss: 984.4538 - mse: 984.4537 - mae: 20.9315\n",
      "Epoch 39/60\n",
      "1850/1850 [==============================] - 1s 727us/step - loss: 984.5889 - mse: 984.5888 - mae: 21.0983\n",
      "Epoch 40/60\n",
      "1850/1850 [==============================] - 2s 817us/step - loss: 984.9881 - mse: 984.9882 - mae: 20.9298\n",
      "Epoch 41/60\n",
      "1850/1850 [==============================] - 1s 774us/step - loss: 986.6416 - mse: 986.6416 - mae: 21.0729\n",
      "Epoch 42/60\n",
      "1850/1850 [==============================] - 2s 819us/step - loss: 981.1384 - mse: 981.1384 - mae: 21.0025\n",
      "Epoch 43/60\n",
      "1850/1850 [==============================] - 2s 840us/step - loss: 983.5405 - mse: 983.5404 - mae: 20.9586\n",
      "Epoch 44/60\n",
      "1850/1850 [==============================] - 1s 755us/step - loss: 983.8313 - mse: 983.8313 - mae: 21.0885\n",
      "Epoch 45/60\n",
      "1850/1850 [==============================] - 1s 668us/step - loss: 981.7929 - mse: 981.7928 - mae: 20.9505\n",
      "Epoch 46/60\n",
      "1850/1850 [==============================] - 2s 820us/step - loss: 981.6154 - mse: 981.6155 - mae: 20.8878\n",
      "Epoch 47/60\n",
      "1850/1850 [==============================] - 1s 711us/step - loss: 979.3892 - mse: 979.3891 - mae: 21.0195\n",
      "Epoch 48/60\n",
      "1850/1850 [==============================] - 1s 689us/step - loss: 981.1572 - mse: 981.1573 - mae: 20.8976\n",
      "Epoch 49/60\n",
      "1850/1850 [==============================] - 1s 686us/step - loss: 974.4291 - mse: 974.4291 - mae: 20.9168\n",
      "Epoch 50/60\n",
      "1850/1850 [==============================] - 1s 709us/step - loss: 978.9794 - mse: 978.9794 - mae: 20.8529\n",
      "Epoch 51/60\n",
      "1850/1850 [==============================] - 1s 798us/step - loss: 980.3548 - mse: 980.3549 - mae: 20.8872\n",
      "Epoch 52/60\n",
      "1850/1850 [==============================] - 2s 819us/step - loss: 981.1737 - mse: 981.1737 - mae: 20.9536\n",
      "Epoch 53/60\n",
      "1850/1850 [==============================] - 1s 795us/step - loss: 980.6432 - mse: 980.6431 - mae: 20.9286\n",
      "Epoch 54/60\n",
      "1850/1850 [==============================] - 1s 736us/step - loss: 978.1422 - mse: 978.1423 - mae: 20.8415\n",
      "Epoch 55/60\n",
      "1850/1850 [==============================] - 2s 954us/step - loss: 976.3600 - mse: 976.3601 - mae: 20.8819\n",
      "Epoch 56/60\n",
      "1850/1850 [==============================] - 2s 933us/step - loss: 977.8759 - mse: 977.8758 - mae: 20.8592\n",
      "Epoch 57/60\n",
      "1850/1850 [==============================] - 1s 752us/step - loss: 977.2331 - mse: 977.2330 - mae: 20.8740\n",
      "Epoch 58/60\n",
      "1850/1850 [==============================] - 1s 777us/step - loss: 976.4771 - mse: 976.4772 - mae: 20.6625\n",
      "Epoch 59/60\n",
      "1850/1850 [==============================] - 1s 670us/step - loss: 975.4289 - mse: 975.4288 - mae: 20.9061\n",
      "Epoch 60/60\n",
      "1850/1850 [==============================] - 1s 777us/step - loss: 972.2232 - mse: 972.2232 - mae: 20.8238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=55)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "3699/3699 [==============================] - 8s 2ms/step - loss: 5067.6743 - mse: 5067.6748 - mae: 55.1616\n",
      "Epoch 2/60\n",
      "3699/3699 [==============================] - 3s 785us/step - loss: 1160.2090 - mse: 1160.2089 - mae: 23.3278\n",
      "Epoch 3/60\n",
      "3699/3699 [==============================] - 3s 787us/step - loss: 1147.4256 - mse: 1147.4254 - mae: 23.1711\n",
      "Epoch 4/60\n",
      "3699/3699 [==============================] - 3s 797us/step - loss: 1138.9393 - mse: 1138.9395 - mae: 22.9969\n",
      "Epoch 5/60\n",
      "3699/3699 [==============================] - 3s 732us/step - loss: 1131.2294 - mse: 1131.2294 - mae: 22.9103\n",
      "Epoch 6/60\n",
      "3699/3699 [==============================] - 3s 787us/step - loss: 1132.1915 - mse: 1132.1915 - mae: 22.9117\n",
      "Epoch 7/60\n",
      "3699/3699 [==============================] - 3s 862us/step - loss: 1124.9524 - mse: 1124.9525 - mae: 22.8677\n",
      "Epoch 8/60\n",
      "3699/3699 [==============================] - 3s 841us/step - loss: 1125.2011 - mse: 1125.2010 - mae: 22.7531\n",
      "Epoch 9/60\n",
      "3699/3699 [==============================] - 3s 873us/step - loss: 1123.3358 - mse: 1123.3356 - mae: 22.8205\n",
      "Epoch 10/60\n",
      "3699/3699 [==============================] - 3s 840us/step - loss: 1121.2574 - mse: 1121.2574 - mae: 22.7913\n",
      "Epoch 11/60\n",
      "3699/3699 [==============================] - 3s 852us/step - loss: 1121.7214 - mse: 1121.7214 - mae: 22.7669\n",
      "Epoch 12/60\n",
      "3699/3699 [==============================] - 3s 818us/step - loss: 1121.6149 - mse: 1121.6147 - mae: 22.7205\n",
      "Epoch 13/60\n",
      "3699/3699 [==============================] - 3s 775us/step - loss: 1121.7228 - mse: 1121.7227 - mae: 22.7461\n",
      "Epoch 14/60\n",
      "3699/3699 [==============================] - 3s 775us/step - loss: 1120.5577 - mse: 1120.5575 - mae: 22.6869\n",
      "Epoch 15/60\n",
      "3699/3699 [==============================] - 3s 852us/step - loss: 1117.6900 - mse: 1117.6901 - mae: 22.5774\n",
      "Epoch 16/60\n",
      "3699/3699 [==============================] - 3s 810us/step - loss: 1117.4611 - mse: 1117.4612 - mae: 22.6202\n",
      "Epoch 17/60\n",
      "3699/3699 [==============================] - 3s 787us/step - loss: 1116.1841 - mse: 1116.1843 - mae: 22.6108\n",
      "Epoch 18/60\n",
      "3699/3699 [==============================] - 3s 744us/step - loss: 1112.8136 - mse: 1112.8134 - mae: 22.6298\n",
      "Epoch 19/60\n",
      "3699/3699 [==============================] - 3s 743us/step - loss: 1112.6694 - mse: 1112.6693 - mae: 22.5318\n",
      "Epoch 20/60\n",
      "3699/3699 [==============================] - 3s 829us/step - loss: 1113.1635 - mse: 1113.1635 - mae: 22.6297\n",
      "Epoch 21/60\n",
      "3699/3699 [==============================] - 3s 754us/step - loss: 1114.0910 - mse: 1114.0911 - mae: 22.5629\n",
      "Epoch 22/60\n",
      "3699/3699 [==============================] - 3s 743us/step - loss: 1109.1835 - mse: 1109.1835 - mae: 22.6401\n",
      "Epoch 23/60\n",
      "3699/3699 [==============================] - 3s 742us/step - loss: 1110.8523 - mse: 1110.8522 - mae: 22.5257\n",
      "Epoch 24/60\n",
      "3699/3699 [==============================] - 3s 719us/step - loss: 1108.5788 - mse: 1108.5786 - mae: 22.5190\n",
      "Epoch 25/60\n",
      "3699/3699 [==============================] - 3s 818us/step - loss: 1107.6598 - mse: 1107.6598 - mae: 22.4778\n",
      "Epoch 26/60\n",
      "3699/3699 [==============================] - 3s 755us/step - loss: 1108.5124 - mse: 1108.5123 - mae: 22.5301\n",
      "Epoch 27/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1111.9013 - mse: 1111.9015 - mae: 22.4845\n",
      "Epoch 28/60\n",
      "3699/3699 [==============================] - 3s 697us/step - loss: 1107.8270 - mse: 1107.8273 - mae: 22.4325\n",
      "Epoch 29/60\n",
      "3699/3699 [==============================] - 0s 43us/step - loss: 1105.3129 - mse: 1105.3130 - mae: 22.5123\n",
      "Epoch 30/60\n",
      "3699/3699 [==============================] - 0s 42us/step - loss: 1106.0999 - mse: 1106.1001 - mae: 22.3764\n",
      "Epoch 31/60\n",
      "3699/3699 [==============================] - 0s 43us/step - loss: 1104.1587 - mse: 1104.1586 - mae: 22.3641\n",
      "Epoch 32/60\n",
      "3699/3699 [==============================] - 0s 42us/step - loss: 1103.8769 - mse: 1103.8770 - mae: 22.4461\n",
      "Epoch 33/60\n",
      "3699/3699 [==============================] - 0s 42us/step - loss: 1109.0156 - mse: 1109.0156 - mae: 22.3671\n",
      "Epoch 34/60\n",
      "3699/3699 [==============================] - 0s 42us/step - loss: 1103.9094 - mse: 1103.9093 - mae: 22.3693\n",
      "Epoch 35/60\n",
      "3699/3699 [==============================] - 0s 42us/step - loss: 1104.6434 - mse: 1104.6434 - mae: 22.3641\n",
      "Epoch 36/60\n",
      "3699/3699 [==============================] - 0s 43us/step - loss: 1104.6759 - mse: 1104.6759 - mae: 22.3593\n",
      "Epoch 37/60\n",
      "3699/3699 [==============================] - 0s 43us/step - loss: 1103.2471 - mse: 1103.2472 - mae: 22.3586\n",
      "Epoch 38/60\n",
      "3699/3699 [==============================] - 0s 43us/step - loss: 1105.0506 - mse: 1105.0508 - mae: 22.3295\n",
      "Epoch 39/60\n",
      "3699/3699 [==============================] - 0s 43us/step - loss: 1099.9465 - mse: 1099.9467 - mae: 22.3918\n",
      "Epoch 40/60\n",
      "3699/3699 [==============================] - 0s 43us/step - loss: 1103.6579 - mse: 1103.6580 - mae: 22.3410\n",
      "Epoch 41/60\n",
      "3699/3699 [==============================] - 0s 42us/step - loss: 1100.7686 - mse: 1100.7686 - mae: 22.2943\n",
      "Epoch 42/60\n",
      "3699/3699 [==============================] - 0s 42us/step - loss: 1100.7528 - mse: 1100.7527 - mae: 22.3906\n",
      "Epoch 43/60\n",
      "3699/3699 [==============================] - 0s 42us/step - loss: 1101.7245 - mse: 1101.7246 - mae: 22.3295\n",
      "Epoch 44/60\n",
      "3699/3699 [==============================] - 0s 42us/step - loss: 1101.1343 - mse: 1101.1345 - mae: 22.3182\n",
      "Epoch 45/60\n",
      "3699/3699 [==============================] - 0s 42us/step - loss: 1102.5350 - mse: 1102.5348 - mae: 22.3268\n",
      "Epoch 46/60\n",
      "3699/3699 [==============================] - 0s 42us/step - loss: 1098.5679 - mse: 1098.5681 - mae: 22.3349\n",
      "Epoch 47/60\n",
      "3699/3699 [==============================] - 0s 41us/step - loss: 1103.2076 - mse: 1103.2079 - mae: 22.2899\n",
      "Epoch 48/60\n",
      "3699/3699 [==============================] - 0s 41us/step - loss: 1101.8015 - mse: 1101.8015 - mae: 22.3144\n",
      "Epoch 49/60\n",
      "3699/3699 [==============================] - 0s 41us/step - loss: 1097.7326 - mse: 1097.7325 - mae: 22.2296\n",
      "Epoch 50/60\n",
      "3699/3699 [==============================] - 0s 42us/step - loss: 1104.1418 - mse: 1104.1420 - mae: 22.3331\n",
      "Epoch 51/60\n",
      "3699/3699 [==============================] - 0s 42us/step - loss: 1097.5042 - mse: 1097.5046 - mae: 22.2738\n",
      "Epoch 52/60\n",
      "3699/3699 [==============================] - 0s 41us/step - loss: 1097.7503 - mse: 1097.7502 - mae: 22.2468\n",
      "Epoch 53/60\n",
      "3699/3699 [==============================] - 0s 42us/step - loss: 1100.7143 - mse: 1100.7142 - mae: 22.3212\n",
      "Epoch 54/60\n",
      "3699/3699 [==============================] - 0s 42us/step - loss: 1096.5903 - mse: 1096.5902 - mae: 22.1616\n",
      "Epoch 55/60\n",
      "3699/3699 [==============================] - 0s 43us/step - loss: 1098.0541 - mse: 1098.0541 - mae: 22.2831\n",
      "Epoch 56/60\n",
      "3699/3699 [==============================] - 0s 42us/step - loss: 1098.6335 - mse: 1098.6335 - mae: 22.2582\n",
      "Epoch 57/60\n",
      "3699/3699 [==============================] - 0s 43us/step - loss: 1097.9989 - mse: 1097.9991 - mae: 22.2438\n",
      "Epoch 58/60\n",
      "3699/3699 [==============================] - 0s 42us/step - loss: 1099.1220 - mse: 1099.1221 - mae: 22.2422\n",
      "Epoch 59/60\n",
      "3699/3699 [==============================] - 0s 43us/step - loss: 1098.5310 - mse: 1098.5308 - mae: 22.2031\n",
      "Epoch 60/60\n",
      "3699/3699 [==============================] - 0s 64us/step - loss: 1096.1450 - mse: 1096.1449 - mae: 22.1694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=55)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "5548/5548 [==============================] - 1s 188us/step - loss: 5093.7594 - mse: 5093.7588 - mae: 51.4840\n",
      "Epoch 2/60\n",
      "5548/5548 [==============================] - 0s 62us/step - loss: 1680.8965 - mse: 1680.8961 - mae: 25.2550\n",
      "Epoch 3/60\n",
      "5548/5548 [==============================] - 0s 62us/step - loss: 1671.9758 - mse: 1671.9757 - mae: 25.1515\n",
      "Epoch 4/60\n",
      "5548/5548 [==============================] - 0s 60us/step - loss: 1669.0887 - mse: 1669.0889 - mae: 25.0880\n",
      "Epoch 5/60\n",
      "5548/5548 [==============================] - 0s 62us/step - loss: 1662.9281 - mse: 1662.9282 - mae: 24.9186\n",
      "Epoch 6/60\n",
      "5548/5548 [==============================] - 0s 62us/step - loss: 1657.3709 - mse: 1657.3713 - mae: 24.9099\n",
      "Epoch 7/60\n",
      "5548/5548 [==============================] - 0s 64us/step - loss: 1654.0540 - mse: 1654.0541 - mae: 24.8758\n",
      "Epoch 8/60\n",
      "5548/5548 [==============================] - 0s 60us/step - loss: 1650.9139 - mse: 1650.9148 - mae: 24.9161\n",
      "Epoch 9/60\n",
      "5548/5548 [==============================] - 0s 62us/step - loss: 1650.1013 - mse: 1650.1007 - mae: 24.8429\n",
      "Epoch 10/60\n",
      "5548/5548 [==============================] - 0s 84us/step - loss: 1647.0767 - mse: 1647.0769 - mae: 24.7627\n",
      "Epoch 11/60\n",
      "5548/5548 [==============================] - 1s 118us/step - loss: 1639.9161 - mse: 1639.9156 - mae: 24.7381\n",
      "Epoch 12/60\n",
      "5548/5548 [==============================] - 1s 114us/step - loss: 1639.7651 - mse: 1639.7650 - mae: 24.6285\n",
      "Epoch 13/60\n",
      "5548/5548 [==============================] - 1s 115us/step - loss: 1635.5354 - mse: 1635.5353 - mae: 24.6325\n",
      "Epoch 14/60\n",
      "5548/5548 [==============================] - 1s 113us/step - loss: 1635.1269 - mse: 1635.1266 - mae: 24.6695\n",
      "Epoch 15/60\n",
      "5548/5548 [==============================] - 1s 112us/step - loss: 1635.7158 - mse: 1635.7157 - mae: 24.6837\n",
      "Epoch 16/60\n",
      "5548/5548 [==============================] - 1s 111us/step - loss: 1626.8382 - mse: 1626.8381 - mae: 24.6710\n",
      "Epoch 17/60\n",
      "5548/5548 [==============================] - 1s 115us/step - loss: 1630.8959 - mse: 1630.8960 - mae: 24.6030\n",
      "Epoch 18/60\n",
      "5548/5548 [==============================] - 3s 573us/step - loss: 1631.5182 - mse: 1631.5178 - mae: 24.5741\n",
      "Epoch 19/60\n",
      "5548/5548 [==============================] - 4s 786us/step - loss: 1627.9761 - mse: 1627.9761 - mae: 24.5871\n",
      "Epoch 20/60\n",
      "5548/5548 [==============================] - 4s 681us/step - loss: 1627.0552 - mse: 1627.0553 - mae: 24.5566\n",
      "Epoch 21/60\n",
      "5548/5548 [==============================] - 4s 718us/step - loss: 1628.1252 - mse: 1628.1255 - mae: 24.5475\n",
      "Epoch 22/60\n",
      "5548/5548 [==============================] - 4s 790us/step - loss: 1624.3383 - mse: 1624.3380 - mae: 24.5576\n",
      "Epoch 23/60\n",
      "5548/5548 [==============================] - 4s 668us/step - loss: 1623.4234 - mse: 1623.4232 - mae: 24.5327\n",
      "Epoch 24/60\n",
      "5548/5548 [==============================] - 4s 681us/step - loss: 1625.5264 - mse: 1625.5267 - mae: 24.4698\n",
      "Epoch 25/60\n",
      "5548/5548 [==============================] - 4s 731us/step - loss: 1626.2250 - mse: 1626.2255 - mae: 24.6368\n",
      "Epoch 26/60\n",
      "5548/5548 [==============================] - 4s 723us/step - loss: 1625.0580 - mse: 1625.0582 - mae: 24.4887\n",
      "Epoch 27/60\n",
      "5548/5548 [==============================] - 4s 711us/step - loss: 1620.6281 - mse: 1620.6279 - mae: 24.4051\n",
      "Epoch 28/60\n",
      "5548/5548 [==============================] - 4s 804us/step - loss: 1621.6747 - mse: 1621.6747 - mae: 24.4346\n",
      "Epoch 29/60\n",
      "5548/5548 [==============================] - 5s 835us/step - loss: 1621.4555 - mse: 1621.4561 - mae: 24.4645\n",
      "Epoch 30/60\n",
      "5548/5548 [==============================] - 4s 717us/step - loss: 1623.6520 - mse: 1623.6527 - mae: 24.5513\n",
      "Epoch 31/60\n",
      "5548/5548 [==============================] - 4s 689us/step - loss: 1618.7936 - mse: 1618.7936 - mae: 24.4520\n",
      "Epoch 32/60\n",
      "5548/5548 [==============================] - 4s 761us/step - loss: 1620.2202 - mse: 1620.2208 - mae: 24.5324\n",
      "Epoch 33/60\n",
      "5548/5548 [==============================] - 4s 718us/step - loss: 1617.9745 - mse: 1617.9747 - mae: 24.4824\n",
      "Epoch 34/60\n",
      "5548/5548 [==============================] - 4s 689us/step - loss: 1617.6282 - mse: 1617.6283 - mae: 24.4413\n",
      "Epoch 35/60\n",
      "5548/5548 [==============================] - 4s 703us/step - loss: 1619.6176 - mse: 1619.6176 - mae: 24.4761\n",
      "Epoch 36/60\n",
      "5548/5548 [==============================] - 4s 715us/step - loss: 1614.2233 - mse: 1614.2233 - mae: 24.3755\n",
      "Epoch 37/60\n",
      "5548/5548 [==============================] - 4s 709us/step - loss: 1620.5393 - mse: 1620.5389 - mae: 24.4681\n",
      "Epoch 38/60\n",
      "5548/5548 [==============================] - 4s 717us/step - loss: 1618.0858 - mse: 1618.0865 - mae: 24.4137\n",
      "Epoch 39/60\n",
      "5548/5548 [==============================] - 4s 723us/step - loss: 1615.7698 - mse: 1615.7701 - mae: 24.4741\n",
      "Epoch 40/60\n",
      "5548/5548 [==============================] - 4s 776us/step - loss: 1616.6010 - mse: 1616.6017 - mae: 24.4347\n",
      "Epoch 41/60\n",
      "5548/5548 [==============================] - 4s 659us/step - loss: 1617.7901 - mse: 1617.7902 - mae: 24.4197\n",
      "Epoch 42/60\n",
      "5548/5548 [==============================] - 4s 739us/step - loss: 1616.3654 - mse: 1616.3655 - mae: 24.3752\n",
      "Epoch 43/60\n",
      "5548/5548 [==============================] - 4s 810us/step - loss: 1616.2568 - mse: 1616.2565 - mae: 24.3657\n",
      "Epoch 44/60\n",
      "5548/5548 [==============================] - 4s 704us/step - loss: 1614.5807 - mse: 1614.5811 - mae: 24.3380\n",
      "Epoch 45/60\n",
      "5548/5548 [==============================] - 4s 667us/step - loss: 1615.1835 - mse: 1615.1835 - mae: 24.3678\n",
      "Epoch 46/60\n",
      "5548/5548 [==============================] - 4s 727us/step - loss: 1614.8839 - mse: 1614.8839 - mae: 24.3280\n",
      "Epoch 47/60\n",
      "5548/5548 [==============================] - 4s 733us/step - loss: 1618.9990 - mse: 1618.9991 - mae: 24.4008\n",
      "Epoch 48/60\n",
      "5548/5548 [==============================] - 4s 799us/step - loss: 1610.6055 - mse: 1610.6058 - mae: 24.4303\n",
      "Epoch 49/60\n",
      "5548/5548 [==============================] - 4s 739us/step - loss: 1614.0809 - mse: 1614.0808 - mae: 24.4708\n",
      "Epoch 50/60\n",
      "5548/5548 [==============================] - 5s 848us/step - loss: 1614.8904 - mse: 1614.8904 - mae: 24.3567\n",
      "Epoch 51/60\n",
      "5548/5548 [==============================] - 4s 763us/step - loss: 1610.8987 - mse: 1610.8987 - mae: 24.3103\n",
      "Epoch 52/60\n",
      "5548/5548 [==============================] - 4s 688us/step - loss: 1614.8519 - mse: 1614.8514 - mae: 24.3673\n",
      "Epoch 53/60\n",
      "5548/5548 [==============================] - 5s 814us/step - loss: 1613.0856 - mse: 1613.0858 - mae: 24.3785\n",
      "Epoch 54/60\n",
      "5548/5548 [==============================] - 4s 681us/step - loss: 1611.5952 - mse: 1611.5956 - mae: 24.3417\n",
      "Epoch 55/60\n",
      "5548/5548 [==============================] - 4s 689us/step - loss: 1613.9023 - mse: 1613.9017 - mae: 24.3706\n",
      "Epoch 56/60\n",
      "5548/5548 [==============================] - 4s 744us/step - loss: 1609.2089 - mse: 1609.2095 - mae: 24.3616\n",
      "Epoch 57/60\n",
      "5548/5548 [==============================] - 4s 803us/step - loss: 1614.4159 - mse: 1614.4160 - mae: 24.3808\n",
      "Epoch 58/60\n",
      "5548/5548 [==============================] - 4s 731us/step - loss: 1607.0973 - mse: 1607.0972 - mae: 24.2737\n",
      "Epoch 59/60\n",
      "5548/5548 [==============================] - 4s 695us/step - loss: 1614.3706 - mse: 1614.3706 - mae: 24.3037\n",
      "Epoch 60/60\n",
      "5548/5548 [==============================] - 4s 778us/step - loss: 1606.2871 - mse: 1606.2870 - mae: 24.3910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=55)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "7397/7397 [==============================] - 11s 2ms/step - loss: 4698.1501 - mse: 4698.1523 - mae: 48.4595\n",
      "Epoch 2/60\n",
      "7397/7397 [==============================] - 5s 705us/step - loss: 1606.4695 - mse: 1606.4701 - mae: 25.3720\n",
      "Epoch 3/60\n",
      "7397/7397 [==============================] - 6s 827us/step - loss: 1593.9156 - mse: 1593.9159 - mae: 25.2634\n",
      "Epoch 4/60\n",
      "7397/7397 [==============================] - 5s 689us/step - loss: 1587.1750 - mse: 1587.1753 - mae: 25.1118\n",
      "Epoch 5/60\n",
      "7397/7397 [==============================] - 5s 688us/step - loss: 1582.9539 - mse: 1582.9536 - mae: 25.2036\n",
      "Epoch 6/60\n",
      "7397/7397 [==============================] - 6s 770us/step - loss: 1578.6927 - mse: 1578.6929 - mae: 25.0558\n",
      "Epoch 7/60\n",
      "7397/7397 [==============================] - 6s 752us/step - loss: 1578.6284 - mse: 1578.6292 - mae: 25.1489\n",
      "Epoch 8/60\n",
      "7397/7397 [==============================] - 6s 802us/step - loss: 1577.9060 - mse: 1577.9056 - mae: 25.0473\n",
      "Epoch 9/60\n",
      "7397/7397 [==============================] - 6s 765us/step - loss: 1571.9664 - mse: 1571.9662 - mae: 25.0251\n",
      "Epoch 10/60\n",
      "7397/7397 [==============================] - 5s 703us/step - loss: 1570.9695 - mse: 1570.9697 - mae: 24.9261\n",
      "Epoch 11/60\n",
      "7397/7397 [==============================] - 6s 874us/step - loss: 1566.3030 - mse: 1566.3036 - mae: 24.9619\n",
      "Epoch 12/60\n",
      "7397/7397 [==============================] - 5s 737us/step - loss: 1566.9554 - mse: 1566.9550 - mae: 24.9405\n",
      "Epoch 13/60\n",
      "7397/7397 [==============================] - 6s 763us/step - loss: 1564.0889 - mse: 1564.0889 - mae: 24.9021\n",
      "Epoch 14/60\n",
      "7397/7397 [==============================] - 6s 754us/step - loss: 1564.5589 - mse: 1564.5594 - mae: 24.8578\n",
      "Epoch 15/60\n",
      "7397/7397 [==============================] - 5s 705us/step - loss: 1563.6201 - mse: 1563.6201 - mae: 24.8917\n",
      "Epoch 16/60\n",
      "7397/7397 [==============================] - 6s 780us/step - loss: 1562.0806 - mse: 1562.0801 - mae: 24.7893\n",
      "Epoch 17/60\n",
      "7397/7397 [==============================] - 6s 746us/step - loss: 1561.2680 - mse: 1561.2684 - mae: 24.8969\n",
      "Epoch 18/60\n",
      "7397/7397 [==============================] - 6s 841us/step - loss: 1556.7869 - mse: 1556.7869 - mae: 24.9014\n",
      "Epoch 19/60\n",
      "7397/7397 [==============================] - 5s 725us/step - loss: 1557.6266 - mse: 1557.6267 - mae: 24.8258\n",
      "Epoch 20/60\n",
      "7397/7397 [==============================] - 5s 730us/step - loss: 1560.2512 - mse: 1560.2517 - mae: 24.7885\n",
      "Epoch 21/60\n",
      "7397/7397 [==============================] - 6s 797us/step - loss: 1560.8027 - mse: 1560.8026 - mae: 24.7845\n",
      "Epoch 22/60\n",
      "7397/7397 [==============================] - 6s 848us/step - loss: 1558.3915 - mse: 1558.3922 - mae: 24.8952\n",
      "Epoch 23/60\n",
      "7397/7397 [==============================] - 6s 776us/step - loss: 1557.9802 - mse: 1557.9803 - mae: 24.7825\n",
      "Epoch 24/60\n",
      "7397/7397 [==============================] - 6s 777us/step - loss: 1561.2118 - mse: 1561.2118 - mae: 24.8591\n",
      "Epoch 25/60\n",
      "7397/7397 [==============================] - 5s 716us/step - loss: 1557.9678 - mse: 1557.9680 - mae: 24.7866\n",
      "Epoch 26/60\n",
      "7397/7397 [==============================] - 6s 770us/step - loss: 1557.5846 - mse: 1557.5848 - mae: 24.7552\n",
      "Epoch 27/60\n",
      "7397/7397 [==============================] - 5s 693us/step - loss: 1556.4376 - mse: 1556.4377 - mae: 24.7690\n",
      "Epoch 28/60\n",
      "7397/7397 [==============================] - 6s 752us/step - loss: 1557.7062 - mse: 1557.7062 - mae: 24.7746\n",
      "Epoch 29/60\n",
      "7397/7397 [==============================] - 6s 749us/step - loss: 1557.3909 - mse: 1557.3907 - mae: 24.8270\n",
      "Epoch 30/60\n",
      "7397/7397 [==============================] - 5s 699us/step - loss: 1556.1190 - mse: 1556.1182 - mae: 24.6950\n",
      "Epoch 31/60\n",
      "7397/7397 [==============================] - 6s 748us/step - loss: 1554.4750 - mse: 1554.4746 - mae: 24.7139\n",
      "Epoch 32/60\n",
      "7397/7397 [==============================] - 6s 798us/step - loss: 1557.6970 - mse: 1557.6979 - mae: 24.7834\n",
      "Epoch 33/60\n",
      "7397/7397 [==============================] - 5s 732us/step - loss: 1557.3293 - mse: 1557.3289 - mae: 24.7681\n",
      "Epoch 34/60\n",
      "7397/7397 [==============================] - 6s 793us/step - loss: 1553.9033 - mse: 1553.9037 - mae: 24.7054\n",
      "Epoch 35/60\n",
      "7397/7397 [==============================] - 5s 732us/step - loss: 1553.9930 - mse: 1553.9933 - mae: 24.6933\n",
      "Epoch 36/60\n",
      "7397/7397 [==============================] - 6s 811us/step - loss: 1554.3631 - mse: 1554.3625 - mae: 24.7308\n",
      "Epoch 37/60\n",
      "7397/7397 [==============================] - 5s 688us/step - loss: 1552.0373 - mse: 1552.0374 - mae: 24.7524\n",
      "Epoch 38/60\n",
      "7397/7397 [==============================] - 5s 727us/step - loss: 1554.8996 - mse: 1554.8997 - mae: 24.6893\n",
      "Epoch 39/60\n",
      "7397/7397 [==============================] - 6s 801us/step - loss: 1554.3155 - mse: 1554.3152 - mae: 24.6768\n",
      "Epoch 40/60\n",
      "7397/7397 [==============================] - 5s 689us/step - loss: 1552.8075 - mse: 1552.8074 - mae: 24.7245\n",
      "Epoch 41/60\n",
      "7397/7397 [==============================] - 6s 755us/step - loss: 1552.8091 - mse: 1552.8092 - mae: 24.7052\n",
      "Epoch 42/60\n",
      "7397/7397 [==============================] - 5s 701us/step - loss: 1554.7132 - mse: 1554.7131 - mae: 24.6631\n",
      "Epoch 43/60\n",
      "7397/7397 [==============================] - 5s 704us/step - loss: 1555.0052 - mse: 1555.0051 - mae: 24.7360\n",
      "Epoch 44/60\n",
      "7397/7397 [==============================] - 6s 808us/step - loss: 1554.8958 - mse: 1554.8966 - mae: 24.6935\n",
      "Epoch 45/60\n",
      "7397/7397 [==============================] - 6s 761us/step - loss: 1553.9482 - mse: 1553.9484 - mae: 24.6702\n",
      "Epoch 46/60\n",
      "7397/7397 [==============================] - 5s 743us/step - loss: 1553.1846 - mse: 1553.1842 - mae: 24.7359\n",
      "Epoch 47/60\n",
      "7397/7397 [==============================] - 5s 716us/step - loss: 1555.5549 - mse: 1555.5549 - mae: 24.7112\n",
      "Epoch 48/60\n",
      "7397/7397 [==============================] - 5s 667us/step - loss: 1550.3941 - mse: 1550.3933 - mae: 24.7182\n",
      "Epoch 49/60\n",
      "7397/7397 [==============================] - 6s 781us/step - loss: 1547.5786 - mse: 1547.5784 - mae: 24.6815\n",
      "Epoch 50/60\n",
      "7397/7397 [==============================] - 5s 714us/step - loss: 1552.1986 - mse: 1552.1987 - mae: 24.6869\n",
      "Epoch 51/60\n",
      "7397/7397 [==============================] - 5s 699us/step - loss: 1553.3450 - mse: 1553.3450 - mae: 24.7115\n",
      "Epoch 52/60\n",
      "7397/7397 [==============================] - 6s 775us/step - loss: 1551.9718 - mse: 1551.9720 - mae: 24.6101\n",
      "Epoch 53/60\n",
      "7397/7397 [==============================] - 6s 766us/step - loss: 1548.0586 - mse: 1548.0588 - mae: 24.70680s - loss: 1274.6174 - mse: 1274.6176 \n",
      "Epoch 54/60\n",
      "7397/7397 [==============================] - 6s 814us/step - loss: 1551.3041 - mse: 1551.3044 - mae: 24.6653\n",
      "Epoch 55/60\n",
      "7397/7397 [==============================] - 5s 705us/step - loss: 1550.1793 - mse: 1550.1794 - mae: 24.7248\n",
      "Epoch 56/60\n",
      "7397/7397 [==============================] - 6s 747us/step - loss: 1548.4052 - mse: 1548.4050 - mae: 24.6468\n",
      "Epoch 57/60\n",
      "7397/7397 [==============================] - 6s 744us/step - loss: 1548.4912 - mse: 1548.4916 - mae: 24.6493\n",
      "Epoch 58/60\n",
      "7397/7397 [==============================] - 5s 684us/step - loss: 1550.1192 - mse: 1550.1198 - mae: 24.6706\n",
      "Epoch 59/60\n",
      "7397/7397 [==============================] - 6s 748us/step - loss: 1550.2344 - mse: 1550.2344 - mae: 24.6319\n",
      "Epoch 60/60\n",
      "7397/7397 [==============================] - 5s 727us/step - loss: 1550.3788 - mse: 1550.3789 - mae: 24.6710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=15)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "1850/1850 [==============================] - 12s 6ms/step - loss: 12396.6372 - mse: 12396.6367 - mae: 106.6586\n",
      "Epoch 2/60\n",
      "1850/1850 [==============================] - ETA: 0s - loss: 8523.1533 - mse: 8523.1533 - mae: 84.30 - 2s 1ms/step - loss: 8187.5468 - mse: 8187.5464 - mae: 81.6463\n",
      "Epoch 3/60\n",
      "1850/1850 [==============================] - 2s 995us/step - loss: 1079.1703 - mse: 1079.1702 - mae: 23.2462\n",
      "Epoch 4/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 1035.1042 - mse: 1035.1042 - mae: 22.4091\n",
      "Epoch 5/60\n",
      "1850/1850 [==============================] - 2s 909us/step - loss: 1030.0880 - mse: 1030.0879 - mae: 22.4110\n",
      "Epoch 6/60\n",
      "1850/1850 [==============================] - 2s 908us/step - loss: 1027.1224 - mse: 1027.1223 - mae: 22.2918\n",
      "Epoch 7/60\n",
      "1850/1850 [==============================] - 2s 889us/step - loss: 1026.8595 - mse: 1026.8595 - mae: 22.3258\n",
      "Epoch 8/60\n",
      "1850/1850 [==============================] - 2s 869us/step - loss: 1028.8198 - mse: 1028.8199 - mae: 22.2470\n",
      "Epoch 9/60\n",
      "1850/1850 [==============================] - 2s 974us/step - loss: 1024.9140 - mse: 1024.9141 - mae: 22.1359\n",
      "Epoch 10/60\n",
      "1850/1850 [==============================] - 2s 951us/step - loss: 1019.9524 - mse: 1019.9521 - mae: 22.1287\n",
      "Epoch 11/60\n",
      "1850/1850 [==============================] - 2s 994us/step - loss: 1019.1878 - mse: 1019.1876 - mae: 22.1008\n",
      "Epoch 12/60\n",
      "1850/1850 [==============================] - 2s 821us/step - loss: 1021.4901 - mse: 1021.4901 - mae: 21.9914\n",
      "Epoch 13/60\n",
      "1850/1850 [==============================] - 1s 800us/step - loss: 1021.7095 - mse: 1021.7095 - mae: 22.0644\n",
      "Epoch 14/60\n",
      "1850/1850 [==============================] - 2s 824us/step - loss: 1016.9814 - mse: 1016.9813 - mae: 21.9790\n",
      "Epoch 15/60\n",
      "1850/1850 [==============================] - 1s 800us/step - loss: 1014.4379 - mse: 1014.4379 - mae: 21.9990\n",
      "Epoch 16/60\n",
      "1850/1850 [==============================] - 1s 799us/step - loss: 1016.2104 - mse: 1016.2104 - mae: 21.8926\n",
      "Epoch 17/60\n",
      "1850/1850 [==============================] - 2s 837us/step - loss: 1014.5029 - mse: 1014.5030 - mae: 21.7961\n",
      "Epoch 18/60\n",
      "1850/1850 [==============================] - 2s 886us/step - loss: 1020.7665 - mse: 1020.7663 - mae: 22.0363\n",
      "Epoch 19/60\n",
      "1850/1850 [==============================] - 2s 973us/step - loss: 1015.5431 - mse: 1015.5430 - mae: 21.8474\n",
      "Epoch 20/60\n",
      "1850/1850 [==============================] - 2s 888us/step - loss: 1017.6437 - mse: 1017.6438 - mae: 21.9027\n",
      "Epoch 21/60\n",
      "1850/1850 [==============================] - 1s 802us/step - loss: 1009.5528 - mse: 1009.5529 - mae: 21.6926\n",
      "Epoch 22/60\n",
      "1850/1850 [==============================] - 2s 866us/step - loss: 1009.2631 - mse: 1009.2630 - mae: 21.7984\n",
      "Epoch 23/60\n",
      "1850/1850 [==============================] - 2s 909us/step - loss: 1007.6093 - mse: 1007.6094 - mae: 21.7402\n",
      "Epoch 24/60\n",
      "1850/1850 [==============================] - 3s 1ms/step - loss: 1007.6130 - mse: 1007.6129 - mae: 21.6137\n",
      "Epoch 25/60\n",
      "1850/1850 [==============================] - 2s 975us/step - loss: 1004.0322 - mse: 1004.0323 - mae: 21.67340s - loss: 1081.2949 - mse: \n",
      "Epoch 26/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 1008.3322 - mse: 1008.3322 - mae: 21.5463\n",
      "Epoch 27/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 1021.2455 - mse: 1021.2456 - mae: 21.9004: 0s - loss: 1097.0287 - mse\n",
      "Epoch 28/60\n",
      "1850/1850 [==============================] - 2s 909us/step - loss: 1002.8513 - mse: 1002.8511 - mae: 21.6452\n",
      "Epoch 29/60\n",
      "1850/1850 [==============================] - 2s 845us/step - loss: 1005.6766 - mse: 1005.6766 - mae: 21.5435\n",
      "Epoch 30/60\n",
      "1850/1850 [==============================] - 2s 839us/step - loss: 1004.1479 - mse: 1004.1479 - mae: 21.6254\n",
      "Epoch 31/60\n",
      "1850/1850 [==============================] - 2s 821us/step - loss: 1000.8860 - mse: 1000.8859 - mae: 21.5147\n",
      "Epoch 32/60\n",
      "1850/1850 [==============================] - 2s 824us/step - loss: 1002.5245 - mse: 1002.5245 - mae: 21.5194\n",
      "Epoch 33/60\n",
      "1850/1850 [==============================] - 2s 843us/step - loss: 1003.3926 - mse: 1003.3926 - mae: 21.4819\n",
      "Epoch 34/60\n",
      "1850/1850 [==============================] - 2s 843us/step - loss: 1002.0671 - mse: 1002.0671 - mae: 21.3302\n",
      "Epoch 35/60\n",
      "1850/1850 [==============================] - 2s 995us/step - loss: 1004.6892 - mse: 1004.6891 - mae: 21.6845\n",
      "Epoch 36/60\n",
      "1850/1850 [==============================] - 2s 973us/step - loss: 1006.0362 - mse: 1006.0362 - mae: 21.5552\n",
      "Epoch 37/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 1002.5038 - mse: 1002.5037 - mae: 21.4787\n",
      "Epoch 38/60\n",
      "1850/1850 [==============================] - 1s 800us/step - loss: 997.1061 - mse: 997.1062 - mae: 21.4679\n",
      "Epoch 39/60\n",
      "1850/1850 [==============================] - 2s 867us/step - loss: 1010.3250 - mse: 1010.3251 - mae: 21.5547\n",
      "Epoch 40/60\n",
      "1850/1850 [==============================] - 2s 909us/step - loss: 998.9761 - mse: 998.9762 - mae: 21.3836\n",
      "Epoch 41/60\n",
      "1850/1850 [==============================] - 2s 861us/step - loss: 998.3792 - mse: 998.3792 - mae: 21.3531\n",
      "Epoch 42/60\n",
      "1850/1850 [==============================] - 2s 975us/step - loss: 1006.6830 - mse: 1006.6830 - mae: 21.4501\n",
      "Epoch 43/60\n",
      "1850/1850 [==============================] - 2s 992us/step - loss: 996.8112 - mse: 996.8114 - mae: 21.3629\n",
      "Epoch 44/60\n",
      "1850/1850 [==============================] - 2s 951us/step - loss: 995.3462 - mse: 995.3464 - mae: 21.2707\n",
      "Epoch 45/60\n",
      "1850/1850 [==============================] - 2s 822us/step - loss: 999.2816 - mse: 999.2817 - mae: 21.3226\n",
      "Epoch 46/60\n",
      "1850/1850 [==============================] - 2s 887us/step - loss: 1000.3851 - mse: 1000.3849 - mae: 21.4043\n",
      "Epoch 47/60\n",
      "1850/1850 [==============================] - 2s 842us/step - loss: 998.6338 - mse: 998.6338 - mae: 21.3397\n",
      "Epoch 48/60\n",
      "1850/1850 [==============================] - 2s 977us/step - loss: 998.5606 - mse: 998.5607 - mae: 21.2883\n",
      "Epoch 49/60\n",
      "1850/1850 [==============================] - 2s 842us/step - loss: 990.7753 - mse: 990.7751 - mae: 21.2399\n",
      "Epoch 50/60\n",
      "1850/1850 [==============================] - 2s 863us/step - loss: 995.8658 - mse: 995.8658 - mae: 21.3313\n",
      "Epoch 51/60\n",
      "1850/1850 [==============================] - 2s 929us/step - loss: 993.4347 - mse: 993.4348 - mae: 21.2502\n",
      "Epoch 52/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 994.1499 - mse: 994.1500 - mae: 21.3291\n",
      "Epoch 53/60\n",
      "1850/1850 [==============================] - 2s 866us/step - loss: 990.6933 - mse: 990.6934 - mae: 21.2324\n",
      "Epoch 54/60\n",
      "1850/1850 [==============================] - 2s 822us/step - loss: 992.7621 - mse: 992.7621 - mae: 21.2867\n",
      "Epoch 55/60\n",
      "1850/1850 [==============================] - 2s 865us/step - loss: 996.6076 - mse: 996.6076 - mae: 21.2544\n",
      "Epoch 56/60\n",
      "1850/1850 [==============================] - 2s 889us/step - loss: 991.2109 - mse: 991.2109 - mae: 21.1540\n",
      "Epoch 57/60\n",
      "1850/1850 [==============================] - 1s 757us/step - loss: 988.8288 - mse: 988.8288 - mae: 21.1512\n",
      "Epoch 58/60\n",
      "  96/1850 [>.............................] - ETA: 5s - loss: 905.1407 - mse: 905.1407 - mae: 20.7511"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.163005). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1850/1850 [==============================] - ETA: 0s - loss: 988.6257 - mse: 988.6255 - mae: 21.17 - 2s 1ms/step - loss: 987.9470 - mse: 987.9469 - mae: 21.1770\n",
      "Epoch 59/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 990.7686 - mse: 990.7688 - mae: 21.2530: 1s - loss: 8\n",
      "Epoch 60/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 1004.3531 - mse: 1004.3530 - mae: 21.2910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=15)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "3699/3699 [==============================] - 14s 4ms/step - loss: 9064.4755 - mse: 9064.4775 - mae: 84.7412ETA: 12s - loss: 1210\n",
      "Epoch 2/60\n",
      "3699/3699 [==============================] - 3s 887us/step - loss: 1156.7123 - mse: 1156.7124 - mae: 23.4099\n",
      "Epoch 3/60\n",
      "3699/3699 [==============================] - ETA: 0s - loss: 1128.0122 - mse: 1128.0126 - mae: 22.86 - 4s 974us/step - loss: 1129.2012 - mse: 1129.2014 - mae: 22.8657\n",
      "Epoch 4/60\n",
      "3699/3699 [==============================] - 3s 876us/step - loss: 1126.8654 - mse: 1126.8656 - mae: 22.9127\n",
      "Epoch 5/60\n",
      "3699/3699 [==============================] - 3s 856us/step - loss: 1128.2989 - mse: 1128.2990 - mae: 22.8171\n",
      "Epoch 6/60\n",
      "3699/3699 [==============================] - 3s 813us/step - loss: 1123.0329 - mse: 1123.0328 - mae: 22.8708\n",
      "Epoch 7/60\n",
      "3699/3699 [==============================] - 3s 911us/step - loss: 1121.5040 - mse: 1121.5038 - mae: 22.8371\n",
      "Epoch 8/60\n",
      "3699/3699 [==============================] - 3s 921us/step - loss: 1117.1511 - mse: 1117.1510 - mae: 22.6461\n",
      "Epoch 9/60\n",
      "3699/3699 [==============================] - 3s 839us/step - loss: 1118.3475 - mse: 1118.3475 - mae: 22.7881\n",
      "Epoch 10/60\n",
      "3699/3699 [==============================] - 3s 833us/step - loss: 1118.5913 - mse: 1118.5913 - mae: 22.7394\n",
      "Epoch 11/60\n",
      "3699/3699 [==============================] - 3s 887us/step - loss: 1113.4809 - mse: 1113.4810 - mae: 22.6298\n",
      "Epoch 12/60\n",
      "3699/3699 [==============================] - 4s 985us/step - loss: 1117.3647 - mse: 1117.3647 - mae: 22.6474\n",
      "Epoch 13/60\n",
      "3699/3699 [==============================] - 3s 863us/step - loss: 1114.0524 - mse: 1114.0525 - mae: 22.5992\n",
      "Epoch 14/60\n",
      "3699/3699 [==============================] - 3s 846us/step - loss: 1114.2443 - mse: 1114.2443 - mae: 22.73761s - loss: 1099.\n",
      "Epoch 15/60\n",
      "3699/3699 [==============================] - 3s 811us/step - loss: 1116.0269 - mse: 1116.0270 - mae: 22.5785\n",
      "Epoch 16/60\n",
      "3699/3699 [==============================] - 3s 941us/step - loss: 1114.1587 - mse: 1114.1586 - mae: 22.6851\n",
      "Epoch 17/60\n",
      "3699/3699 [==============================] - 3s 845us/step - loss: 1119.3401 - mse: 1119.3403 - mae: 22.6191\n",
      "Epoch 18/60\n",
      "3699/3699 [==============================] - 3s 933us/step - loss: 1120.3115 - mse: 1120.3114 - mae: 22.7697\n",
      "Epoch 19/60\n",
      "3699/3699 [==============================] - 3s 921us/step - loss: 1110.2497 - mse: 1110.2496 - mae: 22.5484\n",
      "Epoch 20/60\n",
      "3699/3699 [==============================] - 3s 908us/step - loss: 1112.4789 - mse: 1112.4789 - mae: 22.6394\n",
      "Epoch 21/60\n",
      "3699/3699 [==============================] - 4s 950us/step - loss: 1111.3294 - mse: 1111.3295 - mae: 22.6254\n",
      "Epoch 22/60\n",
      "3699/3699 [==============================] - 3s 887us/step - loss: 1107.7172 - mse: 1107.7170 - mae: 22.5358\n",
      "Epoch 23/60\n",
      "3699/3699 [==============================] - 3s 898us/step - loss: 1108.6119 - mse: 1108.6119 - mae: 22.5231\n",
      "Epoch 24/60\n",
      "3699/3699 [==============================] - 3s 865us/step - loss: 1107.9665 - mse: 1107.9666 - mae: 22.5228\n",
      "Epoch 25/60\n",
      "3699/3699 [==============================] - 3s 930us/step - loss: 1106.7052 - mse: 1106.7052 - mae: 22.5064\n",
      "Epoch 26/60\n",
      "3699/3699 [==============================] - 3s 800us/step - loss: 1112.5607 - mse: 1112.5608 - mae: 22.5678\n",
      "Epoch 27/60\n",
      "3699/3699 [==============================] - 3s 843us/step - loss: 1103.9502 - mse: 1103.9501 - mae: 22.4422\n",
      "Epoch 28/60\n",
      "3699/3699 [==============================] - 3s 811us/step - loss: 1104.7722 - mse: 1104.7721 - mae: 22.3820\n",
      "Epoch 29/60\n",
      "3699/3699 [==============================] - 4s 961us/step - loss: 1105.5097 - mse: 1105.5098 - mae: 22.4976\n",
      "Epoch 30/60\n",
      "3699/3699 [==============================] - 3s 940us/step - loss: 1110.9678 - mse: 1110.9678 - mae: 22.4788\n",
      "Epoch 31/60\n",
      "3699/3699 [==============================] - 3s 931us/step - loss: 1102.9298 - mse: 1102.9296 - mae: 22.4903\n",
      "Epoch 32/60\n",
      "3699/3699 [==============================] - 3s 920us/step - loss: 1108.1553 - mse: 1108.1553 - mae: 22.4184\n",
      "Epoch 33/60\n",
      "3699/3699 [==============================] - 3s 931us/step - loss: 1103.2369 - mse: 1103.2367 - mae: 22.47152s - loss: 1 - ETA: 1s - loss: 1060.5268\n",
      "Epoch 34/60\n",
      "3699/3699 [==============================] - 3s 885us/step - loss: 1104.3563 - mse: 1104.3563 - mae: 22.5061\n",
      "Epoch 35/60\n",
      "3699/3699 [==============================] - 3s 856us/step - loss: 1100.5649 - mse: 1100.5651 - mae: 22.3192\n",
      "Epoch 36/60\n",
      "3699/3699 [==============================] - 3s 823us/step - loss: 1108.0602 - mse: 1108.0603 - mae: 22.4679\n",
      "Epoch 37/60\n",
      "3699/3699 [==============================] - 3s 778us/step - loss: 1100.5551 - mse: 1100.5548 - mae: 22.4528\n",
      "Epoch 38/60\n",
      "3699/3699 [==============================] - 4s 951us/step - loss: 1104.7624 - mse: 1104.7622 - mae: 22.3397\n",
      "Epoch 39/60\n",
      "3699/3699 [==============================] - 3s 875us/step - loss: 1103.4260 - mse: 1103.4260 - mae: 22.4010\n",
      "Epoch 40/60\n",
      "3699/3699 [==============================] - 3s 843us/step - loss: 1101.0248 - mse: 1101.0253 - mae: 22.3769\n",
      "Epoch 41/60\n",
      "3699/3699 [==============================] - 3s 835us/step - loss: 1101.1590 - mse: 1101.1591 - mae: 22.4178\n",
      "Epoch 42/60\n",
      "3699/3699 [==============================] - 3s 909us/step - loss: 1098.1509 - mse: 1098.1510 - mae: 22.32790s - loss: 1100.2137 - mse: 1100.2139 - mae: 22.\n",
      "Epoch 43/60\n",
      "3699/3699 [==============================] - 3s 864us/step - loss: 1099.9983 - mse: 1099.9984 - mae: 22.3334\n",
      "Epoch 44/60\n",
      "3699/3699 [==============================] - 3s 800us/step - loss: 1100.9273 - mse: 1100.9272 - mae: 22.3263\n",
      "Epoch 45/60\n",
      "3699/3699 [==============================] - 3s 800us/step - loss: 1103.7370 - mse: 1103.7371 - mae: 22.3463\n",
      "Epoch 46/60\n",
      "3699/3699 [==============================] - 3s 790us/step - loss: 1102.1501 - mse: 1102.1498 - mae: 22.4276\n",
      "Epoch 47/60\n",
      "3699/3699 [==============================] - 4s 975us/step - loss: 1100.8387 - mse: 1100.8384 - mae: 22.3199\n",
      "Epoch 48/60\n",
      "3699/3699 [==============================] - 3s 918us/step - loss: 1099.9240 - mse: 1099.9241 - mae: 22.4677\n",
      "Epoch 49/60\n",
      "3699/3699 [==============================] - 3s 929us/step - loss: 1094.4591 - mse: 1094.4591 - mae: 22.2261\n",
      "Epoch 50/60\n",
      "3699/3699 [==============================] - 3s 897us/step - loss: 1104.7649 - mse: 1104.7650 - mae: 22.4895\n",
      "Epoch 51/60\n",
      "3699/3699 [==============================] - 3s 885us/step - loss: 1095.8323 - mse: 1095.8323 - mae: 22.2103\n",
      "Epoch 52/60\n",
      "3699/3699 [==============================] - 3s 919us/step - loss: 1096.6294 - mse: 1096.6293 - mae: 22.2786\n",
      "Epoch 53/60\n",
      "3699/3699 [==============================] - 3s 897us/step - loss: 1103.8811 - mse: 1103.8812 - mae: 22.3652\n",
      "Epoch 54/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1098.2453 - mse: 1098.2452 - mae: 22.2678\n",
      "Epoch 55/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1100.7711 - mse: 1100.7715 - mae: 22.38821s - loss: 950.641\n",
      "Epoch 56/60\n",
      "3699/3699 [==============================] - 3s 908us/step - loss: 1105.7528 - mse: 1105.7529 - mae: 22.4582\n",
      "Epoch 57/60\n",
      "3699/3699 [==============================] - 3s 900us/step - loss: 1095.3810 - mse: 1095.3812 - mae: 22.15421s - loss: 116\n",
      "Epoch 58/60\n",
      "3699/3699 [==============================] - 3s 822us/step - loss: 1100.6931 - mse: 1100.6930 - mae: 22.3249\n",
      "Epoch 59/60\n",
      "3699/3699 [==============================] - 4s 996us/step - loss: 1096.9024 - mse: 1096.9025 - mae: 22.3115\n",
      "Epoch 60/60\n",
      "3699/3699 [==============================] - 3s 855us/step - loss: 1103.3628 - mse: 1103.3628 - mae: 22.2954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=15)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "5548/5548 [==============================] - 10s 2ms/step - loss: 9023.5994 - mse: 9023.5996 - mae: 78.6949\n",
      "Epoch 2/60\n",
      "5548/5548 [==============================] - 0s 50us/step - loss: 1685.1274 - mse: 1685.1271 - mae: 25.2442\n",
      "Epoch 3/60\n",
      "5548/5548 [==============================] - 0s 50us/step - loss: 1674.4684 - mse: 1674.4686 - mae: 25.1358\n",
      "Epoch 4/60\n",
      "5548/5548 [==============================] - 0s 50us/step - loss: 1670.4642 - mse: 1670.4637 - mae: 25.0618\n",
      "Epoch 5/60\n",
      "5548/5548 [==============================] - 0s 50us/step - loss: 1672.6644 - mse: 1672.6644 - mae: 25.1705\n",
      "Epoch 6/60\n",
      "5548/5548 [==============================] - 0s 50us/step - loss: 1663.6061 - mse: 1663.6062 - mae: 24.9628\n",
      "Epoch 7/60\n",
      "5548/5548 [==============================] - 0s 50us/step - loss: 1657.7183 - mse: 1657.7181 - mae: 24.9530\n",
      "Epoch 8/60\n",
      "5548/5548 [==============================] - 0s 50us/step - loss: 1655.7909 - mse: 1655.7911 - mae: 24.9778\n",
      "Epoch 9/60\n",
      "5548/5548 [==============================] - 0s 50us/step - loss: 1663.6046 - mse: 1663.6049 - mae: 24.8526\n",
      "Epoch 10/60\n",
      "5548/5548 [==============================] - 0s 50us/step - loss: 1657.6800 - mse: 1657.6801 - mae: 24.9503\n",
      "Epoch 11/60\n",
      "5548/5548 [==============================] - 0s 50us/step - loss: 1651.0967 - mse: 1651.0966 - mae: 24.8479\n",
      "Epoch 12/60\n",
      "5548/5548 [==============================] - 0s 50us/step - loss: 1648.3601 - mse: 1648.3601 - mae: 24.8298\n",
      "Epoch 13/60\n",
      "5548/5548 [==============================] - 0s 50us/step - loss: 1652.3446 - mse: 1652.3441 - mae: 24.8994\n",
      "Epoch 14/60\n",
      "5548/5548 [==============================] - 0s 50us/step - loss: 1642.6179 - mse: 1642.6177 - mae: 24.8017\n",
      "Epoch 15/60\n",
      "5548/5548 [==============================] - 0s 50us/step - loss: 1637.7317 - mse: 1637.7322 - mae: 24.7596\n",
      "Epoch 16/60\n",
      "5548/5548 [==============================] - 0s 50us/step - loss: 1645.9231 - mse: 1645.9229 - mae: 24.7535\n",
      "Epoch 17/60\n",
      "5548/5548 [==============================] - 0s 50us/step - loss: 1645.6165 - mse: 1645.6166 - mae: 24.7842\n",
      "Epoch 18/60\n",
      "5548/5548 [==============================] - 0s 57us/step - loss: 1638.0027 - mse: 1638.0023 - mae: 24.7027\n",
      "Epoch 19/60\n",
      "5548/5548 [==============================] - 0s 71us/step - loss: 1637.3849 - mse: 1637.3851 - mae: 24.7667\n",
      "Epoch 20/60\n",
      "5548/5548 [==============================] - 0s 72us/step - loss: 1636.0435 - mse: 1636.0432 - mae: 24.7327\n",
      "Epoch 21/60\n",
      "5548/5548 [==============================] - 0s 72us/step - loss: 1634.6246 - mse: 1634.6241 - mae: 24.7397\n",
      "Epoch 22/60\n",
      "5548/5548 [==============================] - 0s 72us/step - loss: 1632.3485 - mse: 1632.3484 - mae: 24.7065\n",
      "Epoch 23/60\n",
      "5548/5548 [==============================] - 0s 73us/step - loss: 1635.1427 - mse: 1635.1423 - mae: 24.6931\n",
      "Epoch 24/60\n",
      "5548/5548 [==============================] - 0s 72us/step - loss: 1632.3522 - mse: 1632.3518 - mae: 24.6819\n",
      "Epoch 25/60\n",
      "5548/5548 [==============================] - 0s 74us/step - loss: 1633.4065 - mse: 1633.4062 - mae: 24.6227\n",
      "Epoch 26/60\n",
      "5548/5548 [==============================] - 0s 72us/step - loss: 1629.2304 - mse: 1629.2308 - mae: 24.7063\n",
      "Epoch 27/60\n",
      "5548/5548 [==============================] - 0s 74us/step - loss: 1625.5767 - mse: 1625.5771 - mae: 24.5900\n",
      "Epoch 28/60\n",
      "5548/5548 [==============================] - 0s 74us/step - loss: 1623.0172 - mse: 1623.0178 - mae: 24.5307\n",
      "Epoch 29/60\n",
      "5548/5548 [==============================] - 0s 72us/step - loss: 1626.1104 - mse: 1626.1107 - mae: 24.5513\n",
      "Epoch 30/60\n",
      "5548/5548 [==============================] - 0s 78us/step - loss: 1624.1684 - mse: 1624.1686 - mae: 24.5994\n",
      "Epoch 31/60\n",
      "5548/5548 [==============================] - 1s 140us/step - loss: 1626.8024 - mse: 1626.8019 - mae: 24.6115\n",
      "Epoch 32/60\n",
      "5548/5548 [==============================] - 1s 136us/step - loss: 1621.5404 - mse: 1621.5402 - mae: 24.5644\n",
      "Epoch 33/60\n",
      "5548/5548 [==============================] - 1s 132us/step - loss: 1622.8364 - mse: 1622.8359 - mae: 24.5473\n",
      "Epoch 34/60\n",
      "5548/5548 [==============================] - 1s 134us/step - loss: 1623.6466 - mse: 1623.6461 - mae: 24.6179\n",
      "Epoch 35/60\n",
      "5548/5548 [==============================] - 1s 135us/step - loss: 1619.9697 - mse: 1619.9697 - mae: 24.4834\n",
      "Epoch 36/60\n",
      "5548/5548 [==============================] - 1s 135us/step - loss: 1618.7397 - mse: 1618.7402 - mae: 24.5485\n",
      "Epoch 37/60\n",
      "5548/5548 [==============================] - 3s 608us/step - loss: 1619.1004 - mse: 1619.1010 - mae: 24.50110s - loss: 1667.03\n",
      "Epoch 38/60\n",
      "5548/5548 [==============================] - 5s 859us/step - loss: 1626.2852 - mse: 1626.2856 - mae: 24.6560\n",
      "Epoch 39/60\n",
      "5548/5548 [==============================] - 5s 910us/step - loss: 1617.0947 - mse: 1617.0950 - mae: 24.4522\n",
      "Epoch 40/60\n",
      "5548/5548 [==============================] - ETA: 0s - loss: 1621.7378 - mse: 1621.7379 - mae: 24.56 - 5s 962us/step - loss: 1618.8802 - mse: 1618.8804 - mae: 24.5465\n",
      "Epoch 41/60\n",
      "5548/5548 [==============================] - 5s 859us/step - loss: 1617.8534 - mse: 1617.8533 - mae: 24.4875\n",
      "Epoch 42/60\n",
      "5548/5548 [==============================] - 5s 857us/step - loss: 1621.3708 - mse: 1621.3702 - mae: 24.5660\n",
      "Epoch 43/60\n",
      "5548/5548 [==============================] - 5s 960us/step - loss: 1623.0780 - mse: 1623.0776 - mae: 24.48384s -\n",
      "Epoch 44/60\n",
      "5548/5548 [==============================] - 5s 844us/step - loss: 1620.1851 - mse: 1620.1846 - mae: 24.5072\n",
      "Epoch 45/60\n",
      "5548/5548 [==============================] - 5s 987us/step - loss: 1621.2456 - mse: 1621.2454 - mae: 24.5252\n",
      "Epoch 46/60\n",
      "5548/5548 [==============================] - 5s 968us/step - loss: 1620.6429 - mse: 1620.6426 - mae: 24.5243\n",
      "Epoch 47/60\n",
      "5548/5548 [==============================] - 5s 852us/step - loss: 1621.7955 - mse: 1621.7957 - mae: 24.5229\n",
      "Epoch 48/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1618.2975 - mse: 1618.2976 - mae: 24.4483: 2s - loss: 1 - ETA: 1s - los\n",
      "Epoch 49/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1614.1941 - mse: 1614.1941 - mae: 24.4850\n",
      "Epoch 50/60\n",
      "5548/5548 [==============================] - 5s 926us/step - loss: 1618.8950 - mse: 1618.8951 - mae: 24.5487\n",
      "Epoch 51/60\n",
      "5548/5548 [==============================] - 5s 879us/step - loss: 1619.4315 - mse: 1619.4320 - mae: 24.4823\n",
      "Epoch 52/60\n",
      "5548/5548 [==============================] - 5s 873us/step - loss: 1617.7985 - mse: 1617.7985 - mae: 24.4270\n",
      "Epoch 53/60\n",
      "5548/5548 [==============================] - 5s 881us/step - loss: 1615.5286 - mse: 1615.5284 - mae: 24.5420\n",
      "Epoch 54/60\n",
      "5548/5548 [==============================] - 5s 909us/step - loss: 1623.6479 - mse: 1623.6482 - mae: 24.4679\n",
      "Epoch 55/60\n",
      "5548/5548 [==============================] - 5s 820us/step - loss: 1623.6731 - mse: 1623.6733 - mae: 24.5769\n",
      "Epoch 56/60\n",
      "5548/5548 [==============================] - 5s 902us/step - loss: 1622.2871 - mse: 1622.2878 - mae: 24.5449\n",
      "Epoch 57/60\n",
      "5548/5548 [==============================] - 5s 967us/step - loss: 1619.1613 - mse: 1619.1611 - mae: 24.4878\n",
      "Epoch 58/60\n",
      "5548/5548 [==============================] - 5s 867us/step - loss: 1615.0661 - mse: 1615.0659 - mae: 24.51700s - loss: 1298.2406 - mse: \n",
      "Epoch 59/60\n",
      "5548/5548 [==============================] - 5s 901us/step - loss: 1615.0150 - mse: 1615.0151 - mae: 24.3896\n",
      "Epoch 60/60\n",
      "5548/5548 [==============================] - 5s 909us/step - loss: 1617.1354 - mse: 1617.1350 - mae: 24.4682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=15)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "7397/7397 [==============================] - 16s 2ms/step - loss: 6821.2371 - mse: 6821.2393 - mae: 62.6640\n",
      "Epoch 2/60\n",
      "7397/7397 [==============================] - 7s 914us/step - loss: 1634.6691 - mse: 1634.6688 - mae: 25.6248\n",
      "Epoch 3/60\n",
      "7397/7397 [==============================] - 7s 942us/step - loss: 1618.0345 - mse: 1618.0348 - mae: 25.5077\n",
      "Epoch 4/60\n",
      "7397/7397 [==============================] - 7s 962us/step - loss: 1604.1093 - mse: 1604.1091 - mae: 25.3566\n",
      "Epoch 5/60\n",
      "7397/7397 [==============================] - 6s 856us/step - loss: 1593.8424 - mse: 1593.8428 - mae: 25.2041\n",
      "Epoch 6/60\n",
      "7397/7397 [==============================] - 7s 883us/step - loss: 1593.1760 - mse: 1593.1764 - mae: 25.2727\n",
      "Epoch 7/60\n",
      "7397/7397 [==============================] - 7s 1ms/step - loss: 1588.4744 - mse: 1588.4738 - mae: 25.2125: 2s - loss: 1743.2778 - mse: 1743.2\n",
      "Epoch 8/60\n",
      "7397/7397 [==============================] - 7s 913us/step - loss: 1579.6586 - mse: 1579.6573 - mae: 25.1468\n",
      "Epoch 9/60\n",
      "7397/7397 [==============================] - 7s 917us/step - loss: 1581.9076 - mse: 1581.9073 - mae: 25.12980s - loss: 1562.5857 - mse: 1562.5854 \n",
      "Epoch 10/60\n",
      "7397/7397 [==============================] - 7s 898us/step - loss: 1581.5547 - mse: 1581.5546 - mae: 25.1150\n",
      "Epoch 11/60\n",
      "7397/7397 [==============================] - 6s 855us/step - loss: 1572.5042 - mse: 1572.5044 - mae: 25.0611\n",
      "Epoch 12/60\n",
      "7397/7397 [==============================] - 7s 945us/step - loss: 1572.8702 - mse: 1572.8699 - mae: 25.0798\n",
      "Epoch 13/60\n",
      "7397/7397 [==============================] - ETA: 0s - loss: 1570.4218 - mse: 1570.4220 - mae: 24.95 - 7s 896us/step - loss: 1570.5483 - mse: 1570.5485 - mae: 24.9940\n",
      "Epoch 14/60\n",
      "7397/7397 [==============================] - 7s 984us/step - loss: 1577.3421 - mse: 1577.3419 - mae: 25.1224\n",
      "Epoch 15/60\n",
      "7397/7397 [==============================] - 7s 925us/step - loss: 1569.3799 - mse: 1569.3799 - mae: 25.0608\n",
      "Epoch 16/60\n",
      "7397/7397 [==============================] - 7s 992us/step - loss: 1568.7421 - mse: 1568.7421 - mae: 25.0616\n",
      "Epoch 17/60\n",
      "7397/7397 [==============================] - 6s 833us/step - loss: 1571.5304 - mse: 1571.5306 - mae: 25.0324\n",
      "Epoch 18/60\n",
      "7397/7397 [==============================] - 7s 923us/step - loss: 1564.3659 - mse: 1564.3665 - mae: 24.9650\n",
      "Epoch 19/60\n",
      "7397/7397 [==============================] - 6s 806us/step - loss: 1570.8857 - mse: 1570.8856 - mae: 24.9797\n",
      "Epoch 20/60\n",
      "7397/7397 [==============================] - 7s 910us/step - loss: 1563.1104 - mse: 1563.1107 - mae: 24.9582\n",
      "Epoch 21/60\n",
      "7397/7397 [==============================] - 7s 975us/step - loss: 1564.4851 - mse: 1564.4851 - mae: 24.9128\n",
      "Epoch 22/60\n",
      "7397/7397 [==============================] - 7s 995us/step - loss: 1563.5604 - mse: 1563.5608 - mae: 24.9464\n",
      "Epoch 23/60\n",
      "7397/7397 [==============================] - 7s 952us/step - loss: 1559.6024 - mse: 1559.6021 - mae: 24.8873\n",
      "Epoch 24/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1562.7165 - mse: 1562.7157 - mae: 24.9692: 3s - los - ETA\n",
      "Epoch 25/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1562.6106 - mse: 1562.6101 - mae: 24.8867\n",
      "Epoch 26/60\n",
      "7397/7397 [==============================] - 7s 1ms/step - loss: 1563.5678 - mse: 1563.5684 - mae: 24.8448\n",
      "Epoch 27/60\n",
      "7397/7397 [==============================] - 6s 877us/step - loss: 1558.7885 - mse: 1558.7882 - mae: 24.7945\n",
      "Epoch 28/60\n",
      "7397/7397 [==============================] - 6s 869us/step - loss: 1557.2191 - mse: 1557.2192 - mae: 24.9046\n",
      "Epoch 29/60\n",
      "7397/7397 [==============================] - 6s 827us/step - loss: 1558.7469 - mse: 1558.7474 - mae: 24.8933\n",
      "Epoch 30/60\n",
      "7397/7397 [==============================] - 7s 963us/step - loss: 1562.0170 - mse: 1562.0168 - mae: 24.9383\n",
      "Epoch 31/60\n",
      "7397/7397 [==============================] - 6s 853us/step - loss: 1554.9932 - mse: 1554.9932 - mae: 24.8205\n",
      "Epoch 32/60\n",
      "7397/7397 [==============================] - 6s 831us/step - loss: 1556.9912 - mse: 1556.9908 - mae: 24.9309\n",
      "Epoch 33/60\n",
      "7397/7397 [==============================] - 7s 980us/step - loss: 1558.0255 - mse: 1558.0261 - mae: 24.7926\n",
      "Epoch 34/60\n",
      "7397/7397 [==============================] - 7s 915us/step - loss: 1557.5843 - mse: 1557.5846 - mae: 24.8342\n",
      "Epoch 35/60\n",
      "7397/7397 [==============================] - 7s 915us/step - loss: 1560.6550 - mse: 1560.6548 - mae: 24.9424\n",
      "Epoch 36/60\n",
      "7397/7397 [==============================] - 6s 833us/step - loss: 1555.7420 - mse: 1555.7421 - mae: 24.8053\n",
      "Epoch 37/60\n",
      "7397/7397 [==============================] - 7s 891us/step - loss: 1557.7479 - mse: 1557.7484 - mae: 24.7562\n",
      "Epoch 38/60\n",
      "7397/7397 [==============================] - 6s 844us/step - loss: 1554.4258 - mse: 1554.4260 - mae: 24.8133\n",
      "Epoch 39/60\n",
      "7397/7397 [==============================] - 7s 947us/step - loss: 1555.2785 - mse: 1555.2791 - mae: 24.7835\n",
      "Epoch 40/60\n",
      "7397/7397 [==============================] - 6s 827us/step - loss: 1555.3825 - mse: 1555.3822 - mae: 24.8340\n",
      "Epoch 41/60\n",
      "7397/7397 [==============================] - 7s 896us/step - loss: 1552.7942 - mse: 1552.7944 - mae: 24.7378\n",
      "Epoch 42/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1564.1543 - mse: 1564.1548 - mae: 24.9397\n",
      "Epoch 43/60\n",
      "7397/7397 [==============================] - 7s 932us/step - loss: 1554.1673 - mse: 1554.1674 - mae: 24.8090\n",
      "Epoch 44/60\n",
      "7397/7397 [==============================] - 6s 850us/step - loss: 1551.3789 - mse: 1551.3790 - mae: 24.7445\n",
      "Epoch 45/60\n",
      "7397/7397 [==============================] - 6s 850us/step - loss: 1551.9357 - mse: 1551.9364 - mae: 24.7607\n",
      "Epoch 46/60\n",
      "7397/7397 [==============================] - 7s 883us/step - loss: 1559.0996 - mse: 1559.0997 - mae: 24.7428\n",
      "Epoch 47/60\n",
      "7397/7397 [==============================] - 6s 828us/step - loss: 1550.0251 - mse: 1550.0255 - mae: 24.7805\n",
      "Epoch 48/60\n",
      "7397/7397 [==============================] - 7s 962us/step - loss: 1556.6396 - mse: 1556.6398 - mae: 24.8652\n",
      "Epoch 49/60\n",
      "7397/7397 [==============================] - 6s 850us/step - loss: 1550.4052 - mse: 1550.4052 - mae: 24.7126\n",
      "Epoch 50/60\n",
      "7397/7397 [==============================] - 6s 859us/step - loss: 1556.0628 - mse: 1556.0630 - mae: 24.6963\n",
      "Epoch 51/60\n",
      "7397/7397 [==============================] - 7s 904us/step - loss: 1552.4153 - mse: 1552.4147 - mae: 24.8186\n",
      "Epoch 52/60\n",
      "7397/7397 [==============================] - 7s 919us/step - loss: 1549.9746 - mse: 1549.9745 - mae: 24.7588\n",
      "Epoch 53/60\n",
      "7397/7397 [==============================] - 6s 861us/step - loss: 1549.8242 - mse: 1549.8235 - mae: 24.6445\n",
      "Epoch 54/60\n",
      "7397/7397 [==============================] - 7s 910us/step - loss: 1550.5638 - mse: 1550.5643 - mae: 24.75190s - loss: 1592.5333 - mse: \n",
      "Epoch 55/60\n",
      "7397/7397 [==============================] - 7s 900us/step - loss: 1551.2615 - mse: 1551.2617 - mae: 24.7263\n",
      "Epoch 56/60\n",
      "7397/7397 [==============================] - 6s 827us/step - loss: 1546.4449 - mse: 1546.4457 - mae: 24.7049\n",
      "Epoch 57/60\n",
      "7397/7397 [==============================] - 7s 982us/step - loss: 1548.1248 - mse: 1548.1240 - mae: 24.6468\n",
      "Epoch 58/60\n",
      "7397/7397 [==============================] - 7s 946us/step - loss: 1550.2319 - mse: 1550.2322 - mae: 24.65540s - loss: 1567.0865 - mse: 1567.0867 - \n",
      "Epoch 59/60\n",
      "7397/7397 [==============================] - 7s 995us/step - loss: 1548.8579 - mse: 1548.8582 - mae: 24.7381\n",
      "Epoch 60/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1549.0034 - mse: 1549.0040 - mae: 24.7060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=10)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "1850/1850 [==============================] - 19s 10ms/step - loss: 9551.7544 - mse: 9551.7539 - mae: 89.4682\n",
      "Epoch 2/60\n",
      "1850/1850 [==============================] - 3s 1ms/step - loss: 1079.9535 - mse: 1079.9535 - mae: 23.54510s - loss: 924.9523 - ms\n",
      "Epoch 3/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 1059.4086 - mse: 1059.4086 - mae: 23.0500\n",
      "Epoch 4/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 1048.9359 - mse: 1048.9358 - mae: 22.7630\n",
      "Epoch 5/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 1036.8938 - mse: 1036.8936 - mae: 22.6372\n",
      "Epoch 6/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 1034.2327 - mse: 1034.2327 - mae: 22.4685\n",
      "Epoch 7/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 1028.4261 - mse: 1028.4263 - mae: 22.3567\n",
      "Epoch 8/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 1019.9156 - mse: 1019.9158 - mae: 22.1989\n",
      "Epoch 9/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 1018.3552 - mse: 1018.3553 - mae: 22.1715\n",
      "Epoch 10/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 1017.0182 - mse: 1017.0182 - mae: 22.0232\n",
      "Epoch 11/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 1014.9550 - mse: 1014.9550 - mae: 21.9904\n",
      "Epoch 12/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 1011.4172 - mse: 1011.4174 - mae: 21.8824\n",
      "Epoch 13/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 1012.3163 - mse: 1012.3162 - mae: 21.8748\n",
      "Epoch 14/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 1003.8219 - mse: 1003.8220 - mae: 21.8091\n",
      "Epoch 15/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 1008.0391 - mse: 1008.0390 - mae: 21.7589\n",
      "Epoch 16/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 1004.7520 - mse: 1004.7520 - mae: 21.7088\n",
      "Epoch 17/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 1001.2944 - mse: 1001.2944 - mae: 21.5514\n",
      "Epoch 18/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 1005.5816 - mse: 1005.5815 - mae: 21.6882\n",
      "Epoch 19/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 1007.1283 - mse: 1007.1282 - mae: 21.6673\n",
      "Epoch 20/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 1007.4852 - mse: 1007.4851 - mae: 21.6521\n",
      "Epoch 21/60\n",
      "1850/1850 [==============================] - 2s 977us/step - loss: 997.1678 - mse: 997.1678 - mae: 21.4570\n",
      "Epoch 22/60\n",
      "1850/1850 [==============================] - 2s 936us/step - loss: 1003.0223 - mse: 1003.0223 - mae: 21.5777\n",
      "Epoch 23/60\n",
      "1850/1850 [==============================] - 2s 951us/step - loss: 999.6565 - mse: 999.6564 - mae: 21.5893\n",
      "Epoch 24/60\n",
      "1850/1850 [==============================] - 2s 977us/step - loss: 998.4077 - mse: 998.4077 - mae: 21.4791\n",
      "Epoch 25/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 998.8226 - mse: 998.8224 - mae: 21.4404\n",
      "Epoch 26/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 992.8985 - mse: 992.8984 - mae: 21.2986\n",
      "Epoch 27/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 989.8308 - mse: 989.8309 - mae: 21.3207\n",
      "Epoch 28/60\n",
      "1850/1850 [==============================] - 2s 979us/step - loss: 997.8858 - mse: 997.8858 - mae: 21.3948\n",
      "Epoch 29/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 995.4445 - mse: 995.4446 - mae: 21.2887\n",
      "Epoch 30/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 990.3756 - mse: 990.3757 - mae: 21.3020\n",
      "Epoch 31/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 992.2877 - mse: 992.2875 - mae: 21.3130\n",
      "Epoch 32/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 989.0840 - mse: 989.0841 - mae: 21.2675\n",
      "Epoch 33/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 993.5329 - mse: 993.5329 - mae: 21.3695\n",
      "Epoch 34/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 985.9813 - mse: 985.9813 - mae: 21.1975\n",
      "Epoch 35/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 991.2471 - mse: 991.2470 - mae: 21.2769\n",
      "Epoch 36/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 986.2838 - mse: 986.2839 - mae: 21.2056\n",
      "Epoch 37/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 983.4029 - mse: 983.4028 - mae: 21.0464\n",
      "Epoch 38/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 987.7729 - mse: 987.7729 - mae: 21.2646\n",
      "Epoch 39/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 985.1836 - mse: 985.1837 - mae: 21.2455\n",
      "Epoch 40/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 987.6541 - mse: 987.6542 - mae: 21.1468\n",
      "Epoch 41/60\n",
      "1850/1850 [==============================] - 3s 1ms/step - loss: 979.5220 - mse: 979.5221 - mae: 21.0821\n",
      "Epoch 42/60\n",
      "1850/1850 [==============================] - 3s 1ms/step - loss: 986.0778 - mse: 986.0779 - mae: 21.1939\n",
      "Epoch 43/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 981.1872 - mse: 981.1874 - mae: 21.0632\n",
      "Epoch 44/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 979.1702 - mse: 979.1702 - mae: 21.0980\n",
      "Epoch 45/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 983.3044 - mse: 983.3044 - mae: 21.0613TA: 1s\n",
      "Epoch 46/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 977.6697 - mse: 977.6697 - mae: 20.9161\n",
      "Epoch 47/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 978.5318 - mse: 978.5318 - mae: 21.0204: 1s - loss: 926.0732 - mse: 926.0732 - mae: - ETA: 1s - loss: 835.7\n",
      "Epoch 48/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 980.1022 - mse: 980.1024 - mae: 21.1107\n",
      "Epoch 49/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 977.5571 - mse: 977.5572 - mae: 21.0346\n",
      "Epoch 50/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 981.0865 - mse: 981.0865 - mae: 20.9623\n",
      "Epoch 51/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 981.8114 - mse: 981.8113 - mae: 21.0390\n",
      "Epoch 52/60\n",
      "1850/1850 [==============================] - 2s 978us/step - loss: 980.3913 - mse: 980.3913 - mae: 21.0108: 1s - loss: 1220.6226 - m\n",
      "Epoch 53/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 977.5553 - mse: 977.5555 - mae: 21.0184\n",
      "Epoch 54/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 976.4380 - mse: 976.4380 - mae: 20.9320\n",
      "Epoch 55/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 975.8008 - mse: 975.8009 - mae: 20.8792\n",
      "Epoch 56/60\n",
      "1850/1850 [==============================] - 2s 999us/step - loss: 978.7310 - mse: 978.7309 - mae: 20.9791\n",
      "Epoch 57/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 977.4412 - mse: 977.4411 - mae: 20.9275\n",
      "Epoch 58/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 975.5219 - mse: 975.5220 - mae: 20.9398\n",
      "Epoch 59/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 971.6497 - mse: 971.6498 - mae: 20.8956\n",
      "Epoch 60/60\n",
      "1850/1850 [==============================] - 2s 1ms/step - loss: 971.8457 - mse: 971.8456 - mae: 20.8629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=10)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "3699/3699 [==============================] - 21s 6ms/step - loss: 5664.0072 - mse: 5664.0063 - mae: 57.6249\n",
      "Epoch 2/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1149.4245 - mse: 1149.4246 - mae: 23.1058\n",
      "Epoch 3/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1138.6191 - mse: 1138.6194 - mae: 22.9882\n",
      "Epoch 4/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1137.7825 - mse: 1137.7826 - mae: 22.8862\n",
      "Epoch 5/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1129.4735 - mse: 1129.4733 - mae: 22.8785\n",
      "Epoch 6/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1127.9579 - mse: 1127.9575 - mae: 22.8614\n",
      "Epoch 7/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1124.8886 - mse: 1124.8888 - mae: 22.7896\n",
      "Epoch 8/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1124.2459 - mse: 1124.2457 - mae: 22.8072\n",
      "Epoch 9/60\n",
      "3699/3699 [==============================] - 4s 978us/step - loss: 1122.4684 - mse: 1122.4683 - mae: 22.7171\n",
      "Epoch 10/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1124.0254 - mse: 1124.0258 - mae: 22.7490\n",
      "Epoch 11/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1118.1261 - mse: 1118.1262 - mae: 22.6502\n",
      "Epoch 12/60\n",
      "3699/3699 [==============================] - 5s 1ms/step - loss: 1117.1076 - mse: 1117.1075 - mae: 22.5970\n",
      "Epoch 13/60\n",
      "3699/3699 [==============================] - 5s 1ms/step - loss: 1120.3428 - mse: 1120.3430 - mae: 22.7296\n",
      "Epoch 14/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1119.5798 - mse: 1119.5797 - mae: 22.6383\n",
      "Epoch 15/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1117.6113 - mse: 1117.6116 - mae: 22.6318\n",
      "Epoch 16/60\n",
      "3699/3699 [==============================] - 4s 999us/step - loss: 1111.3101 - mse: 1111.3099 - mae: 22.5621\n",
      "Epoch 17/60\n",
      "3699/3699 [==============================] - 4s 966us/step - loss: 1116.9961 - mse: 1116.9963 - mae: 22.5631\n",
      "Epoch 18/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1112.7323 - mse: 1112.7324 - mae: 22.5991\n",
      "Epoch 19/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1110.9397 - mse: 1110.9398 - mae: 22.5645\n",
      "Epoch 20/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1110.7969 - mse: 1110.7969 - mae: 22.5412\n",
      "Epoch 21/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1108.1411 - mse: 1108.1411 - mae: 22.4753\n",
      "Epoch 22/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1107.3205 - mse: 1107.3204 - mae: 22.5389\n",
      "Epoch 23/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1107.4267 - mse: 1107.4266 - mae: 22.4657\n",
      "Epoch 24/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1110.1037 - mse: 1110.1039 - mae: 22.4936\n",
      "Epoch 25/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1107.4133 - mse: 1107.4135 - mae: 22.4894\n",
      "Epoch 26/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1105.4440 - mse: 1105.4438 - mae: 22.4172\n",
      "Epoch 27/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1109.7750 - mse: 1109.7748 - mae: 22.5176\n",
      "Epoch 28/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1107.2333 - mse: 1107.2335 - mae: 22.3552\n",
      "Epoch 29/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1105.0280 - mse: 1105.0280 - mae: 22.3967\n",
      "Epoch 30/60\n",
      "3699/3699 [==============================] - 4s 989us/step - loss: 1104.9002 - mse: 1104.9004 - mae: 22.4075\n",
      "Epoch 31/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1108.1639 - mse: 1108.1641 - mae: 22.4163\n",
      "Epoch 32/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1105.0365 - mse: 1105.0363 - mae: 22.3431\n",
      "Epoch 33/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1103.4391 - mse: 1103.4391 - mae: 22.4045\n",
      "Epoch 34/60\n",
      "3699/3699 [==============================] - 4s 966us/step - loss: 1103.5847 - mse: 1103.5847 - mae: 22.3001\n",
      "Epoch 35/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1102.9261 - mse: 1102.9264 - mae: 22.3377\n",
      "Epoch 36/60\n",
      "3699/3699 [==============================] - 5s 1ms/step - loss: 1104.9066 - mse: 1104.9065 - mae: 22.4258\n",
      "Epoch 37/60\n",
      "3699/3699 [==============================] - 3s 851us/step - loss: 1102.3161 - mse: 1102.3162 - mae: 22.3724\n",
      "Epoch 38/60\n",
      "3699/3699 [==============================] - 0s 61us/step - loss: 1104.4028 - mse: 1104.4028 - mae: 22.3618\n",
      "Epoch 39/60\n",
      "3699/3699 [==============================] - 0s 61us/step - loss: 1099.4247 - mse: 1099.4243 - mae: 22.3135\n",
      "Epoch 40/60\n",
      "3699/3699 [==============================] - 0s 61us/step - loss: 1101.2593 - mse: 1101.2594 - mae: 22.3385\n",
      "Epoch 41/60\n",
      "3699/3699 [==============================] - 0s 61us/step - loss: 1099.8262 - mse: 1099.8260 - mae: 22.3218\n",
      "Epoch 42/60\n",
      "3699/3699 [==============================] - 0s 61us/step - loss: 1100.0944 - mse: 1100.0947 - mae: 22.3176\n",
      "Epoch 43/60\n",
      "3699/3699 [==============================] - 0s 61us/step - loss: 1103.5411 - mse: 1103.5411 - mae: 22.3518\n",
      "Epoch 44/60\n",
      "3699/3699 [==============================] - 0s 61us/step - loss: 1098.0361 - mse: 1098.0361 - mae: 22.2463\n",
      "Epoch 45/60\n",
      "3699/3699 [==============================] - 0s 61us/step - loss: 1100.9677 - mse: 1100.9678 - mae: 22.2985\n",
      "Epoch 46/60\n",
      "3699/3699 [==============================] - 0s 61us/step - loss: 1104.1963 - mse: 1104.1965 - mae: 22.3340\n",
      "Epoch 47/60\n",
      "3699/3699 [==============================] - 0s 61us/step - loss: 1100.3558 - mse: 1100.3560 - mae: 22.2958\n",
      "Epoch 48/60\n",
      "3699/3699 [==============================] - 0s 61us/step - loss: 1097.9210 - mse: 1097.9211 - mae: 22.3026\n",
      "Epoch 49/60\n",
      "3699/3699 [==============================] - 0s 61us/step - loss: 1097.4834 - mse: 1097.4833 - mae: 22.1751\n",
      "Epoch 50/60\n",
      "3699/3699 [==============================] - 0s 61us/step - loss: 1099.6468 - mse: 1099.6467 - mae: 22.1938\n",
      "Epoch 51/60\n",
      "3699/3699 [==============================] - 0s 61us/step - loss: 1100.9575 - mse: 1100.9578 - mae: 22.3514\n",
      "Epoch 52/60\n",
      "3699/3699 [==============================] - 0s 61us/step - loss: 1098.6455 - mse: 1098.6454 - mae: 22.2371\n",
      "Epoch 53/60\n",
      "3699/3699 [==============================] - 0s 61us/step - loss: 1097.5738 - mse: 1097.5740 - mae: 22.2226\n",
      "Epoch 54/60\n",
      "3699/3699 [==============================] - 0s 61us/step - loss: 1098.4370 - mse: 1098.4373 - mae: 22.2429\n",
      "Epoch 55/60\n",
      "3699/3699 [==============================] - 0s 61us/step - loss: 1095.9808 - mse: 1095.9808 - mae: 22.2433\n",
      "Epoch 56/60\n",
      "3699/3699 [==============================] - 0s 61us/step - loss: 1096.4016 - mse: 1096.4016 - mae: 22.1756\n",
      "Epoch 57/60\n",
      "3699/3699 [==============================] - 0s 61us/step - loss: 1101.7584 - mse: 1101.7585 - mae: 22.3311\n",
      "Epoch 58/60\n",
      "3699/3699 [==============================] - 0s 61us/step - loss: 1094.0127 - mse: 1094.0128 - mae: 22.1870\n",
      "Epoch 59/60\n",
      "3699/3699 [==============================] - 0s 72us/step - loss: 1098.4080 - mse: 1098.4082 - mae: 22.2114\n",
      "Epoch 60/60\n",
      "3699/3699 [==============================] - 0s 87us/step - loss: 1098.3175 - mse: 1098.3175 - mae: 22.2932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=10)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "5548/5548 [==============================] - 3s 531us/step - loss: 4257.9141 - mse: 4257.9141 - mae: 43.7980\n",
      "Epoch 2/60\n",
      "5548/5548 [==============================] - 1s 166us/step - loss: 1669.0975 - mse: 1669.0977 - mae: 24.9954\n",
      "Epoch 3/60\n",
      "5548/5548 [==============================] - 1s 172us/step - loss: 1655.7491 - mse: 1655.7489 - mae: 24.7909\n",
      "Epoch 4/60\n",
      "5548/5548 [==============================] - ETA: 0s - loss: 1663.6083 - mse: 1663.6083 - mae: 24.79 - 1s 172us/step - loss: 1651.4733 - mse: 1651.4733 - mae: 24.7865\n",
      "Epoch 5/60\n",
      "5548/5548 [==============================] - 1s 166us/step - loss: 1642.9547 - mse: 1642.9543 - mae: 24.8159\n",
      "Epoch 6/60\n",
      "5548/5548 [==============================] - 3s 491us/step - loss: 1641.6808 - mse: 1641.6804 - mae: 24.7568\n",
      "Epoch 7/60\n",
      "5548/5548 [==============================] - 7s 1ms/step - loss: 1640.7443 - mse: 1640.7446 - mae: 24.7125\n",
      "Epoch 8/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1638.0962 - mse: 1638.0959 - mae: 24.7800\n",
      "Epoch 9/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1637.6692 - mse: 1637.6687 - mae: 24.6774\n",
      "Epoch 10/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1634.1367 - mse: 1634.1366 - mae: 24.6221\n",
      "Epoch 11/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1634.8722 - mse: 1634.8722 - mae: 24.6563\n",
      "Epoch 12/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1627.0047 - mse: 1627.0050 - mae: 24.5514\n",
      "Epoch 13/60\n",
      "5548/5548 [==============================] - 7s 1ms/step - loss: 1630.4552 - mse: 1630.4554 - mae: 24.6367\n",
      "Epoch 14/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1625.2482 - mse: 1625.2480 - mae: 24.5446\n",
      "Epoch 15/60\n",
      "5548/5548 [==============================] - 6s 998us/step - loss: 1619.3398 - mse: 1619.3394 - mae: 24.5262\n",
      "Epoch 16/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1625.8867 - mse: 1625.8870 - mae: 24.5587\n",
      "Epoch 17/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1622.9565 - mse: 1622.9573 - mae: 24.4655: 1s - loss: 1769.2119\n",
      "Epoch 18/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1618.0840 - mse: 1618.0835 - mae: 24.4539\n",
      "Epoch 19/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1623.2386 - mse: 1623.2384 - mae: 24.5187\n",
      "Epoch 20/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1622.8941 - mse: 1622.8938 - mae: 24.4493\n",
      "Epoch 21/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1624.7252 - mse: 1624.7251 - mae: 24.5031\n",
      "Epoch 22/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1623.9846 - mse: 1623.9849 - mae: 24.4877\n",
      "Epoch 23/60\n",
      "5548/5548 [==============================] - 7s 1ms/step - loss: 1618.8367 - mse: 1618.8363 - mae: 24.4479\n",
      "Epoch 24/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1619.2102 - mse: 1619.2103 - mae: 24.4410\n",
      "Epoch 25/60\n",
      "5548/5548 [==============================] - 7s 1ms/step - loss: 1625.2057 - mse: 1625.2053 - mae: 24.5104\n",
      "Epoch 26/60\n",
      "5548/5548 [==============================] - 7s 1ms/step - loss: 1621.1629 - mse: 1621.1630 - mae: 24.4247\n",
      "Epoch 27/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1618.1685 - mse: 1618.1687 - mae: 24.4676\n",
      "Epoch 28/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1621.3172 - mse: 1621.3177 - mae: 24.4855\n",
      "Epoch 29/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1620.5290 - mse: 1620.5291 - mae: 24.4459\n",
      "Epoch 30/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1617.9994 - mse: 1617.9995 - mae: 24.4576\n",
      "Epoch 31/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1618.9192 - mse: 1618.9180 - mae: 24.4079\n",
      "Epoch 32/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1619.9504 - mse: 1619.9502 - mae: 24.4714\n",
      "Epoch 33/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1618.1168 - mse: 1618.1165 - mae: 24.3579\n",
      "Epoch 34/60\n",
      "5548/5548 [==============================] - 7s 1ms/step - loss: 1619.2776 - mse: 1619.2773 - mae: 24.4389\n",
      "Epoch 35/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1620.0670 - mse: 1620.0665 - mae: 24.3930\n",
      "Epoch 36/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1619.2748 - mse: 1619.2749 - mae: 24.4314\n",
      "Epoch 37/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1617.0392 - mse: 1617.0391 - mae: 24.4824\n",
      "Epoch 38/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1621.6097 - mse: 1621.6097 - mae: 24.4915: 0s - loss: 1605.9938 - mse: 1605.9938 \n",
      "Epoch 39/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1617.6496 - mse: 1617.6497 - mae: 24.4547\n",
      "Epoch 40/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1619.4521 - mse: 1619.4523 - mae: 24.4627\n",
      "Epoch 41/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1619.9613 - mse: 1619.9607 - mae: 24.3534\n",
      "Epoch 42/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1615.0451 - mse: 1615.0457 - mae: 24.3384\n",
      "Epoch 43/60\n",
      "5548/5548 [==============================] - 7s 1ms/step - loss: 1618.4234 - mse: 1618.4229 - mae: 24.3721\n",
      "Epoch 44/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1621.1431 - mse: 1621.1427 - mae: 24.4421\n",
      "Epoch 45/60\n",
      "5548/5548 [==============================] - 7s 1ms/step - loss: 1619.1011 - mse: 1619.1011 - mae: 24.4115\n",
      "Epoch 46/60\n",
      "5548/5548 [==============================] - 7s 1ms/step - loss: 1616.8286 - mse: 1616.8286 - mae: 24.4210\n",
      "Epoch 47/60\n",
      "5548/5548 [==============================] - 7s 1ms/step - loss: 1619.2648 - mse: 1619.2648 - mae: 24.4346\n",
      "Epoch 48/60\n",
      "5548/5548 [==============================] - 7s 1ms/step - loss: 1621.9122 - mse: 1621.9122 - mae: 24.4191\n",
      "Epoch 49/60\n",
      "5548/5548 [==============================] - 8s 1ms/step - loss: 1615.3321 - mse: 1615.3328 - mae: 24.3843\n",
      "Epoch 50/60\n",
      "5548/5548 [==============================] - 7s 1ms/step - loss: 1615.1894 - mse: 1615.1891 - mae: 24.3434\n",
      "Epoch 51/60\n",
      "5548/5548 [==============================] - 7s 1ms/step - loss: 1615.1090 - mse: 1615.1093 - mae: 24.3989\n",
      "Epoch 52/60\n",
      "5548/5548 [==============================] - 7s 1ms/step - loss: 1618.7093 - mse: 1618.7096 - mae: 24.3486\n",
      "Epoch 53/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1616.2103 - mse: 1616.2106 - mae: 24.4203\n",
      "Epoch 54/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1617.4007 - mse: 1617.4009 - mae: 24.3136\n",
      "Epoch 55/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1613.3856 - mse: 1613.3851 - mae: 24.3948: 1s - loss: 1703.1337\n",
      "Epoch 56/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1616.3671 - mse: 1616.3668 - mae: 24.4159\n",
      "Epoch 57/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1617.9038 - mse: 1617.9034 - mae: 24.3279\n",
      "Epoch 58/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1619.2480 - mse: 1619.2478 - mae: 24.4284\n",
      "Epoch 59/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1613.9579 - mse: 1613.9576 - mae: 24.4060\n",
      "Epoch 60/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1612.6765 - mse: 1612.6770 - mae: 24.3954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=10)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "7397/7397 [==============================] - 26s 4ms/step - loss: 3640.6600 - mse: 3640.6584 - mae: 40.2030\n",
      "Epoch 2/60\n",
      "7397/7397 [==============================] - 9s 1ms/step - loss: 1619.2141 - mse: 1619.2142 - mae: 25.4817\n",
      "Epoch 3/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1602.4973 - mse: 1602.4971 - mae: 25.3714\n",
      "Epoch 4/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1592.1053 - mse: 1592.1057 - mae: 25.2349\n",
      "Epoch 5/60\n",
      "7397/7397 [==============================] - 7s 1ms/step - loss: 1587.4492 - mse: 1587.4490 - mae: 25.1721\n",
      "Epoch 6/60\n",
      "7397/7397 [==============================] - 9s 1ms/step - loss: 1580.8432 - mse: 1580.8428 - mae: 25.1701\n",
      "Epoch 7/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1577.0441 - mse: 1577.0448 - mae: 25.0359\n",
      "Epoch 8/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1573.8731 - mse: 1573.8733 - mae: 24.9651\n",
      "Epoch 9/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1573.3175 - mse: 1573.3168 - mae: 25.0144\n",
      "Epoch 10/60\n",
      "7397/7397 [==============================] - 7s 1ms/step - loss: 1571.3200 - mse: 1571.3199 - mae: 24.9839\n",
      "Epoch 11/60\n",
      "7397/7397 [==============================] - 9s 1ms/step - loss: 1565.8960 - mse: 1565.8958 - mae: 24.9589\n",
      "Epoch 12/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1566.5452 - mse: 1566.5452 - mae: 24.9461\n",
      "Epoch 13/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1564.3613 - mse: 1564.3612 - mae: 24.9885\n",
      "Epoch 14/60\n",
      "7397/7397 [==============================] - 9s 1ms/step - loss: 1563.7311 - mse: 1563.7311 - mae: 24.9782\n",
      "Epoch 15/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1565.5825 - mse: 1565.5820 - mae: 24.9039\n",
      "Epoch 16/60\n",
      "7397/7397 [==============================] - 9s 1ms/step - loss: 1564.1641 - mse: 1564.1644 - mae: 24.8941\n",
      "Epoch 17/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1561.0554 - mse: 1561.0554 - mae: 24.7976\n",
      "Epoch 18/60\n",
      "7397/7397 [==============================] - 9s 1ms/step - loss: 1559.0529 - mse: 1559.0526 - mae: 24.8353\n",
      "Epoch 19/60\n",
      "7397/7397 [==============================] - 9s 1ms/step - loss: 1561.1682 - mse: 1561.1678 - mae: 24.9051\n",
      "Epoch 20/60\n",
      "7397/7397 [==============================] - 9s 1ms/step - loss: 1558.5834 - mse: 1558.5833 - mae: 24.7285\n",
      "Epoch 21/60\n",
      "7397/7397 [==============================] - 9s 1ms/step - loss: 1560.1724 - mse: 1560.1722 - mae: 24.8058\n",
      "Epoch 22/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1554.4571 - mse: 1554.4570 - mae: 24.7602\n",
      "Epoch 23/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1550.2191 - mse: 1550.2192 - mae: 24.6819\n",
      "Epoch 24/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1550.4653 - mse: 1550.4657 - mae: 24.6772\n",
      "Epoch 25/60\n",
      "7397/7397 [==============================] - 9s 1ms/step - loss: 1545.6523 - mse: 1545.6520 - mae: 24.6105\n",
      "Epoch 26/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1546.8906 - mse: 1546.8903 - mae: 24.6314\n",
      "Epoch 27/60\n",
      "7397/7397 [==============================] - 7s 1ms/step - loss: 1547.4143 - mse: 1547.4143 - mae: 24.6383\n",
      "Epoch 28/60\n",
      "7397/7397 [==============================] - 9s 1ms/step - loss: 1547.9801 - mse: 1547.9801 - mae: 24.6950\n",
      "Epoch 29/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1546.7619 - mse: 1546.7618 - mae: 24.6618\n",
      "Epoch 30/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1544.8777 - mse: 1544.8781 - mae: 24.6838\n",
      "Epoch 31/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1546.6295 - mse: 1546.6293 - mae: 24.6217\n",
      "Epoch 32/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1545.2869 - mse: 1545.2871 - mae: 24.5735\n",
      "Epoch 33/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1544.7027 - mse: 1544.7026 - mae: 24.5368\n",
      "Epoch 34/60\n",
      "7397/7397 [==============================] - 7s 1ms/step - loss: 1543.8506 - mse: 1543.8502 - mae: 24.6024\n",
      "Epoch 35/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1545.6983 - mse: 1545.6990 - mae: 24.5775\n",
      "Epoch 36/60\n",
      "7397/7397 [==============================] - 7s 956us/step - loss: 1542.6591 - mse: 1542.6592 - mae: 24.61040s - loss: 1537.1225 - mse: 1537.1227 \n",
      "Epoch 37/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1543.7237 - mse: 1543.7235 - mae: 24.5549\n",
      "Epoch 38/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1544.0208 - mse: 1544.0210 - mae: 24.5742\n",
      "Epoch 39/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1543.2144 - mse: 1543.2135 - mae: 24.5233\n",
      "Epoch 40/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1542.6475 - mse: 1542.6475 - mae: 24.5302\n",
      "Epoch 41/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1538.9567 - mse: 1538.9569 - mae: 24.4978\n",
      "Epoch 42/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1540.1261 - mse: 1540.1270 - mae: 24.5254\n",
      "Epoch 43/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1541.3806 - mse: 1541.3807 - mae: 24.5927\n",
      "Epoch 44/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1540.5817 - mse: 1540.5814 - mae: 24.5904: 1s - loss:\n",
      "Epoch 45/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1543.4777 - mse: 1543.4777 - mae: 24.4787\n",
      "Epoch 46/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1539.5236 - mse: 1539.5233 - mae: 24.5182\n",
      "Epoch 47/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1541.1505 - mse: 1541.1505 - mae: 24.4856\n",
      "Epoch 48/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1536.9389 - mse: 1536.9386 - mae: 24.4501\n",
      "Epoch 49/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1536.2749 - mse: 1536.2747 - mae: 24.5018\n",
      "Epoch 50/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1541.3534 - mse: 1541.3533 - mae: 24.5487\n",
      "Epoch 51/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1540.1843 - mse: 1540.1842 - mae: 24.4879\n",
      "Epoch 52/60\n",
      "7397/7397 [==============================] - 7s 1ms/step - loss: 1537.6499 - mse: 1537.6505 - mae: 24.4297\n",
      "Epoch 53/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1535.5254 - mse: 1535.5253 - mae: 24.5084\n",
      "Epoch 54/60\n",
      "7397/7397 [==============================] - 7s 1ms/step - loss: 1538.5950 - mse: 1538.5942 - mae: 24.4338\n",
      "Epoch 55/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1539.3454 - mse: 1539.3450 - mae: 24.4463\n",
      "Epoch 56/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1535.8552 - mse: 1535.8550 - mae: 24.4468\n",
      "Epoch 57/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1538.4318 - mse: 1538.4326 - mae: 24.4458\n",
      "Epoch 58/60\n",
      "7397/7397 [==============================] - 10s 1ms/step - loss: 1539.6056 - mse: 1539.6053 - mae: 24.4761\n",
      "Epoch 59/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1533.7616 - mse: 1533.7617 - mae: 24.4441\n",
      "Epoch 60/60\n",
      "7397/7397 [==============================] - 8s 1ms/step - loss: 1544.7310 - mse: 1544.7310 - mae: 24.6101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=90)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "1850/1850 [==============================] - 7s 4ms/step - loss: 6602.8339 - mse: 6602.8350 - mae: 67.9401\n",
      "Epoch 2/60\n",
      "1850/1850 [==============================] - 2s 818us/step - loss: 1050.8896 - mse: 1050.8896 - mae: 22.7060\n",
      "Epoch 3/60\n",
      "1850/1850 [==============================] - 2s 864us/step - loss: 1043.7812 - mse: 1043.7812 - mae: 22.5413\n",
      "Epoch 4/60\n",
      "1850/1850 [==============================] - 2s 884us/step - loss: 1029.5568 - mse: 1029.5568 - mae: 22.2674\n",
      "Epoch 5/60\n",
      "1850/1850 [==============================] - 2s 864us/step - loss: 1025.6117 - mse: 1025.6118 - mae: 22.1567\n",
      "Epoch 6/60\n",
      "1850/1850 [==============================] - 1s 732us/step - loss: 1024.8572 - mse: 1024.8572 - mae: 21.9397\n",
      "Epoch 7/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 1018.1180 - mse: 1018.1179 - mae: 21.8281\n",
      "Epoch 8/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 1018.5957 - mse: 1018.5955 - mae: 21.9203\n",
      "Epoch 9/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 1012.2084 - mse: 1012.2086 - mae: 21.7007\n",
      "Epoch 10/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 1008.8065 - mse: 1008.8063 - mae: 21.7303\n",
      "Epoch 11/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 1017.7858 - mse: 1017.7858 - mae: 21.6885\n",
      "Epoch 12/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 1017.0618 - mse: 1017.0618 - mae: 21.6218\n",
      "Epoch 13/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 1001.5799 - mse: 1001.5798 - mae: 21.5329\n",
      "Epoch 14/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 1009.6610 - mse: 1009.6609 - mae: 21.5915\n",
      "Epoch 15/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 1006.8983 - mse: 1006.8984 - mae: 21.4708\n",
      "Epoch 16/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 1007.7181 - mse: 1007.7183 - mae: 21.3846\n",
      "Epoch 17/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 1002.3633 - mse: 1002.3634 - mae: 21.3946\n",
      "Epoch 18/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 998.1947 - mse: 998.1948 - mae: 21.3174\n",
      "Epoch 19/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 1004.5055 - mse: 1004.5056 - mae: 21.2765\n",
      "Epoch 20/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 994.1269 - mse: 994.1267 - mae: 21.2052\n",
      "Epoch 21/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 999.6895 - mse: 999.6896 - mae: 21.3028\n",
      "Epoch 22/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 994.3813 - mse: 994.3813 - mae: 21.2660\n",
      "Epoch 23/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 995.6285 - mse: 995.6284 - mae: 21.2106\n",
      "Epoch 24/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 991.3306 - mse: 991.3306 - mae: 21.1357\n",
      "Epoch 25/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 999.7242 - mse: 999.7241 - mae: 21.1722\n",
      "Epoch 26/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 996.0190 - mse: 996.0189 - mae: 21.2075\n",
      "Epoch 27/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 990.0338 - mse: 990.0339 - mae: 21.1741\n",
      "Epoch 28/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 995.4839 - mse: 995.4838 - mae: 21.1997\n",
      "Epoch 29/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 988.6104 - mse: 988.6104 - mae: 21.0699\n",
      "Epoch 30/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 984.6028 - mse: 984.6027 - mae: 21.0630\n",
      "Epoch 31/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 994.4802 - mse: 994.4802 - mae: 21.1908\n",
      "Epoch 32/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 988.2941 - mse: 988.2939 - mae: 21.0950\n",
      "Epoch 33/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 986.8703 - mse: 986.8701 - mae: 20.9470\n",
      "Epoch 34/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 986.7903 - mse: 986.7903 - mae: 21.0108\n",
      "Epoch 35/60\n",
      "1850/1850 [==============================] - 0s 45us/step - loss: 983.4238 - mse: 983.4239 - mae: 20.9973\n",
      "Epoch 36/60\n",
      "1850/1850 [==============================] - 0s 45us/step - loss: 989.6040 - mse: 989.6040 - mae: 21.1177\n",
      "Epoch 37/60\n",
      "1850/1850 [==============================] - 0s 45us/step - loss: 985.3269 - mse: 985.3269 - mae: 20.9811\n",
      "Epoch 38/60\n",
      "1850/1850 [==============================] - 0s 45us/step - loss: 985.2642 - mse: 985.2642 - mae: 20.9984\n",
      "Epoch 39/60\n",
      "1850/1850 [==============================] - 0s 45us/step - loss: 984.2485 - mse: 984.2485 - mae: 20.8896\n",
      "Epoch 40/60\n",
      "1850/1850 [==============================] - 0s 45us/step - loss: 981.1994 - mse: 981.1995 - mae: 21.0717\n",
      "Epoch 41/60\n",
      "1850/1850 [==============================] - 0s 45us/step - loss: 988.7408 - mse: 988.7407 - mae: 21.0174\n",
      "Epoch 42/60\n",
      "1850/1850 [==============================] - 0s 45us/step - loss: 981.1095 - mse: 981.1094 - mae: 20.9107\n",
      "Epoch 43/60\n",
      "1850/1850 [==============================] - 0s 45us/step - loss: 985.1679 - mse: 985.1675 - mae: 20.9169\n",
      "Epoch 44/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 981.2799 - mse: 981.2799 - mae: 20.8915\n",
      "Epoch 45/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 979.2985 - mse: 979.2984 - mae: 20.8251\n",
      "Epoch 46/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 981.6041 - mse: 981.6039 - mae: 20.9094\n",
      "Epoch 47/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 976.9542 - mse: 976.9542 - mae: 20.9208\n",
      "Epoch 48/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 979.2192 - mse: 979.2191 - mae: 20.8367\n",
      "Epoch 49/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 979.5592 - mse: 979.5591 - mae: 20.8574\n",
      "Epoch 50/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 980.8201 - mse: 980.8201 - mae: 20.9255\n",
      "Epoch 51/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 969.5694 - mse: 969.5692 - mae: 20.9398\n",
      "Epoch 52/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 975.1577 - mse: 975.1577 - mae: 20.8148\n",
      "Epoch 53/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 983.1648 - mse: 983.1647 - mae: 20.9809\n",
      "Epoch 54/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 978.6185 - mse: 978.6186 - mae: 20.8339\n",
      "Epoch 55/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 973.9921 - mse: 973.9922 - mae: 20.7876\n",
      "Epoch 56/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 974.7251 - mse: 974.7252 - mae: 20.8452\n",
      "Epoch 57/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 980.0265 - mse: 980.0264 - mae: 20.8411\n",
      "Epoch 58/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 972.8848 - mse: 972.8849 - mae: 20.7183\n",
      "Epoch 59/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 971.9482 - mse: 971.9482 - mae: 20.8236\n",
      "Epoch 60/60\n",
      "1850/1850 [==============================] - 0s 46us/step - loss: 974.0136 - mse: 974.0134 - mae: 20.7714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=90)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "3699/3699 [==============================] - 1s 252us/step - loss: 3773.6123 - mse: 3773.6135 - mae: 44.2771\n",
      "Epoch 2/60\n",
      "3699/3699 [==============================] - 0s 66us/step - loss: 1155.0777 - mse: 1155.0774 - mae: 23.1549\n",
      "Epoch 3/60\n",
      "3699/3699 [==============================] - 0s 68us/step - loss: 1137.4508 - mse: 1137.4509 - mae: 23.0140\n",
      "Epoch 4/60\n",
      "3699/3699 [==============================] - 0s 65us/step - loss: 1131.4972 - mse: 1131.4969 - mae: 22.9735\n",
      "Epoch 5/60\n",
      "3699/3699 [==============================] - 0s 66us/step - loss: 1129.5365 - mse: 1129.5365 - mae: 22.8230\n",
      "Epoch 6/60\n",
      "3699/3699 [==============================] - 0s 67us/step - loss: 1129.6423 - mse: 1129.6423 - mae: 22.8554\n",
      "Epoch 7/60\n",
      "3699/3699 [==============================] - 0s 69us/step - loss: 1124.6194 - mse: 1124.6193 - mae: 22.7404\n",
      "Epoch 8/60\n",
      "3699/3699 [==============================] - 0s 66us/step - loss: 1129.8467 - mse: 1129.8468 - mae: 22.7630\n",
      "Epoch 9/60\n",
      "3699/3699 [==============================] - 0s 69us/step - loss: 1123.0465 - mse: 1123.0468 - mae: 22.6898\n",
      "Epoch 10/60\n",
      "3699/3699 [==============================] - 0s 68us/step - loss: 1121.9990 - mse: 1121.9989 - mae: 22.7542\n",
      "Epoch 11/60\n",
      "3699/3699 [==============================] - 0s 66us/step - loss: 1125.9142 - mse: 1125.9141 - mae: 22.6746\n",
      "Epoch 12/60\n",
      "3699/3699 [==============================] - 0s 66us/step - loss: 1116.7213 - mse: 1116.7216 - mae: 22.6866\n",
      "Epoch 13/60\n",
      "3699/3699 [==============================] - 0s 68us/step - loss: 1113.3337 - mse: 1113.3336 - mae: 22.5728\n",
      "Epoch 14/60\n",
      "3699/3699 [==============================] - 0s 66us/step - loss: 1122.1073 - mse: 1122.1071 - mae: 22.6783\n",
      "Epoch 15/60\n",
      "3699/3699 [==============================] - 0s 68us/step - loss: 1115.1135 - mse: 1115.1136 - mae: 22.6233\n",
      "Epoch 16/60\n",
      "3699/3699 [==============================] - 0s 115us/step - loss: 1117.7791 - mse: 1117.7792 - mae: 22.5617\n",
      "Epoch 17/60\n",
      "3699/3699 [==============================] - 0s 130us/step - loss: 1115.8343 - mse: 1115.8341 - mae: 22.5965\n",
      "Epoch 18/60\n",
      "3699/3699 [==============================] - 0s 126us/step - loss: 1112.4548 - mse: 1112.4548 - mae: 22.6042\n",
      "Epoch 19/60\n",
      "3699/3699 [==============================] - 0s 121us/step - loss: 1111.5797 - mse: 1111.5795 - mae: 22.5708\n",
      "Epoch 20/60\n",
      "3699/3699 [==============================] - 0s 118us/step - loss: 1111.8628 - mse: 1111.8628 - mae: 22.4770\n",
      "Epoch 21/60\n",
      "3699/3699 [==============================] - 0s 121us/step - loss: 1111.5701 - mse: 1111.5699 - mae: 22.4990\n",
      "Epoch 22/60\n",
      "3699/3699 [==============================] - 0s 121us/step - loss: 1106.5229 - mse: 1106.5226 - mae: 22.4304\n",
      "Epoch 23/60\n",
      "3699/3699 [==============================] - 0s 123us/step - loss: 1111.3362 - mse: 1111.3364 - mae: 22.4685\n",
      "Epoch 24/60\n",
      "3699/3699 [==============================] - 0s 121us/step - loss: 1113.1305 - mse: 1113.1305 - mae: 22.5179\n",
      "Epoch 25/60\n",
      "3699/3699 [==============================] - 0s 124us/step - loss: 1109.1182 - mse: 1109.1183 - mae: 22.3746\n",
      "Epoch 26/60\n",
      "3699/3699 [==============================] - 0s 119us/step - loss: 1109.8449 - mse: 1109.8447 - mae: 22.5026\n",
      "Epoch 27/60\n",
      "3699/3699 [==============================] - 3s 906us/step - loss: 1109.3449 - mse: 1109.3447 - mae: 22.5132\n",
      "Epoch 28/60\n",
      "3699/3699 [==============================] - 3s 940us/step - loss: 1108.9761 - mse: 1108.9760 - mae: 22.5642\n",
      "Epoch 29/60\n",
      "3699/3699 [==============================] - 4s 951us/step - loss: 1107.9185 - mse: 1107.9188 - mae: 22.4093\n",
      "Epoch 30/60\n",
      "3699/3699 [==============================] - 3s 886us/step - loss: 1104.7369 - mse: 1104.7367 - mae: 22.4201\n",
      "Epoch 31/60\n",
      "3699/3699 [==============================] - 3s 919us/step - loss: 1107.1781 - mse: 1107.1781 - mae: 22.4059\n",
      "Epoch 32/60\n",
      "3699/3699 [==============================] - 3s 873us/step - loss: 1105.0025 - mse: 1105.0027 - mae: 22.3852\n",
      "Epoch 33/60\n",
      "3699/3699 [==============================] - 3s 897us/step - loss: 1108.2768 - mse: 1108.2770 - mae: 22.3778\n",
      "Epoch 34/60\n",
      "3699/3699 [==============================] - 3s 830us/step - loss: 1108.6117 - mse: 1108.6117 - mae: 22.3756\n",
      "Epoch 35/60\n",
      "3699/3699 [==============================] - 3s 832us/step - loss: 1106.5456 - mse: 1106.5455 - mae: 22.3430\n",
      "Epoch 36/60\n",
      "3699/3699 [==============================] - 3s 832us/step - loss: 1106.5299 - mse: 1106.5298 - mae: 22.4274\n",
      "Epoch 37/60\n",
      "3699/3699 [==============================] - 3s 886us/step - loss: 1108.6754 - mse: 1108.6754 - mae: 22.4200\n",
      "Epoch 38/60\n",
      "3699/3699 [==============================] - 3s 885us/step - loss: 1104.0042 - mse: 1104.0040 - mae: 22.3075\n",
      "Epoch 39/60\n",
      "3699/3699 [==============================] - 3s 919us/step - loss: 1109.4091 - mse: 1109.4089 - mae: 22.3328\n",
      "Epoch 40/60\n",
      "3699/3699 [==============================] - 3s 909us/step - loss: 1103.8061 - mse: 1103.8062 - mae: 22.2913\n",
      "Epoch 41/60\n",
      "3699/3699 [==============================] - ETA: 0s - loss: 1103.4314 - mse: 1103.4312 - mae: 22.23 - 3s 833us/step - loss: 1101.0725 - mse: 1101.0723 - mae: 22.2372\n",
      "Epoch 42/60\n",
      "3699/3699 [==============================] - 3s 911us/step - loss: 1101.4846 - mse: 1101.4845 - mae: 22.2748\n",
      "Epoch 43/60\n",
      "3699/3699 [==============================] - 3s 779us/step - loss: 1105.6992 - mse: 1105.6993 - mae: 22.2467\n",
      "Epoch 44/60\n",
      "3699/3699 [==============================] - 3s 766us/step - loss: 1102.2455 - mse: 1102.2454 - mae: 22.3362\n",
      "Epoch 45/60\n",
      "3699/3699 [==============================] - 3s 766us/step - loss: 1102.2597 - mse: 1102.2599 - mae: 22.2388\n",
      "Epoch 46/60\n",
      "3699/3699 [==============================] - 4s 1ms/step - loss: 1102.5500 - mse: 1102.5499 - mae: 22.2400\n",
      "Epoch 47/60\n",
      "3699/3699 [==============================] - 3s 757us/step - loss: 1103.4714 - mse: 1103.4714 - mae: 22.3810\n",
      "Epoch 48/60\n",
      "3699/3699 [==============================] - 3s 776us/step - loss: 1103.8938 - mse: 1103.8937 - mae: 22.2748\n",
      "Epoch 49/60\n",
      "3699/3699 [==============================] - 3s 800us/step - loss: 1104.8343 - mse: 1104.8345 - mae: 22.2954\n",
      "Epoch 50/60\n",
      "3699/3699 [==============================] - 3s 822us/step - loss: 1103.7434 - mse: 1103.7433 - mae: 22.2771\n",
      "Epoch 51/60\n",
      "3699/3699 [==============================] - 3s 900us/step - loss: 1103.2307 - mse: 1103.2307 - mae: 22.2489\n",
      "Epoch 52/60\n",
      "3699/3699 [==============================] - 3s 746us/step - loss: 1102.2634 - mse: 1102.2634 - mae: 22.2190\n",
      "Epoch 53/60\n",
      "3699/3699 [==============================] - 3s 778us/step - loss: 1106.5888 - mse: 1106.5886 - mae: 22.3361\n",
      "Epoch 54/60\n",
      "3699/3699 [==============================] - 3s 776us/step - loss: 1103.0522 - mse: 1103.0520 - mae: 22.2844\n",
      "Epoch 55/60\n",
      "3699/3699 [==============================] - 3s 830us/step - loss: 1099.5052 - mse: 1099.5051 - mae: 22.1653\n",
      "Epoch 56/60\n",
      "3699/3699 [==============================] - 3s 820us/step - loss: 1100.7986 - mse: 1100.7983 - mae: 22.2188\n",
      "Epoch 57/60\n",
      "3699/3699 [==============================] - 3s 767us/step - loss: 1102.5593 - mse: 1102.5594 - mae: 22.2738\n",
      "Epoch 58/60\n",
      "3699/3699 [==============================] - 3s 839us/step - loss: 1106.0038 - mse: 1106.0038 - mae: 22.3169\n",
      "Epoch 59/60\n",
      "3699/3699 [==============================] - 3s 763us/step - loss: 1103.0716 - mse: 1103.0720 - mae: 22.1881\n",
      "Epoch 60/60\n",
      "3699/3699 [==============================] - 3s 916us/step - loss: 1101.6747 - mse: 1101.6748 - mae: 22.2992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=90)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "5548/5548 [==============================] - 10s 2ms/step - loss: 3557.5606 - mse: 3557.5583 - mae: 39.5600\n",
      "Epoch 2/60\n",
      "5548/5548 [==============================] - 4s 756us/step - loss: 1687.2656 - mse: 1687.2656 - mae: 25.2353\n",
      "Epoch 3/60\n",
      "5548/5548 [==============================] - 4s 747us/step - loss: 1671.1297 - mse: 1671.1298 - mae: 25.1364\n",
      "Epoch 4/60\n",
      "5548/5548 [==============================] - 5s 835us/step - loss: 1677.3429 - mse: 1677.3431 - mae: 25.1390\n",
      "Epoch 5/60\n",
      "5548/5548 [==============================] - 4s 805us/step - loss: 1655.5377 - mse: 1655.5375 - mae: 24.9724\n",
      "Epoch 6/60\n",
      "5548/5548 [==============================] - 5s 835us/step - loss: 1657.2286 - mse: 1657.2280 - mae: 24.9556\n",
      "Epoch 7/60\n",
      "5548/5548 [==============================] - 5s 869us/step - loss: 1654.7170 - mse: 1654.7174 - mae: 24.8216\n",
      "Epoch 8/60\n",
      "5548/5548 [==============================] - 5s 857us/step - loss: 1651.1994 - mse: 1651.1996 - mae: 24.8008\n",
      "Epoch 9/60\n",
      "5548/5548 [==============================] - 5s 827us/step - loss: 1638.4173 - mse: 1638.4175 - mae: 24.7693\n",
      "Epoch 10/60\n",
      "5548/5548 [==============================] - 5s 951us/step - loss: 1644.3947 - mse: 1644.3948 - mae: 24.8495\n",
      "Epoch 11/60\n",
      "5548/5548 [==============================] - 5s 826us/step - loss: 1638.3641 - mse: 1638.3641 - mae: 24.7054\n",
      "Epoch 12/60\n",
      "5548/5548 [==============================] - 4s 747us/step - loss: 1639.9103 - mse: 1639.9104 - mae: 24.7146\n",
      "Epoch 13/60\n",
      "5548/5548 [==============================] - 5s 842us/step - loss: 1632.9992 - mse: 1632.9989 - mae: 24.65140s - loss: 1649.2659 - mse: 1649.2655 - ma\n",
      "Epoch 14/60\n",
      "5548/5548 [==============================] - 4s 768us/step - loss: 1633.2200 - mse: 1633.2202 - mae: 24.7263\n",
      "Epoch 15/60\n",
      "5548/5548 [==============================] - 5s 879us/step - loss: 1629.2812 - mse: 1629.2814 - mae: 24.6735\n",
      "Epoch 16/60\n",
      "5548/5548 [==============================] - 5s 849us/step - loss: 1634.1530 - mse: 1634.1538 - mae: 24.6978\n",
      "Epoch 17/60\n",
      "5548/5548 [==============================] - 4s 805us/step - loss: 1631.5774 - mse: 1631.5775 - mae: 24.6228\n",
      "Epoch 18/60\n",
      "5548/5548 [==============================] - 4s 745us/step - loss: 1631.2020 - mse: 1631.2015 - mae: 24.6427\n",
      "Epoch 19/60\n",
      "5548/5548 [==============================] - 4s 775us/step - loss: 1632.7626 - mse: 1632.7622 - mae: 24.5471\n",
      "Epoch 20/60\n",
      "5548/5548 [==============================] - 5s 834us/step - loss: 1627.9333 - mse: 1627.9335 - mae: 24.5986\n",
      "Epoch 21/60\n",
      "5548/5548 [==============================] - 4s 747us/step - loss: 1630.0716 - mse: 1630.0714 - mae: 24.6755\n",
      "Epoch 22/60\n",
      "5548/5548 [==============================] - 4s 772us/step - loss: 1625.8370 - mse: 1625.8365 - mae: 24.5826\n",
      "Epoch 23/60\n",
      "5548/5548 [==============================] - 5s 886us/step - loss: 1625.6269 - mse: 1625.6270 - mae: 24.5232\n",
      "Epoch 24/60\n",
      "5548/5548 [==============================] - 4s 789us/step - loss: 1621.2011 - mse: 1621.2008 - mae: 24.5065\n",
      "Epoch 25/60\n",
      "5548/5548 [==============================] - 4s 767us/step - loss: 1624.8194 - mse: 1624.8196 - mae: 24.4250\n",
      "Epoch 26/60\n",
      "5548/5548 [==============================] - 4s 788us/step - loss: 1621.7480 - mse: 1621.7478 - mae: 24.5846\n",
      "Epoch 27/60\n",
      "5548/5548 [==============================] - 4s 778us/step - loss: 1624.6144 - mse: 1624.6145 - mae: 24.4450\n",
      "Epoch 28/60\n",
      "5548/5548 [==============================] - 4s 726us/step - loss: 1623.1847 - mse: 1623.1846 - mae: 24.5061\n",
      "Epoch 29/60\n",
      "5548/5548 [==============================] - 5s 900us/step - loss: 1623.7419 - mse: 1623.7417 - mae: 24.4375\n",
      "Epoch 30/60\n",
      "5548/5548 [==============================] - 5s 818us/step - loss: 1622.2019 - mse: 1622.2020 - mae: 24.4404\n",
      "Epoch 31/60\n",
      "5548/5548 [==============================] - 4s 769us/step - loss: 1620.8532 - mse: 1620.8533 - mae: 24.4825\n",
      "Epoch 32/60\n",
      "5548/5548 [==============================] - 5s 840us/step - loss: 1615.3013 - mse: 1615.3021 - mae: 24.3420\n",
      "Epoch 33/60\n",
      "5548/5548 [==============================] - 4s 760us/step - loss: 1617.2423 - mse: 1617.2417 - mae: 24.4084\n",
      "Epoch 34/60\n",
      "5548/5548 [==============================] - 4s 752us/step - loss: 1612.5010 - mse: 1612.5007 - mae: 24.4107\n",
      "Epoch 35/60\n",
      "5548/5548 [==============================] - ETA: 0s - loss: 1617.1109 - mse: 1617.1102 - mae: 24.43 - 4s 798us/step - loss: 1613.4681 - mse: 1613.4675 - mae: 24.4288\n",
      "Epoch 36/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1615.8419 - mse: 1615.8419 - mae: 24.3581\n",
      "Epoch 37/60\n",
      "5548/5548 [==============================] - 5s 841us/step - loss: 1611.7647 - mse: 1611.7646 - mae: 24.3000\n",
      "Epoch 38/60\n",
      "5548/5548 [==============================] - 5s 885us/step - loss: 1616.2433 - mse: 1616.2435 - mae: 24.3182\n",
      "Epoch 39/60\n",
      "5548/5548 [==============================] - 4s 791us/step - loss: 1614.3209 - mse: 1614.3207 - mae: 24.3657\n",
      "Epoch 40/60\n",
      "5548/5548 [==============================] - 4s 754us/step - loss: 1610.6274 - mse: 1610.6270 - mae: 24.3272\n",
      "Epoch 41/60\n",
      "5548/5548 [==============================] - 6s 1ms/step - loss: 1610.0409 - mse: 1610.0411 - mae: 24.2166\n",
      "Epoch 42/60\n",
      "5548/5548 [==============================] - 5s 847us/step - loss: 1607.6118 - mse: 1607.6117 - mae: 24.2255\n",
      "Epoch 43/60\n",
      "5548/5548 [==============================] - 5s 863us/step - loss: 1616.4793 - mse: 1616.4788 - mae: 24.2629\n",
      "Epoch 44/60\n",
      "5548/5548 [==============================] - 5s 914us/step - loss: 1607.0908 - mse: 1607.0905 - mae: 24.3424\n",
      "Epoch 45/60\n",
      "5548/5548 [==============================] - 4s 797us/step - loss: 1608.4747 - mse: 1608.4747 - mae: 24.2209\n",
      "Epoch 46/60\n",
      "5548/5548 [==============================] - 4s 732us/step - loss: 1607.3726 - mse: 1607.3718 - mae: 24.2681\n",
      "Epoch 47/60\n",
      "5548/5548 [==============================] - 5s 855us/step - loss: 1601.5100 - mse: 1601.5109 - mae: 24.1217\n",
      "Epoch 48/60\n",
      "5548/5548 [==============================] - 4s 716us/step - loss: 1600.5832 - mse: 1600.5835 - mae: 24.1688\n",
      "Epoch 49/60\n",
      "5548/5548 [==============================] - 5s 826us/step - loss: 1602.6893 - mse: 1602.6891 - mae: 24.0902\n",
      "Epoch 50/60\n",
      "5548/5548 [==============================] - 5s 900us/step - loss: 1600.3302 - mse: 1600.3302 - mae: 24.2044\n",
      "Epoch 51/60\n",
      "5548/5548 [==============================] - 4s 760us/step - loss: 1602.0157 - mse: 1602.0155 - mae: 24.1621\n",
      "Epoch 52/60\n",
      "5548/5548 [==============================] - 4s 754us/step - loss: 1597.2454 - mse: 1597.2450 - mae: 24.0667\n",
      "Epoch 53/60\n",
      "5548/5548 [==============================] - 4s 760us/step - loss: 1597.6088 - mse: 1597.6085 - mae: 24.1827\n",
      "Epoch 54/60\n",
      "5548/5548 [==============================] - 4s 761us/step - loss: 1596.8164 - mse: 1596.8163 - mae: 24.0730\n",
      "Epoch 55/60\n",
      "5548/5548 [==============================] - 4s 783us/step - loss: 1599.0531 - mse: 1599.0532 - mae: 24.1515\n",
      "Epoch 56/60\n",
      "5548/5548 [==============================] - 5s 863us/step - loss: 1599.9380 - mse: 1599.9382 - mae: 24.0155\n",
      "Epoch 57/60\n",
      "5548/5548 [==============================] - 5s 922us/step - loss: 1593.4475 - mse: 1593.4478 - mae: 24.0086\n",
      "Epoch 58/60\n",
      "5548/5548 [==============================] - 5s 870us/step - loss: 1594.8215 - mse: 1594.8219 - mae: 24.0545\n",
      "Epoch 59/60\n",
      "5548/5548 [==============================] - 5s 943us/step - loss: 1591.7234 - mse: 1591.7235 - mae: 24.0400\n",
      "Epoch 60/60\n",
      "5548/5548 [==============================] - 5s 950us/step - loss: 1587.4410 - mse: 1587.4403 - mae: 23.9504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, units=90)`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python-cpu/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"linear\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "7397/7397 [==============================] - 12s 2ms/step - loss: 3214.3567 - mse: 3214.3557 - mae: 36.9611\n",
      "Epoch 2/60\n",
      "7397/7397 [==============================] - 6s 775us/step - loss: 1608.5722 - mse: 1608.5718 - mae: 25.3637\n",
      "Epoch 3/60\n",
      "7397/7397 [==============================] - 7s 914us/step - loss: 1596.3080 - mse: 1596.3079 - mae: 25.2547\n",
      "Epoch 4/60\n",
      "7397/7397 [==============================] - 6s 777us/step - loss: 1590.2797 - mse: 1590.2800 - mae: 25.2646\n",
      "Epoch 5/60\n",
      "7397/7397 [==============================] - 6s 837us/step - loss: 1586.0242 - mse: 1586.0236 - mae: 25.1113\n",
      "Epoch 6/60\n",
      "7397/7397 [==============================] - 6s 838us/step - loss: 1585.0625 - mse: 1585.0624 - mae: 25.0852\n",
      "Epoch 7/60\n",
      "7397/7397 [==============================] - 6s 749us/step - loss: 1574.7479 - mse: 1574.7482 - mae: 25.0816\n",
      "Epoch 8/60\n",
      "7397/7397 [==============================] - 6s 814us/step - loss: 1571.8135 - mse: 1571.8135 - mae: 24.9807\n",
      "Epoch 9/60\n",
      "7397/7397 [==============================] - 6s 785us/step - loss: 1574.4185 - mse: 1574.4186 - mae: 25.0804\n",
      "Epoch 10/60\n",
      "7397/7397 [==============================] - 7s 890us/step - loss: 1569.5607 - mse: 1569.5603 - mae: 24.9119\n",
      "Epoch 11/60\n",
      "7397/7397 [==============================] - 6s 843us/step - loss: 1570.3553 - mse: 1570.3549 - mae: 24.9525\n",
      "Epoch 12/60\n",
      "7397/7397 [==============================] - 6s 870us/step - loss: 1567.8873 - mse: 1567.8878 - mae: 24.9176\n",
      "Epoch 13/60\n",
      "7397/7397 [==============================] - 6s 821us/step - loss: 1564.7492 - mse: 1564.7496 - mae: 24.8886\n",
      "Epoch 14/60\n",
      "7397/7397 [==============================] - 6s 837us/step - loss: 1568.0400 - mse: 1568.0400 - mae: 24.9691\n",
      "Epoch 15/60\n",
      "7397/7397 [==============================] - 6s 871us/step - loss: 1566.5338 - mse: 1566.5336 - mae: 24.8579\n",
      "Epoch 16/60\n",
      "7397/7397 [==============================] - 6s 750us/step - loss: 1562.3618 - mse: 1562.3616 - mae: 24.8595\n",
      "Epoch 17/60\n",
      "7397/7397 [==============================] - 6s 821us/step - loss: 1561.4986 - mse: 1561.4987 - mae: 24.7761\n",
      "Epoch 18/60\n",
      "7397/7397 [==============================] - 6s 761us/step - loss: 1558.3985 - mse: 1558.3983 - mae: 24.8443\n",
      "Epoch 19/60\n",
      "7397/7397 [==============================] - 7s 880us/step - loss: 1558.1753 - mse: 1558.1755 - mae: 24.7776\n",
      "Epoch 20/60\n",
      "7397/7397 [==============================] - 7s 880us/step - loss: 1558.4001 - mse: 1558.3998 - mae: 24.6939\n",
      "Epoch 21/60\n",
      "7397/7397 [==============================] - 6s 852us/step - loss: 1558.3749 - mse: 1558.3752 - mae: 24.8322\n",
      "Epoch 22/60\n",
      "7397/7397 [==============================] - 7s 930us/step - loss: 1558.2019 - mse: 1558.2021 - mae: 24.7293\n",
      "Epoch 23/60\n",
      "7397/7397 [==============================] - 7s 904us/step - loss: 1559.0047 - mse: 1559.0051 - mae: 24.7682\n",
      "Epoch 24/60\n",
      "7397/7397 [==============================] - 6s 836us/step - loss: 1557.1339 - mse: 1557.1344 - mae: 24.7304\n",
      "Epoch 25/60\n",
      "7397/7397 [==============================] - 6s 816us/step - loss: 1554.8549 - mse: 1554.8545 - mae: 24.7472\n",
      "Epoch 26/60\n",
      "7397/7397 [==============================] - 7s 919us/step - loss: 1553.7092 - mse: 1553.7097 - mae: 24.7589\n",
      "Epoch 27/60\n",
      "7397/7397 [==============================] - 6s 832us/step - loss: 1549.2075 - mse: 1549.2078 - mae: 24.6773\n",
      "Epoch 28/60\n",
      "7397/7397 [==============================] - 7s 880us/step - loss: 1548.4506 - mse: 1548.4507 - mae: 24.6511\n",
      "Epoch 29/60\n",
      "7397/7397 [==============================] - 6s 813us/step - loss: 1549.4345 - mse: 1549.4341 - mae: 24.6865\n",
      "Epoch 30/60\n",
      "7397/7397 [==============================] - 6s 814us/step - loss: 1549.9053 - mse: 1549.9055 - mae: 24.5907\n",
      "Epoch 31/60\n",
      "7397/7397 [==============================] - 6s 781us/step - loss: 1547.1914 - mse: 1547.1917 - mae: 24.6328\n",
      "Epoch 32/60\n",
      "7397/7397 [==============================] - 6s 845us/step - loss: 1548.5179 - mse: 1548.5183 - mae: 24.6388\n",
      "Epoch 33/60\n",
      "7397/7397 [==============================] - 6s 843us/step - loss: 1546.7301 - mse: 1546.7295 - mae: 24.5587\n",
      "Epoch 34/60\n",
      "7397/7397 [==============================] - 6s 828us/step - loss: 1544.6087 - mse: 1544.6090 - mae: 24.5350\n",
      "Epoch 35/60\n",
      "7397/7397 [==============================] - 6s 833us/step - loss: 1542.5511 - mse: 1542.5507 - mae: 24.5979\n",
      "Epoch 36/60\n",
      "7397/7397 [==============================] - 6s 756us/step - loss: 1540.5926 - mse: 1540.5930 - mae: 24.5057\n",
      "Epoch 37/60\n",
      "7397/7397 [==============================] - 5s 722us/step - loss: 1539.8085 - mse: 1539.8079 - mae: 24.5068\n",
      "Epoch 38/60\n",
      "7397/7397 [==============================] - 6s 807us/step - loss: 1538.7902 - mse: 1538.7906 - mae: 24.4183\n",
      "Epoch 39/60\n",
      "7397/7397 [==============================] - 6s 771us/step - loss: 1538.4310 - mse: 1538.4310 - mae: 24.4331\n",
      "Epoch 40/60\n",
      "7397/7397 [==============================] - 6s 826us/step - loss: 1532.0806 - mse: 1532.0804 - mae: 24.4018\n",
      "Epoch 41/60\n",
      "7397/7397 [==============================] - 6s 776us/step - loss: 1537.1278 - mse: 1537.1281 - mae: 24.4110\n",
      "Epoch 42/60\n",
      "7397/7397 [==============================] - 7s 970us/step - loss: 1539.3386 - mse: 1539.3386 - mae: 24.3978\n",
      "Epoch 43/60\n",
      "7397/7397 [==============================] - 6s 783us/step - loss: 1535.0854 - mse: 1535.0857 - mae: 24.3005\n",
      "Epoch 44/60\n",
      "7397/7397 [==============================] - 6s 779us/step - loss: 1530.7924 - mse: 1530.7928 - mae: 24.3613\n",
      "Epoch 45/60\n",
      "7397/7397 [==============================] - 6s 779us/step - loss: 1529.9118 - mse: 1529.9117 - mae: 24.3357\n",
      "Epoch 46/60\n",
      "7397/7397 [==============================] - 6s 772us/step - loss: 1528.0587 - mse: 1528.0588 - mae: 24.3672\n",
      "Epoch 47/60\n",
      "7397/7397 [==============================] - 6s 812us/step - loss: 1526.1318 - mse: 1526.1316 - mae: 24.3046\n",
      "Epoch 48/60\n",
      "7397/7397 [==============================] - 6s 793us/step - loss: 1526.5915 - mse: 1526.5913 - mae: 24.2799\n",
      "Epoch 49/60\n",
      "7397/7397 [==============================] - 6s 835us/step - loss: 1522.9455 - mse: 1522.9451 - mae: 24.2223\n",
      "Epoch 50/60\n",
      "7397/7397 [==============================] - 6s 767us/step - loss: 1519.9891 - mse: 1519.9895 - mae: 24.1887\n",
      "Epoch 51/60\n",
      "7397/7397 [==============================] - 6s 772us/step - loss: 1517.3363 - mse: 1517.3361 - mae: 24.1515\n",
      "Epoch 52/60\n",
      "7397/7397 [==============================] - 5s 738us/step - loss: 1515.0254 - mse: 1515.0256 - mae: 24.1517\n",
      "Epoch 53/60\n",
      "7397/7397 [==============================] - 6s 778us/step - loss: 1520.8462 - mse: 1520.8462 - mae: 24.1860\n",
      "Epoch 54/60\n",
      "7397/7397 [==============================] - 6s 865us/step - loss: 1519.1455 - mse: 1519.1464 - mae: 24.2073\n",
      "Epoch 55/60\n",
      "7397/7397 [==============================] - 6s 805us/step - loss: 1515.6270 - mse: 1515.6270 - mae: 24.1461\n",
      "Epoch 56/60\n",
      "7397/7397 [==============================] - 6s 790us/step - loss: 1516.3052 - mse: 1516.3049 - mae: 24.2181\n",
      "Epoch 57/60\n",
      "7397/7397 [==============================] - 6s 810us/step - loss: 1508.4542 - mse: 1508.4542 - mae: 24.0704\n",
      "Epoch 58/60\n",
      "7397/7397 [==============================] - 6s 799us/step - loss: 1512.0580 - mse: 1512.0582 - mae: 24.0783\n",
      "Epoch 59/60\n",
      "7397/7397 [==============================] - 6s 863us/step - loss: 1513.5012 - mse: 1513.5013 - mae: 24.1175\n",
      "Epoch 60/60\n",
      "7397/7397 [==============================] - 6s 745us/step - loss: 1510.6337 - mse: 1510.6338 - mae: 24.0545\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Cannot clone object <keras.wrappers.scikit_learn.KerasRegressor object at 0x7f43a375a610>, as the constructor either does not set or modifies parameter optimizer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-d04b0a426b6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mrnd_search_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python-cpu/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python-cpu/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0;31m# of the params are estimators as well.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m             self.best_estimator_ = clone(clone(base_estimator).set_params(\n\u001b[0;32m--> 762\u001b[0;31m                 **self.best_params_))\n\u001b[0m\u001b[1;32m    763\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python-cpu/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python-cpu/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     96\u001b[0m             raise RuntimeError('Cannot clone object %s, as the constructor '\n\u001b[1;32m     97\u001b[0m                                \u001b[0;34m'either does not set or modifies parameter %s'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m                                (estimator, name))\n\u001b[0m\u001b[1;32m     99\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Cannot clone object <keras.wrappers.scikit_learn.KerasRegressor object at 0x7f43a375a610>, as the constructor either does not set or modifies parameter optimizer"
     ]
    }
   ],
   "source": [
    "regressor = KerasRegressor(build_fn = regressor_tunning)\n",
    "\n",
    "# Dictionary to include the parameters\n",
    "parameters = {'n_hidden': [1, 2, 3, 4, 6],\n",
    "              'n_neurons': np.arange(10,100, 5),\n",
    "              'bias_initializer':[initializers.Zeros(),\n",
    "                                 initializers.Ones()],\n",
    "              'kernel_initializer': ['glorot_uniform',\n",
    "                                     'he_normal',\n",
    "                                     'he_uniform'],\n",
    "              'optimizer': [keras.optimizers.RMSprop(), \n",
    "                            keras.optimizers.Adam(), \n",
    "                            keras.optimizers.Nadam(),\n",
    "                            keras.optimizers.Adamax()]\n",
    "               }\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits = 7)\n",
    "\n",
    "# add some early stopping\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='mse', patience = 15)\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(estimator = regressor,\n",
    "                                   param_distributions = parameters,\n",
    "                                   scoring = 'neg_mean_squared_error',\n",
    "                                   n_iter = 20,\n",
    "                                   n_jobs = -1,\n",
    "                                   cv = tscv)\n",
    "\n",
    "# checkpoints:\n",
    "# early_stopping_cb = keras.callbacks.EarlyStopping(patience = 10, restore_best_weights = True)\n",
    "# checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\")\n",
    "\n",
    "rnd_search_cv.fit(X_train, y_train, batch_size = 32, epochs = 60, callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the best parameters are:{'optimizer': <keras.optimizers.Adamax object at 0x7f43e1fdbfd0>, 'n_neurons': 50, 'n_hidden': 4, 'kernel_initializer': 'glorot_uniform', 'bias_initializer': <keras.initializers.Zeros object at 0x7f43b955cbd0>}\n",
      "the best score is:-1995.0684018410414\n"
     ]
    }
   ],
   "source": [
    "best_params_1 = rnd_search_cv.best_params_\n",
    "best_score_1 = rnd_search_cv.best_score_\n",
    "#results = rnd_search_cv.cv_results_\n",
    "\n",
    "print(\"the best parameters are:{}\".format(best_params_1))\n",
    "print(\"the best score is:{}\".format(best_score_1))\n",
    "#print(\"results:\".format(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
