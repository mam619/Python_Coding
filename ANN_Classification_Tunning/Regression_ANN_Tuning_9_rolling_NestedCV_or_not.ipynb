{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression ANN with best parameters\n",
    "    find the best approach for training - Rolling Nested CV or small train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd;\n",
    "import numpy as np;\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split, cross_validate, cross_val_predict;\n",
    "from sklearn.preprocessing import MinMaxScaler;\n",
    "from sklearn import metrics;\n",
    "from sklearn.model_selection import TimeSeriesSplit;\n",
    "\n",
    "mae_cv = []\n",
    "mse_cv = []\n",
    "mae_gen = []\n",
    "mse_gen  =[]\n",
    "rmse_gen = []\n",
    "mae_nor = []\n",
    "mae_spi = []\n",
    "mse_nor = []\n",
    "mse_spi = []\n",
    "rmse_nor = []\n",
    "rmse_spi = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results for rolling Nested CV with max training set of 3 months:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:6245: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "231/231 [==============================] - 0s 735us/step - loss: 11100.0234 - mse: 11100.0234 - mae: 90.4366\n",
      "Epoch 2/80\n",
      "231/231 [==============================] - 0s 820us/step - loss: 2391.7061 - mse: 2391.7061 - mae: 33.7787\n",
      "Epoch 3/80\n",
      "231/231 [==============================] - 0s 795us/step - loss: 2320.1462 - mse: 2320.1462 - mae: 32.7420\n",
      "Epoch 4/80\n",
      "231/231 [==============================] - 0s 691us/step - loss: 2332.6702 - mse: 2332.6702 - mae: 33.2082\n",
      "Epoch 5/80\n",
      "231/231 [==============================] - 0s 700us/step - loss: 2331.5552 - mse: 2331.5552 - mae: 33.2827\n",
      "Epoch 6/80\n",
      "231/231 [==============================] - 0s 695us/step - loss: 2255.7798 - mse: 2255.7798 - mae: 32.4089\n",
      "Epoch 7/80\n",
      "231/231 [==============================] - 0s 687us/step - loss: 2238.7219 - mse: 2238.7219 - mae: 32.5472\n",
      "Epoch 8/80\n",
      "231/231 [==============================] - 0s 764us/step - loss: 2278.2043 - mse: 2278.2043 - mae: 33.1511\n",
      "Epoch 9/80\n",
      "231/231 [==============================] - 0s 807us/step - loss: 2255.7529 - mse: 2255.7529 - mae: 32.5414\n",
      "Epoch 10/80\n",
      "231/231 [==============================] - 0s 702us/step - loss: 2202.2317 - mse: 2202.2317 - mae: 32.4850\n",
      "Epoch 11/80\n",
      "231/231 [==============================] - 0s 687us/step - loss: 2200.5186 - mse: 2200.5186 - mae: 32.4055\n",
      "Epoch 12/80\n",
      "231/231 [==============================] - 0s 665us/step - loss: 2210.0396 - mse: 2210.0396 - mae: 32.5310\n",
      "Epoch 13/80\n",
      "231/231 [==============================] - 0s 647us/step - loss: 2238.6919 - mse: 2238.6919 - mae: 32.4610\n",
      "Epoch 14/80\n",
      "231/231 [==============================] - 0s 770us/step - loss: 2203.8245 - mse: 2203.8245 - mae: 32.5048\n",
      "Epoch 15/80\n",
      "231/231 [==============================] - 0s 984us/step - loss: 2203.5874 - mse: 2203.5874 - mae: 32.2149\n",
      "Epoch 16/80\n",
      "231/231 [==============================] - 0s 989us/step - loss: 2203.6213 - mse: 2203.6213 - mae: 32.2532\n",
      "Epoch 17/80\n",
      "231/231 [==============================] - 0s 652us/step - loss: 2195.0461 - mse: 2195.0461 - mae: 32.3887\n",
      "Epoch 18/80\n",
      "231/231 [==============================] - 0s 718us/step - loss: 2161.6418 - mse: 2161.6418 - mae: 32.0583\n",
      "Epoch 19/80\n",
      "231/231 [==============================] - 0s 648us/step - loss: 2186.8418 - mse: 2186.8418 - mae: 32.3497\n",
      "Epoch 20/80\n",
      "231/231 [==============================] - 0s 699us/step - loss: 2172.4980 - mse: 2172.4980 - mae: 31.9806\n",
      "Epoch 21/80\n",
      "231/231 [==============================] - 0s 702us/step - loss: 2154.8252 - mse: 2154.8252 - mae: 31.9521\n",
      "Epoch 22/80\n",
      "231/231 [==============================] - 0s 820us/step - loss: 2157.3972 - mse: 2157.3972 - mae: 31.9386\n",
      "Epoch 23/80\n",
      "231/231 [==============================] - 0s 737us/step - loss: 2178.0803 - mse: 2178.0803 - mae: 31.8163\n",
      "Epoch 24/80\n",
      "231/231 [==============================] - 0s 705us/step - loss: 2176.2002 - mse: 2176.2002 - mae: 31.7029\n",
      "Epoch 25/80\n",
      "231/231 [==============================] - 0s 628us/step - loss: 2196.4792 - mse: 2196.4792 - mae: 32.1324\n",
      "Epoch 26/80\n",
      "231/231 [==============================] - 0s 700us/step - loss: 2129.3230 - mse: 2129.3232 - mae: 31.7210\n",
      "Epoch 27/80\n",
      "231/231 [==============================] - 0s 630us/step - loss: 2142.1995 - mse: 2142.1995 - mae: 31.9575\n",
      "Epoch 28/80\n",
      "231/231 [==============================] - 0s 652us/step - loss: 2183.2437 - mse: 2183.2437 - mae: 32.0979\n",
      "Epoch 29/80\n",
      "231/231 [==============================] - 0s 980us/step - loss: 2135.6611 - mse: 2135.6611 - mae: 31.9322\n",
      "Epoch 30/80\n",
      "231/231 [==============================] - 0s 971us/step - loss: 2117.2639 - mse: 2117.2639 - mae: 31.4829\n",
      "Epoch 31/80\n",
      "231/231 [==============================] - 0s 818us/step - loss: 2144.4587 - mse: 2144.4587 - mae: 31.5371\n",
      "Epoch 32/80\n",
      "231/231 [==============================] - 0s 870us/step - loss: 2111.1785 - mse: 2111.1785 - mae: 31.3836\n",
      "Epoch 33/80\n",
      "231/231 [==============================] - 0s 799us/step - loss: 2138.1582 - mse: 2138.1582 - mae: 31.7139\n",
      "Epoch 34/80\n",
      "231/231 [==============================] - 0s 928us/step - loss: 2125.5632 - mse: 2125.5632 - mae: 31.6965\n",
      "Epoch 35/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 2106.2739 - mse: 2106.2739 - mae: 31.3837\n",
      "Epoch 36/80\n",
      "231/231 [==============================] - 0s 756us/step - loss: 2158.9136 - mse: 2158.9136 - mae: 31.5739\n",
      "Epoch 37/80\n",
      "231/231 [==============================] - 0s 747us/step - loss: 2158.4724 - mse: 2158.4724 - mae: 31.8803\n",
      "Epoch 38/80\n",
      "231/231 [==============================] - 0s 688us/step - loss: 2131.3420 - mse: 2131.3420 - mae: 31.2586\n",
      "Epoch 39/80\n",
      "231/231 [==============================] - 0s 646us/step - loss: 2136.7725 - mse: 2136.7725 - mae: 31.8211\n",
      "Epoch 40/80\n",
      "231/231 [==============================] - ETA: 0s - loss: 2116.0730 - mse: 2116.0730 - mae: 31.86 - 0s 789us/step - loss: 2134.6272 - mse: 2134.6272 - mae: 31.8294\n",
      "Epoch 41/80\n",
      "231/231 [==============================] - 0s 996us/step - loss: 2130.5642 - mse: 2130.5642 - mae: 31.58800s - loss: 2234.2988 - mse: 2234.2988 - mae: 31.\n",
      "Epoch 42/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 2095.8479 - mse: 2095.8479 - mae: 31.3941\n",
      "Epoch 43/80\n",
      "231/231 [==============================] - 0s 715us/step - loss: 2091.8062 - mse: 2091.8062 - mae: 31.2947\n",
      "Epoch 44/80\n",
      "231/231 [==============================] - 0s 984us/step - loss: 2134.3823 - mse: 2134.3823 - mae: 31.6052\n",
      "Epoch 45/80\n",
      "231/231 [==============================] - 0s 948us/step - loss: 2109.5332 - mse: 2109.5332 - mae: 31.3271\n",
      "Epoch 46/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 2127.8684 - mse: 2127.8684 - mae: 31.7371\n",
      "Epoch 47/80\n",
      "231/231 [==============================] - 0s 856us/step - loss: 2126.3481 - mse: 2126.3481 - mae: 31.4445\n",
      "Epoch 48/80\n",
      "231/231 [==============================] - 0s 759us/step - loss: 2118.5500 - mse: 2118.5500 - mae: 31.4359\n",
      "Epoch 49/80\n",
      "231/231 [==============================] - 0s 781us/step - loss: 2126.9512 - mse: 2126.9512 - mae: 31.2939\n",
      "Epoch 50/80\n",
      "231/231 [==============================] - 0s 768us/step - loss: 2127.2634 - mse: 2127.2634 - mae: 31.3304\n",
      "Epoch 51/80\n",
      "231/231 [==============================] - 0s 876us/step - loss: 2127.3645 - mse: 2127.3645 - mae: 31.5627\n",
      "Epoch 52/80\n",
      "231/231 [==============================] - 0s 791us/step - loss: 2077.8044 - mse: 2077.8044 - mae: 31.3245\n",
      "Epoch 53/80\n",
      "231/231 [==============================] - 0s 989us/step - loss: 2068.2913 - mse: 2068.2913 - mae: 31.1129\n",
      "Epoch 54/80\n",
      "231/231 [==============================] - 0s 719us/step - loss: 2074.0847 - mse: 2074.0847 - mae: 31.1184\n",
      "Epoch 55/80\n",
      "231/231 [==============================] - 0s 683us/step - loss: 2130.1074 - mse: 2130.1074 - mae: 31.5324\n",
      "Epoch 56/80\n",
      "231/231 [==============================] - 0s 664us/step - loss: 2109.9016 - mse: 2109.9016 - mae: 31.5061\n",
      "Epoch 57/80\n",
      "231/231 [==============================] - 0s 737us/step - loss: 2080.3799 - mse: 2080.3799 - mae: 31.0264\n",
      "Epoch 58/80\n",
      "231/231 [==============================] - 0s 853us/step - loss: 2090.5952 - mse: 2090.5952 - mae: 31.4539\n",
      "Epoch 59/80\n",
      "231/231 [==============================] - 0s 924us/step - loss: 2090.9587 - mse: 2090.9587 - mae: 31.2910\n",
      "Epoch 60/80\n",
      "231/231 [==============================] - 0s 741us/step - loss: 2118.0007 - mse: 2118.0007 - mae: 31.2977\n",
      "Epoch 61/80\n",
      "231/231 [==============================] - 0s 671us/step - loss: 2063.4097 - mse: 2063.4097 - mae: 31.0770\n",
      "Epoch 62/80\n",
      "231/231 [==============================] - 0s 663us/step - loss: 2086.2229 - mse: 2086.2229 - mae: 31.0670\n",
      "Epoch 63/80\n",
      "231/231 [==============================] - 0s 723us/step - loss: 2117.2795 - mse: 2117.2795 - mae: 31.5834\n",
      "Epoch 64/80\n",
      "231/231 [==============================] - 0s 833us/step - loss: 2080.9697 - mse: 2080.9697 - mae: 31.2873\n",
      "Epoch 65/80\n",
      "231/231 [==============================] - 0s 779us/step - loss: 2069.0730 - mse: 2069.0730 - mae: 31.0679\n",
      "Epoch 66/80\n",
      "231/231 [==============================] - 0s 954us/step - loss: 2086.9917 - mse: 2086.9917 - mae: 31.1724\n",
      "Epoch 67/80\n",
      "231/231 [==============================] - 0s 695us/step - loss: 2069.3982 - mse: 2069.3982 - mae: 31.3466\n",
      "Epoch 68/80\n",
      "231/231 [==============================] - 0s 686us/step - loss: 2096.0620 - mse: 2096.0620 - mae: 31.1699\n",
      "Epoch 69/80\n",
      "231/231 [==============================] - 0s 727us/step - loss: 2076.1067 - mse: 2076.1067 - mae: 31.1631\n",
      "Epoch 70/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 2106.0037 - mse: 2106.0037 - mae: 31.4070\n",
      "Epoch 71/80\n",
      "231/231 [==============================] - 0s 799us/step - loss: 2125.0476 - mse: 2125.0476 - mae: 31.5559\n",
      "Epoch 72/80\n",
      "231/231 [==============================] - 0s 846us/step - loss: 2093.6191 - mse: 2093.6191 - mae: 31.3287\n",
      "Epoch 73/80\n",
      "231/231 [==============================] - 0s 902us/step - loss: 2086.6846 - mse: 2086.6846 - mae: 31.1918\n",
      "Epoch 74/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 2090.5559 - mse: 2090.5559 - mae: 31.1790\n",
      "Epoch 75/80\n",
      "231/231 [==============================] - 0s 768us/step - loss: 2090.3096 - mse: 2090.3096 - mae: 31.0299\n",
      "Epoch 76/80\n",
      "231/231 [==============================] - 0s 669us/step - loss: 2073.4844 - mse: 2073.4844 - mae: 30.9266\n",
      "Epoch 77/80\n",
      "231/231 [==============================] - 0s 808us/step - loss: 2072.1675 - mse: 2072.1675 - mae: 30.9414\n",
      "Epoch 78/80\n",
      "231/231 [==============================] - 0s 907us/step - loss: 2098.0686 - mse: 2098.0686 - mae: 30.9827\n",
      "Epoch 79/80\n",
      "231/231 [==============================] - 0s 831us/step - loss: 2079.0332 - mse: 2079.0332 - mae: 30.9650\n",
      "Epoch 80/80\n",
      "231/231 [==============================] - 0s 694us/step - loss: 2108.4773 - mse: 2108.4773 - mae: 31.2364\n",
      "1\n",
      "Epoch 1/80\n",
      "231/231 [==============================] - 0s 787us/step - loss: 7159.0776 - mse: 7159.0776 - mae: 35.1391\n",
      "Epoch 2/80\n",
      "231/231 [==============================] - 0s 707us/step - loss: 7137.5957 - mse: 7137.5957 - mae: 35.1855\n",
      "Epoch 3/80\n",
      "231/231 [==============================] - 0s 820us/step - loss: 7035.1089 - mse: 7035.1089 - mae: 35.3932\n",
      "Epoch 4/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 7104.5625 - mse: 7104.5625 - mae: 35.9092\n",
      "Epoch 5/80\n",
      "231/231 [==============================] - 0s 802us/step - loss: 7048.3872 - mse: 7048.3872 - mae: 35.2225\n",
      "Epoch 6/80\n",
      "231/231 [==============================] - 0s 778us/step - loss: 7004.3818 - mse: 7004.3818 - mae: 35.4373\n",
      "Epoch 7/80\n",
      "231/231 [==============================] - 0s 696us/step - loss: 6970.8721 - mse: 6970.8721 - mae: 35.1829\n",
      "Epoch 8/80\n",
      "231/231 [==============================] - 0s 750us/step - loss: 6940.7524 - mse: 6940.7524 - mae: 35.9889\n",
      "Epoch 9/80\n",
      "231/231 [==============================] - 0s 808us/step - loss: 7004.1411 - mse: 7004.1411 - mae: 35.9115\n",
      "Epoch 10/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 6938.7397 - mse: 6938.7397 - mae: 35.5622\n",
      "Epoch 11/80\n",
      "231/231 [==============================] - 0s 981us/step - loss: 6983.8789 - mse: 6983.8789 - mae: 35.7509\n",
      "Epoch 12/80\n",
      "231/231 [==============================] - 0s 865us/step - loss: 6944.3281 - mse: 6944.3281 - mae: 35.8542\n",
      "Epoch 13/80\n",
      "231/231 [==============================] - 0s 730us/step - loss: 6915.5620 - mse: 6915.5620 - mae: 35.7324\n",
      "Epoch 14/80\n",
      "231/231 [==============================] - 0s 656us/step - loss: 6896.3120 - mse: 6896.3120 - mae: 36.2776\n",
      "Epoch 15/80\n",
      "231/231 [==============================] - 0s 812us/step - loss: 6895.2246 - mse: 6895.2246 - mae: 35.9597\n",
      "Epoch 16/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 6898.2373 - mse: 6898.2373 - mae: 35.7242\n",
      "Epoch 17/80\n",
      "231/231 [==============================] - 0s 864us/step - loss: 6894.8594 - mse: 6894.8594 - mae: 36.1803\n",
      "Epoch 18/80\n",
      "231/231 [==============================] - 0s 720us/step - loss: 6828.1279 - mse: 6828.1279 - mae: 36.3184\n",
      "Epoch 19/80\n",
      "231/231 [==============================] - 0s 678us/step - loss: 6787.7456 - mse: 6787.7456 - mae: 35.8988\n",
      "Epoch 20/80\n",
      "231/231 [==============================] - 0s 692us/step - loss: 6847.9902 - mse: 6847.9902 - mae: 36.3522\n",
      "Epoch 21/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 6834.8521 - mse: 6834.8521 - mae: 36.4860\n",
      "Epoch 22/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 6887.6147 - mse: 6887.6147 - mae: 36.5848\n",
      "Epoch 23/80\n",
      "231/231 [==============================] - 0s 928us/step - loss: 6774.5181 - mse: 6774.5181 - mae: 36.0778\n",
      "Epoch 24/80\n",
      "231/231 [==============================] - 0s 678us/step - loss: 6793.1128 - mse: 6793.1128 - mae: 36.2648\n",
      "Epoch 25/80\n",
      "231/231 [==============================] - 0s 811us/step - loss: 6755.9277 - mse: 6755.9277 - mae: 36.2856\n",
      "Epoch 26/80\n",
      "231/231 [==============================] - 0s 950us/step - loss: 6764.8115 - mse: 6764.8115 - mae: 36.7658\n",
      "Epoch 27/80\n",
      "231/231 [==============================] - 0s 972us/step - loss: 6714.7026 - mse: 6714.7026 - mae: 37.0712\n",
      "Epoch 28/80\n",
      "231/231 [==============================] - 0s 832us/step - loss: 6743.2700 - mse: 6743.2700 - mae: 36.5421\n",
      "Epoch 29/80\n",
      "231/231 [==============================] - 0s 832us/step - loss: 6757.7739 - mse: 6757.7739 - mae: 36.7404\n",
      "Epoch 30/80\n",
      "231/231 [==============================] - 0s 787us/step - loss: 6823.2148 - mse: 6823.2148 - mae: 36.6011\n",
      "Epoch 31/80\n",
      "231/231 [==============================] - 0s 768us/step - loss: 6687.1187 - mse: 6687.1187 - mae: 36.4888\n",
      "Epoch 32/80\n",
      "231/231 [==============================] - 0s 873us/step - loss: 6577.9600 - mse: 6577.9600 - mae: 36.7430\n",
      "Epoch 33/80\n",
      "231/231 [==============================] - 0s 920us/step - loss: 6761.3721 - mse: 6761.3721 - mae: 36.6986\n",
      "Epoch 34/80\n",
      "231/231 [==============================] - 0s 937us/step - loss: 6695.9214 - mse: 6695.9214 - mae: 36.6035\n",
      "Epoch 35/80\n",
      "231/231 [==============================] - 0s 858us/step - loss: 6696.1147 - mse: 6696.1147 - mae: 36.3674\n",
      "Epoch 36/80\n",
      "231/231 [==============================] - 0s 763us/step - loss: 6565.0063 - mse: 6565.0063 - mae: 36.4532\n",
      "Epoch 37/80\n",
      "231/231 [==============================] - 0s 796us/step - loss: 6664.0063 - mse: 6664.0063 - mae: 36.5720\n",
      "Epoch 38/80\n",
      "231/231 [==============================] - 0s 958us/step - loss: 6673.8633 - mse: 6673.8633 - mae: 36.4538\n",
      "Epoch 39/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 6635.0288 - mse: 6635.0288 - mae: 36.9303\n",
      "Epoch 40/80\n",
      "231/231 [==============================] - 0s 734us/step - loss: 6700.8101 - mse: 6700.8101 - mae: 36.4537\n",
      "Epoch 41/80\n",
      "231/231 [==============================] - 0s 864us/step - loss: 6614.8159 - mse: 6614.8159 - mae: 37.0367\n",
      "Epoch 42/80\n",
      "231/231 [==============================] - 0s 708us/step - loss: 6602.1001 - mse: 6602.1001 - mae: 36.6054\n",
      "Epoch 43/80\n",
      "231/231 [==============================] - 0s 721us/step - loss: 6634.2246 - mse: 6634.2246 - mae: 36.8957\n",
      "Epoch 44/80\n",
      "231/231 [==============================] - 0s 717us/step - loss: 6640.5981 - mse: 6640.5981 - mae: 36.6572\n",
      "Epoch 45/80\n",
      "231/231 [==============================] - 0s 920us/step - loss: 6737.5742 - mse: 6737.5742 - mae: 36.8235\n",
      "Epoch 46/80\n",
      "231/231 [==============================] - 0s 838us/step - loss: 6594.8950 - mse: 6594.8950 - mae: 36.9894\n",
      "Epoch 47/80\n",
      "231/231 [==============================] - 0s 766us/step - loss: 6722.5176 - mse: 6722.5176 - mae: 37.2294\n",
      "Epoch 48/80\n",
      "231/231 [==============================] - 0s 716us/step - loss: 6550.7153 - mse: 6550.7153 - mae: 36.8970\n",
      "Epoch 49/80\n",
      "231/231 [==============================] - 0s 933us/step - loss: 6589.5464 - mse: 6589.5464 - mae: 36.8898\n",
      "Epoch 50/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 6477.7744 - mse: 6477.7744 - mae: 36.8795\n",
      "Epoch 51/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 6577.2446 - mse: 6577.2446 - mae: 37.0151\n",
      "Epoch 52/80\n",
      "231/231 [==============================] - 0s 802us/step - loss: 6524.3369 - mse: 6524.3369 - mae: 37.3495\n",
      "Epoch 53/80\n",
      "231/231 [==============================] - 0s 856us/step - loss: 6565.9551 - mse: 6565.9551 - mae: 36.9032\n",
      "Epoch 54/80\n",
      "231/231 [==============================] - 0s 811us/step - loss: 6627.9521 - mse: 6627.9521 - mae: 36.8829\n",
      "Epoch 55/80\n",
      "231/231 [==============================] - 0s 823us/step - loss: 6508.1636 - mse: 6508.1636 - mae: 37.2087\n",
      "Epoch 56/80\n",
      "231/231 [==============================] - 0s 952us/step - loss: 6548.4771 - mse: 6548.4771 - mae: 37.1853\n",
      "Epoch 57/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 6422.0728 - mse: 6422.0728 - mae: 36.9864\n",
      "Epoch 58/80\n",
      "231/231 [==============================] - 0s 956us/step - loss: 6579.6353 - mse: 6579.6353 - mae: 37.4259\n",
      "Epoch 59/80\n",
      "231/231 [==============================] - 0s 825us/step - loss: 6532.8438 - mse: 6532.8438 - mae: 37.3788\n",
      "Epoch 60/80\n",
      "231/231 [==============================] - 0s 800us/step - loss: 6436.5723 - mse: 6436.5723 - mae: 37.0323\n",
      "Epoch 61/80\n",
      "231/231 [==============================] - 0s 840us/step - loss: 6507.7085 - mse: 6507.7085 - mae: 37.4487\n",
      "Epoch 62/80\n",
      "231/231 [==============================] - 0s 954us/step - loss: 6507.0840 - mse: 6507.0840 - mae: 37.2154\n",
      "Epoch 63/80\n",
      "231/231 [==============================] - 0s 794us/step - loss: 6488.7432 - mse: 6488.7432 - mae: 37.2738\n",
      "Epoch 64/80\n",
      "231/231 [==============================] - 0s 764us/step - loss: 6558.0605 - mse: 6558.0605 - mae: 37.0728\n",
      "Epoch 65/80\n",
      "231/231 [==============================] - 0s 841us/step - loss: 6381.4526 - mse: 6381.4526 - mae: 37.3754\n",
      "Epoch 66/80\n",
      "231/231 [==============================] - 0s 792us/step - loss: 6387.9941 - mse: 6387.9941 - mae: 36.9907\n",
      "Epoch 67/80\n",
      "231/231 [==============================] - 0s 888us/step - loss: 6413.0869 - mse: 6413.0869 - mae: 37.1894\n",
      "Epoch 68/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 6442.9434 - mse: 6442.9434 - mae: 37.0548\n",
      "Epoch 69/80\n",
      "231/231 [==============================] - 0s 953us/step - loss: 6327.3833 - mse: 6327.3833 - mae: 37.2196\n",
      "Epoch 70/80\n",
      "231/231 [==============================] - 0s 898us/step - loss: 6330.1709 - mse: 6330.1709 - mae: 37.1638\n",
      "Epoch 71/80\n",
      "231/231 [==============================] - 0s 850us/step - loss: 6232.2974 - mse: 6232.2974 - mae: 37.0765\n",
      "Epoch 72/80\n",
      "231/231 [==============================] - 0s 951us/step - loss: 6428.9849 - mse: 6428.9849 - mae: 37.4262\n",
      "Epoch 73/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 6370.5894 - mse: 6370.5894 - mae: 37.0250\n",
      "Epoch 74/80\n",
      "231/231 [==============================] - 0s 830us/step - loss: 6241.4019 - mse: 6241.4019 - mae: 37.0855\n",
      "Epoch 75/80\n",
      "231/231 [==============================] - 0s 937us/step - loss: 6230.0645 - mse: 6230.0645 - mae: 37.1140\n",
      "Epoch 76/80\n",
      "231/231 [==============================] - 0s 920us/step - loss: 6353.2559 - mse: 6353.2559 - mae: 37.4075\n",
      "Epoch 77/80\n",
      "231/231 [==============================] - 0s 717us/step - loss: 6338.7900 - mse: 6338.7900 - mae: 37.2860\n",
      "Epoch 78/80\n",
      "231/231 [==============================] - 0s 856us/step - loss: 6328.7598 - mse: 6328.7598 - mae: 37.0425\n",
      "Epoch 79/80\n",
      "231/231 [==============================] - 0s 962us/step - loss: 6200.3135 - mse: 6200.3135 - mae: 36.9583\n",
      "Epoch 80/80\n",
      "231/231 [==============================] - 0s 892us/step - loss: 6277.7676 - mse: 6277.7676 - mae: 37.3319\n",
      "2\n",
      "Epoch 1/80\n",
      "231/231 [==============================] - 0s 778us/step - loss: 1445.4990 - mse: 1445.4990 - mae: 27.6751\n",
      "Epoch 2/80\n",
      "231/231 [==============================] - 0s 801us/step - loss: 1433.9685 - mse: 1433.9685 - mae: 27.4755\n",
      "Epoch 3/80\n",
      "231/231 [==============================] - 0s 837us/step - loss: 1400.4182 - mse: 1400.4182 - mae: 26.9839\n",
      "Epoch 4/80\n",
      "231/231 [==============================] - 0s 835us/step - loss: 1375.5807 - mse: 1375.5807 - mae: 26.6773\n",
      "Epoch 5/80\n",
      "231/231 [==============================] - 0s 979us/step - loss: 1336.9218 - mse: 1336.9218 - mae: 26.3683\n",
      "Epoch 6/80\n",
      "231/231 [==============================] - 0s 795us/step - loss: 1330.3765 - mse: 1330.3765 - mae: 26.2644\n",
      "Epoch 7/80\n",
      "231/231 [==============================] - 0s 795us/step - loss: 1293.3630 - mse: 1293.3630 - mae: 25.8856\n",
      "Epoch 8/80\n",
      "231/231 [==============================] - 0s 802us/step - loss: 1319.0848 - mse: 1319.0848 - mae: 25.9239\n",
      "Epoch 9/80\n",
      "231/231 [==============================] - 0s 990us/step - loss: 1315.8318 - mse: 1315.8318 - mae: 25.8867\n",
      "Epoch 10/80\n",
      "231/231 [==============================] - 0s 931us/step - loss: 1307.8672 - mse: 1307.8672 - mae: 25.6578\n",
      "Epoch 11/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1262.7505 - mse: 1262.7505 - mae: 25.6676\n",
      "Epoch 12/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1281.2997 - mse: 1281.2997 - mae: 25.2885\n",
      "Epoch 13/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1266.3978 - mse: 1266.3978 - mae: 25.1932\n",
      "Epoch 14/80\n",
      "231/231 [==============================] - 0s 915us/step - loss: 1237.8110 - mse: 1237.8110 - mae: 24.8782\n",
      "Epoch 15/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1263.2877 - mse: 1263.2877 - mae: 25.2528\n",
      "Epoch 16/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1263.8387 - mse: 1263.8387 - mae: 25.4416\n",
      "Epoch 17/80\n",
      "231/231 [==============================] - 0s 862us/step - loss: 1253.7795 - mse: 1253.7795 - mae: 25.0902\n",
      "Epoch 18/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1249.2562 - mse: 1249.2562 - mae: 25.1758\n",
      "Epoch 19/80\n",
      "231/231 [==============================] - 0s 914us/step - loss: 1267.8374 - mse: 1267.8374 - mae: 25.1216\n",
      "Epoch 20/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1239.1908 - mse: 1239.1908 - mae: 25.1218\n",
      "Epoch 21/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1234.7604 - mse: 1234.7604 - mae: 24.9749\n",
      "Epoch 22/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1244.9620 - mse: 1244.9620 - mae: 24.9881\n",
      "Epoch 23/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1250.4829 - mse: 1250.4829 - mae: 25.1227\n",
      "Epoch 24/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1235.3107 - mse: 1235.3107 - mae: 25.1135\n",
      "Epoch 25/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1239.7509 - mse: 1239.7509 - mae: 24.8416\n",
      "Epoch 26/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1207.4951 - mse: 1207.4951 - mae: 24.6725\n",
      "Epoch 27/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1218.7783 - mse: 1218.7783 - mae: 24.8246\n",
      "Epoch 28/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1254.1414 - mse: 1254.1414 - mae: 25.1603\n",
      "Epoch 29/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1211.5604 - mse: 1211.5604 - mae: 24.8472\n",
      "Epoch 30/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1228.7114 - mse: 1228.7114 - mae: 24.8470\n",
      "Epoch 31/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1226.2384 - mse: 1226.2384 - mae: 24.9303\n",
      "Epoch 32/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1234.0126 - mse: 1234.0126 - mae: 24.9308\n",
      "Epoch 33/80\n",
      "231/231 [==============================] - 0s 893us/step - loss: 1210.3032 - mse: 1210.3032 - mae: 24.7077\n",
      "Epoch 34/80\n",
      "231/231 [==============================] - 0s 976us/step - loss: 1209.5391 - mse: 1209.5391 - mae: 24.7622\n",
      "Epoch 35/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1223.1858 - mse: 1223.1858 - mae: 24.8528\n",
      "Epoch 36/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1204.4255 - mse: 1204.4255 - mae: 24.8004\n",
      "Epoch 37/80\n",
      "231/231 [==============================] - 0s 932us/step - loss: 1236.3202 - mse: 1236.3202 - mae: 24.8926\n",
      "Epoch 38/80\n",
      "231/231 [==============================] - 0s 946us/step - loss: 1219.1768 - mse: 1219.1768 - mae: 24.8501\n",
      "Epoch 39/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1215.2281 - mse: 1215.2281 - mae: 24.9174\n",
      "Epoch 40/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1236.3922 - mse: 1236.3922 - mae: 24.7728\n",
      "Epoch 41/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1221.4967 - mse: 1221.4967 - mae: 24.6540\n",
      "Epoch 42/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1202.2428 - mse: 1202.2428 - mae: 24.5952\n",
      "Epoch 43/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1211.3059 - mse: 1211.3059 - mae: 24.7795\n",
      "Epoch 44/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1215.4427 - mse: 1215.4427 - mae: 24.6452\n",
      "Epoch 45/80\n",
      "231/231 [==============================] - 0s 992us/step - loss: 1204.0127 - mse: 1204.0127 - mae: 24.7470\n",
      "Epoch 46/80\n",
      "231/231 [==============================] - 0s 988us/step - loss: 1198.6810 - mse: 1198.6810 - mae: 24.4309\n",
      "Epoch 47/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1190.7734 - mse: 1190.7734 - mae: 24.3841\n",
      "Epoch 48/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1202.8054 - mse: 1202.8054 - mae: 24.8189\n",
      "Epoch 49/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1193.1473 - mse: 1193.1473 - mae: 24.5945\n",
      "Epoch 50/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1200.2798 - mse: 1200.2798 - mae: 24.7238\n",
      "Epoch 51/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1202.8097 - mse: 1202.8097 - mae: 24.4363\n",
      "Epoch 52/80\n",
      "231/231 [==============================] - 0s 909us/step - loss: 1201.7339 - mse: 1201.7339 - mae: 24.5844\n",
      "Epoch 53/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1190.2275 - mse: 1190.2275 - mae: 24.6687\n",
      "Epoch 54/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1189.7521 - mse: 1189.7521 - mae: 24.5844\n",
      "Epoch 55/80\n",
      "231/231 [==============================] - 0s 991us/step - loss: 1174.5680 - mse: 1174.5680 - mae: 24.4712\n",
      "Epoch 56/80\n",
      "231/231 [==============================] - 0s 892us/step - loss: 1199.9771 - mse: 1199.9771 - mae: 24.5195\n",
      "Epoch 57/80\n",
      "231/231 [==============================] - 0s 913us/step - loss: 1196.2499 - mse: 1196.2499 - mae: 24.6414\n",
      "Epoch 58/80\n",
      "231/231 [==============================] - 0s 935us/step - loss: 1216.9333 - mse: 1216.9333 - mae: 24.9296\n",
      "Epoch 59/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1215.4226 - mse: 1215.4226 - mae: 24.8406\n",
      "Epoch 60/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1199.4403 - mse: 1199.4403 - mae: 24.8440\n",
      "Epoch 61/80\n",
      "231/231 [==============================] - 0s 863us/step - loss: 1170.8893 - mse: 1170.8893 - mae: 24.3042\n",
      "Epoch 62/80\n",
      "231/231 [==============================] - 0s 989us/step - loss: 1205.9271 - mse: 1205.9271 - mae: 24.3998\n",
      "Epoch 63/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1187.1636 - mse: 1187.1636 - mae: 24.4871\n",
      "Epoch 64/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1163.6484 - mse: 1163.6484 - mae: 24.2807\n",
      "Epoch 65/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1184.5021 - mse: 1184.5021 - mae: 24.4960\n",
      "Epoch 66/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1179.6455 - mse: 1179.6455 - mae: 24.5033\n",
      "Epoch 67/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1180.5844 - mse: 1180.5844 - mae: 24.4330\n",
      "Epoch 68/80\n",
      "231/231 [==============================] - 0s 970us/step - loss: 1171.8401 - mse: 1171.8401 - mae: 24.4451\n",
      "Epoch 69/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1197.0747 - mse: 1197.0747 - mae: 24.5886\n",
      "Epoch 70/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1194.7819 - mse: 1194.7819 - mae: 24.4496\n",
      "Epoch 71/80\n",
      "231/231 [==============================] - 0s 970us/step - loss: 1186.0186 - mse: 1186.0186 - mae: 24.6289\n",
      "Epoch 72/80\n",
      "231/231 [==============================] - 0s 982us/step - loss: 1172.2585 - mse: 1172.2585 - mae: 24.4698\n",
      "Epoch 73/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1183.8473 - mse: 1183.8473 - mae: 24.6346\n",
      "Epoch 74/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1187.9357 - mse: 1187.9357 - mae: 24.5792\n",
      "Epoch 75/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1193.4515 - mse: 1193.4514 - mae: 24.6145\n",
      "Epoch 76/80\n",
      "231/231 [==============================] - 0s 945us/step - loss: 1158.5341 - mse: 1158.5342 - mae: 24.2847\n",
      "Epoch 77/80\n",
      "231/231 [==============================] - 0s 901us/step - loss: 1189.9462 - mse: 1189.9462 - mae: 24.7132\n",
      "Epoch 78/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1183.3110 - mse: 1183.3110 - mae: 24.4155\n",
      "Epoch 79/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1173.7822 - mse: 1173.7822 - mae: 24.6234\n",
      "Epoch 80/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1182.9156 - mse: 1182.9156 - mae: 24.5766\n",
      "3\n",
      "Epoch 1/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1065.8552 - mse: 1065.8552 - mae: 25.0639\n",
      "Epoch 2/80\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 1027.9000 - mse: 1027.9000 - mae: 24.5936\n",
      "Epoch 3/80\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 1034.3303 - mse: 1034.3303 - mae: 24.3578\n",
      "Epoch 4/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1007.1099 - mse: 1007.1099 - mae: 24.2833\n",
      "Epoch 5/80\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 1031.2999 - mse: 1031.2999 - mae: 24.5692\n",
      "Epoch 6/80\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 1021.2830 - mse: 1021.2830 - mae: 24.2373\n",
      "Epoch 7/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1015.0355 - mse: 1015.0355 - mae: 24.3610\n",
      "Epoch 8/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1000.9255 - mse: 1000.9255 - mae: 24.0583\n",
      "Epoch 9/80\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 997.0148 - mse: 997.0148 - mae: 23.8768\n",
      "Epoch 10/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1030.4028 - mse: 1030.4028 - mae: 24.3918\n",
      "Epoch 11/80\n",
      "231/231 [==============================] - 0s 991us/step - loss: 975.9863 - mse: 975.9863 - mae: 23.7884\n",
      "Epoch 12/80\n",
      "231/231 [==============================] - 0s 946us/step - loss: 1005.6644 - mse: 1005.6644 - mae: 24.1898\n",
      "Epoch 13/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 999.8840 - mse: 999.8840 - mae: 23.9909\n",
      "Epoch 14/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 988.5814 - mse: 988.5814 - mae: 23.9275\n",
      "Epoch 15/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 990.8749 - mse: 990.8749 - mae: 23.8870\n",
      "Epoch 16/80\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 1001.9462 - mse: 1001.9462 - mae: 24.0858\n",
      "Epoch 17/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 988.9099 - mse: 988.9099 - mae: 23.9576\n",
      "Epoch 18/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 978.8538 - mse: 978.8538 - mae: 23.8371\n",
      "Epoch 19/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 998.4281 - mse: 998.4281 - mae: 23.8646\n",
      "Epoch 20/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1017.4835 - mse: 1017.4835 - mae: 24.1491\n",
      "Epoch 21/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 982.2144 - mse: 982.2144 - mae: 23.6987\n",
      "Epoch 22/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 980.6618 - mse: 980.6618 - mae: 23.7958\n",
      "Epoch 23/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 998.2128 - mse: 998.2128 - mae: 23.9492\n",
      "Epoch 24/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 997.1752 - mse: 997.1752 - mae: 23.9830\n",
      "Epoch 25/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1007.3130 - mse: 1007.3130 - mae: 24.1286\n",
      "Epoch 26/80\n",
      "231/231 [==============================] - 0s 2ms/step - loss: 999.7989 - mse: 999.7991 - mae: 23.8223\n",
      "Epoch 27/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 999.7708 - mse: 999.7708 - mae: 23.9022\n",
      "Epoch 28/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 981.2945 - mse: 981.2945 - mae: 23.6844\n",
      "Epoch 29/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 982.4329 - mse: 982.4329 - mae: 23.7774\n",
      "Epoch 30/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 985.5969 - mse: 985.5969 - mae: 23.9103\n",
      "Epoch 31/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 983.7900 - mse: 983.7900 - mae: 23.8670\n",
      "Epoch 32/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 992.0602 - mse: 992.0602 - mae: 23.8845\n",
      "Epoch 33/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1006.2542 - mse: 1006.2542 - mae: 23.9783\n",
      "Epoch 34/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 994.0611 - mse: 994.0611 - mae: 23.8803\n",
      "Epoch 35/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 991.9905 - mse: 991.9905 - mae: 23.9387\n",
      "Epoch 36/80\n",
      "231/231 [==============================] - 0s 913us/step - loss: 991.6810 - mse: 991.6810 - mae: 23.9069\n",
      "Epoch 37/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 972.2973 - mse: 972.2973 - mae: 23.5106\n",
      "Epoch 38/80\n",
      "231/231 [==============================] - 0s 957us/step - loss: 985.9907 - mse: 985.9907 - mae: 23.7036\n",
      "Epoch 39/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 980.4376 - mse: 980.4376 - mae: 23.5870\n",
      "Epoch 40/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 987.9260 - mse: 987.9260 - mae: 23.7237\n",
      "Epoch 41/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 978.9504 - mse: 978.9504 - mae: 23.7744\n",
      "Epoch 42/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 989.6531 - mse: 989.6531 - mae: 23.7689\n",
      "Epoch 43/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 988.5415 - mse: 988.5415 - mae: 23.7214\n",
      "Epoch 44/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 988.3989 - mse: 988.3989 - mae: 23.8163\n",
      "Epoch 45/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1001.1956 - mse: 1001.1956 - mae: 23.9057\n",
      "Epoch 46/80\n",
      "231/231 [==============================] - 0s 981us/step - loss: 988.7598 - mse: 988.7598 - mae: 23.7913\n",
      "Epoch 47/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 986.6309 - mse: 986.6309 - mae: 23.8162\n",
      "Epoch 48/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 985.9151 - mse: 985.9151 - mae: 23.7247\n",
      "Epoch 49/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 995.9735 - mse: 995.9735 - mae: 23.8789\n",
      "Epoch 50/80\n",
      "231/231 [==============================] - 0s 947us/step - loss: 970.5599 - mse: 970.5599 - mae: 23.6329\n",
      "Epoch 51/80\n",
      "231/231 [==============================] - 0s 924us/step - loss: 999.9567 - mse: 999.9567 - mae: 23.9016\n",
      "Epoch 52/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 979.3503 - mse: 979.3503 - mae: 23.5533\n",
      "Epoch 53/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 981.3030 - mse: 981.3030 - mae: 23.6453\n",
      "Epoch 54/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 983.7577 - mse: 983.7577 - mae: 23.5976\n",
      "Epoch 55/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 981.8528 - mse: 981.8528 - mae: 23.5558\n",
      "Epoch 56/80\n",
      "231/231 [==============================] - 0s 971us/step - loss: 970.4578 - mse: 970.4578 - mae: 23.5553\n",
      "Epoch 57/80\n",
      "231/231 [==============================] - 0s 839us/step - loss: 973.6968 - mse: 973.6968 - mae: 23.6264\n",
      "Epoch 58/80\n",
      "231/231 [==============================] - 0s 981us/step - loss: 975.3135 - mse: 975.3135 - mae: 23.6553\n",
      "Epoch 59/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 976.6006 - mse: 976.6006 - mae: 23.7527\n",
      "Epoch 60/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 972.6000 - mse: 972.6000 - mae: 23.5475\n",
      "Epoch 61/80\n",
      "231/231 [==============================] - 0s 999us/step - loss: 978.4199 - mse: 978.4199 - mae: 23.7228\n",
      "Epoch 62/80\n",
      "231/231 [==============================] - 0s 955us/step - loss: 982.2804 - mse: 982.2804 - mae: 23.6305\n",
      "Epoch 63/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 978.4986 - mse: 978.4986 - mae: 23.6941\n",
      "Epoch 64/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 976.7125 - mse: 976.7125 - mae: 23.6455\n",
      "Epoch 65/80\n",
      "231/231 [==============================] - 0s 967us/step - loss: 982.1646 - mse: 982.1646 - mae: 23.7340\n",
      "Epoch 66/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 968.2242 - mse: 968.2242 - mae: 23.5956\n",
      "Epoch 67/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 965.7499 - mse: 965.7499 - mae: 23.3835\n",
      "Epoch 68/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 975.7439 - mse: 975.7439 - mae: 23.7449\n",
      "Epoch 69/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 968.3722 - mse: 968.3722 - mae: 23.5588\n",
      "Epoch 70/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 952.1910 - mse: 952.1910 - mae: 23.4338\n",
      "Epoch 71/80\n",
      "231/231 [==============================] - 0s 943us/step - loss: 961.6489 - mse: 961.6489 - mae: 23.3676\n",
      "Epoch 72/80\n",
      "231/231 [==============================] - 0s 910us/step - loss: 960.1733 - mse: 960.1733 - mae: 23.3456\n",
      "Epoch 73/80\n",
      "231/231 [==============================] - 0s 958us/step - loss: 975.7124 - mse: 975.7123 - mae: 23.5145\n",
      "Epoch 74/80\n",
      "231/231 [==============================] - 0s 991us/step - loss: 975.8922 - mse: 975.8922 - mae: 23.5972\n",
      "Epoch 75/80\n",
      "231/231 [==============================] - 0s 904us/step - loss: 961.1943 - mse: 961.1943 - mae: 23.4717\n",
      "Epoch 76/80\n",
      "231/231 [==============================] - 0s 865us/step - loss: 964.8913 - mse: 964.8913 - mae: 23.4062\n",
      "Epoch 77/80\n",
      "231/231 [==============================] - 0s 850us/step - loss: 979.4012 - mse: 979.4012 - mae: 23.4962\n",
      "Epoch 78/80\n",
      "231/231 [==============================] - 0s 968us/step - loss: 958.5151 - mse: 958.5151 - mae: 23.2630\n",
      "Epoch 79/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 958.0749 - mse: 958.0749 - mae: 23.4638\n",
      "Epoch 80/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 961.3909 - mse: 961.3909 - mae: 23.6173\n",
      "4\n",
      "Epoch 1/80\n",
      "231/231 [==============================] - 0s 932us/step - loss: 1156.3462 - mse: 1156.3462 - mae: 26.0566\n",
      "Epoch 2/80\n",
      "231/231 [==============================] - 0s 941us/step - loss: 1126.2714 - mse: 1126.2714 - mae: 25.6226\n",
      "Epoch 3/80\n",
      "231/231 [==============================] - 0s 984us/step - loss: 1128.7969 - mse: 1128.7969 - mae: 25.4878\n",
      "Epoch 4/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1124.2192 - mse: 1124.2192 - mae: 25.6250\n",
      "Epoch 5/80\n",
      "231/231 [==============================] - 0s 891us/step - loss: 1134.8221 - mse: 1134.8221 - mae: 25.6817\n",
      "Epoch 6/80\n",
      "231/231 [==============================] - 0s 842us/step - loss: 1109.9342 - mse: 1109.9342 - mae: 25.4381\n",
      "Epoch 7/80\n",
      "231/231 [==============================] - 0s 772us/step - loss: 1128.1320 - mse: 1128.1320 - mae: 25.2157\n",
      "Epoch 8/80\n",
      "231/231 [==============================] - 0s 888us/step - loss: 1114.1459 - mse: 1114.1459 - mae: 25.2729\n",
      "Epoch 9/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1124.3469 - mse: 1124.3469 - mae: 25.4150\n",
      "Epoch 10/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1129.0609 - mse: 1129.0609 - mae: 25.5575\n",
      "Epoch 11/80\n",
      "231/231 [==============================] - 0s 977us/step - loss: 1130.4065 - mse: 1130.4065 - mae: 25.7152\n",
      "Epoch 12/80\n",
      "231/231 [==============================] - 0s 825us/step - loss: 1112.2377 - mse: 1112.2377 - mae: 25.3348\n",
      "Epoch 13/80\n",
      "231/231 [==============================] - 0s 855us/step - loss: 1125.6017 - mse: 1125.6017 - mae: 25.3560\n",
      "Epoch 14/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1128.6162 - mse: 1128.6162 - mae: 25.6570\n",
      "Epoch 15/80\n",
      "231/231 [==============================] - 0s 975us/step - loss: 1131.1410 - mse: 1131.1410 - mae: 25.6455\n",
      "Epoch 16/80\n",
      "231/231 [==============================] - 0s 793us/step - loss: 1119.0327 - mse: 1119.0327 - mae: 25.5045\n",
      "Epoch 17/80\n",
      "231/231 [==============================] - 0s 783us/step - loss: 1122.3983 - mse: 1122.3983 - mae: 25.4342\n",
      "Epoch 18/80\n",
      "231/231 [==============================] - 0s 779us/step - loss: 1115.7871 - mse: 1115.7871 - mae: 25.2347\n",
      "Epoch 19/80\n",
      "231/231 [==============================] - 0s 935us/step - loss: 1110.7499 - mse: 1110.7499 - mae: 25.4247\n",
      "Epoch 20/80\n",
      "231/231 [==============================] - 0s 997us/step - loss: 1112.4127 - mse: 1112.4127 - mae: 25.3547\n",
      "Epoch 21/80\n",
      "231/231 [==============================] - 0s 852us/step - loss: 1135.9249 - mse: 1135.9249 - mae: 25.6245\n",
      "Epoch 22/80\n",
      "231/231 [==============================] - 0s 791us/step - loss: 1102.7506 - mse: 1102.7506 - mae: 25.2203\n",
      "Epoch 23/80\n",
      "231/231 [==============================] - 0s 794us/step - loss: 1147.8629 - mse: 1147.8629 - mae: 25.7090\n",
      "Epoch 24/80\n",
      "231/231 [==============================] - 0s 820us/step - loss: 1128.1274 - mse: 1128.1274 - mae: 25.5160\n",
      "Epoch 25/80\n",
      "231/231 [==============================] - 0s 894us/step - loss: 1110.7208 - mse: 1110.7208 - mae: 25.2174\n",
      "Epoch 26/80\n",
      "231/231 [==============================] - 0s 937us/step - loss: 1106.0294 - mse: 1106.0294 - mae: 25.2659\n",
      "Epoch 27/80\n",
      "231/231 [==============================] - 0s 860us/step - loss: 1111.2255 - mse: 1111.2255 - mae: 25.2578\n",
      "Epoch 28/80\n",
      "231/231 [==============================] - 0s 837us/step - loss: 1092.1339 - mse: 1092.1339 - mae: 25.0238\n",
      "Epoch 29/80\n",
      "231/231 [==============================] - 0s 818us/step - loss: 1131.4310 - mse: 1131.4310 - mae: 25.5409\n",
      "Epoch 30/80\n",
      "231/231 [==============================] - 0s 807us/step - loss: 1116.9420 - mse: 1116.9420 - mae: 25.3708\n",
      "Epoch 31/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1098.4369 - mse: 1098.4369 - mae: 25.2123\n",
      "Epoch 32/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1124.7476 - mse: 1124.7476 - mae: 25.6255\n",
      "Epoch 33/80\n",
      "231/231 [==============================] - 0s 896us/step - loss: 1133.2157 - mse: 1133.2157 - mae: 25.6339\n",
      "Epoch 34/80\n",
      "231/231 [==============================] - 0s 861us/step - loss: 1113.7036 - mse: 1113.7036 - mae: 25.3513\n",
      "Epoch 35/80\n",
      "231/231 [==============================] - 0s 927us/step - loss: 1106.8135 - mse: 1106.8135 - mae: 25.3403\n",
      "Epoch 36/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1115.4952 - mse: 1115.4952 - mae: 25.2731\n",
      "Epoch 37/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1135.1384 - mse: 1135.1384 - mae: 25.5529\n",
      "Epoch 38/80\n",
      "231/231 [==============================] - 0s 939us/step - loss: 1092.4456 - mse: 1092.4456 - mae: 25.2296\n",
      "Epoch 39/80\n",
      "231/231 [==============================] - 0s 923us/step - loss: 1129.4187 - mse: 1129.4187 - mae: 25.4667\n",
      "Epoch 40/80\n",
      "231/231 [==============================] - 0s 830us/step - loss: 1128.5873 - mse: 1128.5873 - mae: 25.6853\n",
      "Epoch 41/80\n",
      "231/231 [==============================] - 0s 789us/step - loss: 1096.0317 - mse: 1096.0317 - mae: 25.2362\n",
      "Epoch 42/80\n",
      "231/231 [==============================] - 0s 954us/step - loss: 1129.4844 - mse: 1129.4845 - mae: 25.3919\n",
      "Epoch 43/80\n",
      "231/231 [==============================] - 0s 926us/step - loss: 1113.7671 - mse: 1113.7671 - mae: 25.2190\n",
      "Epoch 44/80\n",
      "231/231 [==============================] - 0s 858us/step - loss: 1113.2966 - mse: 1113.2966 - mae: 25.2509\n",
      "Epoch 45/80\n",
      "231/231 [==============================] - 0s 789us/step - loss: 1105.0581 - mse: 1105.0581 - mae: 25.2707\n",
      "Epoch 46/80\n",
      "231/231 [==============================] - 0s 789us/step - loss: 1107.0225 - mse: 1107.0225 - mae: 25.2794\n",
      "Epoch 47/80\n",
      "231/231 [==============================] - 0s 775us/step - loss: 1082.9546 - mse: 1082.9546 - mae: 25.0802\n",
      "Epoch 48/80\n",
      "231/231 [==============================] - 0s 887us/step - loss: 1114.0450 - mse: 1114.0450 - mae: 25.3669\n",
      "Epoch 49/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1105.1609 - mse: 1105.1609 - mae: 25.2929\n",
      "Epoch 50/80\n",
      "231/231 [==============================] - 0s 845us/step - loss: 1118.9158 - mse: 1118.9158 - mae: 25.5100\n",
      "Epoch 51/80\n",
      "231/231 [==============================] - 0s 793us/step - loss: 1095.4443 - mse: 1095.4443 - mae: 25.1963\n",
      "Epoch 52/80\n",
      "231/231 [==============================] - 0s 769us/step - loss: 1115.2972 - mse: 1115.2972 - mae: 25.4798\n",
      "Epoch 53/80\n",
      "231/231 [==============================] - 0s 794us/step - loss: 1114.8975 - mse: 1114.8975 - mae: 25.3206\n",
      "Epoch 54/80\n",
      "231/231 [==============================] - 0s 971us/step - loss: 1117.1923 - mse: 1117.1923 - mae: 25.3926\n",
      "Epoch 55/80\n",
      "231/231 [==============================] - 0s 909us/step - loss: 1091.3961 - mse: 1091.3961 - mae: 25.0939\n",
      "Epoch 56/80\n",
      "231/231 [==============================] - 0s 806us/step - loss: 1107.6846 - mse: 1107.6846 - mae: 25.2575\n",
      "Epoch 57/80\n",
      "231/231 [==============================] - 0s 768us/step - loss: 1095.5635 - mse: 1095.5635 - mae: 25.1884\n",
      "Epoch 58/80\n",
      "231/231 [==============================] - 0s 853us/step - loss: 1088.9471 - mse: 1088.9471 - mae: 25.1176\n",
      "Epoch 59/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1113.6509 - mse: 1113.6509 - mae: 25.4151\n",
      "Epoch 60/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1118.5687 - mse: 1118.5688 - mae: 25.3910\n",
      "Epoch 61/80\n",
      "231/231 [==============================] - 0s 937us/step - loss: 1086.2600 - mse: 1086.2600 - mae: 25.1476\n",
      "Epoch 62/80\n",
      "231/231 [==============================] - 0s 975us/step - loss: 1099.3881 - mse: 1099.3881 - mae: 25.1881\n",
      "Epoch 63/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1115.0352 - mse: 1115.0352 - mae: 25.2444\n",
      "Epoch 64/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1095.4000 - mse: 1095.4000 - mae: 25.1499\n",
      "Epoch 65/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1093.8989 - mse: 1093.8989 - mae: 25.0772\n",
      "Epoch 66/80\n",
      "231/231 [==============================] - 0s 866us/step - loss: 1095.0170 - mse: 1095.0170 - mae: 25.1220\n",
      "Epoch 67/80\n",
      "231/231 [==============================] - 0s 798us/step - loss: 1120.4487 - mse: 1120.4487 - mae: 25.2959\n",
      "Epoch 68/80\n",
      "231/231 [==============================] - 0s 801us/step - loss: 1109.0176 - mse: 1109.0176 - mae: 25.1518\n",
      "Epoch 69/80\n",
      "231/231 [==============================] - 0s 812us/step - loss: 1092.5050 - mse: 1092.5050 - mae: 25.0985\n",
      "Epoch 70/80\n",
      "231/231 [==============================] - 0s 803us/step - loss: 1102.1189 - mse: 1102.1189 - mae: 25.3282\n",
      "Epoch 71/80\n",
      "231/231 [==============================] - 0s 902us/step - loss: 1096.4816 - mse: 1096.4816 - mae: 25.1182\n",
      "Epoch 72/80\n",
      "231/231 [==============================] - 0s 883us/step - loss: 1101.8549 - mse: 1101.8549 - mae: 25.2171\n",
      "Epoch 73/80\n",
      "231/231 [==============================] - 0s 828us/step - loss: 1107.4723 - mse: 1107.4723 - mae: 25.3423\n",
      "Epoch 74/80\n",
      "231/231 [==============================] - 0s 803us/step - loss: 1102.4131 - mse: 1102.4131 - mae: 25.2381\n",
      "Epoch 75/80\n",
      "231/231 [==============================] - 0s 862us/step - loss: 1108.2740 - mse: 1108.2740 - mae: 25.2277\n",
      "Epoch 76/80\n",
      "231/231 [==============================] - 0s 906us/step - loss: 1124.6954 - mse: 1124.6954 - mae: 25.4607\n",
      "Epoch 77/80\n",
      "231/231 [==============================] - 0s 984us/step - loss: 1112.0699 - mse: 1112.0699 - mae: 25.2963\n",
      "Epoch 78/80\n",
      "231/231 [==============================] - 0s 835us/step - loss: 1099.2338 - mse: 1099.2338 - mae: 25.1852\n",
      "Epoch 79/80\n",
      "231/231 [==============================] - 0s 786us/step - loss: 1096.3260 - mse: 1096.3260 - mae: 25.0523\n",
      "Epoch 80/80\n",
      "231/231 [==============================] - 0s 766us/step - loss: 1083.9807 - mse: 1083.9807 - mae: 25.0287\n",
      "5\n",
      "Epoch 1/80\n",
      "231/231 [==============================] - 0s 791us/step - loss: 6827.6758 - mse: 6827.6758 - mae: 41.4177\n",
      "Epoch 2/80\n",
      "231/231 [==============================] - 0s 802us/step - loss: 6750.3564 - mse: 6750.3569 - mae: 41.8661\n",
      "Epoch 3/80\n",
      "231/231 [==============================] - 0s 971us/step - loss: 6749.3149 - mse: 6749.3149 - mae: 41.4048\n",
      "Epoch 4/80\n",
      "231/231 [==============================] - 0s 905us/step - loss: 6637.7148 - mse: 6637.7148 - mae: 41.0684\n",
      "Epoch 5/80\n",
      "231/231 [==============================] - 0s 788us/step - loss: 6643.4707 - mse: 6643.4707 - mae: 42.0536\n",
      "Epoch 6/80\n",
      "231/231 [==============================] - 0s 803us/step - loss: 6405.1025 - mse: 6405.1025 - mae: 41.5827\n",
      "Epoch 7/80\n",
      "231/231 [==============================] - 0s 778us/step - loss: 6385.1050 - mse: 6385.1050 - mae: 41.3093\n",
      "Epoch 8/80\n",
      "231/231 [==============================] - 0s 920us/step - loss: 6277.6333 - mse: 6277.6333 - mae: 41.3332\n",
      "Epoch 9/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 6219.8052 - mse: 6219.8052 - mae: 40.9264\n",
      "Epoch 10/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 6317.2241 - mse: 6317.2241 - mae: 41.2011\n",
      "Epoch 11/80\n",
      "231/231 [==============================] - 0s 923us/step - loss: 6041.8848 - mse: 6041.8848 - mae: 41.2415\n",
      "Epoch 12/80\n",
      "231/231 [==============================] - 0s 824us/step - loss: 6018.9873 - mse: 6018.9873 - mae: 40.4482\n",
      "Epoch 13/80\n",
      "231/231 [==============================] - 0s 763us/step - loss: 6090.6523 - mse: 6090.6523 - mae: 40.9630\n",
      "Epoch 14/80\n",
      "231/231 [==============================] - 0s 928us/step - loss: 5945.3604 - mse: 5945.3604 - mae: 40.8291\n",
      "Epoch 15/80\n",
      "231/231 [==============================] - 0s 866us/step - loss: 5877.9341 - mse: 5877.9341 - mae: 40.3008\n",
      "Epoch 16/80\n",
      "231/231 [==============================] - 0s 794us/step - loss: 5897.6382 - mse: 5897.6382 - mae: 40.5128\n",
      "Epoch 17/80\n",
      "231/231 [==============================] - 0s 792us/step - loss: 5795.5503 - mse: 5795.5503 - mae: 40.7404\n",
      "Epoch 18/80\n",
      "231/231 [==============================] - 0s 793us/step - loss: 5726.6021 - mse: 5726.6021 - mae: 40.5995\n",
      "Epoch 19/80\n",
      "231/231 [==============================] - 0s 781us/step - loss: 5647.0693 - mse: 5647.0693 - mae: 40.2391\n",
      "Epoch 20/80\n",
      "231/231 [==============================] - 0s 915us/step - loss: 5678.4873 - mse: 5678.4873 - mae: 40.7138\n",
      "Epoch 21/80\n",
      "231/231 [==============================] - 0s 888us/step - loss: 5594.0396 - mse: 5594.0396 - mae: 40.3019\n",
      "Epoch 22/80\n",
      "231/231 [==============================] - 0s 784us/step - loss: 5569.3931 - mse: 5569.3931 - mae: 40.1266\n",
      "Epoch 23/80\n",
      "231/231 [==============================] - 0s 796us/step - loss: 5497.9819 - mse: 5497.9819 - mae: 40.1661\n",
      "Epoch 24/80\n",
      "231/231 [==============================] - 0s 754us/step - loss: 5419.0430 - mse: 5419.0430 - mae: 39.8663\n",
      "Epoch 25/80\n",
      "231/231 [==============================] - 0s 748us/step - loss: 5393.8662 - mse: 5393.8662 - mae: 39.9606\n",
      "Epoch 26/80\n",
      "231/231 [==============================] - 0s 855us/step - loss: 5296.3667 - mse: 5296.3667 - mae: 39.9550\n",
      "Epoch 27/80\n",
      "231/231 [==============================] - 0s 931us/step - loss: 5261.0913 - mse: 5261.0913 - mae: 39.3909\n",
      "Epoch 28/80\n",
      "231/231 [==============================] - 0s 848us/step - loss: 5276.9961 - mse: 5276.9961 - mae: 39.4955\n",
      "Epoch 29/80\n",
      "231/231 [==============================] - 0s 825us/step - loss: 5300.7974 - mse: 5300.7974 - mae: 39.4689\n",
      "Epoch 30/80\n",
      "231/231 [==============================] - 0s 742us/step - loss: 5069.3584 - mse: 5069.3584 - mae: 39.3745\n",
      "Epoch 31/80\n",
      "231/231 [==============================] - 0s 791us/step - loss: 5114.1831 - mse: 5114.1831 - mae: 39.1792\n",
      "Epoch 32/80\n",
      "231/231 [==============================] - 0s 941us/step - loss: 5055.2852 - mse: 5055.2852 - mae: 39.2358\n",
      "Epoch 33/80\n",
      "231/231 [==============================] - 0s 893us/step - loss: 5071.5630 - mse: 5071.5630 - mae: 39.0574\n",
      "Epoch 34/80\n",
      "231/231 [==============================] - 0s 791us/step - loss: 4926.9834 - mse: 4926.9834 - mae: 39.1955\n",
      "Epoch 35/80\n",
      "231/231 [==============================] - 0s 745us/step - loss: 4896.0449 - mse: 4896.0449 - mae: 38.9688\n",
      "Epoch 36/80\n",
      "231/231 [==============================] - 0s 757us/step - loss: 4893.4009 - mse: 4893.4009 - mae: 38.8888\n",
      "Epoch 37/80\n",
      "231/231 [==============================] - 0s 902us/step - loss: 4867.0581 - mse: 4867.0581 - mae: 38.5106\n",
      "Epoch 38/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 4859.9185 - mse: 4859.9185 - mae: 38.5960\n",
      "Epoch 39/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 4730.3994 - mse: 4730.3994 - mae: 38.8498\n",
      "Epoch 40/80\n",
      "231/231 [==============================] - 0s 827us/step - loss: 4644.2070 - mse: 4644.2070 - mae: 38.7170\n",
      "Epoch 41/80\n",
      "231/231 [==============================] - 0s 871us/step - loss: 4634.5288 - mse: 4634.5288 - mae: 37.8365\n",
      "Epoch 42/80\n",
      "231/231 [==============================] - 0s 794us/step - loss: 4605.2666 - mse: 4605.2666 - mae: 37.8381\n",
      "Epoch 43/80\n",
      "231/231 [==============================] - 0s 915us/step - loss: 4630.5605 - mse: 4630.5605 - mae: 38.3138\n",
      "Epoch 44/80\n",
      "231/231 [==============================] - 0s 855us/step - loss: 4444.4756 - mse: 4444.4756 - mae: 38.0408\n",
      "Epoch 45/80\n",
      "231/231 [==============================] - 0s 782us/step - loss: 4408.2578 - mse: 4408.2578 - mae: 37.6933\n",
      "Epoch 46/80\n",
      "231/231 [==============================] - 0s 768us/step - loss: 4463.2817 - mse: 4463.2817 - mae: 38.0784\n",
      "Epoch 47/80\n",
      "231/231 [==============================] - 0s 753us/step - loss: 4427.6538 - mse: 4427.6538 - mae: 37.8212\n",
      "Epoch 48/80\n",
      "231/231 [==============================] - 0s 772us/step - loss: 4448.5645 - mse: 4448.5645 - mae: 37.5525\n",
      "Epoch 49/80\n",
      "231/231 [==============================] - 0s 768us/step - loss: 4403.2983 - mse: 4403.2983 - mae: 37.7494\n",
      "Epoch 50/80\n",
      "231/231 [==============================] - 0s 898us/step - loss: 4378.4756 - mse: 4378.4756 - mae: 37.4236\n",
      "Epoch 51/80\n",
      "231/231 [==============================] - 0s 900us/step - loss: 4349.8013 - mse: 4349.8013 - mae: 37.1397\n",
      "Epoch 52/80\n",
      "231/231 [==============================] - 0s 863us/step - loss: 4349.1548 - mse: 4349.1548 - mae: 37.3397\n",
      "Epoch 53/80\n",
      "231/231 [==============================] - 0s 800us/step - loss: 4309.9810 - mse: 4309.9810 - mae: 37.4091\n",
      "Epoch 54/80\n",
      "231/231 [==============================] - 0s 809us/step - loss: 4317.1030 - mse: 4317.1030 - mae: 37.2435\n",
      "Epoch 55/80\n",
      "231/231 [==============================] - 0s 816us/step - loss: 4275.1948 - mse: 4275.1948 - mae: 37.3777\n",
      "Epoch 56/80\n",
      "231/231 [==============================] - 0s 876us/step - loss: 4263.8525 - mse: 4263.8525 - mae: 36.9968\n",
      "Epoch 57/80\n",
      "231/231 [==============================] - 0s 840us/step - loss: 4311.0903 - mse: 4311.0903 - mae: 37.6422\n",
      "Epoch 58/80\n",
      "231/231 [==============================] - 0s 781us/step - loss: 4198.8877 - mse: 4198.8877 - mae: 37.4494\n",
      "Epoch 59/80\n",
      "231/231 [==============================] - 0s 784us/step - loss: 4168.2842 - mse: 4168.2842 - mae: 36.9948\n",
      "Epoch 60/80\n",
      "231/231 [==============================] - 0s 773us/step - loss: 4199.4443 - mse: 4199.4443 - mae: 36.9137\n",
      "Epoch 61/80\n",
      "231/231 [==============================] - 0s 748us/step - loss: 4338.7007 - mse: 4338.7007 - mae: 37.5178\n",
      "Epoch 62/80\n",
      "231/231 [==============================] - 0s 751us/step - loss: 4199.8945 - mse: 4199.8945 - mae: 37.0825\n",
      "Epoch 63/80\n",
      "231/231 [==============================] - 0s 937us/step - loss: 4302.4150 - mse: 4302.4150 - mae: 37.1207\n",
      "Epoch 64/80\n",
      "231/231 [==============================] - 0s 883us/step - loss: 4185.8477 - mse: 4185.8477 - mae: 36.8612\n",
      "Epoch 65/80\n",
      "231/231 [==============================] - 0s 989us/step - loss: 4072.5293 - mse: 4072.5293 - mae: 36.5656\n",
      "Epoch 66/80\n",
      "231/231 [==============================] - 0s 989us/step - loss: 4145.9829 - mse: 4145.9829 - mae: 37.2075\n",
      "Epoch 67/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 4193.0483 - mse: 4193.0483 - mae: 36.8689\n",
      "Epoch 68/80\n",
      "231/231 [==============================] - 0s 927us/step - loss: 4128.0054 - mse: 4128.0054 - mae: 36.5732\n",
      "Epoch 69/80\n",
      "231/231 [==============================] - 0s 857us/step - loss: 4094.0483 - mse: 4094.0483 - mae: 36.6433\n",
      "Epoch 70/80\n",
      "231/231 [==============================] - 0s 769us/step - loss: 4053.1357 - mse: 4053.1355 - mae: 36.5336\n",
      "Epoch 71/80\n",
      "231/231 [==============================] - 0s 737us/step - loss: 4185.9458 - mse: 4185.9458 - mae: 36.4807\n",
      "Epoch 72/80\n",
      "231/231 [==============================] - 0s 735us/step - loss: 4014.3264 - mse: 4014.3264 - mae: 36.1734\n",
      "Epoch 73/80\n",
      "231/231 [==============================] - 0s 758us/step - loss: 4066.9365 - mse: 4066.9365 - mae: 36.5481\n",
      "Epoch 74/80\n",
      "231/231 [==============================] - 0s 924us/step - loss: 4130.9644 - mse: 4130.9644 - mae: 36.2904\n",
      "Epoch 75/80\n",
      "231/231 [==============================] - 0s 865us/step - loss: 3976.1860 - mse: 3976.1860 - mae: 36.5544\n",
      "Epoch 76/80\n",
      "231/231 [==============================] - 0s 769us/step - loss: 4074.3354 - mse: 4074.3354 - mae: 36.7301\n",
      "Epoch 77/80\n",
      "231/231 [==============================] - 0s 742us/step - loss: 4078.0613 - mse: 4078.0613 - mae: 36.5216\n",
      "Epoch 78/80\n",
      "231/231 [==============================] - 0s 753us/step - loss: 4077.2500 - mse: 4077.2500 - mae: 36.1950 - loss: 5886.9805 - mse: 5886.9805 - mae: 3\n",
      "Epoch 79/80\n",
      "231/231 [==============================] - 0s 826us/step - loss: 4241.0898 - mse: 4241.0898 - mae: 36.2574\n",
      "Epoch 80/80\n",
      "231/231 [==============================] - 0s 963us/step - loss: 3959.9543 - mse: 3959.9543 - mae: 36.0880\n",
      "6\n",
      "Epoch 1/80\n",
      "231/231 [==============================] - 0s 803us/step - loss: 1538.9663 - mse: 1538.9662 - mae: 27.6518\n",
      "Epoch 2/80\n",
      "231/231 [==============================] - 0s 762us/step - loss: 1459.7882 - mse: 1459.7882 - mae: 26.6807\n",
      "Epoch 3/80\n",
      "231/231 [==============================] - 0s 755us/step - loss: 1456.9180 - mse: 1456.9180 - mae: 26.6655\n",
      "Epoch 4/80\n",
      "231/231 [==============================] - 0s 784us/step - loss: 1419.4373 - mse: 1419.4373 - mae: 26.2074\n",
      "Epoch 5/80\n",
      "231/231 [==============================] - 0s 792us/step - loss: 1397.2079 - mse: 1397.2079 - mae: 26.0371\n",
      "Epoch 6/80\n",
      "231/231 [==============================] - 0s 859us/step - loss: 1383.5497 - mse: 1383.5497 - mae: 25.9582\n",
      "Epoch 7/80\n",
      "231/231 [==============================] - 0s 863us/step - loss: 1364.2723 - mse: 1364.2720 - mae: 25.6566\n",
      "Epoch 8/80\n",
      "231/231 [==============================] - 0s 804us/step - loss: 1355.2009 - mse: 1355.2009 - mae: 25.6113\n",
      "Epoch 9/80\n",
      "231/231 [==============================] - 0s 776us/step - loss: 1357.3123 - mse: 1357.3123 - mae: 25.7469\n",
      "Epoch 10/80\n",
      "231/231 [==============================] - 0s 791us/step - loss: 1336.6553 - mse: 1336.6553 - mae: 25.4541\n",
      "Epoch 11/80\n",
      "231/231 [==============================] - 0s 820us/step - loss: 1338.1221 - mse: 1338.1221 - mae: 25.5579\n",
      "Epoch 12/80\n",
      "231/231 [==============================] - 0s 881us/step - loss: 1335.9126 - mse: 1335.9126 - mae: 25.5196\n",
      "Epoch 13/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1345.8167 - mse: 1345.8167 - mae: 25.2447\n",
      "Epoch 14/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1314.7572 - mse: 1314.7572 - mae: 25.2396\n",
      "Epoch 15/80\n",
      "231/231 [==============================] - 0s 964us/step - loss: 1336.4131 - mse: 1336.4131 - mae: 25.4294\n",
      "Epoch 16/80\n",
      "231/231 [==============================] - 0s 761us/step - loss: 1337.5029 - mse: 1337.5029 - mae: 25.4697\n",
      "Epoch 17/80\n",
      "231/231 [==============================] - 0s 755us/step - loss: 1327.7510 - mse: 1327.7510 - mae: 25.2132\n",
      "Epoch 18/80\n",
      "231/231 [==============================] - 0s 846us/step - loss: 1332.4547 - mse: 1332.4547 - mae: 25.3082\n",
      "Epoch 19/80\n",
      "231/231 [==============================] - 0s 861us/step - loss: 1312.2056 - mse: 1312.2056 - mae: 25.1884\n",
      "Epoch 20/80\n",
      "231/231 [==============================] - 0s 833us/step - loss: 1316.5681 - mse: 1316.5681 - mae: 25.1442\n",
      "Epoch 21/80\n",
      "231/231 [==============================] - 0s 796us/step - loss: 1308.0117 - mse: 1308.0117 - mae: 24.9982\n",
      "Epoch 22/80\n",
      "231/231 [==============================] - 0s 755us/step - loss: 1317.7419 - mse: 1317.7419 - mae: 25.1884\n",
      "Epoch 23/80\n",
      "231/231 [==============================] - 0s 920us/step - loss: 1309.4985 - mse: 1309.4985 - mae: 25.0330\n",
      "Epoch 24/80\n",
      "231/231 [==============================] - 0s 898us/step - loss: 1310.4797 - mse: 1310.4797 - mae: 25.0084\n",
      "Epoch 25/80\n",
      "231/231 [==============================] - 0s 889us/step - loss: 1311.5760 - mse: 1311.5760 - mae: 25.1449\n",
      "Epoch 26/80\n",
      "231/231 [==============================] - 0s 802us/step - loss: 1302.8497 - mse: 1302.8497 - mae: 25.0640\n",
      "Epoch 27/80\n",
      "231/231 [==============================] - 0s 796us/step - loss: 1306.4341 - mse: 1306.4341 - mae: 25.0598\n",
      "Epoch 28/80\n",
      "231/231 [==============================] - 0s 785us/step - loss: 1306.4165 - mse: 1306.4165 - mae: 24.9635\n",
      "Epoch 29/80\n",
      "231/231 [==============================] - 0s 736us/step - loss: 1296.2007 - mse: 1296.2006 - mae: 24.8834\n",
      "Epoch 30/80\n",
      "231/231 [==============================] - 0s 842us/step - loss: 1292.4939 - mse: 1292.4939 - mae: 24.7340\n",
      "Epoch 31/80\n",
      "231/231 [==============================] - 0s 924us/step - loss: 1313.6718 - mse: 1313.6718 - mae: 24.8078\n",
      "Epoch 32/80\n",
      "231/231 [==============================] - 0s 806us/step - loss: 1293.9841 - mse: 1293.9841 - mae: 24.8131\n",
      "Epoch 33/80\n",
      "231/231 [==============================] - 0s 778us/step - loss: 1294.3875 - mse: 1294.3875 - mae: 24.7703\n",
      "Epoch 34/80\n",
      "231/231 [==============================] - 0s 749us/step - loss: 1311.7412 - mse: 1311.7412 - mae: 24.9257\n",
      "Epoch 35/80\n",
      "231/231 [==============================] - 0s 768us/step - loss: 1299.5831 - mse: 1299.5831 - mae: 25.0506\n",
      "Epoch 36/80\n",
      "231/231 [==============================] - 0s 946us/step - loss: 1294.2843 - mse: 1294.2843 - mae: 24.8475\n",
      "Epoch 37/80\n",
      "231/231 [==============================] - 0s 852us/step - loss: 1294.2274 - mse: 1294.2274 - mae: 24.8653\n",
      "Epoch 38/80\n",
      "231/231 [==============================] - 0s 777us/step - loss: 1291.7657 - mse: 1291.7657 - mae: 24.8431\n",
      "Epoch 39/80\n",
      "231/231 [==============================] - 0s 771us/step - loss: 1295.3781 - mse: 1295.3781 - mae: 24.7207\n",
      "Epoch 40/80\n",
      "231/231 [==============================] - 0s 732us/step - loss: 1289.0588 - mse: 1289.0588 - mae: 24.8039\n",
      "Epoch 41/80\n",
      "231/231 [==============================] - 0s 846us/step - loss: 1277.1654 - mse: 1277.1654 - mae: 24.5668\n",
      "Epoch 42/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1307.8805 - mse: 1307.8805 - mae: 24.9897\n",
      "Epoch 43/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1288.2208 - mse: 1288.2208 - mae: 24.7921\n",
      "Epoch 44/80\n",
      "231/231 [==============================] - 0s 804us/step - loss: 1293.3600 - mse: 1293.3600 - mae: 24.8679\n",
      "Epoch 45/80\n",
      "231/231 [==============================] - 0s 795us/step - loss: 1283.7772 - mse: 1283.7772 - mae: 24.7978\n",
      "Epoch 46/80\n",
      "231/231 [==============================] - 0s 850us/step - loss: 1282.5485 - mse: 1282.5485 - mae: 24.5534\n",
      "Epoch 47/80\n",
      "231/231 [==============================] - 0s 872us/step - loss: 1290.2346 - mse: 1290.2346 - mae: 24.7919\n",
      "Epoch 48/80\n",
      "231/231 [==============================] - 0s 898us/step - loss: 1270.8104 - mse: 1270.8104 - mae: 24.6922\n",
      "Epoch 49/80\n",
      "231/231 [==============================] - 0s 799us/step - loss: 1290.5048 - mse: 1290.5048 - mae: 24.9601\n",
      "Epoch 50/80\n",
      "231/231 [==============================] - 0s 770us/step - loss: 1276.7921 - mse: 1276.7921 - mae: 24.7582\n",
      "Epoch 51/80\n",
      "231/231 [==============================] - 0s 759us/step - loss: 1288.2863 - mse: 1288.2863 - mae: 24.9065\n",
      "Epoch 52/80\n",
      "231/231 [==============================] - 0s 765us/step - loss: 1271.2150 - mse: 1271.2150 - mae: 24.6741\n",
      "Epoch 53/80\n",
      "231/231 [==============================] - 0s 789us/step - loss: 1295.5680 - mse: 1295.5680 - mae: 24.8222\n",
      "Epoch 54/80\n",
      "231/231 [==============================] - 0s 841us/step - loss: 1255.7886 - mse: 1255.7886 - mae: 24.4381\n",
      "Epoch 55/80\n",
      "231/231 [==============================] - 0s 902us/step - loss: 1269.6886 - mse: 1269.6886 - mae: 24.5484\n",
      "Epoch 56/80\n",
      "231/231 [==============================] - 0s 793us/step - loss: 1285.8258 - mse: 1285.8258 - mae: 24.9025\n",
      "Epoch 57/80\n",
      "231/231 [==============================] - 0s 779us/step - loss: 1290.3872 - mse: 1290.3872 - mae: 24.8211\n",
      "Epoch 58/80\n",
      "231/231 [==============================] - 0s 749us/step - loss: 1290.9724 - mse: 1290.9724 - mae: 24.8564\n",
      "Epoch 59/80\n",
      "231/231 [==============================] - 0s 816us/step - loss: 1284.6783 - mse: 1284.6783 - mae: 24.4767\n",
      "Epoch 60/80\n",
      "231/231 [==============================] - 0s 863us/step - loss: 1278.8735 - mse: 1278.8735 - mae: 24.5965\n",
      "Epoch 61/80\n",
      "231/231 [==============================] - 0s 847us/step - loss: 1278.5720 - mse: 1278.5720 - mae: 24.8644\n",
      "Epoch 62/80\n",
      "231/231 [==============================] - 0s 802us/step - loss: 1278.3270 - mse: 1278.3270 - mae: 24.5446\n",
      "Epoch 63/80\n",
      "231/231 [==============================] - 0s 780us/step - loss: 1299.3159 - mse: 1299.3159 - mae: 25.0511\n",
      "Epoch 64/80\n",
      "231/231 [==============================] - 0s 803us/step - loss: 1290.5115 - mse: 1290.5115 - mae: 24.7813\n",
      "Epoch 65/80\n",
      "231/231 [==============================] - 0s 745us/step - loss: 1297.3086 - mse: 1297.3086 - mae: 24.8331\n",
      "Epoch 66/80\n",
      "231/231 [==============================] - 0s 777us/step - loss: 1282.6925 - mse: 1282.6925 - mae: 24.6032\n",
      "Epoch 67/80\n",
      "231/231 [==============================] - 0s 868us/step - loss: 1276.9659 - mse: 1276.9659 - mae: 24.6872\n",
      "Epoch 68/80\n",
      "231/231 [==============================] - 0s 855us/step - loss: 1282.3564 - mse: 1282.3564 - mae: 24.7984\n",
      "Epoch 69/80\n",
      "231/231 [==============================] - 0s 874us/step - loss: 1281.8369 - mse: 1281.8369 - mae: 24.6358\n",
      "Epoch 70/80\n",
      "231/231 [==============================] - 0s 967us/step - loss: 1271.6310 - mse: 1271.6307 - mae: 24.6185\n",
      "Epoch 71/80\n",
      "231/231 [==============================] - 0s 1ms/step - loss: 1272.0642 - mse: 1272.0642 - mae: 24.5080\n",
      "Epoch 72/80\n",
      "231/231 [==============================] - 0s 971us/step - loss: 1271.2893 - mse: 1271.2893 - mae: 24.5557\n",
      "Epoch 73/80\n",
      "231/231 [==============================] - 0s 843us/step - loss: 1271.0463 - mse: 1271.0463 - mae: 24.6232\n",
      "Epoch 74/80\n",
      "231/231 [==============================] - 0s 798us/step - loss: 1296.4200 - mse: 1296.4200 - mae: 24.7128\n",
      "Epoch 75/80\n",
      "231/231 [==============================] - 0s 767us/step - loss: 1284.9393 - mse: 1284.9393 - mae: 24.7236\n",
      "Epoch 76/80\n",
      "231/231 [==============================] - 0s 745us/step - loss: 1280.1583 - mse: 1280.1583 - mae: 24.6614\n",
      "Epoch 77/80\n",
      "231/231 [==============================] - 0s 740us/step - loss: 1276.0308 - mse: 1276.0308 - mae: 24.6776\n",
      "Epoch 78/80\n",
      "231/231 [==============================] - 0s 859us/step - loss: 1295.6788 - mse: 1295.6788 - mae: 24.7578\n",
      "Epoch 79/80\n",
      "231/231 [==============================] - 0s 938us/step - loss: 1272.7876 - mse: 1272.7876 - mae: 24.6241\n",
      "Epoch 80/80\n",
      "231/231 [==============================] - 0s 794us/step - loss: 1268.2802 - mse: 1268.2802 - mae: 24.5351\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "# data\n",
    "data = pd.read_csv('Data_set_1_smaller.csv', index_col = 0)\n",
    "\n",
    "# COMPLETE\n",
    "data = data.loc[data.index > 2017000000, :]\n",
    "    \n",
    "# reset index\n",
    "data.reset_index(inplace = True)\n",
    "data.drop('index', axis = 1, inplace = True)\n",
    "    \n",
    "# Divide features and labels\n",
    "X = data.iloc[:, 0:15]\n",
    "y = data.loc[:, 'Offers']\n",
    "\n",
    "X.fillna(X.mean(), inplace = True)\n",
    "y.fillna(y.mean(), inplace = True)\n",
    "    \n",
    "X = X.astype('float64')\n",
    "X = X.round(20)\n",
    "    \n",
    "# divide data into train and test with 20% test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "             X, y, test_size=0.2, shuffle=False)\n",
    "    \n",
    "# feature scaling\n",
    "sc_X = MinMaxScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)\n",
    "    \n",
    "import keras\n",
    "from keras.models import Sequential # to initialise the NN\n",
    "from keras.layers import Dense # to create layers\n",
    "from keras.layers import Dropout\n",
    "from keras import initializers\n",
    "from keras import optimizers\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "    \n",
    "# possible debug\n",
    "X_train = np.nan_to_num(X_train)\n",
    "X_test = np.nan_to_num(X_test)\n",
    "    \n",
    "def regressor_tunning(n_hidden = 2, \n",
    "                      n_neurons = 30,  \n",
    "                      kernel_initializer = \"he_normal\",\n",
    "                      bias_initializer = initializers.Ones()):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = n_neurons, input_dim = 15))        \n",
    "    model.add(keras.layers.LeakyReLU(alpha = 0.2))\n",
    "    model.add(Dropout(rate = 0.1))        \n",
    "    for layer in range(n_hidden):\n",
    "        model.add(Dense(n_neurons))\n",
    "        model.add(keras.layers.LeakyReLU(alpha = 0.2))\n",
    "        model.add(Dropout(rate = 0.1))\n",
    "    model.add(Dense(units = 1, activation = 'linear'))\n",
    "    optimizer = optimizers.Adamax(lr = 0.001)\n",
    "    model.compile(loss = 'mse', optimizer = optimizer, metrics = ['mse', 'mae'])\n",
    "    return model\n",
    "\n",
    "# 48*30*3*0.8 = 3456\n",
    "tscv = TimeSeriesSplit(n_splits = 7, max_train_size = 3456)\n",
    "\n",
    "hist_list = pd.DataFrame()\n",
    "count = 1\n",
    "    \n",
    "regressor = regressor_tunning()\n",
    "    \n",
    "for train_index, test_index in tscv.split(X_train):\n",
    "    X_train_split, X_test_split = X_train[train_index], X_train[test_index]\n",
    "    y_train_split, y_test_split = y_train[train_index], y_train[test_index]\n",
    "    hist = regressor.fit(X_train_split, y_train_split, batch_size = 15, epochs = 80)\n",
    "    hist_list = hist_list.append(hist.history, ignore_index = True)\n",
    "    print(count)\n",
    "    count = count + 1\n",
    "\n",
    "a = []\n",
    "b = []\n",
    "\n",
    "for i in range(len(hist_list.mse)):\n",
    "    a.append(np.mean(hist_list.mse[i]))\n",
    "    b.append(np.mean(hist_list.mae[i]))\n",
    "\n",
    "mse_cv.append(np.mean(a))\n",
    "mae_cv.append(np.mean(b))\n",
    "\n",
    "# predict for X_test  \n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "\n",
    "rmse_error = mse(y_test, y_pred, squared = False)\n",
    "mse_error = mse(y_test, y_pred) # 1479.61335\n",
    "mae_error = mae(y_test, y_pred) # 23.1525\n",
    "\n",
    "rmse_gen.append(rmse_error)\n",
    "mse_gen.append(mse_error)\n",
    "mae_gen.append(mae_error)\n",
    "\n",
    "# =============================================================================\n",
    "# Metrics evaluation on spike regions\n",
    "# =============================================================================\n",
    "\n",
    "y_spike_occ = pd.read_csv('Spike_binary_1std.csv', usecols = [6])\n",
    "\n",
    "# create array same size as y_test\n",
    "y_spike_occ = y_spike_occ.iloc[- len(y_test):]\n",
    "y_spike_occ = pd.Series(y_spike_occ.iloc[:,0]).values\n",
    "\n",
    "\n",
    "# smal adjustment\n",
    "y_test.replace(0, 0.0001,inplace = True)\n",
    "\n",
    "\n",
    "# select y_pred and y_test only for regions with spikes\n",
    "y_test_spike = (y_test.T * y_spike_occ).T\n",
    "y_pred_spike = (y_pred.T * y_spike_occ).T\n",
    "y_test_spike = y_test_spike[y_test_spike != 0]\n",
    "y_pred_spike = y_pred_spike[y_pred_spike != 0]\n",
    "\n",
    "# calculate metric\n",
    "rmse_spike = mse(y_test_spike, y_pred_spike, squared = False)\n",
    "mse_spike = mse(y_test_spike, y_pred_spike)\n",
    "mae_spike = mae(y_test_spike, y_pred_spike)\n",
    "\n",
    "rmse_spi.append(rmse_spike)\n",
    "mse_spi.append(mse_spike)\n",
    "mae_spi.append(mae_spike)\n",
    "\n",
    "# =============================================================================\n",
    "# Metric evaluation on normal regions\n",
    "# =============================================================================\n",
    "\n",
    "# inverse y_spike_occ so the only normal occurences are chosen\n",
    "y_normal_occ = (y_spike_occ - 1) * (-1)\n",
    "\n",
    "# sanity check\n",
    "y_normal_occ.sum() + y_spike_occ.sum() # gives the correct total \n",
    "\n",
    "# select y_pred and y_test only for normal regions\n",
    "y_test_normal = (y_test.T * y_normal_occ).T\n",
    "y_pred_normal = (y_pred.T * y_normal_occ).T\n",
    "y_test_normal = y_test_normal[y_test_normal != 0.00]\n",
    "y_pred_normal = y_pred_normal[y_pred_normal != 0.00]\n",
    "\n",
    "# calculate metric\n",
    "rmse_normal = mse(y_test_normal, y_pred_normal, squared = False)\n",
    "mse_normal = mse(y_test_normal, y_pred_normal)\n",
    "mae_normal = mae(y_test_normal, y_pred_normal)\n",
    "\n",
    "rmse_nor.append(rmse_normal)\n",
    "mse_nor.append(mse_normal)\n",
    "mae_nor.append(mae_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse_cv</th>\n",
       "      <th>mae_cv</th>\n",
       "      <th>rmse_general</th>\n",
       "      <th>mae_general</th>\n",
       "      <th>rmse_spike</th>\n",
       "      <th>mae_spike</th>\n",
       "      <th>rmse_normal</th>\n",
       "      <th>mae_normal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51.426324</td>\n",
       "      <td>29.554428</td>\n",
       "      <td>45.943478</td>\n",
       "      <td>24.16925</td>\n",
       "      <td>95.228273</td>\n",
       "      <td>60.172302</td>\n",
       "      <td>20.690682</td>\n",
       "      <td>15.461921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     rmse_cv     mae_cv  rmse_general  mae_general  rmse_spike  mae_spike  \\\n",
       "0  51.426324  29.554428     45.943478     24.16925   95.228273  60.172302   \n",
       "\n",
       "   rmse_normal  mae_normal  \n",
       "0    20.690682   15.461921  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_cv = []\n",
    "for i in mse_cv:\n",
    "    rmse_cv.append(i ** 0.5)\n",
    "    \n",
    "results = pd.DataFrame({'rmse_cv':rmse_cv,\n",
    "              \n",
    "                        'mae_cv': mae_cv,\n",
    "                        \n",
    "                        'rmse_general': rmse_gen, \n",
    "                 \n",
    "                        'mae_general': mae_gen,\n",
    "                        \n",
    "                        'rmse_spike': rmse_spi,\n",
    "                 \n",
    "                        'mae_spike': mae_spi,\n",
    "                        \n",
    "                        'rmse_normal': rmse_nor,\n",
    "                    \n",
    "                        'mae_normal': mae_nor})\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results for 3 months data set only (with Nested CV):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:6245: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "40/40 [==============================] - 0s 812us/step - loss: 17680.5566 - mse: 17680.5566 - mae: 114.4199\n",
      "Epoch 2/80\n",
      "40/40 [==============================] - 0s 748us/step - loss: 17281.0098 - mse: 17281.0098 - mae: 112.6702\n",
      "Epoch 3/80\n",
      "40/40 [==============================] - 0s 698us/step - loss: 16593.3027 - mse: 16593.3027 - mae: 109.6024\n",
      "Epoch 4/80\n",
      "40/40 [==============================] - 0s 798us/step - loss: 15306.7646 - mse: 15306.7646 - mae: 103.5658\n",
      "Epoch 5/80\n",
      "40/40 [==============================] - 0s 773us/step - loss: 13517.5146 - mse: 13517.5146 - mae: 94.4721\n",
      "Epoch 6/80\n",
      "40/40 [==============================] - 0s 723us/step - loss: 11254.7021 - mse: 11254.7021 - mae: 81.4893\n",
      "Epoch 7/80\n",
      "40/40 [==============================] - 0s 723us/step - loss: 8916.2900 - mse: 8916.2900 - mae: 65.7561\n",
      "Epoch 8/80\n",
      "40/40 [==============================] - 0s 726us/step - loss: 7262.1445 - mse: 7262.1445 - mae: 51.0009\n",
      "Epoch 9/80\n",
      "40/40 [==============================] - 0s 773us/step - loss: 6123.2861 - mse: 6123.2861 - mae: 38.5596\n",
      "Epoch 10/80\n",
      "40/40 [==============================] - 0s 759us/step - loss: 5175.3091 - mse: 5175.3091 - mae: 30.7371\n",
      "Epoch 11/80\n",
      "40/40 [==============================] - 0s 744us/step - loss: 4683.3413 - mse: 4683.3413 - mae: 26.8888\n",
      "Epoch 12/80\n",
      "40/40 [==============================] - 0s 748us/step - loss: 5021.0913 - mse: 5021.0913 - mae: 28.0410\n",
      "Epoch 13/80\n",
      "40/40 [==============================] - 0s 752us/step - loss: 4753.1152 - mse: 4753.1152 - mae: 28.6398\n",
      "Epoch 14/80\n",
      "40/40 [==============================] - 0s 773us/step - loss: 4781.3096 - mse: 4781.3096 - mae: 27.5588\n",
      "Epoch 15/80\n",
      "40/40 [==============================] - 0s 723us/step - loss: 4804.5273 - mse: 4804.5273 - mae: 28.0176\n",
      "Epoch 16/80\n",
      "40/40 [==============================] - 0s 698us/step - loss: 4860.5684 - mse: 4860.5684 - mae: 28.9434\n",
      "Epoch 17/80\n",
      "40/40 [==============================] - 0s 698us/step - loss: 4852.6279 - mse: 4852.6279 - mae: 27.7787\n",
      "Epoch 18/80\n",
      "40/40 [==============================] - 0s 698us/step - loss: 4809.3687 - mse: 4809.3687 - mae: 29.5607\n",
      "Epoch 19/80\n",
      "40/40 [==============================] - 0s 723us/step - loss: 4834.5918 - mse: 4834.5918 - mae: 28.8176\n",
      "Epoch 20/80\n",
      "40/40 [==============================] - 0s 723us/step - loss: 4846.5713 - mse: 4846.5713 - mae: 28.2641\n",
      "Epoch 21/80\n",
      "40/40 [==============================] - 0s 748us/step - loss: 4908.2153 - mse: 4908.2158 - mae: 28.5122\n",
      "Epoch 22/80\n",
      "40/40 [==============================] - 0s 772us/step - loss: 4823.9790 - mse: 4823.9790 - mae: 28.3073\n",
      "Epoch 23/80\n",
      "40/40 [==============================] - 0s 723us/step - loss: 4738.6455 - mse: 4738.6455 - mae: 28.6489\n",
      "Epoch 24/80\n",
      "40/40 [==============================] - 0s 698us/step - loss: 4762.6074 - mse: 4762.6074 - mae: 28.4595\n",
      "Epoch 25/80\n",
      "40/40 [==============================] - 0s 698us/step - loss: 4790.8687 - mse: 4790.8687 - mae: 27.2831\n",
      "Epoch 26/80\n",
      "40/40 [==============================] - 0s 698us/step - loss: 4737.5142 - mse: 4737.5142 - mae: 28.6442\n",
      "Epoch 27/80\n",
      "40/40 [==============================] - 0s 723us/step - loss: 4726.7832 - mse: 4726.7832 - mae: 28.7595\n",
      "Epoch 28/80\n",
      "40/40 [==============================] - 0s 775us/step - loss: 4652.4282 - mse: 4652.4282 - mae: 28.1956\n",
      "Epoch 29/80\n",
      "40/40 [==============================] - 0s 873us/step - loss: 4836.9956 - mse: 4836.9956 - mae: 29.6661\n",
      "Epoch 30/80\n",
      "40/40 [==============================] - 0s 723us/step - loss: 4939.8511 - mse: 4939.8511 - mae: 28.7725\n",
      "Epoch 31/80\n",
      "40/40 [==============================] - 0s 723us/step - loss: 4825.2686 - mse: 4825.2686 - mae: 28.8913\n",
      "Epoch 32/80\n",
      "40/40 [==============================] - 0s 754us/step - loss: 4862.5732 - mse: 4862.5732 - mae: 27.7187\n",
      "Epoch 33/80\n",
      "40/40 [==============================] - 0s 773us/step - loss: 4950.2637 - mse: 4950.2637 - mae: 28.5857\n",
      "Epoch 34/80\n",
      "40/40 [==============================] - 0s 798us/step - loss: 4773.9160 - mse: 4773.9160 - mae: 27.6630\n",
      "Epoch 35/80\n",
      "40/40 [==============================] - 0s 798us/step - loss: 4750.7378 - mse: 4750.7378 - mae: 29.0127\n",
      "Epoch 36/80\n",
      "40/40 [==============================] - 0s 898us/step - loss: 4816.0469 - mse: 4816.0469 - mae: 28.0860\n",
      "Epoch 37/80\n",
      "40/40 [==============================] - 0s 947us/step - loss: 4923.7104 - mse: 4923.7104 - mae: 29.0527\n",
      "Epoch 38/80\n",
      "40/40 [==============================] - 0s 823us/step - loss: 4888.6279 - mse: 4888.6279 - mae: 29.2712\n",
      "Epoch 39/80\n",
      "40/40 [==============================] - 0s 823us/step - loss: 4743.9072 - mse: 4743.9072 - mae: 27.9843\n",
      "Epoch 40/80\n",
      "40/40 [==============================] - 0s 798us/step - loss: 4760.1685 - mse: 4760.1685 - mae: 28.3392\n",
      "Epoch 41/80\n",
      "40/40 [==============================] - 0s 798us/step - loss: 4628.2720 - mse: 4628.2720 - mae: 27.4955\n",
      "Epoch 42/80\n",
      "40/40 [==============================] - 0s 764us/step - loss: 4634.2866 - mse: 4634.2866 - mae: 28.1096\n",
      "Epoch 43/80\n",
      "40/40 [==============================] - 0s 834us/step - loss: 4671.7036 - mse: 4671.7036 - mae: 28.6414\n",
      "Epoch 44/80\n",
      "40/40 [==============================] - 0s 789us/step - loss: 4879.6660 - mse: 4879.6660 - mae: 29.0385\n",
      "Epoch 45/80\n",
      "40/40 [==============================] - 0s 773us/step - loss: 4688.6030 - mse: 4688.6030 - mae: 27.5723\n",
      "Epoch 46/80\n",
      "40/40 [==============================] - 0s 748us/step - loss: 4860.3257 - mse: 4860.3257 - mae: 28.1944\n",
      "Epoch 47/80\n",
      "40/40 [==============================] - 0s 698us/step - loss: 4678.0278 - mse: 4678.0278 - mae: 28.4793\n",
      "Epoch 48/80\n",
      "40/40 [==============================] - 0s 723us/step - loss: 4682.3423 - mse: 4682.3423 - mae: 28.3465\n",
      "Epoch 49/80\n",
      "40/40 [==============================] - 0s 748us/step - loss: 4733.9648 - mse: 4733.9648 - mae: 28.3181\n",
      "Epoch 50/80\n",
      "40/40 [==============================] - 0s 742us/step - loss: 4747.3911 - mse: 4747.3911 - mae: 28.0545\n",
      "Epoch 51/80\n",
      "40/40 [==============================] - 0s 806us/step - loss: 4694.3638 - mse: 4694.3638 - mae: 28.4744\n",
      "Epoch 52/80\n",
      "40/40 [==============================] - 0s 737us/step - loss: 4656.8032 - mse: 4656.8032 - mae: 29.0901\n",
      "Epoch 53/80\n",
      "40/40 [==============================] - 0s 734us/step - loss: 4727.5586 - mse: 4727.5586 - mae: 28.7957\n",
      "Epoch 54/80\n",
      "40/40 [==============================] - 0s 752us/step - loss: 4870.2124 - mse: 4870.2124 - mae: 27.9443\n",
      "Epoch 55/80\n",
      "40/40 [==============================] - 0s 698us/step - loss: 4802.9551 - mse: 4802.9551 - mae: 28.0760\n",
      "Epoch 56/80\n",
      "40/40 [==============================] - 0s 714us/step - loss: 4777.2358 - mse: 4777.2358 - mae: 28.5485\n",
      "Epoch 57/80\n",
      "40/40 [==============================] - 0s 810us/step - loss: 4765.0049 - mse: 4765.0049 - mae: 29.1339\n",
      "Epoch 58/80\n",
      "40/40 [==============================] - 0s 708us/step - loss: 4726.7749 - mse: 4726.7749 - mae: 27.8873\n",
      "Epoch 59/80\n",
      "40/40 [==============================] - 0s 748us/step - loss: 4615.1069 - mse: 4615.1069 - mae: 28.4222\n",
      "Epoch 60/80\n",
      "40/40 [==============================] - 0s 748us/step - loss: 4795.2319 - mse: 4795.2319 - mae: 28.7242\n",
      "Epoch 61/80\n",
      "40/40 [==============================] - 0s 773us/step - loss: 4856.9414 - mse: 4856.9414 - mae: 28.6169\n",
      "Epoch 62/80\n",
      "40/40 [==============================] - 0s 773us/step - loss: 4617.9956 - mse: 4617.9956 - mae: 27.2549\n",
      "Epoch 63/80\n",
      "40/40 [==============================] - 0s 823us/step - loss: 4630.6406 - mse: 4630.6406 - mae: 28.4323\n",
      "Epoch 64/80\n",
      "40/40 [==============================] - 0s 798us/step - loss: 4922.7373 - mse: 4922.7373 - mae: 28.9322\n",
      "Epoch 65/80\n",
      "40/40 [==============================] - 0s 873us/step - loss: 5001.2212 - mse: 5001.2212 - mae: 28.7859\n",
      "Epoch 66/80\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 4848.9507 - mse: 4848.9507 - mae: 28.3020\n",
      "Epoch 67/80\n",
      "40/40 [==============================] - 0s 873us/step - loss: 4933.2461 - mse: 4933.2456 - mae: 27.5490\n",
      "Epoch 68/80\n",
      "40/40 [==============================] - 0s 823us/step - loss: 4583.0537 - mse: 4583.0537 - mae: 27.4891\n",
      "Epoch 69/80\n",
      "40/40 [==============================] - 0s 972us/step - loss: 4850.1377 - mse: 4850.1377 - mae: 28.4132\n",
      "Epoch 70/80\n",
      "40/40 [==============================] - 0s 848us/step - loss: 4624.7383 - mse: 4624.7383 - mae: 28.4921\n",
      "Epoch 71/80\n",
      "40/40 [==============================] - 0s 831us/step - loss: 4654.5176 - mse: 4654.5176 - mae: 28.0016\n",
      "Epoch 72/80\n",
      "40/40 [==============================] - 0s 972us/step - loss: 4642.2358 - mse: 4642.2358 - mae: 28.5244\n",
      "Epoch 73/80\n",
      "40/40 [==============================] - 0s 923us/step - loss: 4879.2954 - mse: 4879.2954 - mae: 28.3497\n",
      "Epoch 74/80\n",
      "40/40 [==============================] - 0s 898us/step - loss: 4633.3462 - mse: 4633.3462 - mae: 27.9096\n",
      "Epoch 75/80\n",
      "40/40 [==============================] - 0s 972us/step - loss: 4620.8613 - mse: 4620.8613 - mae: 27.8421\n",
      "Epoch 76/80\n",
      "40/40 [==============================] - 0s 898us/step - loss: 4799.3149 - mse: 4799.3149 - mae: 27.7249\n",
      "Epoch 77/80\n",
      "40/40 [==============================] - 0s 898us/step - loss: 4804.2690 - mse: 4804.2690 - mae: 28.8955\n",
      "Epoch 78/80\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 4762.3433 - mse: 4762.3433 - mae: 27.8062\n",
      "Epoch 79/80\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 4785.9033 - mse: 4785.9033 - mae: 28.3428\n",
      "Epoch 80/80\n",
      "40/40 [==============================] - 0s 923us/step - loss: 4771.0635 - mse: 4771.0635 - mae: 28.4197\n",
      "1\n",
      "Epoch 1/80\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 3559.3645 - mse: 3559.3645 - mae: 30.9836\n",
      "Epoch 2/80\n",
      "79/79 [==============================] - 0s 781us/step - loss: 3460.1060 - mse: 3460.1060 - mae: 30.5023\n",
      "Epoch 3/80\n",
      "79/79 [==============================] - 0s 795us/step - loss: 3423.4575 - mse: 3423.4575 - mae: 30.9263\n",
      "Epoch 4/80\n",
      "79/79 [==============================] - 0s 732us/step - loss: 3629.4958 - mse: 3629.4958 - mae: 32.3132\n",
      "Epoch 5/80\n",
      "79/79 [==============================] - 0s 750us/step - loss: 3540.2771 - mse: 3540.2771 - mae: 31.3961\n",
      "Epoch 6/80\n",
      "79/79 [==============================] - 0s 768us/step - loss: 3491.5791 - mse: 3491.5791 - mae: 30.8806\n",
      "Epoch 7/80\n",
      "79/79 [==============================] - 0s 846us/step - loss: 3474.5747 - mse: 3474.5747 - mae: 30.5114\n",
      "Epoch 8/80\n",
      "79/79 [==============================] - 0s 758us/step - loss: 3514.0715 - mse: 3514.0715 - mae: 31.3166\n",
      "Epoch 9/80\n",
      "79/79 [==============================] - 0s 808us/step - loss: 3471.3491 - mse: 3471.3491 - mae: 31.0606\n",
      "Epoch 10/80\n",
      "79/79 [==============================] - 0s 808us/step - loss: 3557.9375 - mse: 3557.9375 - mae: 31.4152\n",
      "Epoch 11/80\n",
      "79/79 [==============================] - 0s 858us/step - loss: 3496.9448 - mse: 3496.9448 - mae: 30.9663\n",
      "Epoch 12/80\n",
      "79/79 [==============================] - 0s 922us/step - loss: 3619.3542 - mse: 3619.3542 - mae: 31.3181\n",
      "Epoch 13/80\n",
      "79/79 [==============================] - 0s 846us/step - loss: 3551.2222 - mse: 3551.2222 - mae: 30.6975\n",
      "Epoch 14/80\n",
      "79/79 [==============================] - 0s 931us/step - loss: 3562.7039 - mse: 3562.7039 - mae: 30.6524\n",
      "Epoch 15/80\n",
      "79/79 [==============================] - 0s 903us/step - loss: 3476.4829 - mse: 3476.4829 - mae: 30.9394\n",
      "Epoch 16/80\n",
      "79/79 [==============================] - 0s 819us/step - loss: 3475.8647 - mse: 3475.8647 - mae: 30.7229\n",
      "Epoch 17/80\n",
      "79/79 [==============================] - 0s 756us/step - loss: 3468.8501 - mse: 3468.8501 - mae: 30.8284\n",
      "Epoch 18/80\n",
      "79/79 [==============================] - 0s 757us/step - loss: 3496.9949 - mse: 3496.9949 - mae: 30.8744\n",
      "Epoch 19/80\n",
      "79/79 [==============================] - 0s 757us/step - loss: 3443.1067 - mse: 3443.1067 - mae: 31.2742\n",
      "Epoch 20/80\n",
      "79/79 [==============================] - 0s 740us/step - loss: 3559.6509 - mse: 3559.6509 - mae: 31.3169\n",
      "Epoch 21/80\n",
      "79/79 [==============================] - 0s 749us/step - loss: 3547.7014 - mse: 3547.7009 - mae: 31.6045\n",
      "Epoch 22/80\n",
      "79/79 [==============================] - 0s 780us/step - loss: 3493.7910 - mse: 3493.7910 - mae: 30.8776\n",
      "Epoch 23/80\n",
      "79/79 [==============================] - 0s 808us/step - loss: 3565.7502 - mse: 3565.7502 - mae: 31.2797\n",
      "Epoch 24/80\n",
      "79/79 [==============================] - 0s 846us/step - loss: 3509.2256 - mse: 3509.2256 - mae: 31.1602\n",
      "Epoch 25/80\n",
      "79/79 [==============================] - 0s 846us/step - loss: 3480.5798 - mse: 3480.5798 - mae: 30.6761\n",
      "Epoch 26/80\n",
      "79/79 [==============================] - 0s 833us/step - loss: 3478.1182 - mse: 3478.1182 - mae: 30.7853\n",
      "Epoch 27/80\n",
      "79/79 [==============================] - 0s 846us/step - loss: 3452.6907 - mse: 3452.6907 - mae: 30.5529\n",
      "Epoch 28/80\n",
      "79/79 [==============================] - 0s 808us/step - loss: 3552.3320 - mse: 3552.3320 - mae: 31.6257\n",
      "Epoch 29/80\n",
      "79/79 [==============================] - 0s 808us/step - loss: 3469.4370 - mse: 3469.4370 - mae: 30.6606\n",
      "Epoch 30/80\n",
      "79/79 [==============================] - 0s 793us/step - loss: 3476.1731 - mse: 3476.1731 - mae: 30.9076\n",
      "Epoch 31/80\n",
      "79/79 [==============================] - 0s 790us/step - loss: 3464.6616 - mse: 3464.6616 - mae: 30.4749\n",
      "Epoch 32/80\n",
      "79/79 [==============================] - 0s 751us/step - loss: 3461.4536 - mse: 3461.4536 - mae: 31.0673\n",
      "Epoch 33/80\n",
      "79/79 [==============================] - 0s 707us/step - loss: 3455.2097 - mse: 3455.2097 - mae: 30.7146\n",
      "Epoch 34/80\n",
      "79/79 [==============================] - 0s 808us/step - loss: 3441.5786 - mse: 3441.5786 - mae: 30.5270\n",
      "Epoch 35/80\n",
      "79/79 [==============================] - 0s 720us/step - loss: 3489.8926 - mse: 3489.8926 - mae: 30.6161\n",
      "Epoch 36/80\n",
      "79/79 [==============================] - 0s 732us/step - loss: 3436.6565 - mse: 3436.6565 - mae: 30.7420\n",
      "Epoch 37/80\n",
      "79/79 [==============================] - 0s 741us/step - loss: 3483.9219 - mse: 3483.9219 - mae: 31.3209\n",
      "Epoch 38/80\n",
      "79/79 [==============================] - 0s 795us/step - loss: 3436.0906 - mse: 3436.0906 - mae: 30.6152\n",
      "Epoch 39/80\n",
      "79/79 [==============================] - 0s 786us/step - loss: 3420.6406 - mse: 3420.6406 - mae: 30.7004\n",
      "Epoch 40/80\n",
      "79/79 [==============================] - 0s 745us/step - loss: 3402.1848 - mse: 3402.1848 - mae: 30.8045\n",
      "Epoch 41/80\n",
      "79/79 [==============================] - 0s 737us/step - loss: 3513.3398 - mse: 3513.3398 - mae: 31.2562\n",
      "Epoch 42/80\n",
      "79/79 [==============================] - 0s 732us/step - loss: 3392.0862 - mse: 3392.0862 - mae: 29.9281\n",
      "Epoch 43/80\n",
      "79/79 [==============================] - 0s 720us/step - loss: 3377.1497 - mse: 3377.1497 - mae: 30.4228\n",
      "Epoch 44/80\n",
      "79/79 [==============================] - 0s 757us/step - loss: 3465.8604 - mse: 3465.8604 - mae: 30.9298\n",
      "Epoch 45/80\n",
      "79/79 [==============================] - 0s 884us/step - loss: 3425.2644 - mse: 3425.2644 - mae: 30.0674\n",
      "Epoch 46/80\n",
      "79/79 [==============================] - 0s 896us/step - loss: 3547.2478 - mse: 3547.2478 - mae: 30.7156\n",
      "Epoch 47/80\n",
      "79/79 [==============================] - 0s 884us/step - loss: 3418.8140 - mse: 3418.8140 - mae: 30.6048\n",
      "Epoch 48/80\n",
      "79/79 [==============================] - 0s 871us/step - loss: 3478.1714 - mse: 3478.1714 - mae: 30.3297\n",
      "Epoch 49/80\n",
      "79/79 [==============================] - 0s 805us/step - loss: 3453.3972 - mse: 3453.3972 - mae: 30.3812\n",
      "Epoch 50/80\n",
      "79/79 [==============================] - 0s 808us/step - loss: 3525.0835 - mse: 3525.0835 - mae: 31.0656\n",
      "Epoch 51/80\n",
      "79/79 [==============================] - 0s 770us/step - loss: 3538.1824 - mse: 3538.1824 - mae: 30.4775\n",
      "Epoch 52/80\n",
      "79/79 [==============================] - 0s 762us/step - loss: 3392.7070 - mse: 3392.7070 - mae: 31.0542\n",
      "Epoch 53/80\n",
      "79/79 [==============================] - 0s 775us/step - loss: 3426.8105 - mse: 3426.8105 - mae: 29.8029\n",
      "Epoch 54/80\n",
      "79/79 [==============================] - 0s 852us/step - loss: 3506.8269 - mse: 3506.8269 - mae: 30.7688\n",
      "Epoch 55/80\n",
      "79/79 [==============================] - 0s 745us/step - loss: 3439.4810 - mse: 3439.4810 - mae: 30.4253\n",
      "Epoch 56/80\n",
      "79/79 [==============================] - 0s 746us/step - loss: 3509.8882 - mse: 3509.8882 - mae: 30.7250\n",
      "Epoch 57/80\n",
      "79/79 [==============================] - 0s 720us/step - loss: 3476.4473 - mse: 3476.4473 - mae: 30.1552\n",
      "Epoch 58/80\n",
      "79/79 [==============================] - 0s 758us/step - loss: 3460.0715 - mse: 3460.0715 - mae: 30.5351\n",
      "Epoch 59/80\n",
      "79/79 [==============================] - 0s 909us/step - loss: 3372.4468 - mse: 3372.4468 - mae: 30.0895\n",
      "Epoch 60/80\n",
      "79/79 [==============================] - 0s 959us/step - loss: 3495.0295 - mse: 3495.0295 - mae: 30.6232\n",
      "Epoch 61/80\n",
      "79/79 [==============================] - 0s 871us/step - loss: 3457.3372 - mse: 3457.3372 - mae: 30.2858\n",
      "Epoch 62/80\n",
      "79/79 [==============================] - 0s 858us/step - loss: 3448.5935 - mse: 3448.5935 - mae: 30.3069\n",
      "Epoch 63/80\n",
      "79/79 [==============================] - 0s 846us/step - loss: 3343.6680 - mse: 3343.6680 - mae: 30.0781\n",
      "Epoch 64/80\n",
      "79/79 [==============================] - 0s 770us/step - loss: 3350.6360 - mse: 3350.6360 - mae: 29.9867\n",
      "Epoch 65/80\n",
      "79/79 [==============================] - 0s 757us/step - loss: 3446.5564 - mse: 3446.5564 - mae: 30.4671\n",
      "Epoch 66/80\n",
      "79/79 [==============================] - 0s 785us/step - loss: 3557.2542 - mse: 3557.2542 - mae: 31.2254\n",
      "Epoch 67/80\n",
      "79/79 [==============================] - 0s 761us/step - loss: 3397.9639 - mse: 3397.9639 - mae: 30.4575\n",
      "Epoch 68/80\n",
      "79/79 [==============================] - 0s 768us/step - loss: 3438.4294 - mse: 3438.4294 - mae: 30.0200\n",
      "Epoch 69/80\n",
      "79/79 [==============================] - 0s 783us/step - loss: 3338.5195 - mse: 3338.5195 - mae: 29.7881\n",
      "Epoch 70/80\n",
      "79/79 [==============================] - 0s 770us/step - loss: 3418.1287 - mse: 3418.1287 - mae: 30.5105\n",
      "Epoch 71/80\n",
      "79/79 [==============================] - 0s 732us/step - loss: 3496.8884 - mse: 3496.8884 - mae: 31.1559\n",
      "Epoch 72/80\n",
      "79/79 [==============================] - ETA: 0s - loss: 3503.5540 - mse: 3503.5540 - mae: 29.72 - 0s 745us/step - loss: 3466.3608 - mse: 3466.3608 - mae: 30.0952\n",
      "Epoch 73/80\n",
      "79/79 [==============================] - 0s 724us/step - loss: 3497.1602 - mse: 3497.1602 - mae: 30.5205\n",
      "Epoch 74/80\n",
      "79/79 [==============================] - 0s 731us/step - loss: 3409.4038 - mse: 3409.4038 - mae: 30.3335\n",
      "Epoch 75/80\n",
      "79/79 [==============================] - 0s 744us/step - loss: 3439.9658 - mse: 3439.9658 - mae: 30.1246\n",
      "Epoch 76/80\n",
      "79/79 [==============================] - 0s 813us/step - loss: 3421.7590 - mse: 3421.7590 - mae: 30.6816\n",
      "Epoch 77/80\n",
      "79/79 [==============================] - 0s 803us/step - loss: 3430.9463 - mse: 3430.9463 - mae: 30.2849\n",
      "Epoch 78/80\n",
      "79/79 [==============================] - 0s 884us/step - loss: 3307.7969 - mse: 3307.7969 - mae: 29.6666\n",
      "Epoch 79/80\n",
      "79/79 [==============================] - 0s 934us/step - loss: 3430.7180 - mse: 3430.7180 - mae: 30.1573\n",
      "Epoch 80/80\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 3489.1733 - mse: 3489.1733 - mae: 31.0427\n",
      "2\n",
      "Epoch 1/80\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 2820.7192 - mse: 2820.7192 - mae: 29.1314\n",
      "Epoch 2/80\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 2735.8064 - mse: 2735.8064 - mae: 28.7374\n",
      "Epoch 3/80\n",
      "118/118 [==============================] - 0s 832us/step - loss: 2771.0864 - mse: 2771.0864 - mae: 29.1182\n",
      "Epoch 4/80\n",
      "118/118 [==============================] - 0s 766us/step - loss: 2802.3137 - mse: 2802.3137 - mae: 29.2076\n",
      "Epoch 5/80\n",
      "118/118 [==============================] - 0s 729us/step - loss: 2746.7136 - mse: 2746.7136 - mae: 28.3121\n",
      "Epoch 6/80\n",
      "118/118 [==============================] - 0s 787us/step - loss: 2763.6709 - mse: 2763.6709 - mae: 28.7646\n",
      "Epoch 7/80\n",
      "118/118 [==============================] - 0s 731us/step - loss: 2746.7725 - mse: 2746.7725 - mae: 28.1961\n",
      "Epoch 8/80\n",
      "118/118 [==============================] - 0s 727us/step - loss: 2683.4758 - mse: 2683.4758 - mae: 28.3619\n",
      "Epoch 9/80\n",
      "118/118 [==============================] - 0s 820us/step - loss: 2672.5676 - mse: 2672.5676 - mae: 27.8733\n",
      "Epoch 10/80\n",
      "118/118 [==============================] - 0s 820us/step - loss: 2727.9568 - mse: 2727.9568 - mae: 28.2358\n",
      "Epoch 11/80\n",
      "118/118 [==============================] - 0s 921us/step - loss: 2682.8811 - mse: 2682.8811 - mae: 28.4896\n",
      "Epoch 12/80\n",
      "118/118 [==============================] - 0s 808us/step - loss: 2691.2212 - mse: 2691.2212 - mae: 28.3207\n",
      "Epoch 13/80\n",
      "118/118 [==============================] - 0s 798us/step - loss: 2705.0076 - mse: 2705.0076 - mae: 28.1404\n",
      "Epoch 14/80\n",
      "118/118 [==============================] - 0s 752us/step - loss: 2685.1414 - mse: 2685.1414 - mae: 27.5609\n",
      "Epoch 15/80\n",
      "118/118 [==============================] - 0s 727us/step - loss: 2773.9812 - mse: 2773.9812 - mae: 28.8501\n",
      "Epoch 16/80\n",
      "118/118 [==============================] - 0s 758us/step - loss: 2724.2598 - mse: 2724.2598 - mae: 28.2123\n",
      "Epoch 17/80\n",
      "118/118 [==============================] - 0s 757us/step - loss: 2644.8279 - mse: 2644.8279 - mae: 27.6835\n",
      "Epoch 18/80\n",
      "118/118 [==============================] - ETA: 0s - loss: 1800.7394 - mse: 1800.7394 - mae: 28.35 - 0s 713us/step - loss: 2729.5876 - mse: 2729.5876 - mae: 28.5325\n",
      "Epoch 19/80\n",
      "118/118 [==============================] - 0s 713us/step - loss: 2751.3049 - mse: 2751.3049 - mae: 28.2358\n",
      "Epoch 20/80\n",
      "118/118 [==============================] - 0s 789us/step - loss: 2700.6174 - mse: 2700.6174 - mae: 28.1805\n",
      "Epoch 21/80\n",
      "118/118 [==============================] - 0s 980us/step - loss: 2638.4846 - mse: 2638.4846 - mae: 28.0584\n",
      "Epoch 22/80\n",
      "118/118 [==============================] - 0s 849us/step - loss: 2686.8550 - mse: 2686.8550 - mae: 28.3290 - loss: 3608.2417 - mse: 3608.2417 - mae: 28.77\n",
      "Epoch 23/80\n",
      "118/118 [==============================] - 0s 840us/step - loss: 2758.3308 - mse: 2758.3308 - mae: 28.4129\n",
      "Epoch 24/80\n",
      "118/118 [==============================] - 0s 955us/step - loss: 2760.9636 - mse: 2760.9636 - mae: 28.5299\n",
      "Epoch 25/80\n",
      "118/118 [==============================] - 0s 921us/step - loss: 2760.9519 - mse: 2760.9519 - mae: 28.3429\n",
      "Epoch 26/80\n",
      "118/118 [==============================] - 0s 951us/step - loss: 2685.2598 - mse: 2685.2598 - mae: 27.7563\n",
      "Epoch 27/80\n",
      "118/118 [==============================] - 0s 823us/step - loss: 2687.8030 - mse: 2687.8030 - mae: 28.2971\n",
      "Epoch 28/80\n",
      "118/118 [==============================] - 0s 735us/step - loss: 2720.7109 - mse: 2720.7109 - mae: 28.5552\n",
      "Epoch 29/80\n",
      "118/118 [==============================] - 0s 735us/step - loss: 2655.4548 - mse: 2655.4548 - mae: 27.9334\n",
      "Epoch 30/80\n",
      "118/118 [==============================] - 0s 726us/step - loss: 2741.5500 - mse: 2741.5500 - mae: 27.9791\n",
      "Epoch 31/80\n",
      "118/118 [==============================] - 0s 804us/step - loss: 2740.2839 - mse: 2740.2839 - mae: 28.7232\n",
      "Epoch 32/80\n",
      "118/118 [==============================] - 0s 839us/step - loss: 2681.6697 - mse: 2681.6697 - mae: 28.1796\n",
      "Epoch 33/80\n",
      "118/118 [==============================] - 0s 845us/step - loss: 2708.8030 - mse: 2708.8030 - mae: 28.2949\n",
      "Epoch 34/80\n",
      "118/118 [==============================] - 0s 955us/step - loss: 2769.6792 - mse: 2769.6792 - mae: 28.5402\n",
      "Epoch 35/80\n",
      "118/118 [==============================] - 0s 882us/step - loss: 2737.6843 - mse: 2737.6843 - mae: 28.4411\n",
      "Epoch 36/80\n",
      "118/118 [==============================] - 0s 795us/step - loss: 2724.6941 - mse: 2724.6941 - mae: 28.1450\n",
      "Epoch 37/80\n",
      "118/118 [==============================] - 0s 822us/step - loss: 2771.1287 - mse: 2771.1289 - mae: 28.5510\n",
      "Epoch 38/80\n",
      "118/118 [==============================] - 0s 732us/step - loss: 2723.5225 - mse: 2723.5225 - mae: 27.5598\n",
      "Epoch 39/80\n",
      "118/118 [==============================] - 0s 740us/step - loss: 2681.6074 - mse: 2681.6074 - mae: 28.1190\n",
      "Epoch 40/80\n",
      "118/118 [==============================] - 0s 710us/step - loss: 2719.3584 - mse: 2719.3584 - mae: 27.8166\n",
      "Epoch 41/80\n",
      "118/118 [==============================] - 0s 723us/step - loss: 2694.5508 - mse: 2694.5508 - mae: 28.1811\n",
      "Epoch 42/80\n",
      "118/118 [==============================] - 0s 721us/step - loss: 2689.7185 - mse: 2689.7185 - mae: 28.2771\n",
      "Epoch 43/80\n",
      "118/118 [==============================] - 0s 778us/step - loss: 2664.8723 - mse: 2664.8723 - mae: 28.0386\n",
      "Epoch 44/80\n",
      "118/118 [==============================] - 0s 710us/step - loss: 2701.6948 - mse: 2701.6948 - mae: 28.5512\n",
      "Epoch 45/80\n",
      "118/118 [==============================] - 0s 723us/step - loss: 2743.7620 - mse: 2743.7617 - mae: 27.9329\n",
      "Epoch 46/80\n",
      "118/118 [==============================] - 0s 738us/step - loss: 2690.5212 - mse: 2690.5212 - mae: 28.1761\n",
      "Epoch 47/80\n",
      "118/118 [==============================] - 0s 753us/step - loss: 2750.6101 - mse: 2750.6101 - mae: 27.7211\n",
      "Epoch 48/80\n",
      "118/118 [==============================] - 0s 837us/step - loss: 2679.5962 - mse: 2679.5962 - mae: 27.7695\n",
      "Epoch 49/80\n",
      "118/118 [==============================] - 0s 837us/step - loss: 2688.0830 - mse: 2688.0830 - mae: 28.4791\n",
      "Epoch 50/80\n",
      "118/118 [==============================] - 0s 837us/step - loss: 2660.3474 - mse: 2660.3474 - mae: 28.3859\n",
      "Epoch 51/80\n",
      "118/118 [==============================] - 0s 787us/step - loss: 2673.9683 - mse: 2673.9683 - mae: 28.1682\n",
      "Epoch 52/80\n",
      "118/118 [==============================] - 0s 749us/step - loss: 2759.5103 - mse: 2759.5103 - mae: 28.6793\n",
      "Epoch 53/80\n",
      "118/118 [==============================] - 0s 799us/step - loss: 2713.2283 - mse: 2713.2283 - mae: 28.0275\n",
      "Epoch 54/80\n",
      "118/118 [==============================] - 0s 938us/step - loss: 2760.7805 - mse: 2760.7805 - mae: 27.8749\n",
      "Epoch 55/80\n",
      "118/118 [==============================] - 0s 879us/step - loss: 2722.0632 - mse: 2722.0632 - mae: 28.0810\n",
      "Epoch 56/80\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 2682.9993 - mse: 2682.9993 - mae: 27.8239\n",
      "Epoch 57/80\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 2682.2285 - mse: 2682.2285 - mae: 28.1003\n",
      "Epoch 58/80\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 2649.8452 - mse: 2649.8452 - mae: 27.9761\n",
      "Epoch 59/80\n",
      "118/118 [==============================] - 0s 878us/step - loss: 2608.0068 - mse: 2608.0068 - mae: 27.3725\n",
      "Epoch 60/80\n",
      "118/118 [==============================] - 0s 789us/step - loss: 2691.2075 - mse: 2691.2073 - mae: 27.8309\n",
      "Epoch 61/80\n",
      "118/118 [==============================] - 0s 872us/step - loss: 2636.2668 - mse: 2636.2668 - mae: 28.5021\n",
      "Epoch 62/80\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 2723.3206 - mse: 2723.3206 - mae: 27.9433\n",
      "Epoch 63/80\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 2694.6875 - mse: 2694.6875 - mae: 28.4716\n",
      "Epoch 64/80\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 2672.9165 - mse: 2672.9165 - mae: 28.0553\n",
      "Epoch 65/80\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 2669.6113 - mse: 2669.6113 - mae: 27.5016\n",
      "Epoch 66/80\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 2685.8660 - mse: 2685.8660 - mae: 28.0293\n",
      "Epoch 67/80\n",
      "118/118 [==============================] - 0s 905us/step - loss: 2674.9763 - mse: 2674.9768 - mae: 28.2720\n",
      "Epoch 68/80\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 2670.1021 - mse: 2670.1021 - mae: 28.1439\n",
      "Epoch 69/80\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 2683.5796 - mse: 2683.5796 - mae: 27.9856\n",
      "Epoch 70/80\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 2667.4565 - mse: 2667.4565 - mae: 27.9117\n",
      "Epoch 71/80\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 2678.2139 - mse: 2678.2139 - mae: 28.1838\n",
      "Epoch 72/80\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 2667.1956 - mse: 2667.1956 - mae: 28.2768\n",
      "Epoch 73/80\n",
      "118/118 [==============================] - 0s 927us/step - loss: 2665.4380 - mse: 2665.4380 - mae: 28.1700\n",
      "Epoch 74/80\n",
      "118/118 [==============================] - 0s 871us/step - loss: 2703.9316 - mse: 2703.9316 - mae: 28.0939\n",
      "Epoch 75/80\n",
      "118/118 [==============================] - 0s 749us/step - loss: 2733.2058 - mse: 2733.2058 - mae: 28.5088\n",
      "Epoch 76/80\n",
      "118/118 [==============================] - 0s 794us/step - loss: 2685.7827 - mse: 2685.7827 - mae: 28.0790\n",
      "Epoch 77/80\n",
      "118/118 [==============================] - 0s 828us/step - loss: 2682.4216 - mse: 2682.4216 - mae: 27.6918\n",
      "Epoch 78/80\n",
      "118/118 [==============================] - 0s 913us/step - loss: 2642.4797 - mse: 2642.4797 - mae: 27.9658\n",
      "Epoch 79/80\n",
      "118/118 [==============================] - 0s 857us/step - loss: 2653.6162 - mse: 2653.6162 - mae: 27.7767\n",
      "Epoch 80/80\n",
      "118/118 [==============================] - 0s 746us/step - loss: 2698.6128 - mse: 2698.6128 - mae: 28.1899\n",
      "3\n",
      "Epoch 1/80\n",
      "157/157 [==============================] - 0s 738us/step - loss: 2405.1797 - mse: 2405.1797 - mae: 28.0181\n",
      "Epoch 2/80\n",
      "157/157 [==============================] - 0s 748us/step - loss: 2368.2964 - mse: 2368.2964 - mae: 27.7362\n",
      "Epoch 3/80\n",
      "157/157 [==============================] - 0s 782us/step - loss: 2360.8750 - mse: 2360.8750 - mae: 28.1596\n",
      "Epoch 4/80\n",
      "157/157 [==============================] - 0s 713us/step - loss: 2345.2175 - mse: 2345.2175 - mae: 28.0960\n",
      "Epoch 5/80\n",
      "157/157 [==============================] - 0s 715us/step - loss: 2395.7712 - mse: 2395.7712 - mae: 28.2803\n",
      "Epoch 6/80\n",
      "157/157 [==============================] - 0s 737us/step - loss: 2386.8447 - mse: 2386.8447 - mae: 27.9813\n",
      "Epoch 7/80\n",
      "157/157 [==============================] - 0s 705us/step - loss: 2368.1143 - mse: 2368.1143 - mae: 28.0867\n",
      "Epoch 8/80\n",
      "157/157 [==============================] - 0s 764us/step - loss: 2404.3442 - mse: 2404.3442 - mae: 28.0691\n",
      "Epoch 9/80\n",
      "157/157 [==============================] - 0s 858us/step - loss: 2391.7834 - mse: 2391.7834 - mae: 28.1172\n",
      "Epoch 10/80\n",
      "157/157 [==============================] - 0s 902us/step - loss: 2361.3247 - mse: 2361.3247 - mae: 28.4637\n",
      "Epoch 11/80\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 2380.1821 - mse: 2380.1821 - mae: 27.7757\n",
      "Epoch 12/80\n",
      "157/157 [==============================] - 0s 802us/step - loss: 2365.5298 - mse: 2365.5298 - mae: 27.8728\n",
      "Epoch 13/80\n",
      "157/157 [==============================] - 0s 973us/step - loss: 2405.4458 - mse: 2405.4458 - mae: 27.4318\n",
      "Epoch 14/80\n",
      "157/157 [==============================] - 0s 852us/step - loss: 2352.2744 - mse: 2352.2744 - mae: 27.9898\n",
      "Epoch 15/80\n",
      "157/157 [==============================] - 0s 902us/step - loss: 2406.6147 - mse: 2406.6147 - mae: 28.1919\n",
      "Epoch 16/80\n",
      "157/157 [==============================] - 0s 934us/step - loss: 2420.0457 - mse: 2420.0457 - mae: 28.1080\n",
      "Epoch 17/80\n",
      "157/157 [==============================] - 0s 856us/step - loss: 2364.7537 - mse: 2364.7537 - mae: 28.2597\n",
      "Epoch 18/80\n",
      "157/157 [==============================] - 0s 959us/step - loss: 2369.3667 - mse: 2369.3667 - mae: 28.0645\n",
      "Epoch 19/80\n",
      "157/157 [==============================] - 0s 927us/step - loss: 2412.4077 - mse: 2412.4077 - mae: 28.5337\n",
      "Epoch 20/80\n",
      "157/157 [==============================] - 0s 934us/step - loss: 2345.8525 - mse: 2345.8525 - mae: 27.6257\n",
      "Epoch 21/80\n",
      "157/157 [==============================] - 0s 901us/step - loss: 2320.4153 - mse: 2320.4153 - mae: 28.1364\n",
      "Epoch 22/80\n",
      "157/157 [==============================] - 0s 758us/step - loss: 2350.5264 - mse: 2350.5264 - mae: 27.8357\n",
      "Epoch 23/80\n",
      "157/157 [==============================] - 0s 749us/step - loss: 2359.9875 - mse: 2359.9875 - mae: 27.5132\n",
      "Epoch 24/80\n",
      "157/157 [==============================] - 0s 780us/step - loss: 2326.6433 - mse: 2326.6433 - mae: 27.7130\n",
      "Epoch 25/80\n",
      "157/157 [==============================] - 0s 826us/step - loss: 2347.9114 - mse: 2347.9114 - mae: 27.7488\n",
      "Epoch 26/80\n",
      "157/157 [==============================] - 0s 953us/step - loss: 2403.2156 - mse: 2403.2156 - mae: 28.2512\n",
      "Epoch 27/80\n",
      "157/157 [==============================] - 0s 868us/step - loss: 2391.2878 - mse: 2391.2878 - mae: 27.6646\n",
      "Epoch 28/80\n",
      "157/157 [==============================] - 0s 773us/step - loss: 2375.2324 - mse: 2375.2324 - mae: 27.9196\n",
      "Epoch 29/80\n",
      "157/157 [==============================] - 0s 749us/step - loss: 2419.3064 - mse: 2419.3064 - mae: 28.1000\n",
      "Epoch 30/80\n",
      "157/157 [==============================] - 0s 718us/step - loss: 2384.2139 - mse: 2384.2139 - mae: 28.0350\n",
      "Epoch 31/80\n",
      "157/157 [==============================] - 0s 768us/step - loss: 2354.3459 - mse: 2354.3459 - mae: 27.5958\n",
      "Epoch 32/80\n",
      "157/157 [==============================] - 0s 921us/step - loss: 2365.1719 - mse: 2365.1719 - mae: 27.7496\n",
      "Epoch 33/80\n",
      "157/157 [==============================] - 0s 902us/step - loss: 2371.0291 - mse: 2371.0291 - mae: 28.0562\n",
      "Epoch 34/80\n",
      "157/157 [==============================] - 0s 954us/step - loss: 2356.4075 - mse: 2356.4075 - mae: 27.6678\n",
      "Epoch 35/80\n",
      "157/157 [==============================] - 0s 777us/step - loss: 2349.1870 - mse: 2349.1870 - mae: 28.1228\n",
      "Epoch 36/80\n",
      "157/157 [==============================] - 0s 748us/step - loss: 2385.1968 - mse: 2385.1968 - mae: 27.9568\n",
      "Epoch 37/80\n",
      "157/157 [==============================] - 0s 737us/step - loss: 2360.1475 - mse: 2360.1475 - mae: 27.6468\n",
      "Epoch 38/80\n",
      "157/157 [==============================] - 0s 711us/step - loss: 2394.3171 - mse: 2394.3171 - mae: 28.2983\n",
      "Epoch 39/80\n",
      "157/157 [==============================] - 0s 747us/step - loss: 2378.1907 - mse: 2378.1907 - mae: 27.8558\n",
      "Epoch 40/80\n",
      "157/157 [==============================] - 0s 790us/step - loss: 2336.5254 - mse: 2336.5254 - mae: 27.3589\n",
      "Epoch 41/80\n",
      "157/157 [==============================] - 0s 739us/step - loss: 2375.1582 - mse: 2375.1582 - mae: 27.7210\n",
      "Epoch 42/80\n",
      "157/157 [==============================] - 0s 778us/step - loss: 2391.5107 - mse: 2391.5107 - mae: 27.9063\n",
      "Epoch 43/80\n",
      "157/157 [==============================] - 0s 794us/step - loss: 2310.7234 - mse: 2310.7234 - mae: 27.6540\n",
      "Epoch 44/80\n",
      "157/157 [==============================] - 0s 845us/step - loss: 2380.3870 - mse: 2380.3870 - mae: 27.9189\n",
      "Epoch 45/80\n",
      "157/157 [==============================] - 0s 855us/step - loss: 2346.4270 - mse: 2346.4270 - mae: 27.9280\n",
      "Epoch 46/80\n",
      "157/157 [==============================] - 0s 775us/step - loss: 2297.7861 - mse: 2297.7861 - mae: 27.1811\n",
      "Epoch 47/80\n",
      "157/157 [==============================] - 0s 784us/step - loss: 2376.4734 - mse: 2376.4734 - mae: 27.9776\n",
      "Epoch 48/80\n",
      "157/157 [==============================] - 0s 756us/step - loss: 2382.9089 - mse: 2382.9089 - mae: 27.7930\n",
      "Epoch 49/80\n",
      "157/157 [==============================] - 0s 735us/step - loss: 2363.5945 - mse: 2363.5945 - mae: 27.7376\n",
      "Epoch 50/80\n",
      "157/157 [==============================] - 0s 839us/step - loss: 2379.4333 - mse: 2379.4333 - mae: 27.8530\n",
      "Epoch 51/80\n",
      "157/157 [==============================] - 0s 896us/step - loss: 2349.9351 - mse: 2349.9351 - mae: 27.5411\n",
      "Epoch 52/80\n",
      "157/157 [==============================] - 0s 883us/step - loss: 2331.2217 - mse: 2331.2217 - mae: 27.4120\n",
      "Epoch 53/80\n",
      "157/157 [==============================] - 0s 842us/step - loss: 2380.2207 - mse: 2380.2207 - mae: 28.0244\n",
      "Epoch 54/80\n",
      "157/157 [==============================] - 0s 755us/step - loss: 2386.7173 - mse: 2386.7173 - mae: 27.3158\n",
      "Epoch 55/80\n",
      "157/157 [==============================] - 0s 738us/step - loss: 2391.8376 - mse: 2391.8376 - mae: 27.6743\n",
      "Epoch 56/80\n",
      "157/157 [==============================] - 0s 737us/step - loss: 2327.6484 - mse: 2327.6484 - mae: 27.4497\n",
      "Epoch 57/80\n",
      "157/157 [==============================] - 0s 770us/step - loss: 2361.5344 - mse: 2361.5344 - mae: 27.9215\n",
      "Epoch 58/80\n",
      "157/157 [==============================] - 0s 747us/step - loss: 2346.5022 - mse: 2346.5022 - mae: 27.5969\n",
      "Epoch 59/80\n",
      "157/157 [==============================] - 0s 738us/step - loss: 2390.6099 - mse: 2390.6099 - mae: 27.9817\n",
      "Epoch 60/80\n",
      "157/157 [==============================] - 0s 769us/step - loss: 2345.0879 - mse: 2345.0879 - mae: 27.7938\n",
      "Epoch 61/80\n",
      "157/157 [==============================] - 0s 924us/step - loss: 2342.0974 - mse: 2342.0974 - mae: 27.7340\n",
      "Epoch 62/80\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 2350.0388 - mse: 2350.0388 - mae: 27.7323\n",
      "Epoch 63/80\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 2380.1064 - mse: 2380.1064 - mae: 27.6358\n",
      "Epoch 64/80\n",
      "157/157 [==============================] - 0s 863us/step - loss: 2340.0747 - mse: 2340.0747 - mae: 27.6637\n",
      "Epoch 65/80\n",
      "157/157 [==============================] - 0s 833us/step - loss: 2319.2190 - mse: 2319.2190 - mae: 27.4570\n",
      "Epoch 66/80\n",
      "157/157 [==============================] - 0s 789us/step - loss: 2413.3162 - mse: 2413.3162 - mae: 28.0479\n",
      "Epoch 67/80\n",
      "157/157 [==============================] - 0s 756us/step - loss: 2350.1550 - mse: 2350.1550 - mae: 27.75890s - loss: 2505.5530 - mse: 2505.5530 - mae: 27.96\n",
      "Epoch 68/80\n",
      "157/157 [==============================] - 0s 762us/step - loss: 2346.4021 - mse: 2346.4021 - mae: 27.9239\n",
      "Epoch 69/80\n",
      "157/157 [==============================] - 0s 826us/step - loss: 2355.0334 - mse: 2355.0334 - mae: 27.6758\n",
      "Epoch 70/80\n",
      "157/157 [==============================] - 0s 871us/step - loss: 2363.9958 - mse: 2363.9958 - mae: 27.6792\n",
      "Epoch 71/80\n",
      "157/157 [==============================] - 0s 788us/step - loss: 2345.3079 - mse: 2345.3079 - mae: 27.4940\n",
      "Epoch 72/80\n",
      "157/157 [==============================] - 0s 813us/step - loss: 2336.8723 - mse: 2336.8723 - mae: 27.4018\n",
      "Epoch 73/80\n",
      "157/157 [==============================] - 0s 753us/step - loss: 2365.6057 - mse: 2365.6057 - mae: 27.5557\n",
      "Epoch 74/80\n",
      "157/157 [==============================] - 0s 848us/step - loss: 2372.1182 - mse: 2372.1182 - mae: 28.1464\n",
      "Epoch 75/80\n",
      "157/157 [==============================] - 0s 750us/step - loss: 2398.5959 - mse: 2398.5959 - mae: 27.8412\n",
      "Epoch 76/80\n",
      "157/157 [==============================] - 0s 725us/step - loss: 2314.1714 - mse: 2314.1714 - mae: 27.5073\n",
      "Epoch 77/80\n",
      "157/157 [==============================] - 0s 722us/step - loss: 2366.7319 - mse: 2366.7319 - mae: 27.9332\n",
      "Epoch 78/80\n",
      "157/157 [==============================] - 0s 718us/step - loss: 2381.3740 - mse: 2381.3740 - mae: 27.9639\n",
      "Epoch 79/80\n",
      "157/157 [==============================] - 0s 811us/step - loss: 2327.4604 - mse: 2327.4604 - mae: 27.0498\n",
      "Epoch 80/80\n",
      "157/157 [==============================] - 0s 902us/step - loss: 2385.6099 - mse: 2385.6099 - mae: 27.6796\n",
      "4\n",
      "Epoch 1/80\n",
      "196/196 [==============================] - 0s 896us/step - loss: 2127.3657 - mse: 2127.3657 - mae: 27.6321\n",
      "Epoch 2/80\n",
      "196/196 [==============================] - 0s 766us/step - loss: 2132.0964 - mse: 2132.0964 - mae: 27.3788\n",
      "Epoch 3/80\n",
      "196/196 [==============================] - 0s 733us/step - loss: 2131.4539 - mse: 2131.4539 - mae: 27.1417\n",
      "Epoch 4/80\n",
      "196/196 [==============================] - 0s 733us/step - loss: 2155.2646 - mse: 2155.2646 - mae: 27.4574\n",
      "Epoch 5/80\n",
      "196/196 [==============================] - 0s 813us/step - loss: 2130.5605 - mse: 2130.5605 - mae: 27.5706\n",
      "Epoch 6/80\n",
      "196/196 [==============================] - 0s 896us/step - loss: 2134.1882 - mse: 2134.1882 - mae: 27.1744\n",
      "Epoch 7/80\n",
      "196/196 [==============================] - 0s 882us/step - loss: 2152.8972 - mse: 2152.8972 - mae: 27.6627\n",
      "Epoch 8/80\n",
      "196/196 [==============================] - 0s 760us/step - loss: 2140.3958 - mse: 2140.3958 - mae: 27.2522\n",
      "Epoch 9/80\n",
      "196/196 [==============================] - 0s 755us/step - loss: 2123.1975 - mse: 2123.1975 - mae: 27.6509\n",
      "Epoch 10/80\n",
      "196/196 [==============================] - 0s 733us/step - loss: 2159.6975 - mse: 2159.6975 - mae: 27.4631\n",
      "Epoch 11/80\n",
      "196/196 [==============================] - 0s 713us/step - loss: 2140.2473 - mse: 2140.2473 - mae: 27.6584\n",
      "Epoch 12/80\n",
      "196/196 [==============================] - 0s 693us/step - loss: 2142.4775 - mse: 2142.4775 - mae: 27.2378\n",
      "Epoch 13/80\n",
      "196/196 [==============================] - 0s 758us/step - loss: 2160.0579 - mse: 2160.0579 - mae: 27.5548\n",
      "Epoch 14/80\n",
      "196/196 [==============================] - 0s 752us/step - loss: 2174.4333 - mse: 2174.4333 - mae: 27.5666\n",
      "Epoch 15/80\n",
      "196/196 [==============================] - 0s 896us/step - loss: 2159.0107 - mse: 2159.0107 - mae: 27.2824\n",
      "Epoch 16/80\n",
      "196/196 [==============================] - 0s 922us/step - loss: 2171.9143 - mse: 2171.9143 - mae: 27.5745\n",
      "Epoch 17/80\n",
      "196/196 [==============================] - 0s 755us/step - loss: 2102.8982 - mse: 2102.8982 - mae: 27.2173\n",
      "Epoch 18/80\n",
      "196/196 [==============================] - 0s 799us/step - loss: 2122.1655 - mse: 2122.1655 - mae: 27.4642\n",
      "Epoch 19/80\n",
      "196/196 [==============================] - 0s 936us/step - loss: 2130.6848 - mse: 2130.6848 - mae: 27.0978\n",
      "Epoch 20/80\n",
      "196/196 [==============================] - 0s 1ms/step - loss: 2112.9067 - mse: 2112.9067 - mae: 27.4755\n",
      "Epoch 21/80\n",
      "196/196 [==============================] - 0s 1ms/step - loss: 2135.6750 - mse: 2135.6750 - mae: 27.3784\n",
      "Epoch 22/80\n",
      "196/196 [==============================] - 0s 804us/step - loss: 2135.0908 - mse: 2135.0908 - mae: 27.2505\n",
      "Epoch 23/80\n",
      "196/196 [==============================] - 0s 786us/step - loss: 2135.1169 - mse: 2135.1169 - mae: 27.2287\n",
      "Epoch 24/80\n",
      "196/196 [==============================] - 0s 721us/step - loss: 2134.0957 - mse: 2134.0957 - mae: 27.3869\n",
      "Epoch 25/80\n",
      "196/196 [==============================] - 0s 794us/step - loss: 2109.1606 - mse: 2109.1606 - mae: 27.2847\n",
      "Epoch 26/80\n",
      "196/196 [==============================] - 0s 740us/step - loss: 2127.5808 - mse: 2127.5808 - mae: 27.1614\n",
      "Epoch 27/80\n",
      "196/196 [==============================] - 0s 734us/step - loss: 2155.0076 - mse: 2155.0076 - mae: 27.4805\n",
      "Epoch 28/80\n",
      "196/196 [==============================] - 0s 741us/step - loss: 2128.0764 - mse: 2128.0764 - mae: 27.3689\n",
      "Epoch 29/80\n",
      "196/196 [==============================] - 0s 870us/step - loss: 2159.1155 - mse: 2159.1155 - mae: 27.4790\n",
      "Epoch 30/80\n",
      "196/196 [==============================] - 0s 868us/step - loss: 2139.0291 - mse: 2139.0291 - mae: 27.5780\n",
      "Epoch 31/80\n",
      "196/196 [==============================] - 0s 756us/step - loss: 2127.5095 - mse: 2127.5095 - mae: 26.9054\n",
      "Epoch 32/80\n",
      "196/196 [==============================] - 0s 768us/step - loss: 2164.7114 - mse: 2164.7114 - mae: 27.4090\n",
      "Epoch 33/80\n",
      "196/196 [==============================] - 0s 724us/step - loss: 2109.1809 - mse: 2109.1809 - mae: 27.1050\n",
      "Epoch 34/80\n",
      "196/196 [==============================] - 0s 748us/step - loss: 2123.5210 - mse: 2123.5210 - mae: 26.9117\n",
      "Epoch 35/80\n",
      "196/196 [==============================] - 0s 860us/step - loss: 2103.7004 - mse: 2103.7004 - mae: 27.0706\n",
      "Epoch 36/80\n",
      "196/196 [==============================] - 0s 834us/step - loss: 2140.8828 - mse: 2140.8828 - mae: 27.4519\n",
      "Epoch 37/80\n",
      "196/196 [==============================] - 0s 752us/step - loss: 2119.4832 - mse: 2119.4832 - mae: 26.9932\n",
      "Epoch 38/80\n",
      "196/196 [==============================] - 0s 753us/step - loss: 2118.6985 - mse: 2118.6985 - mae: 27.4702\n",
      "Epoch 39/80\n",
      "196/196 [==============================] - 0s 728us/step - loss: 2104.2908 - mse: 2104.2908 - mae: 26.9520\n",
      "Epoch 40/80\n",
      "196/196 [==============================] - 0s 717us/step - loss: 2101.1682 - mse: 2101.1682 - mae: 27.1853\n",
      "Epoch 41/80\n",
      "196/196 [==============================] - 0s 745us/step - loss: 2081.5876 - mse: 2081.5876 - mae: 27.1094\n",
      "Epoch 42/80\n",
      "196/196 [==============================] - 0s 730us/step - loss: 2148.1609 - mse: 2148.1609 - mae: 27.2831\n",
      "Epoch 43/80\n",
      "196/196 [==============================] - 0s 728us/step - loss: 2104.7986 - mse: 2104.7986 - mae: 27.0658\n",
      "Epoch 44/80\n",
      "196/196 [==============================] - 0s 911us/step - loss: 2146.6558 - mse: 2146.6558 - mae: 27.3888\n",
      "Epoch 45/80\n",
      "196/196 [==============================] - 0s 916us/step - loss: 2138.5422 - mse: 2138.5422 - mae: 27.4408\n",
      "Epoch 46/80\n",
      "196/196 [==============================] - 0s 815us/step - loss: 2109.6216 - mse: 2109.6216 - mae: 27.2259\n",
      "Epoch 47/80\n",
      "196/196 [==============================] - 0s 774us/step - loss: 2155.1953 - mse: 2155.1953 - mae: 27.4172\n",
      "Epoch 48/80\n",
      "196/196 [==============================] - 0s 744us/step - loss: 2128.7744 - mse: 2128.7744 - mae: 27.1982\n",
      "Epoch 49/80\n",
      "196/196 [==============================] - 0s 739us/step - loss: 2102.7451 - mse: 2102.7451 - mae: 27.4282\n",
      "Epoch 50/80\n",
      "196/196 [==============================] - 0s 896us/step - loss: 2092.8152 - mse: 2092.8152 - mae: 27.0671\n",
      "Epoch 51/80\n",
      "196/196 [==============================] - 0s 933us/step - loss: 2112.7141 - mse: 2112.7141 - mae: 27.4300\n",
      "Epoch 52/80\n",
      "196/196 [==============================] - 0s 901us/step - loss: 2146.7886 - mse: 2146.7886 - mae: 27.4386\n",
      "Epoch 53/80\n",
      "196/196 [==============================] - 0s 990us/step - loss: 2103.2368 - mse: 2103.2368 - mae: 27.0839\n",
      "Epoch 54/80\n",
      "196/196 [==============================] - 0s 946us/step - loss: 2131.9653 - mse: 2131.9653 - mae: 27.3555\n",
      "Epoch 55/80\n",
      "196/196 [==============================] - 0s 792us/step - loss: 2088.4976 - mse: 2088.4976 - mae: 27.0962\n",
      "Epoch 56/80\n",
      "196/196 [==============================] - 0s 751us/step - loss: 2107.0830 - mse: 2107.0830 - mae: 27.1454\n",
      "Epoch 57/80\n",
      "196/196 [==============================] - 0s 767us/step - loss: 2157.7830 - mse: 2157.7830 - mae: 27.1369\n",
      "Epoch 58/80\n",
      "196/196 [==============================] - 0s 896us/step - loss: 2118.5054 - mse: 2118.5054 - mae: 27.3071\n",
      "Epoch 59/80\n",
      "196/196 [==============================] - 0s 853us/step - loss: 2121.2300 - mse: 2121.2300 - mae: 27.2962\n",
      "Epoch 60/80\n",
      "196/196 [==============================] - 0s 819us/step - loss: 2113.6714 - mse: 2113.6714 - mae: 26.8572\n",
      "Epoch 61/80\n",
      "196/196 [==============================] - 0s 753us/step - loss: 2162.5251 - mse: 2162.5251 - mae: 27.6884\n",
      "Epoch 62/80\n",
      "196/196 [==============================] - 0s 712us/step - loss: 2132.0410 - mse: 2132.0410 - mae: 27.3102\n",
      "Epoch 63/80\n",
      "196/196 [==============================] - 0s 761us/step - loss: 2122.3105 - mse: 2122.3105 - mae: 27.1517\n",
      "Epoch 64/80\n",
      "196/196 [==============================] - 0s 829us/step - loss: 2114.9722 - mse: 2114.9722 - mae: 27.1400\n",
      "Epoch 65/80\n",
      "196/196 [==============================] - 0s 926us/step - loss: 2123.9148 - mse: 2123.9148 - mae: 27.3618\n",
      "Epoch 66/80\n",
      "196/196 [==============================] - 0s 947us/step - loss: 2130.3967 - mse: 2130.3967 - mae: 27.0984\n",
      "Epoch 67/80\n",
      "196/196 [==============================] - 0s 816us/step - loss: 2142.1179 - mse: 2142.1179 - mae: 27.2191\n",
      "Epoch 68/80\n",
      "196/196 [==============================] - 0s 754us/step - loss: 2098.3762 - mse: 2098.3762 - mae: 26.9150\n",
      "Epoch 69/80\n",
      "196/196 [==============================] - 0s 762us/step - loss: 2081.8350 - mse: 2081.8350 - mae: 26.9549\n",
      "Epoch 70/80\n",
      "196/196 [==============================] - 0s 723us/step - loss: 2136.7222 - mse: 2136.7222 - mae: 27.3308\n",
      "Epoch 71/80\n",
      "196/196 [==============================] - 0s 743us/step - loss: 2140.6646 - mse: 2140.6646 - mae: 27.0865\n",
      "Epoch 72/80\n",
      "196/196 [==============================] - 0s 773us/step - loss: 2125.6143 - mse: 2125.6143 - mae: 27.2609\n",
      "Epoch 73/80\n",
      "196/196 [==============================] - 0s 896us/step - loss: 2104.6257 - mse: 2104.6257 - mae: 27.2886\n",
      "Epoch 74/80\n",
      "196/196 [==============================] - 0s 833us/step - loss: 2112.0864 - mse: 2112.0864 - mae: 27.2015\n",
      "Epoch 75/80\n",
      "196/196 [==============================] - 0s 750us/step - loss: 2108.6843 - mse: 2108.6843 - mae: 27.1197\n",
      "Epoch 76/80\n",
      "196/196 [==============================] - 0s 759us/step - loss: 2118.7771 - mse: 2118.7771 - mae: 26.8781\n",
      "Epoch 77/80\n",
      "196/196 [==============================] - 0s 720us/step - loss: 2119.0935 - mse: 2119.0935 - mae: 27.3183\n",
      "Epoch 78/80\n",
      "196/196 [==============================] - 0s 788us/step - loss: 2122.8596 - mse: 2122.8596 - mae: 27.2761\n",
      "Epoch 79/80\n",
      "196/196 [==============================] - 0s 865us/step - loss: 2153.5938 - mse: 2153.5938 - mae: 27.2400\n",
      "Epoch 80/80\n",
      "196/196 [==============================] - 0s 845us/step - loss: 2155.5330 - mse: 2155.5330 - mae: 27.0233\n",
      "5\n",
      "Epoch 1/80\n",
      "235/235 [==============================] - 0s 817us/step - loss: 2563.1521 - mse: 2563.1521 - mae: 26.8424\n",
      "Epoch 2/80\n",
      "235/235 [==============================] - 0s 793us/step - loss: 2552.3506 - mse: 2552.3506 - mae: 27.2770\n",
      "Epoch 3/80\n",
      "235/235 [==============================] - 0s 729us/step - loss: 2531.2122 - mse: 2531.2122 - mae: 27.2576\n",
      "Epoch 4/80\n",
      "235/235 [==============================] - 0s 752us/step - loss: 2546.6292 - mse: 2546.6292 - mae: 27.0138\n",
      "Epoch 5/80\n",
      "235/235 [==============================] - 0s 823us/step - loss: 2550.4656 - mse: 2550.4656 - mae: 27.3440\n",
      "Epoch 6/80\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 2551.5532 - mse: 2551.5532 - mae: 26.9788\n",
      "Epoch 7/80\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 2517.9463 - mse: 2517.9463 - mae: 27.0626\n",
      "Epoch 8/80\n",
      "235/235 [==============================] - 0s 817us/step - loss: 2537.1501 - mse: 2537.1501 - mae: 27.1476\n",
      "Epoch 9/80\n",
      "235/235 [==============================] - 0s 777us/step - loss: 2528.5969 - mse: 2528.5972 - mae: 27.1202\n",
      "Epoch 10/80\n",
      "235/235 [==============================] - 0s 828us/step - loss: 2487.8291 - mse: 2487.8291 - mae: 26.8047\n",
      "Epoch 11/80\n",
      "235/235 [==============================] - 0s 862us/step - loss: 2554.1985 - mse: 2554.1985 - mae: 27.6151\n",
      "Epoch 12/80\n",
      "235/235 [==============================] - 0s 788us/step - loss: 2542.6375 - mse: 2542.6375 - mae: 26.8772\n",
      "Epoch 13/80\n",
      "235/235 [==============================] - 0s 738us/step - loss: 2555.9507 - mse: 2555.9507 - mae: 27.5322\n",
      "Epoch 14/80\n",
      "235/235 [==============================] - 0s 745us/step - loss: 2544.6985 - mse: 2544.6985 - mae: 27.1640\n",
      "Epoch 15/80\n",
      "235/235 [==============================] - 0s 735us/step - loss: 2522.4529 - mse: 2522.4529 - mae: 26.8320\n",
      "Epoch 16/80\n",
      "235/235 [==============================] - 0s 732us/step - loss: 2509.7734 - mse: 2509.7734 - mae: 26.6602\n",
      "Epoch 17/80\n",
      "235/235 [==============================] - 0s 717us/step - loss: 2514.8557 - mse: 2514.8557 - mae: 26.8015\n",
      "Epoch 18/80\n",
      "235/235 [==============================] - 0s 777us/step - loss: 2593.9414 - mse: 2593.9414 - mae: 27.1473\n",
      "Epoch 19/80\n",
      "235/235 [==============================] - 0s 900us/step - loss: 2517.1812 - mse: 2517.1812 - mae: 26.6738\n",
      "Epoch 20/80\n",
      "235/235 [==============================] - 0s 788us/step - loss: 2497.6033 - mse: 2497.6033 - mae: 27.1270\n",
      "Epoch 21/80\n",
      "235/235 [==============================] - 0s 771us/step - loss: 2496.5776 - mse: 2496.5776 - mae: 26.9229\n",
      "Epoch 22/80\n",
      "235/235 [==============================] - 0s 735us/step - loss: 2523.5862 - mse: 2523.5862 - mae: 27.1328\n",
      "Epoch 23/80\n",
      "235/235 [==============================] - 0s 836us/step - loss: 2507.7781 - mse: 2507.7781 - mae: 26.7522\n",
      "Epoch 24/80\n",
      "235/235 [==============================] - 0s 892us/step - loss: 2533.6714 - mse: 2533.6714 - mae: 26.9605\n",
      "Epoch 25/80\n",
      "235/235 [==============================] - 0s 764us/step - loss: 2543.5442 - mse: 2543.5442 - mae: 27.0687\n",
      "Epoch 26/80\n",
      "235/235 [==============================] - 0s 747us/step - loss: 2522.1851 - mse: 2522.1851 - mae: 27.2884\n",
      "Epoch 27/80\n",
      "235/235 [==============================] - 0s 749us/step - loss: 2567.6038 - mse: 2567.6038 - mae: 27.4270\n",
      "Epoch 28/80\n",
      "235/235 [==============================] - 0s 726us/step - loss: 2517.9678 - mse: 2517.9678 - mae: 27.0574\n",
      "Epoch 29/80\n",
      "235/235 [==============================] - 0s 730us/step - loss: 2512.4417 - mse: 2512.4417 - mae: 26.8451\n",
      "Epoch 30/80\n",
      "235/235 [==============================] - 0s 737us/step - loss: 2536.4739 - mse: 2536.4739 - mae: 27.0230\n",
      "Epoch 31/80\n",
      "235/235 [==============================] - 0s 857us/step - loss: 2520.9773 - mse: 2520.9773 - mae: 27.1871\n",
      "Epoch 32/80\n",
      "235/235 [==============================] - 0s 917us/step - loss: 2521.8606 - mse: 2521.8606 - mae: 26.7455\n",
      "Epoch 33/80\n",
      "235/235 [==============================] - 0s 743us/step - loss: 2503.6116 - mse: 2503.6116 - mae: 27.1512\n",
      "Epoch 34/80\n",
      "235/235 [==============================] - 0s 840us/step - loss: 2533.9609 - mse: 2533.9609 - mae: 26.9969\n",
      "Epoch 35/80\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 2547.4670 - mse: 2547.4670 - mae: 27.2839\n",
      "Epoch 36/80\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 2529.2808 - mse: 2529.2808 - mae: 26.8852\n",
      "Epoch 37/80\n",
      "235/235 [==============================] - 0s 930us/step - loss: 2548.5444 - mse: 2548.5444 - mae: 27.0228\n",
      "Epoch 38/80\n",
      "235/235 [==============================] - 0s 762us/step - loss: 2528.7019 - mse: 2528.7019 - mae: 26.8488\n",
      "Epoch 39/80\n",
      "235/235 [==============================] - 0s 769us/step - loss: 2506.4678 - mse: 2506.4678 - mae: 27.0115\n",
      "Epoch 40/80\n",
      "235/235 [==============================] - 0s 842us/step - loss: 2542.5137 - mse: 2542.5137 - mae: 26.9227\n",
      "Epoch 41/80\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 2540.2483 - mse: 2540.2483 - mae: 27.1820\n",
      "Epoch 42/80\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 2522.9487 - mse: 2522.9487 - mae: 27.1191\n",
      "Epoch 43/80\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 2535.6702 - mse: 2535.6702 - mae: 27.1490\n",
      "Epoch 44/80\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 2503.3833 - mse: 2503.3833 - mae: 27.0215\n",
      "Epoch 45/80\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 2513.6709 - mse: 2513.6709 - mae: 26.8486\n",
      "Epoch 46/80\n",
      "235/235 [==============================] - 0s 997us/step - loss: 2554.1238 - mse: 2554.1238 - mae: 27.2736\n",
      "Epoch 47/80\n",
      "235/235 [==============================] - 0s 796us/step - loss: 2509.2900 - mse: 2509.2900 - mae: 26.8842\n",
      "Epoch 48/80\n",
      "235/235 [==============================] - 0s 800us/step - loss: 2524.9150 - mse: 2524.9150 - mae: 27.0154\n",
      "Epoch 49/80\n",
      "235/235 [==============================] - 0s 838us/step - loss: 2510.7310 - mse: 2510.7310 - mae: 26.8303\n",
      "Epoch 50/80\n",
      "235/235 [==============================] - 0s 954us/step - loss: 2518.8340 - mse: 2518.8340 - mae: 27.0279\n",
      "Epoch 51/80\n",
      "235/235 [==============================] - 0s 782us/step - loss: 2536.9651 - mse: 2536.9651 - mae: 26.8068\n",
      "Epoch 52/80\n",
      "235/235 [==============================] - 0s 963us/step - loss: 2569.2373 - mse: 2569.2373 - mae: 27.1410\n",
      "Epoch 53/80\n",
      "235/235 [==============================] - 0s 843us/step - loss: 2569.2532 - mse: 2569.2532 - mae: 27.2513\n",
      "Epoch 54/80\n",
      "235/235 [==============================] - 0s 790us/step - loss: 2521.2603 - mse: 2521.2603 - mae: 26.6706\n",
      "Epoch 55/80\n",
      "235/235 [==============================] - 0s 733us/step - loss: 2553.5979 - mse: 2553.5977 - mae: 27.0431\n",
      "Epoch 56/80\n",
      "235/235 [==============================] - 0s 827us/step - loss: 2496.9817 - mse: 2496.9817 - mae: 26.6607\n",
      "Epoch 57/80\n",
      "235/235 [==============================] - 0s 900us/step - loss: 2560.7429 - mse: 2560.7429 - mae: 27.0828\n",
      "Epoch 58/80\n",
      "235/235 [==============================] - 0s 843us/step - loss: 2509.7810 - mse: 2509.7810 - mae: 26.9164\n",
      "Epoch 59/80\n",
      "235/235 [==============================] - 0s 997us/step - loss: 2504.6365 - mse: 2504.6365 - mae: 26.7773\n",
      "Epoch 60/80\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 2528.2126 - mse: 2528.2124 - mae: 26.7016\n",
      "Epoch 61/80\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 2473.5466 - mse: 2473.5466 - mae: 26.5871\n",
      "Epoch 62/80\n",
      "235/235 [==============================] - 0s 833us/step - loss: 2504.8850 - mse: 2504.8850 - mae: 27.0425\n",
      "Epoch 63/80\n",
      "235/235 [==============================] - 0s 904us/step - loss: 2529.8015 - mse: 2529.8015 - mae: 27.0942\n",
      "Epoch 64/80\n",
      "235/235 [==============================] - 0s 857us/step - loss: 2525.7568 - mse: 2525.7568 - mae: 26.9516\n",
      "Epoch 65/80\n",
      "235/235 [==============================] - 0s 758us/step - loss: 2513.8911 - mse: 2513.8911 - mae: 26.9417\n",
      "Epoch 66/80\n",
      "235/235 [==============================] - 0s 767us/step - loss: 2548.0054 - mse: 2548.0054 - mae: 26.7922\n",
      "Epoch 67/80\n",
      "235/235 [==============================] - 0s 760us/step - loss: 2528.1848 - mse: 2528.1848 - mae: 27.0161\n",
      "Epoch 68/80\n",
      "235/235 [==============================] - 0s 866us/step - loss: 2517.1399 - mse: 2517.1399 - mae: 26.9100\n",
      "Epoch 69/80\n",
      "235/235 [==============================] - 0s 808us/step - loss: 2501.9575 - mse: 2501.9575 - mae: 26.5792\n",
      "Epoch 70/80\n",
      "235/235 [==============================] - 0s 738us/step - loss: 2546.2358 - mse: 2546.2358 - mae: 27.0676\n",
      "Epoch 71/80\n",
      "235/235 [==============================] - 0s 782us/step - loss: 2535.0032 - mse: 2535.0032 - mae: 26.6955\n",
      "Epoch 72/80\n",
      "235/235 [==============================] - 0s 713us/step - loss: 2531.0830 - mse: 2531.0830 - mae: 26.9231\n",
      "Epoch 73/80\n",
      "235/235 [==============================] - 0s 729us/step - loss: 2542.9258 - mse: 2542.9258 - mae: 27.1719\n",
      "Epoch 74/80\n",
      "235/235 [==============================] - 0s 727us/step - loss: 2526.7334 - mse: 2526.7334 - mae: 26.8849\n",
      "Epoch 75/80\n",
      "235/235 [==============================] - 0s 802us/step - loss: 2516.7651 - mse: 2516.7651 - mae: 26.6642\n",
      "Epoch 76/80\n",
      "235/235 [==============================] - 0s 900us/step - loss: 2491.1855 - mse: 2491.1855 - mae: 26.7292\n",
      "Epoch 77/80\n",
      "235/235 [==============================] - 0s 802us/step - loss: 2530.7615 - mse: 2530.7615 - mae: 27.0311\n",
      "Epoch 78/80\n",
      "235/235 [==============================] - 0s 729us/step - loss: 2516.0500 - mse: 2516.0500 - mae: 26.8737\n",
      "Epoch 79/80\n",
      "235/235 [==============================] - 0s 744us/step - loss: 2537.2795 - mse: 2537.2795 - mae: 26.8333\n",
      "Epoch 80/80\n",
      "235/235 [==============================] - 0s 798us/step - loss: 2503.8159 - mse: 2503.8159 - mae: 26.7318\n",
      "6\n",
      "Epoch 1/80\n",
      "274/274 [==============================] - 0s 848us/step - loss: 2638.5481 - mse: 2638.5483 - mae: 28.0391\n",
      "Epoch 2/80\n",
      "274/274 [==============================] - 0s 785us/step - loss: 2604.8733 - mse: 2604.8733 - mae: 27.7289\n",
      "Epoch 3/80\n",
      "274/274 [==============================] - 0s 753us/step - loss: 2603.2000 - mse: 2603.2000 - mae: 27.9659\n",
      "Epoch 4/80\n",
      "274/274 [==============================] - 0s 777us/step - loss: 2619.5891 - mse: 2619.5891 - mae: 27.7331\n",
      "Epoch 5/80\n",
      "274/274 [==============================] - 0s 771us/step - loss: 2631.1948 - mse: 2631.1948 - mae: 27.7334\n",
      "Epoch 6/80\n",
      "274/274 [==============================] - 0s 1ms/step - loss: 2604.5212 - mse: 2604.5212 - mae: 27.6231\n",
      "Epoch 7/80\n",
      "274/274 [==============================] - 0s 1ms/step - loss: 2611.2007 - mse: 2611.2007 - mae: 27.9925\n",
      "Epoch 8/80\n",
      "274/274 [==============================] - 0s 811us/step - loss: 2634.0652 - mse: 2634.0652 - mae: 27.5814\n",
      "Epoch 9/80\n",
      "274/274 [==============================] - 0s 750us/step - loss: 2577.9846 - mse: 2577.9846 - mae: 27.7948\n",
      "Epoch 10/80\n",
      "274/274 [==============================] - 0s 852us/step - loss: 2622.1609 - mse: 2622.1609 - mae: 27.9342\n",
      "Epoch 11/80\n",
      "274/274 [==============================] - 0s 908us/step - loss: 2579.7864 - mse: 2579.7864 - mae: 27.9345\n",
      "Epoch 12/80\n",
      "274/274 [==============================] - 0s 758us/step - loss: 2613.0972 - mse: 2613.0972 - mae: 27.9545\n",
      "Epoch 13/80\n",
      "274/274 [==============================] - 0s 713us/step - loss: 2611.4331 - mse: 2611.4331 - mae: 27.7460\n",
      "Epoch 14/80\n",
      "274/274 [==============================] - 0s 780us/step - loss: 2602.3813 - mse: 2602.3813 - mae: 27.6069\n",
      "Epoch 15/80\n",
      "274/274 [==============================] - 0s 753us/step - loss: 2645.6628 - mse: 2645.6626 - mae: 27.9109\n",
      "Epoch 16/80\n",
      "274/274 [==============================] - 0s 738us/step - loss: 2600.7588 - mse: 2600.7588 - mae: 27.7325\n",
      "Epoch 17/80\n",
      "274/274 [==============================] - 0s 858us/step - loss: 2594.5085 - mse: 2594.5085 - mae: 27.7495\n",
      "Epoch 18/80\n",
      "274/274 [==============================] - 0s 821us/step - loss: 2613.1692 - mse: 2613.1692 - mae: 27.8704\n",
      "Epoch 19/80\n",
      "274/274 [==============================] - 0s 778us/step - loss: 2611.9226 - mse: 2611.9226 - mae: 27.6166\n",
      "Epoch 20/80\n",
      "274/274 [==============================] - 0s 849us/step - loss: 2594.7561 - mse: 2594.7561 - mae: 27.7093\n",
      "Epoch 21/80\n",
      "274/274 [==============================] - 0s 866us/step - loss: 2616.9080 - mse: 2616.9080 - mae: 27.9181\n",
      "Epoch 22/80\n",
      "274/274 [==============================] - 0s 794us/step - loss: 2563.6011 - mse: 2563.6011 - mae: 27.4421\n",
      "Epoch 23/80\n",
      "274/274 [==============================] - 0s 761us/step - loss: 2586.0398 - mse: 2586.0398 - mae: 27.6801\n",
      "Epoch 24/80\n",
      "274/274 [==============================] - 0s 739us/step - loss: 2591.9250 - mse: 2591.9250 - mae: 27.9172\n",
      "Epoch 25/80\n",
      "274/274 [==============================] - 0s 749us/step - loss: 2616.4216 - mse: 2616.4216 - mae: 27.6517\n",
      "Epoch 26/80\n",
      "274/274 [==============================] - 0s 730us/step - loss: 2606.0100 - mse: 2606.0100 - mae: 27.7094\n",
      "Epoch 27/80\n",
      "274/274 [==============================] - 0s 703us/step - loss: 2616.2861 - mse: 2616.2861 - mae: 27.3627\n",
      "Epoch 28/80\n",
      "274/274 [==============================] - 0s 885us/step - loss: 2622.1895 - mse: 2622.1895 - mae: 27.9318\n",
      "Epoch 29/80\n",
      "274/274 [==============================] - 0s 824us/step - loss: 2604.6321 - mse: 2604.6321 - mae: 27.7614\n",
      "Epoch 30/80\n",
      "274/274 [==============================] - 0s 879us/step - loss: 2647.6492 - mse: 2647.6492 - mae: 27.9792\n",
      "Epoch 31/80\n",
      "274/274 [==============================] - 0s 1ms/step - loss: 2596.0427 - mse: 2596.0427 - mae: 27.6135\n",
      "Epoch 32/80\n",
      "274/274 [==============================] - 0s 970us/step - loss: 2630.5503 - mse: 2630.5503 - mae: 27.8892\n",
      "Epoch 33/80\n",
      "274/274 [==============================] - 0s 800us/step - loss: 2611.8103 - mse: 2611.8103 - mae: 27.7725\n",
      "Epoch 34/80\n",
      "274/274 [==============================] - 0s 777us/step - loss: 2577.9185 - mse: 2577.9185 - mae: 27.6866\n",
      "Epoch 35/80\n",
      "274/274 [==============================] - 0s 723us/step - loss: 2604.9014 - mse: 2604.9014 - mae: 27.5706\n",
      "Epoch 36/80\n",
      "274/274 [==============================] - 0s 721us/step - loss: 2620.3000 - mse: 2620.3000 - mae: 27.9130\n",
      "Epoch 37/80\n",
      "274/274 [==============================] - 0s 729us/step - loss: 2635.5679 - mse: 2635.5679 - mae: 27.9812\n",
      "Epoch 38/80\n",
      "274/274 [==============================] - 0s 968us/step - loss: 2587.2856 - mse: 2587.2856 - mae: 27.3556\n",
      "Epoch 39/80\n",
      "274/274 [==============================] - 0s 902us/step - loss: 2563.2139 - mse: 2563.2139 - mae: 27.3614\n",
      "Epoch 40/80\n",
      "274/274 [==============================] - 0s 737us/step - loss: 2586.7754 - mse: 2586.7754 - mae: 27.6321\n",
      "Epoch 41/80\n",
      "274/274 [==============================] - 0s 776us/step - loss: 2564.6150 - mse: 2564.6150 - mae: 27.6305\n",
      "Epoch 42/80\n",
      "274/274 [==============================] - 0s 866us/step - loss: 2586.6523 - mse: 2586.6523 - mae: 27.5186\n",
      "Epoch 43/80\n",
      "274/274 [==============================] - 0s 807us/step - loss: 2581.8320 - mse: 2581.8320 - mae: 27.7627\n",
      "Epoch 44/80\n",
      "274/274 [==============================] - 0s 747us/step - loss: 2584.7839 - mse: 2584.7839 - mae: 27.4252\n",
      "Epoch 45/80\n",
      "274/274 [==============================] - 0s 713us/step - loss: 2574.4192 - mse: 2574.4192 - mae: 27.6416\n",
      "Epoch 46/80\n",
      "274/274 [==============================] - 0s 726us/step - loss: 2593.6538 - mse: 2593.6538 - mae: 27.7545\n",
      "Epoch 47/80\n",
      "274/274 [==============================] - 0s 746us/step - loss: 2590.4514 - mse: 2590.4514 - mae: 27.9003\n",
      "Epoch 48/80\n",
      "274/274 [==============================] - 0s 739us/step - loss: 2613.9429 - mse: 2613.9429 - mae: 28.0558\n",
      "Epoch 49/80\n",
      "274/274 [==============================] - 0s 895us/step - loss: 2586.6086 - mse: 2586.6086 - mae: 27.5165\n",
      "Epoch 50/80\n",
      "274/274 [==============================] - 0s 801us/step - loss: 2584.9951 - mse: 2584.9951 - mae: 27.6364\n",
      "Epoch 51/80\n",
      "274/274 [==============================] - 0s 730us/step - loss: 2564.2231 - mse: 2564.2231 - mae: 27.4207\n",
      "Epoch 52/80\n",
      "274/274 [==============================] - 0s 823us/step - loss: 2597.5852 - mse: 2597.5852 - mae: 27.8507\n",
      "Epoch 53/80\n",
      "274/274 [==============================] - 0s 888us/step - loss: 2570.9744 - mse: 2570.9744 - mae: 27.5758\n",
      "Epoch 54/80\n",
      "274/274 [==============================] - 0s 793us/step - loss: 2597.0469 - mse: 2597.0471 - mae: 27.4273\n",
      "Epoch 55/80\n",
      "274/274 [==============================] - 0s 910us/step - loss: 2584.9099 - mse: 2584.9099 - mae: 27.8878\n",
      "Epoch 56/80\n",
      "274/274 [==============================] - 0s 921us/step - loss: 2608.1079 - mse: 2608.1079 - mae: 27.4274\n",
      "Epoch 57/80\n",
      "274/274 [==============================] - 0s 768us/step - loss: 2578.8340 - mse: 2578.8340 - mae: 27.4629\n",
      "Epoch 58/80\n",
      "274/274 [==============================] - 0s 768us/step - loss: 2583.6128 - mse: 2583.6128 - mae: 27.7916\n",
      "Epoch 59/80\n",
      "274/274 [==============================] - 0s 946us/step - loss: 2555.3433 - mse: 2555.3433 - mae: 27.5271\n",
      "Epoch 60/80\n",
      "274/274 [==============================] - 0s 1ms/step - loss: 2571.5334 - mse: 2571.5334 - mae: 27.4577\n",
      "Epoch 61/80\n",
      "274/274 [==============================] - 0s 805us/step - loss: 2595.3381 - mse: 2595.3381 - mae: 27.9461\n",
      "Epoch 62/80\n",
      "274/274 [==============================] - 0s 910us/step - loss: 2572.9355 - mse: 2572.9355 - mae: 27.5504\n",
      "Epoch 63/80\n",
      "274/274 [==============================] - 0s 852us/step - loss: 2576.7363 - mse: 2576.7363 - mae: 27.5460\n",
      "Epoch 64/80\n",
      "274/274 [==============================] - 0s 812us/step - loss: 2607.7393 - mse: 2607.7393 - mae: 27.5279\n",
      "Epoch 65/80\n",
      "274/274 [==============================] - 0s 753us/step - loss: 2603.8867 - mse: 2603.8867 - mae: 27.3534\n",
      "Epoch 66/80\n",
      "274/274 [==============================] - 0s 721us/step - loss: 2552.7373 - mse: 2552.7373 - mae: 27.4027\n",
      "Epoch 67/80\n",
      "274/274 [==============================] - 0s 750us/step - loss: 2570.4111 - mse: 2570.4111 - mae: 27.6487\n",
      "Epoch 68/80\n",
      "274/274 [==============================] - 0s 713us/step - loss: 2554.3333 - mse: 2554.3333 - mae: 27.2780\n",
      "Epoch 69/80\n",
      "274/274 [==============================] - 0s 823us/step - loss: 2583.4590 - mse: 2583.4590 - mae: 27.7339\n",
      "Epoch 70/80\n",
      "274/274 [==============================] - 0s 903us/step - loss: 2565.8020 - mse: 2565.8020 - mae: 27.1606\n",
      "Epoch 71/80\n",
      "274/274 [==============================] - 0s 778us/step - loss: 2568.9043 - mse: 2568.9043 - mae: 27.6670\n",
      "Epoch 72/80\n",
      "274/274 [==============================] - 0s 747us/step - loss: 2577.1694 - mse: 2577.1694 - mae: 27.4233\n",
      "Epoch 73/80\n",
      "274/274 [==============================] - 0s 819us/step - loss: 2572.2234 - mse: 2572.2234 - mae: 27.6745\n",
      "Epoch 74/80\n",
      "274/274 [==============================] - 0s 826us/step - loss: 2601.0159 - mse: 2601.0159 - mae: 27.4710\n",
      "Epoch 75/80\n",
      "274/274 [==============================] - 0s 772us/step - loss: 2588.9058 - mse: 2588.9058 - mae: 27.5702\n",
      "Epoch 76/80\n",
      "274/274 [==============================] - 0s 735us/step - loss: 2594.1208 - mse: 2594.1208 - mae: 27.6515\n",
      "Epoch 77/80\n",
      "274/274 [==============================] - 0s 724us/step - loss: 2581.3491 - mse: 2581.3491 - mae: 27.6397\n",
      "Epoch 78/80\n",
      "274/274 [==============================] - 0s 709us/step - loss: 2559.5422 - mse: 2559.5422 - mae: 27.3897\n",
      "Epoch 79/80\n",
      "274/274 [==============================] - 0s 939us/step - loss: 2584.0515 - mse: 2584.0515 - mae: 27.5679\n",
      "Epoch 80/80\n",
      "274/274 [==============================] - 0s 1ms/step - loss: 2582.1680 - mse: 2582.1680 - mae: 27.4237\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "# data\n",
    "data = pd.read_csv('Data_set_1_smaller.csv', index_col = 0)\n",
    "data = data.loc[data.index > 2018090000, :]\n",
    "    \n",
    "# reset index\n",
    "data.reset_index(inplace = True)\n",
    "data.drop('index', axis = 1, inplace = True)\n",
    "    \n",
    "# Divide features and labels\n",
    "X = data.iloc[:, 0:15]\n",
    "y = data.loc[:, 'Offers']\n",
    "\n",
    "X.fillna(X.mean(), inplace = True)\n",
    "y.fillna(y.mean(), inplace = True)\n",
    "    \n",
    "X = X.astype('float64')\n",
    "X = X.round(20)\n",
    "    \n",
    "# divide data into train and test with 20% test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "             X, y, test_size=0.2, shuffle=False)\n",
    "    \n",
    "# feature scaling\n",
    "sc_X = MinMaxScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)\n",
    "    \n",
    "import keras\n",
    "from keras.models import Sequential # to initialise the NN\n",
    "from keras.layers import Dense # to create layers\n",
    "from keras.layers import Dropout\n",
    "from keras import initializers\n",
    "from keras import optimizers\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "    \n",
    "# possible debug\n",
    "X_train = np.nan_to_num(X_train)\n",
    "X_test = np.nan_to_num(X_test)\n",
    "    \n",
    "def regressor_tunning(n_hidden = 2, \n",
    "                      n_neurons = 30,  \n",
    "                      kernel_initializer = \"he_normal\",\n",
    "                      bias_initializer = initializers.Ones()):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = n_neurons, input_dim = 15))        \n",
    "    model.add(keras.layers.LeakyReLU(alpha = 0.2))\n",
    "    model.add(Dropout(rate = 0.1))        \n",
    "    for layer in range(n_hidden):\n",
    "        model.add(Dense(n_neurons))\n",
    "        model.add(keras.layers.LeakyReLU(alpha = 0.2))\n",
    "        model.add(Dropout(rate = 0.1))\n",
    "    model.add(Dense(units = 1, activation = 'linear'))\n",
    "    optimizer = optimizers.Adamax(lr = 0.001)\n",
    "    model.compile(loss = 'mse', optimizer = optimizer, metrics = ['mse', 'mae'])\n",
    "    return model\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits = 7)\n",
    "    \n",
    "hist_list = pd.DataFrame()\n",
    "count = 1\n",
    "    \n",
    "regressor = regressor_tunning()\n",
    "    \n",
    "for train_index, test_index in tscv.split(X_train):\n",
    "    X_train_split, X_test_split = X_train[train_index], X_train[test_index]\n",
    "    y_train_split, y_test_split = y_train[train_index], y_train[test_index]\n",
    "    hist = regressor.fit(X_train_split, y_train_split, batch_size = 15, epochs = 80)\n",
    "    hist_list = hist_list.append(hist.history, ignore_index = True)\n",
    "    print(count)\n",
    "    count = count + 1\n",
    "\n",
    "a = []\n",
    "b = []\n",
    "\n",
    "for i in range(len(hist_list.mse)):\n",
    "    a.append(np.mean(hist_list.mse[i]))\n",
    "    b.append(np.mean(hist_list.mae[i]))\n",
    "\n",
    "mse_cv.append(np.mean(a))\n",
    "mae_cv.append(np.mean(b))\n",
    "\n",
    "# predict for X_test  \n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "\n",
    "rmse_error = mse(y_test, y_pred, squared = False)\n",
    "mse_error = mse(y_test, y_pred) # 1479.61335\n",
    "mae_error = mae(y_test, y_pred) # 23.1525\n",
    "\n",
    "rmse_gen.append(rmse_error)\n",
    "mse_gen.append(mse_error)\n",
    "mae_gen.append(mae_error)\n",
    "\n",
    "# =============================================================================\n",
    "# Metrics evaluation on spike regions\n",
    "# =============================================================================\n",
    "\n",
    "y_spike_occ = pd.read_csv('Spike_binary_1std.csv', usecols = [6])\n",
    "\n",
    "# create array same size as y_test\n",
    "y_spike_occ = y_spike_occ.iloc[- len(y_test):]\n",
    "y_spike_occ = pd.Series(y_spike_occ.iloc[:,0]).values\n",
    "\n",
    "\n",
    "# smal adjustment\n",
    "y_test.replace(0, 0.0001,inplace = True)\n",
    "\n",
    "\n",
    "# select y_pred and y_test only for regions with spikes\n",
    "y_test_spike = (y_test.T * y_spike_occ).T\n",
    "y_pred_spike = (y_pred.T * y_spike_occ).T\n",
    "y_test_spike = y_test_spike[y_test_spike != 0]\n",
    "y_pred_spike = y_pred_spike[y_pred_spike != 0]\n",
    "\n",
    "# calculate metric\n",
    "rmse_spike = mse(y_test_spike, y_pred_spike, squared = False)\n",
    "mse_spike = mse(y_test_spike, y_pred_spike)\n",
    "mae_spike = mae(y_test_spike, y_pred_spike)\n",
    "\n",
    "rmse_spi.append(rmse_spike)\n",
    "mse_spi.append(mse_spike)\n",
    "mae_spi.append(mae_spike)\n",
    "\n",
    "# =============================================================================\n",
    "# Metric evaluation on normal regions\n",
    "# =============================================================================\n",
    "\n",
    "# inverse y_spike_occ so the only normal occurences are chosen\n",
    "y_normal_occ = (y_spike_occ - 1) * (-1)\n",
    "\n",
    "# sanity check\n",
    "y_normal_occ.sum() + y_spike_occ.sum() # gives the correct total \n",
    "\n",
    "# select y_pred and y_test only for normal regions\n",
    "y_test_normal = (y_test.T * y_normal_occ).T\n",
    "y_pred_normal = (y_pred.T * y_normal_occ).T\n",
    "y_test_normal = y_test_normal[y_test_normal != 0.00]\n",
    "y_pred_normal = y_pred_normal[y_pred_normal != 0.00]\n",
    "\n",
    "# calculate metric\n",
    "rmse_normal = mse(y_test_normal, y_pred_normal, squared = False)\n",
    "mse_normal = mse(y_test_normal, y_pred_normal)\n",
    "mae_normal = mae(y_test_normal, y_pred_normal)\n",
    "\n",
    "rmse_nor.append(rmse_normal)\n",
    "mse_nor.append(mse_normal)\n",
    "mae_nor.append(mae_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse_cv</th>\n",
       "      <th>mae_cv</th>\n",
       "      <th>rmse_general</th>\n",
       "      <th>mae_general</th>\n",
       "      <th>rmse_spike</th>\n",
       "      <th>mae_spike</th>\n",
       "      <th>rmse_normal</th>\n",
       "      <th>mae_normal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Rolling Nested CV</th>\n",
       "      <td>51.426324</td>\n",
       "      <td>29.554428</td>\n",
       "      <td>45.943478</td>\n",
       "      <td>24.169250</td>\n",
       "      <td>95.228273</td>\n",
       "      <td>60.172302</td>\n",
       "      <td>20.690682</td>\n",
       "      <td>15.461921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3 months train set</th>\n",
       "      <td>55.370103</td>\n",
       "      <td>29.069298</td>\n",
       "      <td>34.383770</td>\n",
       "      <td>27.454969</td>\n",
       "      <td>68.882055</td>\n",
       "      <td>56.183315</td>\n",
       "      <td>25.833156</td>\n",
       "      <td>23.302825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      rmse_cv     mae_cv  rmse_general  mae_general  \\\n",
       "Rolling Nested CV   51.426324  29.554428     45.943478    24.169250   \n",
       "3 months train set  55.370103  29.069298     34.383770    27.454969   \n",
       "\n",
       "                    rmse_spike  mae_spike  rmse_normal  mae_normal  \n",
       "Rolling Nested CV    95.228273  60.172302    20.690682   15.461921  \n",
       "3 months train set   68.882055  56.183315    25.833156   23.302825  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_cv = []\n",
    "for i in mse_cv:\n",
    "    rmse_cv.append(i ** 0.5)\n",
    "    \n",
    "results = pd.DataFrame({'rmse_cv':rmse_cv,\n",
    "              \n",
    "                        'mae_cv': mae_cv,\n",
    "                        \n",
    "                        'rmse_general': rmse_gen, \n",
    "                 \n",
    "                        'mae_general': mae_gen,\n",
    "                        \n",
    "                        'rmse_spike': rmse_spi,\n",
    "                 \n",
    "                        'mae_spike': mae_spi,\n",
    "                        \n",
    "                        'rmse_normal': rmse_nor,\n",
    "                    \n",
    "                        'mae_normal': mae_nor}, index = ['Rolling Nested CV', '3 months train set'])\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_b30a711c_c462_11ea_b995_7cb27da2bf47row0_col0 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_b30a711c_c462_11ea_b995_7cb27da2bf47row0_col3 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_b30a711c_c462_11ea_b995_7cb27da2bf47row0_col6 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_b30a711c_c462_11ea_b995_7cb27da2bf47row0_col7 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_b30a711c_c462_11ea_b995_7cb27da2bf47row1_col1 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_b30a711c_c462_11ea_b995_7cb27da2bf47row1_col2 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_b30a711c_c462_11ea_b995_7cb27da2bf47row1_col4 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_b30a711c_c462_11ea_b995_7cb27da2bf47row1_col5 {\n",
       "            background-color:  yellow;\n",
       "        }</style><table id=\"T_b30a711c_c462_11ea_b995_7cb27da2bf47\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >rmse_cv</th>        <th class=\"col_heading level0 col1\" >mae_cv</th>        <th class=\"col_heading level0 col2\" >rmse_general</th>        <th class=\"col_heading level0 col3\" >mae_general</th>        <th class=\"col_heading level0 col4\" >rmse_spike</th>        <th class=\"col_heading level0 col5\" >mae_spike</th>        <th class=\"col_heading level0 col6\" >rmse_normal</th>        <th class=\"col_heading level0 col7\" >mae_normal</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_b30a711c_c462_11ea_b995_7cb27da2bf47level0_row0\" class=\"row_heading level0 row0\" >Rolling Nested CV</th>\n",
       "                        <td id=\"T_b30a711c_c462_11ea_b995_7cb27da2bf47row0_col0\" class=\"data row0 col0\" >51.426324</td>\n",
       "                        <td id=\"T_b30a711c_c462_11ea_b995_7cb27da2bf47row0_col1\" class=\"data row0 col1\" >29.554428</td>\n",
       "                        <td id=\"T_b30a711c_c462_11ea_b995_7cb27da2bf47row0_col2\" class=\"data row0 col2\" >45.943478</td>\n",
       "                        <td id=\"T_b30a711c_c462_11ea_b995_7cb27da2bf47row0_col3\" class=\"data row0 col3\" >24.169250</td>\n",
       "                        <td id=\"T_b30a711c_c462_11ea_b995_7cb27da2bf47row0_col4\" class=\"data row0 col4\" >95.228273</td>\n",
       "                        <td id=\"T_b30a711c_c462_11ea_b995_7cb27da2bf47row0_col5\" class=\"data row0 col5\" >60.172302</td>\n",
       "                        <td id=\"T_b30a711c_c462_11ea_b995_7cb27da2bf47row0_col6\" class=\"data row0 col6\" >20.690682</td>\n",
       "                        <td id=\"T_b30a711c_c462_11ea_b995_7cb27da2bf47row0_col7\" class=\"data row0 col7\" >15.461921</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b30a711c_c462_11ea_b995_7cb27da2bf47level0_row1\" class=\"row_heading level0 row1\" >3 months train set</th>\n",
       "                        <td id=\"T_b30a711c_c462_11ea_b995_7cb27da2bf47row1_col0\" class=\"data row1 col0\" >55.370103</td>\n",
       "                        <td id=\"T_b30a711c_c462_11ea_b995_7cb27da2bf47row1_col1\" class=\"data row1 col1\" >29.069298</td>\n",
       "                        <td id=\"T_b30a711c_c462_11ea_b995_7cb27da2bf47row1_col2\" class=\"data row1 col2\" >34.383770</td>\n",
       "                        <td id=\"T_b30a711c_c462_11ea_b995_7cb27da2bf47row1_col3\" class=\"data row1 col3\" >27.454969</td>\n",
       "                        <td id=\"T_b30a711c_c462_11ea_b995_7cb27da2bf47row1_col4\" class=\"data row1 col4\" >68.882055</td>\n",
       "                        <td id=\"T_b30a711c_c462_11ea_b995_7cb27da2bf47row1_col5\" class=\"data row1 col5\" >56.183315</td>\n",
       "                        <td id=\"T_b30a711c_c462_11ea_b995_7cb27da2bf47row1_col6\" class=\"data row1 col6\" >25.833156</td>\n",
       "                        <td id=\"T_b30a711c_c462_11ea_b995_7cb27da2bf47row1_col7\" class=\"data row1 col7\" >23.302825</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1ae5f636f08>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def highlight_min(s):\n",
    "    '''\n",
    "    highlight the maximum in a Series yellow.\n",
    "    '''\n",
    "    is_max = s == s.min()\n",
    "    return ['background-color: yellow' if v else '' for v in is_max]\n",
    "\n",
    "results.style.apply(highlight_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
